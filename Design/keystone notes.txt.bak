list of honorable planets
- JMS 001 <-- Star System in honor of JMS of b5
	- perhaps have two stars A & B and then a planet 1 - 9 with planet JMS B-5 the most prominent.
http://www.makosoft.com/stuff/capitalisms_war_on_democracy.html

LIST OF GAME ENGINES
C4 engine
Shiva
Leadwerks
http://www.panda3d.org/manual/index.php/Features
http://indiegametools.com/ranking/
http://slimdx.org/features.php
http://www.opentk.com/


- http://www.meshweaver.com/tutorials/Thrusters.htm

- hardpoint concept from Kinetic Void
	- http://www.youtube.com/watch?v=bBN5OPJw6T4&context=C4045425ADvjVQa1PpcFN6LEqOKGauu9xI_hxaymOxY30EPhfONg4=
	- what i could do is define the hardpoints from the interior of the ship as helper cubes that dont render during game only ship design.  These are placed on the interior and will then be visible on the exterior to where you can place things.  This ensures that the engines and guns and such are properly placed on the outside.
	And they can also be exported as .obj scene so that you can build your exterior model around it properly.
	The hardpoints will be flexible enough in that they can be lengthened but not shortened so that they can protrude outward enough depending on the exterior hull shape you model.

- sprite batch http://msdn.microsoft.com/en-us/library/bb203866.aspx
- http://www.berecursive.com/2008/c/sprite-sheets-in-xna-the-basics
http://www.hard-light.net/wiki/index.php/Multimedia_Files  - freespace 2 file formats info
	- http://www.hard-light.net/wiki/index.php/ANI_Formal_Definition
	
- freespace 2 model format
	- http://www.hard-light.net/wiki/index.php/POF_-_Formal_specification
		- includes info on glow points, thruster points, etc
		
- billboard rotation seems to need to be at entity level, not mesh
- billboard vibration animation and fading/pulsing 
	- where does this get implemented?  It's similar to an effect and so i suspect
	should be something like a TextureCycle, but in this case it's more of a GeometryMod
	for vibrating, but TextureFade effect for textures

- how to load a billboard as a geometry type and to configure it's dimensions and rotations?
	- Mesh\Billboards\Rectangle.kgbentity ?
					 \Square.kgbentity

- when loading a shader with plugin, seems it never gets applied by the DefaultAppearance
	- possibly it's not fully compiled by then.
	
- Smooth Mouse look with spherical lerp - "Switching to a simple linear interpolation (LERP) of position and spherical linear interpolation (SLERP) for orientation bahaves well at lower frame-rates, and also gives the impression of momentum and inertia. I no longer track manipulation speed, nor continue inertia when the interpolation is complete."
 
- Fixed - ( Threading Issue. ) Lidgren.NetQueue.cs is somehow enqueing null items... i think it's an error in the enqueue code
   that is resulting in empty items.  Cuz i dont think anything null is being enqueued at all.
   
- Fixed - XMLDB.SceneWriter was being created on every call to Write.  It is now a class variable of XMLDB.cs

- Fixed. I think when assigning orbit script to a test playervehicle that has an interior, moving that ship is causing all interior entities (every single floor tile!) to update... that is wrong!  Moving of the playervehicle should not notify child if the child is a CelledRegion.

- Fixed - Viewpoint parenting to a ship fixed.  Was not using globalPosition). 

	
- add an "Instance" flag where an entity can maintain it's reference to a file in the asset database.
	- changes to an instance affect all instances, changes to an entity that is de-instanced, will only affect the one.
	
- todo: I THINK in our loop, we must .Update script running enties BEFORE we process network
  because when processing network we then apply all changes that are in the queue.
  
- the orbit script is not moving the ship at a constant velocity.  Not taking into account framerate?  Move Around Point needs to take into acount framerate when determing the per frame velocity.  So needs to take into account elapsed


FOCUS ON EXTERIOR  - Solar System, Lights, Shaders, Skybox/Starfields, gas clouds
- light parameters for planet shader.
	- the orbit behavior script will set these parameters for now.
	- comment out the semantics in the planet shader that sets light color and direction
	- assign this value in script instead.
	
FIXED - Preliminary light management that determines which lights affect which entities.



light.Flags = dirtyOnMovie
	- for stars, set this to false and only
	- but some of these flags may be relevant in forward renderer but not deferred
	
entity.Flags = requeryLightsOnMove
	- for planets and ships within a sector, we may only requery on region bounds cross (including entering a new region)
	

Light Volume Clipping - Deferred - 
    - http://frictionalgames.blogspot.com/2010/12/tech-feature-light-masking.html
    - it ends up being very similar to stencils for doors
	- http://hacksoflife.blogspot.com/2011/12/stencil-optimization-for-deferred.html
	
LightManagement
		- we can do quick tests for interior vs exterior lights and entities
		- somehow especially if we have a ton of visble point lights, we dont want to go through
		every item to discover which lights touch it
	- for exterior lighting of missiles, vehicles, asteroids(?), ships, worlds this could be good enough though?
	- note remarks on Ogre for shadowmap and LightList queries
	    - http://www.ogre3d.org/docs/api/html/classOgre_1_1MovableObject_1_1Listener.html
	
- It is possible to do shadowmap using multiple light sources
  - http://www.riemers.net/eng/Tutorials/DirectX/Csharp/Series3/Multiple_lights.php
  
 - StarFields / Skyboxes - Attach to the context's current Viewpoint always!  
	- how do i enforce this?
	- for a planetary skybox, you'd want the y axis component fixed but x & z to move with viewpoint
	- OR, if the starfield is bound to the root region, and upon Update it always adjusts itself to the camera's position
	as well as recomputing the position of the pointsprites representing stars about the viewpoint... 
		- we can add a special kind of mousepick to detect pointsprite billboards yes?
	
- atmosphere shader
- clouds shader
- rings shader
- star
	- when adding pointlights which will be our Stars to the planet shaders or any external object using forward rendering
		- how do we place those lights into the correct semantics?
		- the up to 4 point lights with ranges == region radius are those lights.  But we can't do that in shader.
			- other point lights with smaller range but still affecting the mesh wont for example affect atmosphere
				- also wont result in ring shadow casting
				
	- star adds a dir light that gets treated as a pointlight by shader
		(eg dir of dir light is always towards current entity (set as shader param) and there's no attenuation)
		- star light occlussion for moons behind worlds 
			- is occlussion done by light manager? where worlds register as occluders?
			
	- see bi-directional lighting on http://http.developer.nvidia.com/GPUGems3/gpugems3_ch19.html
		- this is very simple method. If the lightDir and surface normal means that the item is unlit, we just apply the negative light with no specular, or fancy fx.
		
	- defineable global ambient
	
- placementtool accidentally selects directional light as a target.  Lights should be filteredwhen placing things.

- combining lights is easy
	- http://rastertek.com/dx10tut30.html
	- you just return saturate (color1 + color2 + color3 + color4) * textureColor
	
- get our deferred test shader working again and on our collossal carrier
	- place point lights around it manually and they should automatically be used by the carrier
		- allow option to have random light color when we add a new pointlight
	- we need to be able to edit the color of a light in our plugin
- get our deferred test to support dir lights also using the DirectionalLight.fx and deferred_combineFinal.fx

4,000 miles radius earth

- sole purpose of sceneNodes is hierarchical bounding volumes
	- otherwise entities only have their own bounding volumes, not those of their children
	- models will have to hold their own region space bounding volumes though to have their own
- FIXED. Model has to have matrix and worldmatrix.
	- FIXED. model needs a way to have it's own local position, rotation, and scale so that one entity can have multiple models that are offset from the origin.
		- model's bounding box is more important than the entity's.  
			- how does this affect scenenodes? scenenodes per entity vs per model?
				- i think during cull traversal, we must seperately test culling of models if entity.Selector != null 
			- scene node overall must use all sequence nodes and only first lod of lod nodes
				- perhaps we can have conditional compile flags to determine how our scene node overall box
				is computed.
			- bounding box computation of Entity has to be able to use Switch nodes, currently it only assumes Model or child Entity
	- FIXED. re-test Zones and ships interior and exterior across zones and rotations.
- FIXED. treeview does not delete viewpoints (and likely every other) that crosses zones and must be removed from previous )
ONE)))
- FIXED.  When the KGBClient.config got corrupted, program would exit instead of loading default config from resx.

Animation panel
	- i finally get how blending animations works and why it can work with spherical interpolators.
		- you compute the resulting vector or quat from both animations, then you multiply them by a weight and you interpolate between the two to get a blended result.

Entity - Mount Child Entity <-- allows you to then mount and place a child entity
- do we use Update() in script to update switch flags?  For example in Update() { if (damage <= .1) SetSwitchParam (none) elseif damage <= .4 SetSwitchCustomParam(lightDamage) else if ... >= 1.00 SetSwitchParam(destroyed)}
	- fxproviders have to be per view too 
		
TWO)) Seperate entities and domain object scripts for single sided and double sided entities.  That is the key.  NOT segments.  Seperate scripts.  The EntityPlacement tool should load all necessary entities + scripts for placing walls, doors and floors using default geometry and appearance, then allowing user to paint the geometry/appearance						


Segments
	- so now that we have a ModelSelector with child flags and we have the ability to dynamically have the Wall script set the enabled children flags for it's ModelSelector, all we need is to send an event to any wall entity when it is placed, or when it's adjacent wall has changed (added/removed or different segment enabled) and this will trigger a fairly tidy automatic update. 
		- this can be disabled when not in edit mode.


Indie Gogo is alternative to kickstarter?
Indiegogo.com

http://thedailywtf.com/  
LOVE THE NEW COLOR SCHEME OF THE DAILY WTF.  I WANT TO COPY THAT FOR MY SIGHT RATHER THAN SOME DARK SCIFI SITE

- Doors
	- if doors are made up of two entities.... how are these
	scripted?  Is it proper they be seperate entities and not a single with multiple meshes but still
	just the single entity script?
		- seperate entities makes it easier to render in batches...
		- can we have a seperate overall entity with two sub-entities instead?
			- the script would be ok to assume that those sub-entities existed.
sims3 footprint info
http://www.thesimsresource.com/tutorials/view-post/post/2719/Adding%20tiles%20and%20fixing%20the%20footprint
NOTE: I can build in a tool into my cell component editor to turn on the high res footprint and allow users
to select the appropriate boxes to be saved out as a data file.

<Hypnotron> Mith
<Hypnotron> http://www.thesimsresource.com/tutorials/view-post/post/2719/Adding%20tiles%20and%20fixing%20the%20footprint
<Hypnotron> scroll down to the picture where there's a grid full of green checkboxes
<Hypnotron> it's the last image on the page
<Hypnotron> what i want to know is... if you rotate the "footprint" (defined by the green checkboxes) by 45 degrees
<Mith> hi
<Hypnotron> will those checkboxes still map 1:1 with another
<Mith> i don't understand
<Hypnotron> cuz in sims3 for instance, you dont have to have a sofa, chair, whatever.. be aligned perfectly square to an axis
<Hypnotron> it can be at 45 degree angle
<Mith> ok
<Hypnotron> and the corresponding footprint of that item then has to set flags in the underlying map
<Hypnotron> im trying to figure out how to compute those when its rotated
<Hypnotron> easy to do when it's not rotated
<Hypnotron> or when it's squared along an axis its easy
<Hypnotron> so figuring out the 45degree case
<Mith> you would end up with partial squares being occupied
<Hypnotron> yeah, thats what it looks like in the game when u turn the grid on and see hwo something aligns when rotated
<Hypnotron> maybe it sets a special flag that indicates it's half occupied.. and maybe even indicates which diagonal half
<Mith> is that necessary?
<Mith> the squares look pretty small
<Mith> i doubt it makes a significant difference
<Hypnotron> yeah, i was wondering about that myself
<Hypnotron> because in game the squares are much bigger... 
<Mith> i would just consider a square occupied or not occupied. If a translated square ends up on four other squares, then all four are taken
<Hypnotron> more like the footprint you see at the top only each of those big tiles is divided into quarters
<Hypnotron> forplacing things, only walls have the minimum limit of a full big tile
<Hypnotron> hrm... that would in fact mean the game has a finer grid that it uses for pathing 
<Mith> yes
<Mith> only for close grids
<Mith> so you after some maths for repositioning the cells?
<Hypnotron> well... i can do the transform of the centers of each and then find where they intersect with a 2d grid.. and maybe the centers is good enuf and dont worry about whether a corner overlaps
<Mith> ok
<Hypnotron> that part is not hard... i was originally worried about dealing with the half squares.. and i didnt realizee they use a finer grid underneath
<Hypnotron> but i do have to re-think some things in light of this
<Hypnotron> i dont think this breaks anything though.. it just means my pathing layer maps are different resolution
<Hypnotron> i hope there's not some weird cases where i rotate and some weird hairline fractures are created
<Hypnotron> because of just rounding to nearest center
* Hypnotron likes to worry
<Hypnotron> probably not possible

http://www.cpp-home.com/forum/viewtopic.php?f=4&t=10614

http://stackoverflow.com/questions/3279148/rotate-2d-array-by-45-degrees
public static class ArrayExtensions 
{ 
    public static Point RoundIndexToPoint(int index, int radius) 
    { 
        if (radius == 0) 
            return new Point(0, 0); 
        Point result = new Point(-radius, -radius); 
 
        while (index < 0) index += radius * 8; 
        index = index % (radius * 8); 
 
        int edgeLen = radius * 2; 
 
        if (index < edgeLen) 
        { 
            result.X += index; 
        } 
        else if ((index -= edgeLen) < edgeLen) 
        { 
            result.X = radius; 
            result.Y += index; 
        } 
        else if ((index -= edgeLen) < edgeLen) 
        { 
            result.X = radius - index; 
            result.Y = radius; 
        } 
        else if ((index -= edgeLen) < edgeLen) 
        { 
            result.Y = radius - index; 
        } 
 
        return result; 
    } 
 
    public static T[,] Rotate45<T>(this T[,] array) 
    { 
        int dim = Math.Max(array.GetLength(0), array.GetLength(0)); 
 
        T[,] result = new T[dim, dim]; 
 
        Point center = new Point((result.GetLength(0) - 1) / 2, (result.GetLength(1) - 1) / 2); 
        Point center2 = new Point((array.GetLength(0) - 1) / 2, (array.GetLength(1) - 1) / 2); 
        for (int r = 0; r <= (dim - 1) / 2; r++) 
        { 
            for (int i = 0; i <= r * 8; i++) 
            { 
                Point source = RoundIndexToPoint(i, r); 
                Point target = RoundIndexToPoint(i + r, r); 
 
                if (!(center2.X + source.X < 0 || center2.Y + source.Y < 0 || center2.X + source.X >= array.GetLength(0) || center2.Y + source.Y >= array.GetLength(1))) 
                    result[center.X + target.X, center.Y + target.Y] = array[center2.X + source.X, center2.Y + source.Y]; 
            } 
        } 
        return result; 
    }      
} 




- when adding a Direction Light to each of a edit workspace and a floorplan workspace, the scaledrawer
setlightposition throws access violation

- diagonal walls
- curved walls
- placmenent of components
- a way to edit ceilings
	- segments
	- a way to edit all partitions appearance without modifying their domain object
	- a quick way to view the armor strength of any partition.
		- perhaps some type of view when a cell is selected all of it's partitions are shown with their main armor data
		- maybe having a hud text number appear to show the hitpoints/pass defense of every partition
		when that toggle is enabled.
		
- floorplan floor dropdown should work
- floorplan root should be 2x size of the floorplan 

- thread isnt stopped when closing app


- ability to assign edit a Domain Object script and save it and have it update the display.
- floorplan gets restricted list of entities in asset browser
	- 
- planets procedural shader in our prochelper
	- needed to start on a nav screen view

- Components should have a specific kgbcomponent  extension so they can be filtered.
	- so that our floorplan creator will only show files of that type.
	- also components should set a mFlag that it's a component.  these flags are only useable by
	the scripts and custom front end code so arent' fixed.  can be app specific.
	
- Workspaces
	- Bar
		- DockContainerItem
			
	- definition files will restore bars and dockcontainer items including their names.
	- ive verified that if i delete all of the bars from the formMain.Designer.cs  that they will
	   get generated for us.  However, we then have to allow for our Workspace implementation to then
	   attach any panels and controls.  Panels are good if you want multiple controls assign to a DockContainer.Control = panelThatContainsManyChildren.
	   Otherwise, you don't need the panel.  Panels are not stored in a Definition or Layout file.
	   
	- so the question is, what do we share between views?  like if a Exterior Edit view is a tab away
	from the Floorplan Edit, then we can't load a new definition because we will lose our Bars which means
	we'll lose our viewport.
	- so our workspaces really are a collective for the most part.  But lots of it is hidden.
	-
	-  For example, when going from code edit to debug running your app. the toolbox window will disappear.
	there's no way to access it at runtime.  But also, the immediate mode and watch windows will appear.
	Interestingly, the immediate mode and watch windows will appear within the existing bottom dock.  Is that just a matter of the layout being restored?  Perhaps?
		- so that view also knows then how to hide it's specific windows and how to maintain the rest.
		- does this mean that there is crossover where both workspaces can share certain windows? 
		like the layout restore doesnt really change the locations of any windows that were existing in
		the previous workspace
			- IF ALL WORKSPACES SHARE SAME DEFINITION, THEN PERHPAPS ITS A MATTER OF HIDING/SHOWING
			- various DockContainerItems and Bars but always having them loaded.  So to show the Immediate
			Window and DebugWatch items simply shows them.  The layout then too is restored only once.
			There is no seperate layout for every workspace.  It's just hiding and showing.
	
	- treeview for floorplan and edit is currently being shared and not kept sepearte
	- definitions shareable?
	- toolbar buttons hide/show enable/disable
	- 
	- get checks in to make sure can only edit floor plan when in floorplan view 
		- can only place objects, cannot modify underlying scripts for them or dimensions via widgets)
	- can only edit exterior when in exterior edit view 
		- can also create and modify every aspect of an object including it's domain object script
	

		
- FormMainBase.cs.LoadScene() has QuerySceneUnload commented out
- switching Workspaces should always set the WorkspaceManager.Current property

- loading of a saved scene does not set the proper EditView
	- see how it's done with Load and then copy it

Improving Rendering Performance 
http://forums.create.msdn.com/forums/p/90000/539613.aspx

- component (like Engine) vs particle system vs laser vs explosion vs engine plume system (glow, halo, animated plume)

	- Modifiers
		- for a normal Entity, i can script the "update" method
		- but that is a bit limited... requires that I rewrite entire chunks just for a slightly different
		  update code to run....   what if instead, our update called our ModifiersCollection
		  that was same style as the Mercury ones and could be used on particle systems too...
		  but instead of passing an array of particles, i pass just the single entity...???
		  
	- Behavior vs Update (transformation and appearance) Modifiers 
		- but what about some particles that update all the time (like laser bolt entities) and those that
		only update when visible?  That is to say, some are part of overall simulation, others are just non interactive
		visual decoration.
		- I THINK THE PRIMARY ANSWER HERE is that a laser bolt would have to be a real entity dervied from Entity
		and fully simulated... so that any collision response could be had...  (but dont we pre-compute hits based on
		simulated dice rolls?)
			- but the main point is that they should still be able to use the same minimesh rendering system?
			- so we have an UpdateScript that can contain any code the user wants and exists in DomainObject
			- but also an array of Modifiers that can be assigned as part of the collection of code blocks to
			update the entity.  These modifiers can be 
			

    //    float GravityPull(float fDistSquared)	{ return (GRAVCONST * m_fMass) / fDistSquared; }
    //CVector GravityVector(C3DObject &obj)
    //{
    //    CVector vGravity = obj.VectorTo(*this);
    //    float fDistSquared = vGravity.MagnitudeSquared();
    //    vGravity *= GravityPull(fDistSquared) / sqrtf(fDistSquared);
    //    return vGravity;
    //}

    //void Accelerate(CVector &vAccel, float fSeconds, float fResistance=0)
    //{
    //    m_vVelocity += vAccel * fSeconds;
    //    if(fResistance > DELTA)
    //        m_vVelocity *= 1.0f - fResistance * fSeconds;
    //    m_vPosition += m_vVelocity * fSeconds;
    //}

    //// Kinetic energy (Joules) = 1/2 * mass * velocity^2 (mass in kg, velocity in m/s)
    //// Kinetic energy (kilotons) = (KE in Joules) / (4.185e12 joules/KT)
    ////float GetKEJoules(C3DObject &obj)		{ return 500000.0f * m_fMass * (m_vVelocity-obj.m_vVelocity).MagnitudeSquared(); }
    ////float GetKEKilotons(C3DObject &obj)		{ return 1.19474e-7f * m_fMass * (m_vVelocity-obj.m_vVelocity).MagnitudeSquared(); }


- i think re-parenting needs to propogate downward to the Model because the Model needs to recompute
it's bounding volume if the parent's RegionMatrix changes which it will if re-parented. Especially when you consider
the inherit scale option... and i still need to debug this and figure why the re-parented entity no longer
renders where it should


COMPONENT WORKFLOW 
---------------------
- launch sketchup 8
- export model via File \ ObjExporter 
- if using freeware version of obj exporter, import the .obj into Silo3d and fix face normals
- import into keystone game blocks asset browser (todo: should a .component be an entire self contained .zip?)

Entity.
	DomainObject
	Model / ModelSelector
		
		
	AnimationController
	
TODO: If you export every .obj to origin, then within KGB, configure one model with an offset and child of another
and then transform the parent object, does the child translate/rotate properly with respect to it's parent and offset?
TODO: And how would you deal with a type of animation like a "retract door" where it's only valid at specific LODs...
yet the script makes the call and the state must be updated somwhere.  Is that state a custom parameter in the Entity file?

TODO: Rather than articulating in a robotic way, with joints and such, how about just simple keyframe matrices and interpolation?  


About Starcraft networking model
 http://aff2aw.com/blog/starcaft-networking.html
Starcaft is the most popular RTS of all time. It might not be the best but it is the most popular. Just recently I got into an discussion on how StarCraft implements networking. We where talking about two types of networking which are lock step networking model and server correcting model.
 
In lock step model every thing happens on all the clients at once and only the client commands player commands are exchanged between the players. This requires 100% deterministic simulation so that each client simulates the game exactly the same.
 
In the server correcting model the clients also try to simulate the game world. But they don't have to be exact. Some clients can use GPU for physics while other use CPU. Some clients might not even have access to the whole game state just what server gives them. Server periodically corrects the clients.
 
Starcarft definitely uses lock step model of networking.
 
Starcarft packets are divided into 2 main groups. The Command1 group and the Command2 group. Command1 groups packets handles with joining or leaving the game while Command2 group handles what happens during the game.
 

Command Group 1
 
Each command one packets stars with a Command1 packet header. This includes check-sum to verify the packet is correct. Thats odd considering the network software/hardware already should do that for you even when you are using UDP. Then it also contains flags to verify and resend lost packets. Does not appears that there is a notion of unimportant packets - probably no need to since this is using lock step model. Then it has sent and receive counters - so that packets stay in order. The flags and ordering combined nicely make the packet loss-less TCP type connection work over UDP.
 
The commands in this group includes Join Requests, Ping, Pick Player position, team, and race, Get Game state, Get Map and Map options, and some Leave Messages.
 
The random seed is also generate at game start. Even though random numbers are random they sequence they come in is not. And this sequence is picket at game start and is used for the duration of the game.
 

Command Group 2
 
This command group is more interesting because its where the real time messages happen. They are very similar to the command 1 group. The messages are sent about 4 a second. Avg time between messages is not quite 250ms but is 219ms probably because the speed constant is easy to tweak. The interesting thing is that every time step a command group 2 packet is sent. Each command group 2 packet contains N sub packets or a special NULL packet if there isn't any. This is how starcaft knows when to start a new simulation turn I guess when it has gotten all packets for that time step from all connected clients.
 
The type sub packets are a lot like what 2aw has. There is player selected units packet and a player selected units to add. Kind of odd considering you can select up to 12 units any ways.
 
The is order packet which is used for all the orders. There is lots of different orders in starcaft even if you don't realize it.
 
Then there is a lot of packets which just active deactivate abilities. I find this odd because there is ton of abilities in starcaft and i would have though that having just use ability and stop ability with and ability ID inside the order would have been enough. If they wanted to optimize and move the ability ID into the space of packets why didn't they do that for orders too?
 
There is no order queues in starcaft. Some thing that was one of the 1st features to make it in 2aw because i love it so much.
 
There is also some messages commands - interesting to note that both command1 and command2 has sending message packet, one in the game lobby and one in game. Its interesting that game lobby is handled by the local game server rather then the battle net lobby - which I would have though be more logical.
 
Note there is no unit positions, health, or stats updates ever. Even when they get build or die. Only what player clicks and orders - that is because using lock step networking model all of that can be derived.
 

RTS Networking
 
Talking about RTS networking always deserves a metnio of the "1,500 Archers" paper about networking in Age of Empires. It looks like starcaft does it nearly the same. I wonder what the modern RTS like SupCom, WC3, Wic, and SoSE doe for networking. Do they jump on flexibility of server correcting model or do they still stick with tried and true lock stepping model.
 
See more info here: http://forum.valhallalegends.com/index.php?topic=17702.0


----
Free For All / Last man standing Game Mode (more than just 1v1, you can have 16 players all against each other)
	- a multiplayer game mode where all players enter the procedural universe and the player with highest score who is still alive at the end works.  The reason highest score matters is, if say 2 players tied, each will have to continue to score points or else will fall behind and then that player who's ahead can wait until x max game time is reached.  So last man standing, but perhaps the opposing players can attack you as well so hiding may not help you if you're being hunted.
	
	- but the key here is the procedural nature of the universe... players who die aren't missing any special scripted content.  they can replay the game and see if they can survive longer.
	- two different victory modes, most tonnage destroyed and last man alive

Defend / Seige
	- defend homeworl
	- defend / protect starbase
	- 
----


- Play by Email could use a central email service that we run.  Running an email server would be trivial.  This way, all users would have an account and so the email system wouldnt require any seperate apps or any special email plugins.


"I agree with nstutt.
The heart of Traveller far more? than trade & space battles...it is about adventure (Twilight's Peak), exploring the unknown (Shadows and Annic Nova), finding political & corporate allies, walking through a hidden Ancient complex on an asteroid, being hired by NPCs (76 Patrons), and misjumping & crash landing on a Gamma World-like planet only to find unstable AI computers & eccentric andriods...while playing as a scientist, Marine, noble, or the *ever-favored* IISS scout..." - steamworks1881 on youtube


music and art design inspiration - Tangerine Dream
http://www.youtube.com/watch?v=T_QXc5duq-4
http://www.youtube.com/watch?v=QuMYV6e18VQ
http://www.youtube.com/watch?v=iYUh88gr7DI
Tangerine? Dream "The Big Sleep In Search of Hades

#236547   
Sci-Fi Corridors Construction SET - Indie Commercial licence
39.60 
This pack contains 63 models (including all collision meshes). There are 32 unique models. Some of them are based on down-scaled textures from the sci-fi 4 textures pack. 

	
Penne Pasta - this reminds me of how mcuh more i should be doing with pasta.  Rice is getting boring.  
http://www.youtube.com/watch?v=vJeJELexpDg

Chicken Divan and Tetrazzini
http://www.youtube.com/watch?v=ouiyPm_o0DM

Beef Stroganoff
http://www.youtube.com/watch?v=s2d2r3-evaU

Yakisoba
http://www.youtube.com/watch?v=x_KdI6BJlAE

Beef Stew
http://www.youtube.com/watch?v=_tm129P-DiA

Arroz con Pollo
http://www.youtube.com/watch?v=tCCPmM90s-4

Sandwiches
 
Rice Roni dishes
	- brocolli & cheddar
	- spanish rice
 
Songs 
	- somewhere over the rainbow/wonderful life hawaii sound
	- tony bennet 



buy his book - The Romance of Difficult Times - Ben Okri 
- Ben Okri 
 
12. When we are successful we believe in the rightness of our whims and thoughts.  We believe the most inflated things about ourselves.  We mythologize our abilities.  We think of ourselves secretly as gods.
This can last only so long either in the life of nations or individuals and this is disasterous for true groth.  It prepares a fall sooner or later.

- perhaps this gentlemans's extra verboseness helps to guide us because our intellect has diminished
or perhaps our knowledge too complicated, that we cant grasp terse sayings.

19) It is in difficult times that the great times ahead are dreamt and built brick by brick with maturity and the hope that comes from wise action 

pramiracetam and alpha-GPC -- uses to treat alzheimers, dimentia... gives regular people improved memory

Like every other good thing in this world, leisure and culture have to be paid for. Fortunately, however, it is not the leisured and the cultured who have to pay. 

Read more: http://www.brainyquote.com/quotes/authors/a/aldous_huxley_3.html#ixzz1OUDlkZVb

Feral Dogs 14 pack leaders... a myth i dreampt of last night 6/12/2011 early am dream.


Gary's Mod users would be a good group to advertise to for Canon Saga

Aurora Trek Star Trek
http://www.auroratrek.com/episodes.html

Autumn Leaves Start To Fall - Eva Cassidy
http://www.youtube.com/watch?v=55p8JHjSACw
	- this song is so melancholy and the instrumental melody sounds like a really good song for when the user's ship is destroyed under Canon Saga...
	or when a mission is lost in general.  You get this forlorn sound of inevitability... that our human condition is to fight and die and here, you die in the cold dark vaccuum of space.
	"Cold Dark Vacuum" would be the title of my similar melancholy song that plays when mission has failed.
Sting - Fragile
	- http://www.youtube.com/watch?v=C3eD3HmFLmM

proper government - http://www.youtube.com/user/Bantokfomoki#p/u/9/JF5OWm-wtHI   <-- a really good / simple system 
http://www.youtube.com/user/Bantokfomoki#p/u/8/67wiw7dJTaI   <-- part 2/2

===================================================================END MISCELLANEOUS NON KEYSTONE RELATED
alien breed
http://www.zonejeu.info/2010/01/test-alien-breed-evolution-episode-1.html
	- i like the floorplan graphics but this vid made me think... you know what's missing?  fear?
	your avatar should show/manifest fear visibly in terms of shaking, fumbling while reloading or changing weapons, being shocked when something comes out the side, etc.  This is something not done in games and should be done... your characters are not mindless, let the player feel their fear from their characters actions as well... screams, rocking in the corner... not wanting to leave a hiding place...
	all of these things the player will grow attached to their character because they have to coax them out, slap themselves in the face... psyche themselves up, maybe even take drugs..
	
	- of course this needs to be playtested to be fine tuned so as not to make the player constantly dying because their character freaks out and panics... instead, the gameplay needs to allow for panic and maybe that means fewer enemies... i dont know yet, but really... when was the last time any game had the player's avatar acting afraid?  it's just not done but it is done.  So even a tough guy bad ass marine corp soldier today would feel fear and you would hear it, you would see it even if they acted courageously.  PTSD, tremors, complete shell shock...   no imaginary fantasy war, REAL war... its ok to portray war if you portray it accurately, but if you dont you're just glorifying it. 
	
Canon Saga: Battle School
Canon Saga: Red Flag
Canon Saga: Biocide  - the invasion of a powerful race that is wants to eliminate sentient competition and preserve non sentient diversity for itself

http://www.pornhub.com/view_video.php?viewkey=735021861


star trek away team
http://www.youtube.com/watch?v=myUsRo5bc44
http://www.youtube.com/watch?v=2gTsLa8x_0Y&feature=related   <-- star trek elite force
http://www.youtube.com/watch?v=BVg9FvZ_Yjs&feature=related <-- star trek legacy
floorplan bugs so far

Kerbal Space Program ->  Design idea to make our sim more "fun"
	- when designing ships, have our sims react to bad designs 
	- make combat very emotional with sims being scared, brave, heroic, etc
		- make our users become attached to each member.
			- this means balancing sims... a scared sim should at least be great at fixing things.
				- they should also be ashamed and need encouraging.

// rpgs
		Valkyria Chronicles 
		xenoblade chronicles  <-- amazing vistas, but seems not enough low detail of things to do...
			- http://www.youtube.com/watch?v=UmhJzZ8PoD0
			- but i do like that it has some huge monsters that you simply cannot fight and thus dont try.  you avoid and go about your business.  Why afterall in RPGs do people try to kill EVERYTHING?!
			
Second Life details
--------------------
http://wiki.secondlife.com/wiki/Avatar_Appearance#Level_Of_Detail_.28LOD.29_mesh

Permissions block 
First line: The token permissions followed by the permission block version 0 
Second line: open brace { 
A sequence of permission name/value pairs, each on its own line 
Final line: close brace } 

The permission name/value pairs are: 
base_mask, with 8-digit hexadecimal value 
owner_mask, with 8-digit hexadecimal value 
group_mask, with 8-digit hexadecimal value 
everyone_mask, with 8-digit hexadecimal value 
next_owner_mask, with 8-digit hexadecimal value 
creator_id, with agent UUID in hexadecimal 8-4-4-4-12 format 
owner_id, with agent UUID in hexadecimal 8-4-4-4-12 format 
last_owner_id, with agent UUID in hexadecimal 8-4-4-4-12 format 
group_id, with group UUID in hexadecimal 8-4-4-4-12 format 
group_owned, with 0 (false) or 1 (true) flag 

If a name/value is missing, a default value is assumed. For maximum compatibility, everything should be explicitly specified except group_owned when false.
 
Flags are defined in llinventory/llpermissionsflags.h: 
PERM_TRANSFER = 0x00002000 
PERM_MODIFY = 0x00004000 
PERM_COPY = 0x00008000 
PERM_MOVE = 0x00080000 

Common masks are: 
PERM_NONE 0x00000000 
PERM_ALL 0x7FFFFFFF 

And common values are: 
no modify: PERM_ALL & ~PERM_MODIFY = 0x7fffbfff 
no copy: PERM_ALL & ~PERM_COPY = 0x7fff7fff 
no modify or copy: = 0x7fff3fff 
no transfer: PERM_ALL & ~PERM_TRANSFER = 0x7fffdfff 
no modify, no transfer = 0x7fff9fff 

Engine and Power Plant construction Kit - using Bricks
======================================
http://www.entoforms.com/2011/06/29/ship-ahoy-man-if-only-that-sounded-cool/
http://code.google.com/p/entoforms/
\keystonegameblocks\design\schematics.pdf  <-- note the warp drive!  it can be built up of parts. 
	- batteries too!
	- storage tanks too.  Sphere cylinder meshes can be stacked vertically or horizontally.  

It just occurred to me that with some basic texture lego like primitives... users can build an engine manually that
looks the way they want.  With scripting they can also add some lights and such.  We can also compute which meshes
of the engine are completely occluded by virtue of being inside the plant and thus dont need to be rendered.

In effect, it's a minecraft esque way of designing engines.  The good news here is, there's no longer any need to 
SCALE the underlying meshes for engines or plants or whatever.  Instead we simply brick them up to size and we can apply
different corner bricks, cap bricks, etc to complete the look.  For purposes of mass and output, the only thing will consider is the
overall volume (this way users dont have to actually add meshes to the inner non visible part).   So, to get this to work, I think 

EngineEntity
	GeometrySequenceNode
		- brick0
		- brick1
		- etc


###And what if we actually then allowed for the exterior of the ship to be built that way as well?  Where the user can place their turrets and snap in parts and what not.
Provide a huge list of barrels, engine nozels.  Allow users to make their own.  But the key is, there's no modeling, just snapping of parts together.
- a tank can be built into the armored areas and be inaccessible.  User then drags on the connctivity piping layer, the connections from the water tank to various relays.
	- the tank parts can be like cut into wedges first, then you can construct a tank and add the end pieces and corner pieces.
###For armoring, they can simply add entire cubes of armor to exterior cells and then finally have a wall.  seperating the exterior.  This way even double hulls can be constructed.
		
###For engines that directly use nuclear reactions for thrust, the same applies.  Connect the nozel to stacked cylinder slices and cap both ends and connect with nozel throat
http://www.projectrho.com/rocket/enginelist.php
And wouldnt it be awesome to have various particle fx for the various types of exhaust.

It seems the more i focus on building a ship inside out, the auto generation of the exterior should take place.  


				
==============================
- Ship Design Mode
	- like Sims3, let's just have the viewport and asset browsers completely change to a mode that is specific to
	ship design.  In fact, our asset browser will filter out many of the trees and only show those branches useful for
	ship design or ship component placement.
	- THis is afterall the ultimate way ship design will be.  Users wont be able to edit new components without creating a mod.
	During actual gameplay they will be restricted to the items in the mod.  
	
- LODs and Appearance?
	- lods are currently shared so can't store Appearances...
		- Appearances are not shared... because they store state for texture mods for instance
			- so fundamentally, part of the issue is that appearance stores state... that there is no more "Model"
				- i dont fully remember why i took out Model. I think it was because i determined i needed to store state there
				and so it no longer made sense to make it shareable.
				- but lets not get sidetracked.  Our only concern now is dealing with different appearances for LODs and damage.
				So i think in that context we have a mirrored appearance.  Maybe this also means we need a mirrored HashCode
				So if there is no appearance at an index, then none is used.  
					- also what about nested LOD's?  I think its necessary because we have SwitchGeometry 
			- procedural shader is not shared either and is child of an Appearance
		
- overwrite of existing prefab not working in xmldb
- deferred rendering of stencil punches works?
	- we need a seperate technique for STENCIL
		- seems this must be set in Appearance because it requires a seperate shader IF we do it in shader
			- but it's just a Technique so we maybe dont need a seperate DEFINE.  Just seperate techniques we set.
			- technique Deferred_Stencil_Target, technique Forward_Stencil_Target
			- technique Deferred_Stencil_Source, technique Forward_Stencil_Source
- set up new test meshes for walls and floors that uses normal mapping and verify it works
	Color rgb Specular Intensity A
	Normals rgb Heightmap A
	
	View rgb, Depth A -- 8 bit depth?  ugh.. no way!
	
	-verify specular masks work
	- verify emissive masks work
		- seems emissive intensity u can put into alpha channel like specular
		and for emissive color you use the diffuse textures color which seems right.
		- the downside is if you want to then disable emissive (a light that is broken) and
		then maybe now you dont want the diffuse that color at all.  but in most cases, even
		that should be fine as the "off" state is dull.
	- shader work to verify material works in forward (defines work when material is added to a GroupAppearance
	- Import needs to create our ProceduralShaders
		- note: Should ProceduralShader be merged with GroupAttribute?  If the shader is not null
		it gets applied to that group of the mesh.  If there exists a default shader, that gets used.
			- but how then do you decide what is the default shader to be loaded?  Or why not manually load
			the shader when designing the prefab entity?
			- The default/overall appearance always gets a default shader created on creation.
			when Geometry is IMported.  The sub-groups do not, although one can be added.
			
	- Defines need to save be saved out to xml in our GroupAttribute just like GeometryType
		- adding a Material to an Appearance updates defines
		- adding a NormalMap texture automatically updates defines
		- adding a SpecularMap automatically updates defines
			- there are two types of specular maps
				- there's the intensity map (which still requires either colormap or specular material color)
				- there's the colormap (which replaces specular material color)
					- colormap works with deferred.
					http://forum.unity3d.com/threads/70614-Color-specular-shader
					http://forums.cgsociety.org/archive/index.php/t-608056.html
		- adding an EmissiveMap automatically updates defines
			- http://www.gamedev.net/topic/364875-emissive-mapping/
			- Should emissive be done in a seperate pass since emissive is hardly used and specular is more important.
				- emissive will take up relatively little screenspace.
				- maybe even combine emissive with bloom pass?
				
		- etc.  Just like geometry type its automatic 
		- adding normal map adds the normal map, ditto for parallax checkbox in alpha
			- i think this answers the question for us for when lightingmode gets set
		
		- eventually test removing normal map and such and verify lightingmode changes and such 
		- eventually switching them to instance renderer works to compile new minimesh specific version 
			- verify we can associate original appearance with the minimesh's cloned version so changes in original can change minimesh
				- this may require on AddInstance() that we supply appearances or something... not sure.
					- maybe the minimesh appearances are special types that maintain that reference and look for changes... dunno yet
				- sorting of minimeshes by hashcode to see if we can enablearray and then change appearances inbetween
				- or maybe not necessary, instead we have seperate minimesh instances in our FXInstanceRender for each
				hashcode variation and not just tied to one mesh instance. so keyed by both mesh and hashcode
					- or maybe a hashcode that takes into account the meshes resourcePath as part of hashcode formula computation
				
- configure geometry switch so that a "door" has both frame and punch switch options based on mode.
- add domain object scripts to our new doors and walls and floors using dexsoft-games models
- configure in assetbrowser all new assets from DexSoft
	- create the combined normal map + heightmaps in GIMP
	
- save as, allow double click and click of the selected file to overwrite
	- and clicking should fill in the filename box

	http://wiki.truevision3d.com/hlsl_phong_sample
	http://fabiensanglard.net/bumpMapping/index.php
	http://rbwhitaker.wikidot.com/bump-map-shader-2
	http://www.bencloward.com/resources_shaders.shtml
	http://knol.google.com/k/shader-fx-parallax-mapping
- shaders show up on "Defaults"
	- should single grouped geometry only have a default appearance tree node?
	
- how to know which layer and on which meshes/actors/landscape chunks to settexture(-1)
  after removing a texture?
	- if Appearance nodes were not shareable, then this would be easy.  Instead of just a hashcode
	we could reference the list of deleted texture layers until we were ready to apply the change
		- layers are already not shared right?  texture mod info can be seperate?

			
- FX tab should go back to primitives and with all our primitives now fit into a gallery control.
 - Re test scene save load
 - Re test prefab save/load

 - LightingMode setting?  Where to put?
	- lighting mode and mesh format are essentially the same thing.
	- thus lighting mode should be tied to the specific geometry
	we load and based on the graphics setting the user has enabled.
		- changing lighting mode means changing setting and requires
		unload/reload of geometry.
			- this is especially important because minimeshes cant have
			lighting mode changed without re-creating from their tvmesh 
			which has the lightngmode to use set.
			
- Where is lighting mode assigned
	- remove from Appearance and move to Mesh3d and Actor3d as
	  - checking the box in General tab to have "Bumpmapping format" and "offset"
	    will re-load the mesh.  User will be prompted whether they want to do that.
		- thus, the same mesh resource must be given a new name if they don't want it 
		also affected.
		- warn them of this and suggest copying the resource with a _bump.tvm 
- Where is the minimesh shader applied?
	- when assigning a new mesh to "UseInstancing" the various properties of the mesh
	  including it's geometry.LightingMode should be viewed and the shader chosen on that
		- but what about various combinations of normal maps, specular, emsisive
		etc?
	- somehow this must be configurable in the editor and NOT via 
	  the Minimesh system automatically. Thus, what we need is some way to assign
	  the minimesh shader via the Mesh3d... something like...
	  - in Shader {get;set;} 
		-  if (UseInstancing, 
			we check not which shader is applied, but which shader options
			as far as normal map, emissive, diffuse, heightmap, etc
			just like TV uses a "mode" we have to have a group of "modes"
			the user can set and then the shader is selected dynamically.
			This way there the equivalent minimesh shader is also chosen
			dynamically.
	-  It'd be nice if i could have a single shader and let the path
	between mini and tvmesh or tvactor be automatically chosen.
		- well, there's no way to have a single Shader node that is shareable between
		both unless it contains within itself seperate shaders for both TVActor, TVMinimesh, TVMesh
			- or unless perhaps the defines that switch between mesh,tva, mini are used
			to define the shader path.
			- but im thinking better to have that shader maintain 3 tvshaders instead?
				- what about paging in/out?
			
ProgrammableAppearance
	- no Material 
	- no Texture
		- just a shader with parameters that appear in a grid that can be edited
		- but  what about groups?
			- shader has to be assigned optionally to every group?  well, normally no, just the main
			but then you'd allow tv to update the semantics for the texture slots.  
			In fact there's no way to do that yourself...  i mean i dont think you can render just a group
			
	- You know what, i think i have to go back to my previous implementation where I add textures, materials
	and whether thye are used or not in the shader is dependant on a) if a shader is set b) if the semantics are used.
	- I think we can still enforce that the default or some otehr shader is always used though, but that's
	all.  When iterating thru the shader's parameters we simply SKIP textures and material semantics.  In fact we skip ALL semantics and only use parameters the user's app code will set, not the ones TV sets.
		- the only real problem with this method is the Texture Mod settings.  those must be set in 
		the shader parameters list and not on the texture notecard.  In this respects, the texture notecard
		is obsolete because all it does is show us the texture.  To change it's mod, that must be done
		in the shader parameters.
		
		// not shareable resource
		public class ShaderGenerator : Generic
		{
			// points to a specific generator script and so our resourceDescriptor
			// will be valid with either disk path or zip entry path.
			//
			// the script (which is INI style) in turn points to scripts
			// The key feature of this is, we can instance the ShaderGenerator using a ResourceDescriptor
			// without breaking the shared qualities of having an underlying shader with one file name but
			// which can be used to generate shaders that don't exist on disk
			
			// this accepts parameters (or grabs them from parent and _core.Settings) to instance
			// a Shader object (not a TVShader directly).  Then... that Shader is a child and is shareable
			// 
		}
		
		public class ProceduralTexture : Texture
		{
			
		}
		
		modes:
		-------
		Actor
		Mesh
		Minimesh
		
		Deferred
		Forward
		
		Diffuse Map
		Diffuse Map with Specular Power in Alpha
			- NOTE: in this case the specular power is used in conjunction with a material specular color
			- The alternative is to use a dedicated specular map + alpha for containing specular color per pixel
			  and intensity per pixel
			  When doing lighting, you calculate the diffuse term, and, if the object is "shiny", a specular term as well. The lightspot on a billiard ball is a typical example of specular lighting.
			// http://www.gamedev.net/topic/482021-what-are-specular-maps/
			The whole ball is made of the same material. So the reflection is the same on all places. But what if the object is made of multiple materials that have different light reflection behavuar? Vampyre_Dark gave some examples. That belt for example, leather will reflect differently than the metal knobs/buckle on it.
			- More/less reflection
			- The reflection color (white, blueish, brownish, etc.)
			- Shininess (how is the reflection spread out? A small spot, or all over the surface?)

			You can encode these values per pixel in a texture. The same principle as a normal map. I ussually take the alpha channel in a normalMap as the reflection intensity factor ( finalSpecular *= normalMapPixel.alpha ). But if you want, you can also take a RGB(A) texture. Where RGB is the specular color/intensity, and alpha the shininess factor for example.

			The calculation of the specular light stays the same in the shader. The only difference is that some of the values are variable and come from a texture now:
			 specularMapPixel = tex2D( specularMap, uv ).rgba;
			 specularColor.rgb = specularMapPixel.rgb;
			 shininess = specularMapPixel.a;
			 specular = pow( dot(reflectVector, lightDir) , shininess ) * specularColor.rgb * lightSpecularColor.rgb;

 
		NormalMap
		NormalMap w/Heightmap in Alpha
		
		options screens
		=====================
		http://wiki.secondlife.com/wiki/Deferred_Rendering_Test#Deferred_rendering_prefs_UI
		http://www.runescape.com/kbase/guid/controls_display_options
		=====================

			
Appearance  <-- never shared
	Shader  <- Never shared
		FX  <-- shared
	Material
	Layers <-- never shared
		Texture <- Shared
	GroupAttributes
		Layers
		Shader <- Never shared
			FX <-- shared
			Material <- Shared
	
	- with the above, it almost seems like i could get away with
	not making Layers nodes, or Shaders (just the FX) and instead
	making Appearance\AppearanceGroup's contain in arrays
	the data for Layers and Shaders
	
ShadowMap, Deferred... what we need to do is make these into types of
Renderers
IRenderer and allow us to plugin the renderer we want to use and to have that renderer
be able to reload resources using current renderer settings.
So before with ShadowMap we had it as an FX, but that's really not correct.
ShadowMap is a renderer.  So will be Deferred.
	- Perhaps our ScaleDrawer is re-implemented? 
		ScaleDeferredDrawer (bool shadowmapsEnabled)

- GeometryEdit
	- MeshFormat
	- FaceCulling
	- ComputeNormals
	- GetVertexCount
	- GetTriangleCount
	- Get
	- LOD Sub Edit
		- Create New LOD
		- Distance Setting
		- Mask
	- Geometry Switch Edit
		- CSG Stencil Mask
		

Pillars - As a "Frame" component that can be placed by walls or in middle of rooms to add strength and break up blockiness of rooms
	- http://www.youtube.com/watch?v=bVN4Sfr58c4&feature=related
	- Interstellar Marines too -> http://www.youtube.com/user/ZeroPointSoftware
	
SequenceSwitch (aka MultiSwitch)
{
	bool[] Enabled;  // can render a sequence of meshes, and will render whichever are enabled.
	                 // this can be a better way to accomplish some of our hierarchical meshes where we
					 // for scripting, it'd be much easier to treat the meshes as just visual relevant only
					// meshes and not full blown entities
}

 
DoubleWallEntity  <-- as you can see it requires multiple appearances and Meshes to allow for different geometry AND appearance and rotations
	Entity[0] - Left Wall
		Appearance
		Mesh3d
	Entity[1] - Right Wall
		Appearance
		Mesh3d 
	DomainObject  <-- so the question is, can this single DomainObject tie these two entities together?
				  <-- so in our script do we first grab each child and then 
						<-- do we also then disable picking of the individual children during runtime?  We want all damage to be as one entity?
		Script
		- BUG - The targets of CSGStencil sources needs to be recursive.
		
DoubleWallEntity <-- users can select single walls or double walls.  Single walls are symmetrical, double walls can have different meshes for each side.
    SwitchGeometry
		Mesh3d[0] - front facing door
		Mesh3d[1] - rear facing door
		
		- how do i get the rear door to render in flipped position?
			- I dont want a seperate mesh that is opposite facing...  
			- i want to be able to swap out one or the other with a different mesh so that opposites sides can have different look
			- I do just want to keep it as one entity
			- What if the switch contained a matrix modifier?  This modifier would take the passed in Entity matrix and apply a reversal transform matrix to it
			
			How do either WallEntity or DoorEntity with SwitchGeometry look with damage LODs and/or regular LODs?
			
DoorEntity
	SwitchGeometry
		Mesh3d[0] - frame mesh
		Mesh3d[1] - CSG Stencil
		
- FIXED. when changing name/tag values for menu item, i broke normal tree node delete.  
  Worker_NodeRemove() will eror cuz the child will be null
  
- check bounding volume of punch mesh in debugger, then create new punch in silo with half width
- find a hatch mesh
	- find ladder
		- ladder prefab should contain both the ladder bottom, ladder top and hole frame + punch as a single prefab.
			- the query script should make sure both the floor and ceiling and floor of 2nd deck are clear and can accept.  So all of thse
			checks by the different subentities must return true to create the final result check bool value.
- FIXED.  find exterior window mesh
- add ceiling/floorplan for 2nd deck
- fix the rotation of the doors so that same side is always on interior of an outside wall
	- actually this is problematic... whether a door is on left or right is relative... somewhat... assuming doors are symmetrical.
	If doors are not symetrical (eg outside has different appearance, then as user, we should be able to manually rotate the door about Y axis by 180)

- FIXED. save/restore the childModes in xml and then resave the door prefab
- FIXED.  mHost.ChangeNodeProperty -> this must 

Mesh3d is no place for the SwitchMode.CSGStencil flag because a simple sphere or cube might be reused as non CSGStencil also.
Clearly the place is in the Switch node and in the Entity.
	- the only question is, does the SwitchNode's flags override the parent Entity's?
	I think it must.  I think the parent entity's only counts if there is a single direct Mesh3d included.
	I think whenever there are Switch node children, the Entity's flag must reflect the cumulative flags of the children.
	In this way, we gray out changing of those flags in plugin, and disallow command to change it as well if SwitchNode exists.
	


- When removing Mesh and adding it, if appearance still exists, the Appearance change flags must be reset for that Entity.
  - easiest way is to just have mesh/lod/etc addchild result in the changeflag for appearancechanged.
 - ClearPanels is occurring on the recursion for Geometry so the LODSwitch gets erased and then the Mesh3d added
 
- Floorplan generation from exterior mesh
	- we need some rules on the interior space as to how it must be designed.
	you CAN have seperate "groups" to the exterior ship mesh, but perhaps we enforce certain group names 
	then only those groups with the proper naming convention will be parsed for specific reqts such as
	- they must be completely closed volumes (no doors, hatches, etc... those are added by the user)
	- minimum volume for 1 tile for each of these closed volumes.
	- anyway above is just preliminary thoughts for how to make computing the floorplans simpler.
	
- UseInstancing ive currently disabled to force path to test CSGSource/Target because currently my minimesh system
  does not sort the mini's between source and targets and so we cant control our CSG Stencil buffer rendering.
http://www.opengl.org/resources/code/samples/advanced/advanced97/notes/node11.html
http://www.opengl.org/resources/code/samples/advanced/advanced96/node33.html  
- In stencil rendering in ScaleDrawer.cs, we have not yet added the Punch geometry to our DoorFrame entity and are currently just rendering
  the frame geometry.  This is very next step to do... and also to keep in mind that our Selector switch needs to work with Minimeshes too.
  Such that the same DoorFrame can be rendered with instancing and without.
	- The Minimesh.cs itself should remain only rendering the one type of Geometry, however, new Minimeshes should be created for 
	the punch, and such when the ModeledEntity.UseInstancing is called 
	- One way since we'll eventually have ModeledEntity.CSGPunch as a type of Geometry, is to have a seperate .RenderPunch() method
	that is easily callable since the item will be in _defaultCSGSource items.
	- Regarding scaling the punch, our proposed method as adding directly as a child to ModeledEntity means that to render the .Punch
	we have to 
- FXInstanceRender - this perhaps should not be treated as an FXProvider.  It is really just an alt renderer and so should be
  callable from within the Render() method where we render near/far/2d while  iterating through RegionCullingInfos.
   - this way we can control the order in which these minimeshes are rendered and vary it for different minimeshes as required
    - One way could be to have info.InstancedRenderedItems instead which is actually our FXInstanceRenderer.
						
 - Entity Stacks - How do we implement this?  
	- Walls & Doors & Windows
	- Other entities
	- Actors - actors move, what if they straddle two cells?  Why not just do dynamic lookup for actors like with tvterrain height(x,z)

- Walls if you look at the models used by FPSCreator, are built as halves, but with (i think) the frame as a single?
  Is there any good point to this?  On the one hand it would put each half wall entity into it's own cell, but this needlessly 
  doubles our culling and rendering.  Forget it. Logically walls are shared and thats how ive implemented them.
  
- Dictionary<uint> Walls; // this is a celled region for building iso maps, we KNOW walls, doors, floors, ceilings and such are mandatory.
                          // we shouldnt get hung up on making everything generic.  Some things are explicit.
						  // so having an explicit Wall type to which get added to our dictionary key'ed by edge ID is fine.

- Dictionary<uint> Stacks // key'd by cellID
	private struct Stack
	{
		public Entity[] Entities;  // ordered by layer - floor first, ceiling last
	}

	- video using GIMP to add grayscale heightmap into alpha channel of normalmap (keywords height map normal map alpha channel)
	http://www.youtube.com/watch?v=pGPJhT5lUpE

- dds format, would be nice to implement pure c# dds loader like the Targa one from codeproject	
http://www.xbdev.net/image_formats/dds/index.php

- OnAddedToScene - change Register to OnAddedToScene
- OnRemovedFromScene - change UnRegister to OnRemovedFromScene
- FIXED. Place Door On Wall
	- is the door AddChild() to wall or to CelledRegion?
		- map layer modification is easier if it's placed to the CelledRegion...
		This is also consistant with the notion of STACKS in a cell rather than other parented children.
		I think the other parented child should be reserved for things that are IN the interior but
		NOT affecting cell layer... that is.. they are weapons being carried, things like that.
		
	- FIXED. first save the door as a prefab
	- FIXED. door domain script must be added
	- FIXED. door script must denote via it's query that it's a type of segment (like wall edge)
	- 
	- Because minimeshes render in FX last, we have a problem where our rendering order for getting CSG Meshes to render
	things behind it properly is prevented.  If we cant fix it by fixing the render order, then minimeshes must have more
	flexible rendering order.  Or at the very least, our CSG meshes must be amongst last to be rendered.
	- currently CelledRegion.Collide does not allow us to pick other entities within the CelledRegion.
	  It stops at edges and vertices or whatever.  
		- Where do we change pickparameters to allow picking of an entity within?
		   - PlacementTool.HandleEvent() - at the start of this function, we perform the Pick and so here clearly is where we 
		 get a chance to alter the pick parameters.  This is good.  This is the proper place to do it and fits in with our current design.
	
DoorEntity  <-- before this entity can be active, child entities must be loaded so a flag (Ready==false) to wait before any scripts can run? 
            // but how on earth do we know if the DoorEntity has a child animated door at all?          
	(flags - CSGStencil, CSGTarget, DrawCSGStencil, 
	Geometry Mesh;
	ICollider Collider;  // could be a BoundingBox too contained in a BoxCollider
	                     // is collider scaled with entity along like mesh?
	Geometry CSGStencil; // is stencil scaled with entity like mesh? 
	AnimatedDoorEntity child; // obviously has to be seperate entity since it can be translated & rotated differently during animation
	     
	
- FIXED. Floor tiling
		- still havent implemented proper drag and drop painting of floors.
		- fix bug with cellindex error on ReadXML for Floor tile prefab.

- FIXED. Entities can have "ignorescenesave" flag set. -Yardstick is being saved and then errors trying to load it.  
- FIXED. boundary cases for placing walls end up appearing on opposite side
- FIXED. seemless switching between wall and floor placement
- FIXED - xml writer error  (Saving the PlayerVehicle first prevents these errors.)
	- Not sure what is going on here.  Turning off exceptions in debug options shows that everything appears to work even with all these exceptions
	- Almost positive now this is because we do not first save the PlayerVehicle during our Auto create PlayerVehicle button click so attempts to then
	save changes to the celledRegion fail.  

				
- FIXED.  fix wall height (art dimensions)	
- FIXED - doors/windows (proof of concept stencil buffer based fake csg implemented as hard coded test. works great!)
	- is it possible during our traversal to first find all segments that have a CSG mesh attached where the CSG mesh is active and needs to be applied.
	And then to render those FIRST?  How on earth do i blend this with the far rendering stuff...  maybe can work since the idea is to not draw anything where the stencil is
	so it wouldnt even overwrite what was drawn first.  Then, once all of these are drawn first, we can render the rest of the scene normally and make sure to skip the CSG ones.
	WOuld this work?  If so, we could do it all in our normal ScaleDrawer.cs and not as an FX
		- Add Flag  CSG <-- that flag can be set by the script controlling the entire "Door" entity which perhaps consists of
		the frame, the door, the punch (the punch is mesh but either through script or a special type of switch node, is used to alter rendering... hrm...
		cuz the key is the wall needs to be rendered with and 
		http://wiki.truevision3d.com/tutorialsarticlesandexamples/programming_hlsl_shaders5
		- BUG - seems back face culling of the door is messed up from reverse angle... are these doors not two sides?
		
- save/load verification
	- CellIndex is restored, but no event for DomainObject deserialization occurs when loading cold celledRegion from disk and deserializing it's interior componens.
	  Those components are AddChild() prior to their own DomainObjects and DomainObjectScripts have deserialized.  The CelledRegion must be notified when
	  one of it's children has it's DomainObjectScript deserialized and ready for initialization calls and queries.
	
- Advanced Floor Tiling
	- eventually when the floorplan is limited to the exterior siloghette, some nooks and crannies may need to be filtered
	as "outside the siloughette" when dragging and dropping tiles to paint big areas.  Cuz right now its just a rectangular fill
	and doesnt check if some of those tiles are outside the silogette.
		- a mask of the un-useable tiles could easily cull those tiles from the returned list.
- Advanced CSG
	- doors or windows that take up two or more wall tiles instead of 1 (eg cargo bay doors, fighter bay doors)
	
- painting over walls and floors with different type should replace them
	- this applies for different wall meshes
	- But for just changing the texture
		- i think an "appearance" prefab where it changes the pointer to a paintbrush or something and that will replace the Appearance 
		under the entity.
		
- real time visual feedback for walls and floors
	- real time add/remove/invalid location marker as mouse moves

- Maksing out Mouse Picks through CSG
	- build list of picked entities sorted by closeness
	- if the closest thing is a CSG Punch mesh (invisible but pickable = true) then select the next closest thing besides the CSGTarget of the punch
	(aka it's parent)
	
- FIXED. PropogateChangeFlags recursion error
	-  this might have something to do with how i change parents at the  beginning of our EntityPlacer's message proc which means i could be changing the parent
	midway, when instead i should only ever switch parents after an operation is completed?
	- in fact, im probably not even allowing some operations to complete properly since i switch parents and dont even clean up and then just try to switch parents again or something.
	
- FIXED. multifloor editing verification
- place an interior turret and allow that turret to target and fire at npc

- Collaborative Diffusion
	- place a Chair component
	- place two boxes and have one entity pathfind to the other
		- allow scripts to have one box provide "power" to another.
	- place a temp actor box mesh
		- have actor navigate collaborative diffusion grid through a maze style room design towards a goal.
			- moving the goal gets the actor navigating to it the new location.
				
- FIXED. minimesh floors seem to draw without proper zbuffer and far away meshes render right throw them when they shouldnt.
- drag and drop mateials and textures onto group of plugin
- deleted textures do not seem to clear that material on the mesh
	- this is part of why hashcode is needed and why i think i cannt delete it.  It's an optimization to test whether
	the existing shared mesh's hashcode is same as required by current entity's appearance.
- behavior plugin tab needs tweaking after modifying how we update the panels
- aniamtion plugin tab needs tweaking after modifying how we update the panels

- in multi-zones regions, either stars/worlds not rendering in proper place or our MoveTo is broken for those cases or both

- still not drawing debug lines in correct place for interiors 
- saving/loading of our interiors
	- works but still not restoring component within it's proper cell properly
	
- why when mouse over exterior box of PlayerVehicle, the EntityPlacer tool is trying to add to the Exterior.
It should only add either to CelledRegion or normal Region and not to any other entity type that the mouse if over.  
	- Having a red outline of the Entity and Mesh Group / Bone that is being attached to for visual feedback would be great.
		`- assuming we did allow this and didnt force user to instead drag and drop entity under new parent.
	
- add option to make exterior only alpha transparent not entirely invisible	
-verify that now interior picking still works when Vehicle is moved
- improve cell picking acuracy... especially when close to the cell being picked it gets worse
- picking of exterior when pickable and visible seems broken

- FIXED. if exterior mesh of proper size we have to make it invisible and have no pick response of it's own yet
still allow for interior to be visible and picked.
	- FIXED. this could be a matter of the Picker.
	- FIXED. Interior should be visible too if exterior is invisible
	
- FIXED (Added check to skip Interior if Entity is Container) EntityNode box of Vehicle uses generic Entity bounding box which takes the interior region's box and of course interiors' coordiante systems are always fixed location.



- Matrix vs RegionMatrix
	- Matrix is currently updating every frame and not just when dirty.
	
- FIXED. Large Culling - I now have a 5km long ship which is probab max size for any station as well
  - how far away does it have to be with more regular culling before it's invisible?
     - that is a good gauage for how to determine moons and things for far rendering distance.
	    - or do i compute seperate max visibilities based on radius and screen scale factor from
		context.GetScaleFactor
		
- FIXED.  override GetRegionalTransform in Zones.  
	- first version will be re-implementation and just verify it all still works
	- second version will accept a translation offset that is the camera relative offset
	so that hopefully we can keep our best possible precision as well as remove a step
	in our cull code that attempts to adjust for the camera offset after the fact
	
- FIXED. MoveTo command

- SwitchViewpoints


- create a better interior ship test
	- add portals
	- add a simple box exterior hull with a decent texture
	- add some turrets

	
- add option during load call, when lodaing .obj or .tva or .x or .tvm, if an existing material with a different name has otherwise the exact same params, share it.
	- UPDATE: Fixed for .OBJ.  I'm fairly sure that every unique material has to have a unique non null name. So shouldn't be any other cases.
	- Not yet fixed for tvm/.x/tva because those cases i think you can have null names and yet same material values.
		- a fix could be to have option if name is null, to check material values and see if it matches existing, if not, create generic unique material name and continue.  but never allow name to be null


- trying to place an asteroid field in a Zone that is too small will attempt for the Simulation to "Move" the asteroids but it may find that some of the Zone's arent paged in and if there's a ton of asteroids this could mean a ton of exceptions to try and ignore.
	- I should check the size of the destination taking into account any offset of the field's translation and determine if the field will fit and if not throw exception before placement is allowed in the first place.
	
- saving not occurring so when zone pages out it wont page back in

- do not let plugin's edit Region's translation.  Regions are fixed.

- test applying of same rotation script to every single asteroid
              //  entityInstance.RotationMatrix = rotationMatrix;
                //this vibrates the blade
                //_mesh.ScaleMesh 0.8 + Rnd() * 0.4, 1, 1
				- add this laser vibration script to a laser when fired

- test applying of a "damage" quake script to our Viewpoint when our ship takes damage


- FIXED. Interior really isnt necessary I don't think.  (But "CelledRegions" are)
	- since all Regions are fixed, Interior is no different.  The only
	defining aspect of an interior Region is that the Region is placed
	in a container and is designated as being "Interior".  That is it.
	So I should simply use an EntityFlag for that that gets set as the child
	is added to a Container.

- FIXED. fix culling of far objects at least to the point where nothing is rendered twice

- FIXED. Container derived entities when computing their bounding volume should only take into account
the Exterior children, not inner Regions because our inner regions dont really exist within the
the ship spatially, only logically via hierarchical relationship.  This is why our bounding volumes
are screwed up for them.

- FIXED. DrawLines and all DebugDraw should accept a ViewMatrix  <-- actually now we control the render order based on which view/projection is set on the camera.

- FIXED. all prefabs currently have no SceneType.Prefab stored so need to be deleted and re-added
- FIXED. editing the translation via edit card does not update bounding box. Scale and Rotation do however.


if (hashcode == GetHashCode()) return _hashCode;
	- in DefaultAppearance if texture mod for a texture changes, the appearance hashcode does not change.
	
core engine scripting demo
http://www.youtube.com/watch?v=_nNBwUUUx2w&feature=related

JUST INCH BY INCH WORK THRU THIS LIST
- fix minimesh deckplan wont remove from repository when app closes
- fix clear our archive and add our ships and things all over again.
	- be nice to get some ship interior stuff (more walls, fixtures, crates) from FPSCreator
- fix picking planetoids works but floor and decks no.  I think maybe its 2d walls and floors are failing boundingbox collision test. Need 3d walls and floors.
	- or our 3d code needs to handle 2d collisions

- fix our widget is not translating properly when trying to select other entities to get the widget to move
	- it appears as a bounding issue?
- fix when enable\disable in plugin an entity, it wont re-enable and i think it's because .update events dont take place and the entity
  never gets added back to mActiveEntitiesd
- Add a delete right mouse click for entities already!
	- delete key response as well
	
- fix our actor duplicates issue where our bounding boxes were totally off 
	and placing multiple instances of actor entity was just acting fubar
- load gun
- place gun on bone
- load particle system
- place particle system on gun
	- plugin to scale the particle system and position it

	
	http://www.codeproject.com/KB/cpp/CollapsiblePanelVB.aspx  
	http://www.codeproject.com/KB/miscctrl/CollapsibleGroupBox.aspx
	http://www.codeproject.com/KB/miscctrl/collapsiblepanelbar.aspx
	
	http://stackoverflow.com/questions/3840898/treeview-to-control-panels <-- what we'll use only we'll maybe just use a listview?
	- although, what if we got rid of the tabs altogehter and used a treeview with a single depth level of children so
		now we have Physics, Appearance, Animations,   directly 
			and then as children for appearance for examples we have our Groups?
				- but ugh i dont want a horrible long list of groups really do i?  maybe its not so bad as long as its in that plugin and not
				- i mean maybe better to see those groups than to then have a drop down selector like in modelview 
				
- What if Geometry is moved under Appearance?    
	- the problem of Geometry and Appearance under Model was that changing the Geometry or Appearance
	  would require to clone a new model and move everything.  In our case here changing geometry would of course
	  do that too but i think you're less inclined.  And besides, often times we DO want to change all of them...
	  - Yeah, Appearance is still shareable because in a sense, it's like a single umbrella node.  
			- the only caveat is that when a user modifies it by default all entities using that appearnace have their instances modified.
			Thus user must need to explicitly clone the Appearance and we need a way to make the number of shared very visible
			and what it actually means obvious.  
				- But as far as the process of cloning appearance, we litterally just create a new Appearance object, copy it's values by member
				and then AddChild() all it's children and then the user can remove the ones he doesnt want.  But materials and Textures can never 
				be cloned as such.  Those must exist as unique per their texture path name or shader path name.  So cloning there means making a
				copy in the archive that then has a unique path.
			
	  - do mesh / actor groups have names?  we should definetly load names and if possible allow them to be renamed.
		- if they can be re-saved we need to re-save them to our archive... perhaps a two part step of save to disk then replace in archive
	  
	(Animation node?  Get rid of BonedEntity and just add an Animation node instead? hrm...)
		 

- fix celestial multiple region rendering
- fix picking across regions
- add a portal to our floor/walls prelim deck
	- fix rendering and culling and picking across interior and exterior and multiple regions

- fix our widget's translation/rotation/scaling
	- this requires our picking be able to give this widget priority
	
- make it easier to initially position something with our alt material version of the loadedEntity in ThrowObject rendering with some alpha
// - we do need to load our actor and place a child weapon entity on her
            // and test the scenarios
            //      - add weapon to actor
            //          - im thinking our same code, only pressing ALT will highlight
            //            individual bones you can attach the item to... 
            //             - also perhaps in the plugin you can drag and drop it onto a bone?
            //              or perhaps better, in the TreeView we list the bones and allow user
            //              to drag an entity and reposition it's Parent to a bone.
            //          - also about time i added ability to clone / paste actors in the scene
            //            by selecting them and then ctrl+c and spawning a new instance in place
            //            with ability to drag it elsewhere with widget that appears instantly.
            //              - maybe make my throwtool a bit smarter by if the picker is over
            //                the widget, then just use that widget tool then when done
            //                revert back to the place tool to allow more pasting.
            //          - actor plugin needs a ton of work for animation configuring 
            //      - interior to exterior
            //      - interior to other interior (boarding)
            // - once we have this bounds stuff done, load up a tiny multi zoned
            //   world and get the exterior zones all rendering with our changing
            //   camera matrices that orient to each region ...why does the code work
            //   for Exterior to Interior but not exterior to exterior neighbor regions?
            //  - verify interior to exterior works too (the opposite of the working ext to int)

			
			
			
			// import dialog for meshes
        // what about textures, shaders, materials
        //  - there are three types of texturs perhaps.  
        //      - textures in use
        //          - the best part about having access here is since they are shared, you can modify one and have it affect all.
        //            that's actually a great thing including changing the texture itself and having that affect globally.  Also from that
        //            gallery, you can get a list of meshes \ entities that are using that texture.  
        //      - textures in our mod resources path
        //      - textures that are not in use or in mod resources and exist on hd/network and are being imported in
        //        by virtue of being applied to a mesh\group attribute and need to also be moved to resources path.
        //        If a texture does not exist in the "in use" gallery or the resource browser, we can browse anywhere.  
        //          So perhaps resource browser + browse anywhere are same regular "Open" dialog.

        // save as a prefab (using current mod, select a category)
        //  - shouldnt actually allow any directory browsing
        //  - allow gen and select rotation/distance of a preview icon
        // save 
        //      - particle systems can be saved as prefab
        //      - actors can be saved as prefab
        //      - 


================================================
	
- if something has an "interior" you can switch from interior to exterior (region centric) and perhaps as well everything else stops getting rendered and it's more of a Sims (or first person shooter creator) open view of your interior.  

================================================
------------
* recursive delete from archive
- deleting folders while then trying to read the contents of the directory results in io exception when the save after delete (or add) is blocked.
	- need to progress dialog when these ops are occurring
	- need to better queue (funnel) all zip io thru the threadpool group name so they get serialized but problem there is
		that's not what happens on just reading to populate gallery.  So that's why i need the progress dialog.
		- verify then im already using a single group name based on zip file name to serialize write operations to zip especially
- when loading models or textures or whenever we have progress up, we should lower priority of the main rendering.
	- or potentially fixed framerate / vsync
- need some type of .bak of our archive somehow?  and that .bak needs to have it's integrity verified.
	- users should be prompted to save a .backup periodically.

- like the Ribbon Style drop down, i can make mod selection and creation like that and then the main tabs
  simply switch between the different .zip's that make up that mod.  or something along these lines	

   depth buffer inbetween planets and grids... am i clearing it a second time when i shouldnt be?
	- bounding boxes for Vehicles with portals are messed up cuz they arent drawn using the proper view matirx
- our Grid is fixed at 0 height.   It looks weird for the grid to suddenly disappear when you move up or down.
	- our grid and presumably other 2d immediate gets drawn after depth buffer is cleared for world rendering... bad...
	- maybe in addition to grid spacing getting larger based on speed, it should get larger based on distance... greater of the two.
    - maybe in game grid should be parallel to an orbit around the planet's equator and aligned with it's axial tilt.
		- in other words, the grid needs to be relative to whatever coordinate system the user's ship is set to.
			- navigation by user (npc helmsman) will require changing coordinate systems for easier navigation		
	- when traveling faster, our grid's spacing should expand proportionally!

* our code editor tab, procedurla texture all have proper tabs... but our Main rendering viewport does not.  It should be enabled by default now as 3D-View.
- our asset gallery's minimum size should update with resizing of the viewport so that whens witching dirs in an archive, the width of the gallery and popup is always the same.
	* remove all of those other gui buttons on the primitives ribbon tab

- clicking on an entity event script that doesnt exist.. shoudl prompt user and NOT silently fail
	- results in the fake script event adding a scriptnode to the entity which then isnt' removed from repository.

* right mouse click menu for script in asset browser should bring up "edit" menu item popup as well as delete
		* editing script then hitting "save" should update archive
		* when do we recompile assembly?  On save and only if that script is also a resource in repository which means it's assign to an entity
			- do we update the resource if the compile errors?
		- show compile error output somewhere!  maybe in a popup text file or textbox they can copy to clipboard
		- ditto for shaders as well
		
http://www.gamedev.net/topic/47159-lets-talk-about-some-real-3d-isometrics-no-more-bs/page__st__20__p__2280344__hl__camera+distance+full+view+model__fromsearch__1#entry2280344


- add ability to dynamically alter the grid spacing 
- grid on the other isometric views needs to be perpendicular to the isometric view
	- grid should always cover up the entire screen in ortho view if the grid is enabled

segment / wall / floor creation
	- our policy is that all walls are ALWAYS created automatically for the user... adjoining of walls is done automatically.
	- but also consider that portals dont apply until you're in first person... from top down deckplan view they just dont apply and the idea is that when top down the LOD drops significantly.
	
snapping
		- snapping with 1:1 meter square cells is simply truncating all projected mosue world coords.
		- draw a red grid cell on that spot last to verify it works
		
ThrowObjectTool placing
	- should be some "mode" property for our place tool that takes into account
		- deckplan orthographic mode
			- the current deck's floor height
			- the curent grid spacing for snapping
			- the specific ortho mode viewport
	- for perspective, our throw tool should already be placing objects out at some distance in front of camera
	such that the placed entity fits...
	
- placing a new ModeledEntity in the orthographic view should put that entity on whatever the perpendicular plane value is.
	- this perpendicular plane value may be different for different levels on the ship's deckplan
	
	
- picking is off in some of the isometric views (not sure if it's light entity interfering, lack of pick sorting, sort order)
- perspective mode is nice too as far as the side views go... looks really cool in sidescrollers so too in this
	
- in isometric view, allow planar translation of entities on the deck along with snapping.  Snapping should be done where... in the tool itself?  Thinking yes for now.


- omg, isometric side three views of deckplans will be awesome too.... oldboy-ish, krellan commander-ish.  just ahvng the option is wicked cool.
===========
- 2d cells like in fps creator
- a cell is a datastructure for collaborative diffusion
- a cell is a spatial node and contains a dynamic list of the objects in it.
	- so for instance, a cell can know if it has a ladder, door, lift to allow passage to another cell even a cell on another deck
	- our decks will all be kept in memory as a single "array of grids" 

	- cell
		byte wallFlags;  flags for floor, celing, front,back,left,right walls
		
		// hrm, the good thing about this structure is maybe if its simplified like X-Com it makes it much easier to do server side
		// calculations without graphics.
		
		// ugh... do we want to have all these flags and crap in a cell?  seems unweildly... i mean is there a way to
		// instead modify the properties of a cell as items are placed in it
		
		// how does one do a "duct" without 3d?  Well im thinking by simply linking ducts as sub-graphs
		// it certainly would be most elegant to have a 3d grid of cells like voxels but the memory use would suck.
		// With 10 centimeter division, there could be quite good detail  but in 100meter x 100 meter x 100 meter Borg cube ship
		// it would consume 1,000,000,000 cells each taking up probably minimum of 
		
		//  In a sense now already by 'SceneNodes" 
		
		- every item still has a SceneNode... a tile though has to be some underlying datastructure
		- adjacent tiles define a room unless they are partitioned
		  - i think some earlier logic has each title having 4 full quad portals and then expanding that "room" and pushing the portal
		  to the outermost adjacents... ugh this is so annoying.
	

* maintain our own cache of scripts so we can do proper tracking of the most up to date version of a particular script.  It's the only way.
* script assginment updates on "save" of script
	* existing script and scriptnode replaced (previous scriptnode released from repository)

- get events from an entity so we list the proper ones
	- regions shouldn't have many events (least not the same ones)
	
- update plugin with the currently selected entity	
- plugin get's focus when loading
	- replace the blank plugin place holder with an actual plugin that we can swap out

	
	- our Primitives gallery then should be able to drag and drop things contextually
	- changing a mesh by dragging onto the Model's mesh image box
	- changing textures by dragging onto a groupattribute boxes
	- changing scripts by dragging onto a .css box
	- changing .fx by dragging onto an appearance shader box



            // todo: we still have to forward a command to the server indicating we've altered a node

            // todo: For a GroupAttribute, i could hide any material, texture nodes and just allow
            //         drag and drop or editing of those nodes via their proxy icons in the plugin?

            // - get enumerated events from entity 
                        //  you have to copy the event name for your method name though and get the method signature right (so thats annoying but passable for now)
            // - individually suspend/resume scripts 
            //- save/load the script settings in my overall scene database
            // - how would we script an engine and reactor pair?
            //      - how is the engine assigned to be powered by a reactor?
            //          I mean i know how i did in GVD, but how now?  especially considering how we design ships in editor?
            //          (via deckplans i mean ala FPS Creator)
            //        The annoying thing is managing the links.  So what if instead of generators/reactors managing a list of
            //        devices connected to it, instead the devices that need power reference their source(s) and each tick they will
            //        actualDraw = source.Consume(reqt).  And that removes that much power from the powersupply and if the 
            //        amount drawn is less that total needed, a device can attempt to draw from backup sources to get the remaining it
            //        needs, or operate at reduced functionality or shut down altogether.


EntityEditCtl.cs  why isnt AddPrefab sending any coordinates to the EditorHost.SEndMessage?  
A target box should appear where we can specify and point where the object should be placed... and those coordinates sent... or something along those lines.



- ImportGeometry isnt differentiated for Vehicles and other types.
	- i think part of the thinking was that a vehicle may not necessarily be a full ship, but some small fighter, or a missile or a drone, etc.
	  and in that case, what we want is to be able to attach the chase cam to any such thing.  
- when too close to planet rings, i get what appears to be flicker of ring in/out near plane.  Maybe i have to widen the alpha transparency part
  - 
 - ref counting not occuring
	- ScaleTool's manipulator needs to have the control access it's children through children[] and not through a seperate 
	 scaleTabs[] array that is disconnected from the scene completely.  Thus getting a cached copy of Control will never fill the
	 scaleTabs array that is in the ScalingManipulator class.
	- in general, i'm not properly ref/dereffing nodes.  ONce we figure out the plan implmeenting this should be trivial.
	  


- Mouse DX input exceptions i think as a result of picking issues.  Really slows down framerate.  I think this will get fixed when i add picking
  code back in.

			
- stars and planets are not in seperate xml entity files, should be will make it easier to load a Star field
- ModeledEntity does not have Read/Write xml or Set/GetProperties!!
	- so the _useFixedScreenSpaceSize and _fixedScreenSpaceSize dont get saved/loaded

- textures aren't loaded into the scene tree when generating our test 2x2x2 galaxy
	- they are loaded it seems when loading the saved generated galaxy
		- ah, the resource is not being loaded because the check to load occurs on IncrementRef 
		but then why do Meshes load (apparently? !!! maybe not all of these!) 
		so lets see if it works when loading saved galaxy
- MoveToTarget command doesnt work as desired... still...	
- VIewports dont report acurate Width when dockpanels are on left or right, only works with top and bottom docked panes.  WTF?  Used to work before i refactored the RenderingContext stuff.
- Definetly copy Sunburn video how textures are dragged and dropped easily to change them.  And how you can select a group or part of a mesh and easily as well see what meshes are used visually, not just by some stupid name.
		http://www.youtube.com/watch?v=yv03HefZ39U&feature=related

- copying of resources to our mod name path during galaxy generation
	- need to supply a mod name when galaxy generating first
- copying of resources to our mod name when importing new resources	

	
- undo for all new commands
- editor commands (first get the near/far culling working and interior/near/far culling)
- physics nodes update to work as Nodes.

- i like the text and line markers that point out planets, jumpgates, etc in this xna game
  http://www.youtube.com/watch?v=zrfq5hjKoWk
	- additionally, we can add some other data to that marker bar to indicate moons, space stations, and perhaps who owns the planet and such 
	in other words similar to a 4x game.
	- as well as different markers for different types of entities.  Remember that our viewport is basically a 3d sensor and spatial system.
	http://www.youtube.com/watch?v=6kpMHOfHJMs  <-- perhaps our zoom tactical scaling map can do similar... also similar to our solar system / nav map
	view where we scale things up but scale distances down.

http://www.turbosquid.com/3d-models/3d-ships-stateroom-model/404996  <-- awesome low poly look & feel to my ships.  Thats a good artistic yet simulation style look and feel for my art direciton 

right mouse click "Add Deck"

when in a "deck" placing things is constrained by the bounds of that deck...?
but the "deck" entity is a good start to start coding this deck design i think... 
maybe look up some The Sims youtube house design vids

but also first person shooter creator i think the key "design" of a deck is simply the level at which it's built.  
though still not sure how ramps are done...   perhaps a ramp is similar to a ladder... they have to connect different decks?


- progression towards networked gameplay
	- lobby does not track all users does it?
		- it certainly does not inform all users of all other users logged in
		- it does not inform user of all games, only filtered games based on some settings.
		- for a specific table the user wants info on or wishes to join, the players at that table are reported.
			- for persistent dog fighting games, the user can go to the "table" view page but from there can only join... 
			- persistant game types as opposed to non persistant do not get removed from list of games in the lobby.
		
	- get authentication and lobby bullet proof and 24/7 on their own.
	- get gameserver bulletproof and working with a persistent single solar system universe, and basic newtonian movement sans gravity
		- spawn one enemy for every user in a region.
			- that enemy targets the one user only
			- when that enemy dies, spawn a new one.
						- no orbit mechanics, just simple direct thrust movement.
	- client lobby and ability to join/quit/anytime
		- server browsing  (useful for editing and gameplay.. hrm..)
		- disconnect resume


- players must be able to host games
	- to host a game, player logs in and selects "Create Game"
		- but these are for specific types of matches... what they can't host are the 24/7 servers.  Why not?
		- they wait for players to join the table and then they start
		- once the game starts the table is removed from list of visible games
		
- we'll run our own as well for the 24/7 furball servers and for some persistent campaigns
	- persistent campaigns require a cheap subscription (something like $25.00 a year)
	- the 24/7 style servers authenticate with authentication server, starts it's games, then logs into the lobby
	to describe the types of games it is running so they can be broadcast to users of the lobby.
- perhaps some match style games can be hosted via a "Create Game" command to a game server via an admin tab in our client
  #ifdef ADMIN_CLIENT
  so that all commands from all clients are validated and authorized by our own server to prevent cheating for important games. 
  Heck, it's also a good option for people running their own servers and to be able to remotely have it create games of it's own so
  to do that the gameserver when connected to lobby must be able to host table matches as well as persistent.
  
  HOW DOES THIS AFFECT DATABASE FOR GAMESERVER?  <-- well for alpha we'll just ignore and only worry about reaching alpha for a single furball persistant server   - also mainly our games database is for statistics tracking.  Part of the fun of playing a properly registered client that must authenticate is that stats get updated to the server.
  So that's our basic reqts.
	- users must be able to create tables and register persistant games
	- gameservers must be able to create tables and register persistant games
	- an admin client should be able to have the lobby tell a game server to create some type of table games or 
	  persistant games.
		- we're going to try to use TCP/IP and keep our bandwidth way down like a poker game

	- only one game can be hosted per authenticated connection.
	- only one instance of an authenticated connection allowed connected to the lobby
	
	
	- actual game interface (no editing ribbon tabs)
	- seperate ship build interface?  - must use the available mods, no importing, browsing is now by component types, not primitives and scripts 

and such.  Can't edit scripts)
	
				

	- loading the same xmldb   (level)
	
	
	- tournaments list (just like in Ultimate Bet or something)
	- a list of custom created user games (traditional master server browsing)
	- a list of custom persistent furball (deathmatch or CTF style) servers
	- an automatic ladder system using predefined game rules and maps 
		-  co-op ladders for 2- 16 player per side teams
 	- DONT - send entire user lists
		- only users added to buddy lists (sortable by clan mates, friends, relatives)
			- perhaps an ability to have your friends list "public" and "personal" sections and users can then spider
			your lists to see the social network between them.
	- DONT - send entire games lists
		- it's always a filtered list of some kind
kgbgame_persistent001


I think several things
	- if we have the ability to load in the gallery existing models and entities that are paged out, then yes we can enforce that changes to the 

live model will obviously (during edit mode) get saved in the xmldb 

	- so when loading from a resource.zip (not the xmldb) then those should be treated as new and seperate instances.
Debugging, Bugs, Testing Checklist
------------------------------------
- verify appearance sub-nodes call changeflags when modifying properties.
- verify all node types set their various change flags for various things.  comprehensive list needed
===================================================================================	
**************************************CONTROLLERS + VIEWPORTS **************************************

Now there is a nice thing about having just a single input monitor for mouse and keyboard so that we dont have to worry about consuming events and preventing them from going on to other controllers which dont have focus or something.  A single InputController is best clearly.  And as long as all the viewports are using that same type of controller anyway, its easy to manage... however
	- once we have disparate controllers for each viewport (ship internal, nav, and an external), things become a headache.  
	- clearly in the above case, with the current EditController's ability to first determine the selected viewport and ONLY allowing that viewport to utilize the received inputs...  maybe instead we can just call Viewport.HandleMouseMove()  viewport.HandleMouseLook, MousePan whatever
		ok, so lets say that then each Viewport now has it's own seperate Controller and we're back to a specific controller per viewport
		BUT, each controller is now indpendant of any camera.  
		- the question then is, how do we then decide if an input should go to a target entity such as the Ship, PlayerCharacter, etc?
		We would absolutely have to "consume" events and if not consumed, then pass them on... or just always pass them on...

		NOTE: Recall that the main reason (im pretty sure) that we wanted a single Controller was so that we could pick the active viewport and only send the commands to that one.  That's something we can still do now with a main Controller, and then having the Camera have it's own CameraController which can be called directly for the selected Camera. 
		NOTE2: The other reason certainly involved Begin\End drag operations in the Editor which we wanted to easily be able to Capture for a single viewport.
			- how do we update that controller if it's like a chase camera?
				- we can still always do for each viewport.Camera.Update()
		


**************************************BUGS**************************************

			- scaling of hte region seems to work, in general, but the scalefactor we compute is too tiny and is resulting in some
			significant scaling of the position.  
				- this exposes the other problem, since the positions are scaled, i obviously cant expect to place an object millions of meters 
				away and still see it!  So the test is, can we place things extremely far away and then zoom in and see them in some proper 
				scale.  So lets try with earth solar system values.  I think several things should become evident
					- our scaling factor is producing an incorrect value... way to tiny
					
			
- network time sych add to lidgren
http://www.mine-control.com/zack/timesync/timesync.html

- create a proper generic semantic shader class where i can set parameters. basically just wrap TV's own parameters
  and then.. hrm, we'd need a controller attached to our Entities for updating the shader's...  some type of controller that Mesh3d.Render could grab
  from EntityBase.Controller.
**************************************PRIMARY**************************************
- Dynamic camera for large render objects needs proper implementation now that proof of concept is in
	- i think we still need the scaling because we'll still end up seeing tiny planets cuz they're farther away than even our big frustum
	and they will just pop out of existance behind even that big farplane eventually.
	- occlusion of things by planets
	- sorting of rendered things
- far/near culling merge
- occlusion culling
- portals thru portals of joined Interior regions?  Is that even allowed that we can have a vehicle with multiple interiors?
- occlusion of ships - http://www.gamedev.net/community/forums/topic.asp?topic_id=116859
- occlusion of star light
	- if our ship decks are in a single octree partitioned region then we gather the lights as we
	traverse the octree and we do that by testing against their light volumes which we'll generate and update as the light moves.
		- 
- picking issues further away from origin as well?
	- picking issues resolved - all along its a precision related issue.
		- external rendering i should set the near to maybe 100
		- then i could keep several cameras ready for swapping while doing a near pick, and a  far pick
		- 
		- moving the app window requires "ResizeViewport" occur or else picking screen to viewport coords will be fubar
		- planet picking is almsot definetly a result of the Model's scale not factored into the mesh during AdvancedCollide... hrm, though it is
	   	during rendering since i call model.Matrix * Regionmatrix
			- and i think the idea is if i go back to limiting one model per entity, but child entities are allowed, then the entity should include
			  the model's matrix in it's own Matrix calculation.
	- i could implement my own overriden sphere AdvancedCollide pick for planets.  That is the easiest solution, although
		then getting the face index of the actual sphere mesh gets trickier...
	- the box for the planet works on picking, but the mesh.AdvancedCollide does not
- picking planets

- get camera to align with the "front" and "up" of the ship model. (the ship should be required to face in a particular direction)
- modifiy the viewport zoom and speed gui to look more like the pdf viewer zoom with the +/- and a box where you can directly edit AND
	- where you can specify km or even au to speed thigns up... 

	
	- use Enums for Commadns in KeyPlugins
	
		
		
	- option to REVERSE winding order of an .obj i load.... perhaps a flag in the Geometry plugin.  I think Sims2 .obj exports reversed.
		- or at the very least in the editor, mesheditctl reverse winding order and then re-export, overwrite, reload w/replace option to replace existing Repository item of same name (internally this unloads the TVResource and re-loads new file)
		- way to export the .mtl file for .obj by right mouse clicking on the Appearance itself.  
	- Export TVM for Mesh3d edit
			
	- TreeView state of collapsed/uncollapsed needs to be preserved
	- copy / paste
	- Rename 
	- Title bar of plugin container should be set by plugin
	- Translate / Rotate / Scale Entities 
	

	- Light Plugin Edit
	- Actor Plugin Edit
	- Particle System plugin
	- Terrain Plugin Edit
	- LOD Mesh Plugin
	
	- Where do Add Prefabs get positioned by default?  
	- Portrait of prefabs generated automatically
	
----------------------

- when compiling a finished level, there will be option to archive resources, but otherwise we should be able to handle either or.
   During editing clearly it's easiest to not have to deal with archiving.
  
  - instead of the File \ Import StaticEntity, BonedEntity etc, we should simply be able to select a Primitive from a gallery!  Save real estate!
    add a new empty Vehicle, Building, Prop, FixedPositionProp (doesn't react to physics or anything), BonedEntity, etc using a default template (crash dummy for actor, box for static, tank with square wheels for vehicle) and then allow the user to modify it by adding underlying resources,behaviors, etc.
	- in other words, let some of the Prefab options be hardcoded buttons to load these placeholder entities.
		- to add an atmosphere entity layer and or cloud entity layer, simply right click and Add Child Primitive and select a sphere of the proper type.  Alternatively you may select an LOD level.
		So bottom line is this, no more "Importing" of entities cuz that never made sense anyway.  Instead now, we import resources only.  
		When importing resources, we must always copy to our resources as well as allow user to select what kind of resource it is so it knows where to copy the files.


mods can be in archive or out archive
	- thus a scene can be opened via the .scene file or the .sceneInfo xml file
	- this is important for server side since server may need mulitple scene readers/writers with ability to access
	  parts of the scene database independantly. THis cant be easily inside the zip, so better for server to have uncompressed version.

	- load a scene, new archive.  A folder is created data\mod name
		- under this folder is either mod name.scene  or mod name.sceneInfo if extracted
			- when importing a prefab, the nodes will obviously get saved if in edit mode to the scene but
			  the extracted resources must also get added to the \mod name\texures  or whatever folders and have the resource paths
			  adjusted... and deal with overwriting dupes and such...
				- i mean, i dont think we want to just copy the prefab over to a prefabs directory under data\mod name\prefabs ?
				although... for user ships...  data\mod name\shipX\prefabs  ?  no cuz ship design is integral to our game even without mods
				

				Prefab Final Design
				------------------------
				1.  Imports of meshes or textures merely adds them to our modname\resources\
				2.  Save As Prefab saves to modname\prefabs
					- These prefabs are all cloned.  Even materials, appearances, are cloned.  Essentially only meshes, actors and textures are NOT cloned.
					- Once a prefab is made on disk, it's immutable.  It can be loaded, deleted, or saved-over, but it can't be loaded just for editing.
					Without cloning it while loading it into yourscene, modifying it, and saving over the existing.
				3.  There is no special "library" 
				3.5  Creating a new Entity starts with getting a GUID from the server for that entity?  Why is that necessary?
					If editing, guids are unique so why not let client create it?
				4.  If you want to share a part of your scene that exists also as a prefab, you do not load the prefab again, 
					intead you must copy the instance from the \level or scene .zip (or unzipped) data.  
				5.  There is no real new code i have to write to support any of this, only two tweaks
					a) The import must import to our modname\resources.  
					b) You will then be given an option to load it into the scene and create a prefab of it.
						- the prefab will then go into modname\prefabs.
							- but the loaded prefab will now be independant of that prefab and changes to it will not update the prefab on disk.
					c) Our various ICOmmands must now handle import to resources, ask you what sub-path you want to save it to
						e.g. walls, floors, furnitute, props, etc and then it'll store them to that dir under \meshes or \textures respectively.
				6.  During games using any set of mods, users are limited to using resources that already exist and can create new prefabs based on primitives or existing resources only.  Otherwise, new mods need to add support for any new resources and then all users must use this mod to play in the same game.
				
			
Common\Lights  (candle, torch, street lamp, directional sun, flashlight, headlight, search light, 
	- to the lights tab, add enable specular, and global ambient settings?
      \Materials  <-- both can be set up as gallery items to pick from.
	  
About this gallery vs Aion's style with a custom control...
	- the key is the difference between active and library browsing... i might still want a custom control for browing
		and again, i need to see if i can enable drag and drop OR WAIT!!!!
		I can simply close the gallery and then center the mouse on the screen and change the icon, set a global "Painting" state
		and wait for the user to click again to apply the texture.  THey can keep painting until right mouse click or ESC.
	-   We can fascilate this by adding a "Paint" tool and placing the selection tool to the Paint tool automatically.
	     
Textures from the Gallery can be dragged and dropped directly onto the Entity tree's Appearance or Group Appearance
where the user will then be prompted to add as Diffuse\NormalMap\Specular\EmissiveMap
- by holding down CTRL, when dragging the texture over a valid entity, you can select sub-groups instead
- if drag and drop is not possible, actually it must be... should be, otherwise canceling the operation is too annoying.

To add a texture that doesnt exist, you must select the entity and click the "Import Texture".
	- importing a texture that is in-use, you'll be prompted if you want to clone it instead and if yes, must select a new name for it to be copied to.

- Ability to merge materials when loading so re-used ones dont all have different id's, merge textures same deal.  Our importer should do a better job of re-using existing. Maybe it is, verify guids are the same.
	
1) Option to dynamically change the near/far planes of our frustum until we properly add the auto switching for world/star rendering.

3.5)  then finally position the rotation and distance for snapshot icon.
4) verify relative paths work in the prefabs when loading and saving , 
	verify relative paths work during paging.

- Right mouse click menu ability to add Material to Appearance
	- Add Shader to Appearance and GroupAttribute
Rename GroupAttribute to GroupAppearance and have it inherit Appearance
	- add texture layer's UV tiling to Appearance.
		- layers are always 4 slots but some are null and they associate directly with tv's layerIDs.  
		  So if a Diffuse child exists, it's uv is taken from UV[0] 
	- GroupAppearance can only be added to an Appearance
	
6) editor widget tools should flawlessly 
	- when Importing and Moving, display a grid overlay (perhaps 8 corners of bounding box like UFO Terrestials) that shows
	where the imported entity will be placed.  However we may not have accurate bounding volume information if the item isnt already in cache
	so just an square will suffice.  This visual feedback is important.
	- the scale tool is fubar, wont disappear when switching tools, wrong location
	
	- better grid altogether, especially suited for deckplan creation
	- grid snapping.
5) Update all ICommands for undo/redo and transmission over loopback and verify each works
7) finish all major plugins.
8) particle systems, actors
9) turrets rotations and beam billboards
Wiring up power conduits, fire control links, etc, treat it like in SimCity where you paint the squares connecting from one thing to another
rather than the Tronics style in N8bit.
10) AI

12) Then with the extra space, add a Help \ Documentation, Help \ About,  Help \ Tutorials <-- with sub-list link to videos 
no, prefabs do not have their own dir structure, just normal xml database
- so, when creating a prefab, you have to select mesh and textures and such from the library and if the path is not, you will be prompted to import it.  That's actually what will happen when you import... plus on import, you should be prompted to save as Prefab as well.  

		
			
I'VE ACTUALLY MADE SOME REALLY GOOD PROGRESS
	- network, plugin structure including how business objects are basically extnesions of my ICommand objects.
	- loopback server ensures im writing in network terms right now.
	- overhauled zip archive handling
	- fixed up widgets
	- scripting, script editor
	- zip management (delete, add)
	
Edit Commands
	Drop At Intersection - drops a mesh _IF_ after a raytest, there is geometry below it.  Otherwise the item will stay where it is. (so it doesnt drop off the map)
	Randomize - takes a collection of minimeshes for instance and randomizes their scale and rotation.
	Show Debug Labels - generates a lable billboard for objects and perhaps even group attribute id's.
	
Vehicle Build COmmands

Game Commands

In the context of validating messages that arrive on the server.. we should work backwards from there.  

OK WAIT, WE HAVE JUST TWO GOOD OPTIONS
- plugins make the commands directly
- they call the api that makes the commands. 

If commands have to be made at all, im inclined to simply have the user make them.
In a sense we go back to the win32 api messaging model where we communicate with the server / scene
through messages that the scene can validate and dispatch. 
Normally on the subject of validation, each node would do this itself, and i think perhaps to an extent
via delegates for the MessageProc\CommandProc we can do that. 
But our model is somewhat different since we support undo/redo.  Communicating directly through commands still allows
our plugins to have a tight API, and they can potentially (maybe) still be allowed direct access to getters since
they have a local copy of the remoteable node, jsut no setters.  Must go through ICommand.

So the only other issue is how does the user get the entire state to fill their plugin interface with?
	- well, plugins work on the Current node... at least the Node edit ones do... some of the other plugins we'll add later
	for editing the deckplans, wiring up vehicles and such might be a little different, but what doesnt change is our asychronous model
	that goes through the loopback and using of ICommand to make changes.  To retreive data, EditorHost will have an interface for
	getting the various data the user wants via functional style commands.  The end.  If we want to change it later... fine, but
	now... no. 
	
	
Server Receives a message
	- reads message id
	- a command class of proper type is instantiated and reads it's values with the net buffer
		- this could be a nodeSTateChange command as well which may within it carry a simple ascii command or an array of them
	- the command now needs to be validated that it's allowed, before it's applied or performed and before
	  any notifications can be forwarded to other players about the event/state change.  
		- How is the validation layer done?

		
		if (command.IsValid(validator))
		{
			// here command can use double dispatch where ICommand
			// can do "return validator.IsValid(me))"  
			// and the Validator will know how to validate every type 
			// against a set of "Rules" objects
			
		}
		else
		{
			// now we can grab the rules that failed which are stored in the validator instance
			Rules[] failedRules = validator.Failed(); // 
			// the good thing about FailedRules is that they can be returned potentially as
			// "Sorry captain, the generators are out!"  
			// and be made apart of the game and thus not errors, just failed rules.  
			// This type of system adds a level of automatic run-time tutorial to the user who may
			// have forgotten to enable his engines before trying to navigate to anew system, etc...
			// or forgotten that his jump drive was disabled, etc.
			// So this means that a method such as weapon.Fire (coordinate)  (with overloads FireAt(EntityBase target)
			// need validation and not just property changes.  How is this accomplished then?
		}
		
		or maybe even
		
		command.BeginExecute (validator, exectutionDelegate, completion);  
			where our executionDelegate could be something like  mLobbyManager.RegisterTable
		    hrm... all this is very annoying to not fully have worked out yet....  
			
// should these commands get the "sender" object appended when received?
AuthenticateCommand.BeginExecute()
	// on completion check any AuthenticationCommand.BrokenRules[]  if null its good

RegisterGameCommand.BeginExecute()

Rules / Business Rules  Business Logic 
WeaponFire.BeginExecute()

Ok, im thinking that the rules based approach is going to work.  Validating an action/method is no different than validating a property
and our rules can be scripted (or maybe hardcoded in the beginning).
But a command to "join" a lobby would first require that the user is registered in the lobby and that only happens if they are authenticated.
But this is the rules based approach to our design... and this basis will hopefully allow us to create our 4x games and a host of others... by
scripting our business rules validation as well as the actions to be called on this entities.
	- so for a property change, normally you'd first 
		- get the entity that is to be modified.	
		- make the call to change the value via Node - public virtual void SetProperties(Settings.PropertySpec[] properties)
		- run the rules
			- return error(s) if fail
			- return null if success
	- so similarly then to perform an action, it's the same process... has to be.  
		- get the type of object we want to perform an action
		- make the call to perform the action with the various args
		- run the rules
			- if successful
				- carry out the action
					- return results/response
			- if fail, return errors
	- NOTE: To perform an action on an entity it's easy to bind these to scripts since our scripts are stored in the entity in a collection that uses the name of that action.  
	- NOTE: But to perform an action on some other domain object, like our LobbyManager, we will just use the hardcoded methods based on the type of the COmmand/Message sent
	
	So going back to our commands (requests) where do our delegates sit? I mean, do we stop using Command.Execute? since they are requests and no
	Command has been authorized yet?  Well, i think that requests should be assumed good unless we get a response of an error.  Though we will get some success responses that includes the results of an action.   So the question remains, what is the execute process after receiving a request?
	- consider a request to turn on an engine.  The server would find the vehicle in question, include that reference to the entity.PerformBehavior ("turnon", vehicle) so that the script can use that reference to check things like whether the engine is connected to a working power source and if there's enough power to send to that engine...
	
	- our first step i think then is to just comment out all the commands that are currently broken.  get back to compiling then just implement ONE
	new request that calls a behavior that uses scripts and another request that has to work on a lobby and uses a fixed function.
	- OUR FIRST STEP MAYBE CAN RATHER BE, disabling ALL of those and just rewriting a new set of Messages and Commands and then we can just delete
	  the obsolete versions.
	  BUT HOW DOES UNDO/REDO work then?  We would need an Undo Command created that then accepted a new NetMessageBase that contained
	  the undo info to use when executing that command?
		- Afterall, Undo before has each command knowing exactly what unexecute function to link to but i think perhaps the key is that
		the Undo Message wrapped in our Generic  command is what gets pushed onto the stack and not the original message itself.  
		So if a command is "undoable" and we're in Edit mode, then we create the Undo and push it.  And thus there is no concept of Undo
		just Execute and the undo message itself is crafted to undo some previous command.
			- but the advantage perhaps is that we actively MUST construct the Undo if we have Undo enabled in order to push anything on the stack
			
	
		
	NetConnection sender = message.Sender;
	int id = message.Buffer.ReadInt32()
	switch (id)
	{
		case Enumerations.JoinGame:
			CommandBase cmd = Create(id, buffer);
			cmd.Execute (lobby.JoinGame, 
			LobbyAPI.JoinGame (cmd, sender); // no need for a cmd.Execute because the api function handles it using supplied args.
			                                 // and this API can be overridden in derived types so client and servers can handle differently
											// or entirely different api's can be called if client receives vs server
			break;
		case Enumerations.PerformBehavior:
			PerformBehavior behavior = Create (id, buffer);
			// don't queue this behavior/command, execute immediately...  but we could easily switch later on
			// when received here we could do behavior.Sender =sender;
			// or we can wrap the command/behavior in an object that will include the Sender
			// note here there is no behavior.Execute ();  but maybe there could be... hrm.. but then
			
			// perhaps below could be sent to BehaviorAPI.PerformBehavior (behavior, sender);
			EntityBase entity = GetEntity(behavior.SourceID);
			entity.PerformBehavior (behavior.Name, behavior.Args);
			// how do we know whether we need a Vehicle reference in the Args?
			// there might be a function in the entity in question to get whatever references to a vehicle parent it needs.
			// otherwise like in lua, the args just need to be specified in an agreed upon order
			// so if say a target ID to fire a laser at is one of the args, we can call a function to get the entity represented by it
		default:
			break;
	}

		// actually from reading this codeproject article 
		// http://www.codeproject.com/KB/cs/DelegateBusinessObjects.aspx
		// he has each class implementing a CreateRules() method and thus
		// all we really have to do to avoid some of these rules (e.g. build rules, game rules, etc) from being available
		// for inspection by the client is to use a Delegate for that CreateRules() method as well and don't allow
		// those same delegates to exist on the Client. 
		
		Validation... I can see one advantage to the above which explicitly is mentioned in the articles which is
		here validation occurs prior to being able to persist this object and that otherwise, it's ok to have
		invalid properties on an object.  
		
		But now I'm realizing a few things.  1) This type of validation doesnt really fit with my ICommand model
		where i need to be able to undo/redo explicit commands (editor or build).  Further, issuing orders to crew
		ICommand.Sender <-- add a Sender object property that can be used to identify issuer of the command.
		
		IResponse <-- results of commands including any details about why the request was denied.
		
		 //mHost.ChangeMaterial(AmbientR.Value, AmbientG.Value, AmbientB.Value);
           // mHost.ChangeNodeState();
            System.Data.DataSet ds = new System.Data.DataSet("Material");
          //  mHost.ChangeNodeState (id , ds);  // dataset effectively contains the member name (eg. "ambient" and the value) so we
            // dont need a "message" param
            // DataSet solves the immediate issue related to my plugins... 

            // in Evo we had these rather complex field type structures so that Lenn wouldn't have to write any SQL
            // but now... im thinking maybe we can \ should for 1.0 just hardcode our SQL queries for our various object types
            // We can still abstract that away, but we wont need these gangly switch statements to convert the fields to from
            // those structs just so we can avoid hand writing all the sql queries.  I think we can still use
            // StorageContext 
            System.Data.DbType fieldType;
            System.Data.DataColumn column;

            //column.DataType = 
            //column.Caption = 

            // note: if i stored the childID as binary and the typename ID as an int that i lookup for string table name
            // then parsing that field could be done extremely quickly so the subsequent call to grab the child ent could be pretty fast
            // could stored procs be written to do that to avoid sending multiple calls across the dbconnection?


            // IStorageContext
            //      SQLStorageContext
            //      BinaryStorageContext  <-- creates an IRemotable byte array
            //          - but does this send just the top + children types/ids or does it have to send the entire hiearchy?
            //            if you send the entire hierarchy you wind up duplicating a lot i think...unless you wind up having to make a seperate
            //            request for the id's of all children that you dont already have cached\stored in the db
            //

            // maybe i can store the mappings for each type in a file.. xml or just CSV

-------------------------------------------------------------------			
**************************************SECONDARY**************************************

- fix planet shader lighting angle
	- i think pointlight is a waste... our light is way too far... it should be directional that is changed for each rendered exterior item
	maybe done entirely in shader from light params (star location, color)
	- gas and ice giants dont need the normal mapping crap or emissive and specular really...
	- but really, this point light issue should be solvable.  
		- verify DIR light ever worked exactly at correct angle.

- rings should be cut in half and rotated to have a half that is towards camera and in front of planet and one that is behind planet so alpha sorting is fixed

- FX/Add Star, blue planet, gas giant, asteroid belt (NewWorld, NewStar, NewPlanetoidBelt dialogs)
		- switch the FX Planet and asteroid fields and such to use queued command loading
		- ability to drag/drop a treenode of a planet to be under a star system, set it's orbit update script and now it's apart of that system
			- perhaps have ability to recalc planet's stats based on star / system it's been moved to.
			- ability to add a world to the orbit around a star
				- the orbital speed and path is precomputed (well, movearoundpoint)
			- ability to add a moon to the orbit around a world
			- ability to attach a new planet to an orbit or replace an existing with a new generated one with configurable parameters
	
- star/world/moon Names toggle or when mouse hover
- ring lookup texture generator that creates the empty areas of the ring in the right spot based on the inner and outer radius of the entire ring system
	- for instance Neptune 49528 diameter 17x earth mass
		Inner diameter 82000 diameter
		Outer diameter 125860 diameter
		- thus we'd scale our 1 unit diamter mesh to 62930 and since 41900 represents 66.581916415064357222310503734308% of the diamter
		we would have 0.0 alpha component in the texture up until the ~66% pixel so in a 1024 long texture it'd be ~675th pixel
	- for Saturn (120,536 km diameter 95x earth mass)
		inner diameter 133796
		outer diameter 361936  (outer ring is 2x planet diameter)

	- for uranus (51,118 km diameter 14.5x earthmass)
		inner diameter 76000  1.4x
		outer diameter 196000 3.8x  but the 2 outer most are extremly faint

	so from these, we see that the outer ring is usally 2.5 -3.8x the diameter of the planet and the inner rings are
	1.1 to 1.65 diameter of the planet
	

- custom newtonian physics for non celestial body entities using gravity
- planets will have a fixed path, but their gravity will be based on their centers World.Gravity 
- fixing issue of rotation changes updating the physics body as well
	- RotationMatrix and Matrix in general and translation should be set directly
		via  Entity.RotationMatrix {get {return Helper.ToMatrix(this.PhysicsBody.GetOrientation());} set {this.PhysicsBody.SetRotationMatrix()}}
- moving ship with physics
	- we should be able to add some preliminary thrusters?  what would that entail?
		- what about a type of physics for exterior that is more built on the stimulus/emitter/receptron/detector Thief model?
	- simple collision that just checks if the swept boxes intersected during the step

**************************************TERTIARY**************************************
- solar system view / nav map <-- ability to change scale, orthographic, and ability to pick planets and stars and ships and such which are not to scale
	- cycling through vehicles as controller
	- switching back/forth from Vehicle control to Edit camera
	- OK, for now lets assume im going to generate a star system, and render it as star system view in my main view with no worry about
	 having a seperate viewport for now.  We'll just work from our primary.

		- rescale the planets and stars?
		- Main issue is we want to keep the same scene and same entities for coherency between what the user picks and their navigation 
			- but to be able to apply a scaling to the models...  
				- scale down the distances (positions) to fit in the ortho view and scale up the models so they are visible
				   - with perhaps custom scaling values for stars which would otherwise be too huge.
					  - perhaps if we have a "zoom" value and if on a nav screen, we can zoom out and scale planets up as we zoom and
					  scale distances down... 
					- actually we'll be scaling the distances down similarly to the scaling to get it to fit in the frustum
					but then we have to scale models up if we want to be able to see them... 
					And then we also want to render proxy's for the planetoid belts
					and proxy's for ships and space stations or 2d hud icons.
					In fact, proxy's might be the best way all around for the star/planet/moon scales as well
						- so how would that work.  Put our camera at  0,+RegionRadius,0 lookat 0,0,0
						  compute a scale that fits RegionDiameter in the viewport
						  
- regions and validating culling and rendering, camera/ship movement, targeting physics across zones

- lighting pass 
	- needs to on/off with portals
	- use the list of Lights and add to the VisibleItemInfo.LightingState each light that is relevant
	- use our culling to get the objects affected by each light
		
- asteroid fields
	- i think if we create a ring(s) of zones around the planet at the proper inner/outer ranges we can prevent from having to try and move individual asteroids in/out of zones to neighboring zones.  Instead, asteriods are fixed in their zones (for 1.0 at least)
	- each asteroid field can then be represented as inner/outer/segments/seed  
		- then, each individual segment when generated uses as it's seed,  segmentSeed = seed + segmentIndex; 
		- then we partition the segment which is basically brick shaped into say 10x10x100 and so the finest grained partition is 10x10x10 but
		some partitions can be merged to hold bigger asteroids.  The point is though, using this partition system to populate the asteroids prevents
		any overlap (asteroids ontop of otehr asteroids) and guarantees a good spacing.  Perhaps the first thing we can do is create an array 10x10x100, and then start by filling in the biggest asteroids and tagging all of those array elements as filled.  Then the medium, then the small, and tiny.

		- and then each indivudal segment uses that segmentSeed to determine which of the internal partitions will contain an asteroid, what kind
		and what rotation (a vector velocity)


- dust field
- lasers from laser coords set on ship
- engine plumes from coords on ship
- movable turrets 	
	- turrets have a rate of rotation
'	- turrets have constraints 
	- turrents can follow targets and shoot in the right direction


- i have Imports, but not the loading of .xml prefabs Vehicles, entities in general.
	- this has to be done since eventually we'll stream these over the wire as well as load via prefabs

- fix the saving and loading
- save/load of entities 
	- save / load of Mesh3d that uses primitives instead of filepaths
		- or should these be forced to export a file?
	- save / load of FX
	- save / load of star systems fix
	- save load of camera thingies... 
	i think what happens with the save archive of my universe and textures not loading is that after loading the files from disk, they are being rewritten 	without the textures because when I re-load the paged data when generating the world, they re-save themselves prior to the textures getting loaded.  	That's why 	if i grab the .tmp file before Save As, i can grab the archive before it gets re-loaded and rewritten and then when i load that
	file after shutting down (because otherwise it uses the resource cache and skips actual xml parsing) the textures show up
**************************************QUARTERARY**************************************
- game rules
- ship designer
- Deckplan auto contstructor based on an exterior model
	- plus a validator
- Exterior model auto constructor based on deckplans 
	- plus a validator when uploading to server
- Decks & portals / sectors
	- add a simple single deck ship with an exterior portal to the outside 
	- decks should appear in entity list under the vehicle they're attached and moving the camera to inside can be done not just through a portal
	but instantly via right mouse click, view deck or view room on a deck if there's multiple
		- thinking about hardware occlusion and then i remembered that one good thing about portals/sectors is it really helps to solve
		the issue of determine which lights affect other objects since you can just follow the light through portals up to their max range.	

//
Known TV Bugs?
===============
http://www.truevision3d.com/forums/tv3d_sdk_65/help_me_with_setgeometry-t20712.0.html
SetGeometry bug i might run into eventually
==========================================================
ACTOR ART STYLE  and DWARF FORTRESS IN SPACE (PROCEDURAL GENERATION SINGLE PLAYER CAMPAIGN)
I think ideally what i'd like is to have a bunch of diferent body and face types and kind of construct a modern LEGO
version of a person. Only unlike current legos where swapping parts is limited, i want much more mix/match flexiblity.

Furthermore, to be able to construct aliens using the same system but with perhaps a limitation that aliens initially are
all humanoid.  But wookies, sleestak, etc users should be able to design a "race", populate a star system's home world with their race
simulate their race's advancement through the stars, construction of starbases based on how much time has passed and then start playing the single player
scenario based on that procedural construction.  The game will also generate procedural alien races like Birdmen, etc.

Basiclaly we're tlaking dwarf fortress in space only you're the captain of your own ship of "dwarves."

And i would LOVE to be able to do our own instanced skeletal animation
http://http.developer.nvidia.com/GPUGems3/gpugems3_ch02.html
I know the batching is doable but the bone weight stuff im not sure
http://www.videosurf.com/video/real-time-shader-rendering-for-crowds-in-virtual-heritage-95920418
http://www.horde3d.org/
cal3d?
libAX?
animadead?

You know, just as minecraft has spearheaded a return to a proper sim where only things that are functional are rendreed and purely decorate crap is not
then so can we too go back to a type of rendering of humanoids that doesnt use skinning but instead strictly skeletal with keyframes and physics and with
each race/actor able to be generated from a toolbox of lego-esque parts.  A poor man's Spore but with more simpler generation of sentients.

sketchup wearhouse ragdolls
http://sketchup.google.com/3dwarehouse/details?mid=1f80bcb77cd7b54e810bb49588f6cc52&ct=mdrm


Max Gruter <-- This guy on sketchup has i think a style i might like to use in my sim for my take on a lego-esque character gen
http://sketchup.google.com/3dwarehouse/search?uq=1601659553860618556857140&scoring=m
Wow his stuff is so awesome.  It's simple but has such a retro throwback style.  The woman are good too.  Like.. industrious looking.  
The people are not at all drunkards, addicted, losers.. these are real adults before the nation became arrested developed across the boards.
	- LOL he's got one named "Nasa Experimental" and it's some crazy looking suit... IMAGINE THAT IMAGE ON A BANNER AD!  "Canon Saga: Experimental"
	
	As far as narrative, id love to bring back a narrative of exploration, of real men not whiny overgrown bitches, of a captain kirk in a alt earth time
	where we still built things to last, we did honest work and for a fair price and where that was our motto and we didn't worship the filthy rich who didnt give back
	and hoarded.
	
	THESE ARE THE PEOPLE OF CANON!  Max Gruter's style is great.
+=========================================================

http://www.gamedev.net/topic/574435-perspective---orthographic-projections/


http://forum.unity3d.com/threads/32765-Smooth-transition-between-perspective-and-orthographic-modes
using UnityEngine; 
using System.Collections; 

[RequireComponent (typeof(Camera))] 
public class MatrixBlender : MonoBehaviour 
{ 
    public static Matrix4x4 MatrixLerp(Matrix4x4 from, Matrix4x4 to, float time) 
    { 
        Matrix4x4 ret = new Matrix4x4(); 
        for (int i = 0; i < 16; i++) 
            ret[i] = Mathf.Lerp(from[i], to[i], time); 
        return ret; 
    } 

    private IEnumerator LerpFromTo(Matrix4x4 src, Matrix4x4 dest, float duration) 
    { 
        float startTime = Time.time; 
        while (Time.time - startTime < duration) 
        { 
            camera.projectionMatrix = MatrixLerp(src, dest, (Time.time - startTime) / duration); 
            yield return 1; 
        } 
        camera.projectionMatrix = dest; 
    } 

    public Coroutine BlendToMatrix(Matrix4x4 targetMatrix, float duration) 
    { 
        StopAllCoroutines(); 
        return StartCoroutine(LerpFromTo(camera.projectionMatrix, targetMatrix, duration)); 
    } 
}

==========================================
    // I see a lot of game scripting examples where all they are doing is scripting "content."
    // And it's a lousy way to teach scripting I think because there's no sense in scripting
    // availability of things or the attributes of things or data driven behavior.  
    // We want to script entirely new behavior that goes beyond simple data driven behavior.
    //
    // so lets start by making our female character an NPC and scripting her behavior.
    // - get a gun in her hand
    // - have the gun have it's event types.
    // - maybe have two of them, and have them fight
    //   using different behavior each


=========================================	
Dragonhood?
====================================
   - name instead of I Am Dragon?
   http://www.youtube.com/watch?v=7fRT7cu7DhY  <-- i like the style of that for "I Am Dragon"  game (<-- register that domain)
	- to help market the game, have lots of vids of user's dragon character flying and torching troops and cities and bridges and ships and such.
	- also in our intro screen background, for when users download the demo, have it show gameplay recorded path of dragon flying high somewhat like a flight sim, only you're a freaking DRAGON!  This will also set the stage for users accepting less than awesome low level graphics.. the awe of flying high in the sky and going to new contents.  Seeking out thermails and jetstreams.  Using magneticsphere sensors like birds to have perfect sense of direction and heat pits to detect thermals... imagine the visuals... we can make the screen / world appear as a drdagon would see it which is another first.  Not nearly as bad as predator though.
	- heat shaders that warp the view a bit... cool graphics as far as the dragon and dragon's capabilities, but otherwise mount and blade modest.
	- Also show the lairs and ability to create lairs and traps and use spells to defend your lair, hide your lair, etc.
	- develop an amzing dragimonicon type lore.
	

Awesome asteroid field (XNA)
- http://www.youtube.com/user/RudiMedia#p/u/19/zbSbx5y5ORk
"I'm currently trying to create an asteroid belt... 
The low frame rate is due to FRAPS, I usualy get arround 60 fps on my old system (AMD X2 6000+ ; ATI HD2600)
The belt itself consists of 500,000 Pointsprites and 25,000 Asteroids, each made of 301 Polys .
I also corrected the wrong specular highlights and added normal maps."
Songs
- Mass Effect - Uncharted Worlds
- Mass Effect - Vigil

Inverse Kinematics 
http://www.ogre3d.org/tikiwiki/SoC2007+Animation
http://www.openprocessing.org/visuals/?visualID=9453
http://www.gamasutra.com/view/feature/3456/animation_blending_achieving_.php

This is a basic implementation of IK using CCD method. Jeff Lander's paper 'Making Kine More Flexible' was used as reference.
 The second chain has joint constraints.
 
	
Keep It Simple Stupid (K.I.S.S KISS)
-------------------------------------
So i was going to implement line fonts and stuff right away and then i thought no, i want to just get it working with the least
amount of code first and then if necessary we can go back and rewrite it... and in doing that with our DebugDraw.cs ive now
got a simpler method where our DebugDraw commands are not fed directly to the RegionCullingInfo and so are sorted for us
already along with other 3d visible items that share the same projection and view matrices.

Line Fonts
========
http://drdave.co.uk/blog/archive/tag/XNA?page=4
It is possible to extract vector definitions from the "Modern", "Roman", and "Script" Windows Fonts. I took the approach of pre-generating the line primitives for a given label at load time and passing them to the shader with a given scale and offset per frame. This proved slightly more performant than the SpriteBatch approach, and provided a good option for scaling the text to large sizes without occluding any objects in the background. Examples are shown in Figures 2 - 4.
-- and here this person provides his code
http://blogs.msdn.com/b/manders/archive/2007/01/12/stroke-based-text-rendering-in-xna.aspx
-end line Fonts
http://roundline.codeplex.com/
-------------------------
Arius deferred
http://www.blitzbasic.com/Community/posts.php?topic=89138
==================================================

ORDERS CREW MAY SOMETIMES QUESTION YOUR ORDER AND YOU SHOULD BE GIVEN A CHANCE TO RESPOND - secret options, maybe all options every time any crew questions

http://blogs.msdn.com/b/shawnhar/archive/2007/08/21/motion-blur.aspx  <-- xna motion blur

http://drdave.co.uk/blog/archive/tag/XNA

http://xnameetingpoint.web.officelive.com/EnglishTwinklingStarBackdrop.aspx

http://www.gamedev.net/blog/1137/entry-2250225-devlog-5-stars-make-up/
Visual Studio .NET custom font scheme
------------------------------------
Tools\Options\Environment->Import and Export Settings
 - then download and select a .vssettings file.  I keep them in
 - User\Hypnotron\Documents\fonts
 
DevComponents DotNetBar  Docking Concepts page
------------------------------------------------
http://www.devcomponents.com/kb/questions.php?questionid=67
the above page finally helped me solve the zorder issues with docking.  in fact i didnt even realize it was zorder related
until i accidentally tried "send to back" and "send to front" on my plugins which were having similar issues.

Fonts
----------------
Consolas 
users\documents\fonts\
-------------

=========================================
Deferred Rendering tutorial -XNA Very well explained and awesome!
http://www.game-developers.org/node/177

http://www.gamedev.net/topic/562818-xna-deferred-rendering---performance-issues/
==========================================
=========================================
Network server browsers
==========================================
http://www.qtracker.com/
   http://www.serverbrowser.net/
   
 DC Universe trailer
 http://www.youtube.com/watch?v=H7Nf-m6WGl4
 
IP to country flag
======================   
   downloading the IP CSV (lat long) there seems to maybe be a way to even do a bit of friendly nation versus matches where we track on our stats the wins and victories by country and by city and such
http://www.ensode.net/postgresql_csv_import.html   <-- import csv into postgres

Components scripting
-========================
in this document, search for without quotes "There are a variety of benefits over the previous implementation"   and there is a paste of a cocnept by someone who was thinking in anti-objects terms.  Put more responsibility on the components for handling various integration with parent entities... and do NOT have the parent entity responsbile for everything.  Consider how adding any new thing forces aall parents to be modified in that case.  that is lame so the antiobjects thinking is good here?  maybe,... im just typing this to remember but i havent thought it thru properly yet.

marketing 
=================================
  - jomsocial example site to copy perhaps   http://www.xxxgamingclan.com/
  
Physics - orbits, n-body  especially the last post in that thread
===========================================
http://www.physicsforums.com/showthread.php?t=262733
http://www.gamedev.net/topic/481263-c-particle-to-particle-gravity/  <-- same guy also posted to gamedev.net and posted his code

// the following i believe uses HNBody Symplectic Integration  --> http://janus.astro.umd.edu/HNBody/
http://shootout.alioth.debian.org/u64q/program.php?test=nbody&lang=csharp&id=2  <
http://shootout.alioth.debian.org/u64q/program.php?test=nbody&lang=csharp&id=3 <--fastest

Graphics Examples
-------------------------------------------
http://www.youtube.com/watch?v=BHDWukWE4Hg   <-- a mod with babylon 5 ships... which mod is this?
----------------------------------------------

COMMS - Chatter to add to atmosphere and offset some of the emptyness and vastness
=---------------------
--> need real proper space chatter like if ther'es a COMMS tab and we're talking to other ships or have an estabilished frequency between fleets, these comm chatter should come in automatically
--> AS WELL AS ONBOARD CREW CHATTER TALKING TO THEIR CAPTAIN AND EACH OTHER, confirming orders, first officer relaying the captains commands as feedback as well (similar to total war where you hear yoru general barkng the orders and units confirming.  Crew saying Aye Aye Sir"  "Changing course to x,y,z captain"  "Course now x,yz, eta to elta at current speed x time"

Freelancer still alive initiative
--------------------------------
http://www.youtube.com/watch?v=ZXD4N_Mi1iE    <-- love the dynamism here and the aliveness of the space station traffic and the trails and particles and everything is high class.  Id love to have graphics that great.
http://www.youtube.com/watch?v=iErvfmqClb8&NR=1
http://www.youtube.com/watch?v=ZQIwupha8Rc
http://www.youtube.com/watch?v=Myw_2niQ6zQ

- BUT AS FAR AS capital ship sizes, look... scifi flicks have way oversized ships for the reqts of destroying other big ships.  Nukes see to that.  the main qualities would be submarine like stealth, some good armor to help them survive long range engagements, and for us our chatter, crew ops, atmosphere centric will make up for the vast ness of space.

- We will thus create a new genre of scifi and who a new type of space combat in depth and frankly define space combat... inconjunctin with our comic we will release to tell our narrative.
	- perhaps the comic updates can be a bonus of subscriptions... but i dont think so, i want the story to be known and to be free to see even if you dont like to play games.

Tactical / Nav map and waypoint plotting! (SOLVES MY 3D NAV/TACTICAL/HELM DESIGN ISSUES!!!) http://www.freeworlds-tow.net/dev/
------------------------------------------
http://www.youtube.com/watch?v=_QfsYIvJ8pY  <-- watch this from the freeworlds 2.0 vid 
http://www.freeworlds-tow.net/dev/

asteroid fields
---------------------
http://www.youtube.com/watch?v=ZQIwupha8Rc  <-- must remember to copy them.  increase alpha big time of the 2d ring when anywhere near close and
insert lots of dust billboards along with the field itself.
also look at the infinity april 2010 tech demo vid! search youtube

xna editor
--------------------
http://www.youtube.com/watch?v=6PBoEaY8u7E

stem cell editor
====================================================
http://www.youtube.com/watch?v=BxjuBsahNXE

		
http://www.youtube.com/watch?v=boqHWm3fQmc  <-- Hero engine



**************************************************************************************
AUDIO - Ambience
**************************************************************************************
Was thinking about what type of audio music or whatever to have as a theme and it occurred to me what i really really want is how Falcon 3.0 made
me feel.  It had realistic sounding comms traffic for fighters, and in our game id like to have realistic comms with fighters (like you also had in the new Galactica) and real sounds in terms of shift changes (beeps and tones to notify crew of upcoming changes as well...even like 15 minute warning beeps).  Also a day night cycle on the bridge, whirring of engines, ocmputers, fans, and such.

To the extent we can make this sound musical would be a challenge.  SOmething that is NOT annoying is key.  How to make non annoying audio?  What sounds \ frequencies and such are good to hear?  Relaxing?

**************************************************************************************
shader extra
	- sun as a post process http://www.sgtconker.com/2010/04/article-sun-and-lens-flare-as-a-post-process/
http://www.creativecrash.com/marketplace/3d-models/weapons-armor/projectiles/missile/c/rocket-exhaust-trail
**************************************************************************************
- 
LODModel vs SimpleModel
	- merge to one and just use constructor arg that can't be changed and which sets flag + abilty to set minimesh instance

verify deletenode as it is now does not delete children from repository?

-------------------------------------------------------------------------
SCRIPTING - THIEF - RECEPTRONS, STIMULUS
-------------------------------------------------------------------------
Important note about Sensor Detection (actually maybe rethink with the thief style receptron/stimulus method that is easy to script and elegant code wise too)

- the server should create a sensor profile for the various types of detection for each craft and then use that profile to 
broadcast explicitly a value to other units.  Why?  So we can create decoy profiles.  A player can construct a decoy emitter and attach it to 
something or a countermeasure and since it's a real entity, it will be received by remote players just as if it were any other type.  In other words
rather than tell the user they've contacted something, we send them sensor return data and then it's up to the player/npc sensor operators to determine
whether the signal is real or not.  Part of that could be comparing the return data's signature or something.  This is something we can
implement sooner rather than later as part of how our sighting/detection works
reactor.OnTick()
{
	// this onTick for component specific simulation shoudl run at just 1hertz.  We could alternate
	// every .5 hertz where power gens create power and dispatch, then in the second .5 hertz the 
	// power is consumed and those devices perform if active.
	if (this.PoweredOn)
	{
		output = this.PowerOutPutPercentage * MaxPower * this.Efficiency 
		
		// deliever units of power to all devices 
		remainingPower = output;
		while (remainingPower > 0)
			foreach (PowerConsumer device in mDevices)
				if (remainingPower >= device.PowerReqt)
					// emit power to this consumer
					// todo: i recall wanting to use the theif darkengines concept of stimulus & receptrons and such... but now the details of how
					// i was going to implement that are more sketchy.
					
					// a Star should produce a unit of heat and send that to every vehicle or craft in range... those vehicles
					// can then propogate that heat and it may not penetrate the armor and do no damage except maybe raise the hull temperature.
					// But this sort of stimulus object sending to receptors offers a generic way to deal with transmissions of energy (kinetic energy too) and programming the responses based on the type of energy as well as the type of receiver that's processing it.
	}		
}

//    // to me the concept behind Thief's sources and receptrons is that a source is a type of stimulus object
//    // and the receptron is an object that holds various properties for responding to a received stimulus.  
//    // The receptron is thus a definition for the resulting behavior that should occur when a stimulus is recepted.
//    // Thus receptron is synonymous with "response" where all these various responses are specifc.
//    // The key to understanding receptrons though is to understand the benefits of being able to communicate
//    // in terms of Stimulus and Receptrons via scripts because it simplifies the interfaces needed and 
//    // yet it provides a large enough vocabulary to be very expressive and flexible.
//    // However, the above description of how its used and why its used isnt very concrete.  First of all
//    // this language provides specific actions and events and so is completely un-nebulous.
//    // For instance, an arrow that hits a guard in the chest... that arrow is a stimulus and is handled by a receptron
//    // on the guard that is scripted to handle the specific stimulus class that is being applied.  Thus, a quick dictionary
//    // lookup of  receptron[stim.GetType().Name)].Apply (stim)
//    // can be done.  or perhaps first a TryGetValue(stim.GetType().Name) so that it can be ignored.
//    // a Key thng about these scripts is that really they're not performed that often..  So a question might be
//    // all of these perhaps little scriptable objects, are better than scripting all the individual entities?  I think the obvious
//    // answer is found in looking at the nature of receptrons and stimuli.  The stimuli is emitted and the receptron absorbs
//    // and so the source and target entities are different and yet all the information on how a stimulus should affect
//    // a target is embedded solely in the stimuli object and the receptron.  So you can fire a blue green laser
//    // with 1000 watts of output, and that stimulus contains all the info for the damage that can be done against various materials.
//    // It then applies to a receptron that is charged with handling that particular class of stimulus and combined,
//    // damage results, and sounds, and fx are all contained with no need whatsoever for that info to be contained in
//    // either the gun or the hull entities themselves.  They instead exist solely in the output and the input entities themslves
//    // which we call stimulus and receptron.
//      // Entity.Receptors[]   
//      Entity.ReceiveStimulus (stimulus)
//      {
//          // how do we implement fall through?  Where say some stimulus is reduced by contact, but not entirely and so
//          // falls through to other parts?  I think from the server side, that must be computed ahead of times so only specific
//          // final affects apply... however, they use the receptor pattern so those client side scripts can run and produce proper
//          // sound and visuals and animations and particles such.
//          foreach (Receptor receptor in mReceptors)        // the potentially cool thing here is that these stimuli can be sent over the wire
//              bool result = receptor.TryApply(stimulus);    // and much more easily occluded, or otherwise not sent to users who cant/shouldnt see them
//                
//      }
//      //  A laser "OnFire" script might emit a Stimulus every 30 ms while it's firing. (or some configurable hertz)
//      //  But by objectifying emissions (including radio emissions and such) our receptrons act like geiger counters and 
//      //  our interactions become much more easy to govern.
//      //  
//    // And so your actual entities can be rather simple, but combined with a bunch of receptrons can end up being
//    // able to respond in complex ways.
//
//      Receptors absorb stimulus.  In effect, Receptors are both sensor objects and physical response objects since Receptrons
//      can be used to detect signals and such as well as deliver damage to the host of that Receptron.
//      // I think the key thing about so called stimuli and receptrons is that they are more akin to "material" properites
//     // of something in the world.  So they can help dictate in a generic way, what sound should occur when a certain stimuli
//     // hits a certain receptron.  In this way, you're scripting those specific interactions and NOT having to script how a bullet
//     // interacts with every specific NPC out there.  Instead if that NPC has a specific receptron to handle a specific stimulus
//      // that receptron can be shared across many NPC's or even non NPCs.
//      // waterEmitter <-- type of stimulus
//      // fire_receiveWater <-- type of receptron
//      // a radio transmitter can emit a single Stimulus to every enemy in range (via server side tests) modified by the enemies instruments 
//      // sensing capabilities (eg they have a Receptron that can detect the Stimulus)
//    //  I think....  What I do know is that we want/must start narrow focus and _only_ expose what we need
//    // when we need and to consider anything we add and whether it would represent a way for players to cheat in multiplayer.


//    //http://thief.wikia.com/wiki/DromEd/Properties/Act_React/Receptrons
//    // http://thief.wikia.com/wiki/DromEd/Properties

//    

//     So in turns of scripting the above, obviously Stimuli and Receptors are individual scripted objects that are easily shared.
//     However, we ended up potentially needing lots of them.  Object explosion...
//     And they don't entirely replace in fact the scripting of behaviors like OnHit (where a receptron doesnt know how to specifically
//     tell a ship what type of lod damage model to switch to or something) or OnDie, or OnSpawn etc.  Those we still need.
//     All this specifically does is objectify the interactions between emitters and receptors.  
//     In this sense, our game interactions are much more object oriented.  Perhaps this is ok so long as we can share lots of
//     Receptors and not have a ton of unique implementations.
//     

//   So how does this impact our actual implementation decision where im still trying to resolve how to tie
//   entity scripted behaviors to entities, and then later entity's receptrons's responding to stimli.
//   Well in terms of our Receptrons, i think one very useful feature is that types of receptron can only be added (hosted by)
//   entities which have specific interfaces.  e.g.   within the handling of 
//      receptor.TryApply(stimulus)  // where say stimulus is laser beam and receptor is just weaponHit
//      {
//          // we know that the mHost of this receptor has been cast as a IDestructable
//          // 

//  IColdReceptor
//  IHeatReceptor
//  IConcussionReceptor
//  IParticleEnergyReceptor   (perhaps same as IRadiationReceptor)
//  IKineticEnergyReceptor
//  IRadiationReceptor    ( but wouldnt we want different receptors for weapon energy vs communications energy like LADAR vs Beam?)
// IAlive -> ISentient

// IScriptable
//      Scripts[] GetScriptableEvents()  // all - read only
//      Scripts[] GetScriptableEvents (InterfaceID) // only those scripts specific to a particular interface - read only
//      AssignScript ()
//      RemoveScript()
//      IEntity -> most all entities are scriptable 

//  Entity.GetEvents()
//  Entity.AssignScript(eventID, script)

// NOTE: THe primary purpose of these interfaces is just to describe those unique methods and properties that those types need
//           such as for PoweredMachine (TurnOn, TurnOff)
//           This will be important when we want to be able to do queries on our Vehicle to find objects of a particular interface
//          Then we can also sort those based on location (container\subassembly) on the ship

// IDestructable (Implements ICollidable)
    // note: regualar (non IPhysicalEntity) IEntity does not inherit IDestructable because some entities like lights or wayponts or portals are not physical entities
        // IPhysicalEntity - IReceptor[] mReceptors, void ReceiveStimulus(),  Tick() --> OnTick script
        // IArmor  -> armor is not a component as it does not have volume or count towards surface area (only assemblies count toward surface area)
        // IContainer 
        //     ISubAssembly (note landing gear will not be an assembly, we will handle that differently than GURPS)
        // IComponent -has weight, cost, volume, surface area, hitpoints, 
            // IWeapon  - consumes ammo and/or power, Fire - OnFire event script, Tick - OnTick handles recharges and reloads, Reload - OnReload, 
                                // - Fire OnFire - produces Stimulus (sound, muzzle blast/smoke, and a damage projectile stimulus  
            // IPoweredWeapon
            // IPoweredMachine  - TurnOn, TurnOff, 
                // IPowerSuppy
                // IFuelConsumer
                // IPowerConsumer
                // IPropulsion --> produces a unit of thrust each cycle.  Consumes a unit of power and/or fuel each cycle (also implements IDestructable)
// 
//  Hrm...
//  public class Control : StaticEntity, IEventHandler, IInputCapture  <-- Keystone\\Controls\\

// I like perhaps that our scriptable events are in the form of  EventType.XXXX
// so our dictionary of events uses EventType.XXX for key.
// and some of these events can be null.  
// So let's start simply by using our Control as our template since that will make it easy to just start coding...
// Our various base classes can initiate the events in that dictionary, where some are null and some are not... we cant externally
// add new events, only replace existing ones in the dictionary.  So the question seems to be just how do we serialize?
// each needs to be a key value pair of eventType, scriptPath  (if not null)
//  So we can assign null, a default delegate or a script

// But maybe better to just have the ScriptNodes to simplify how these are saved/read in our XML.  We still have
// restrictions on how these scripts can be assigned to the dictionary of scripts, (cant load a script that's not relevant and have it apply)
// So what does this mean for our entity browser?   Do we see the script nodes and can click on them and pop up a plugin that is
// the script editor?
 
// - EntityEditCtrl has to list the allowed events, then we need to allow drag and drop of scripts
     // with option to createNew, and then name it and drag and drop and code it and save changes.


///////////////////////////////////////////////////////////////
////    On Sun, 22 Sep 2002 22:55:30 -0500
////Steve Baker <sjbaker1@airmail.net> wrote:

////<snip>

////I'm in work so I don't have a lot of time to type: I'll try to give more
////answers later.

////> * How should the game handle collision detection for scripted objects?
////>   Does
////>    the script make collision detection queries and do the business of
////>    stopping the motion when it hits something - or should the game
////>    engine deal with the consequences of a collision and just inform
////>    the script what hapened?

////Event queries are possibly a bad idea - you could end up with all
////manner of odd timing behaviours. One method you may want to try is to
////let scripted objects register handlers that are called by the engine
////when specific events are detected. So say that when a scripted object
////hits a wall, its "on_scene_collision()" function is called. When it is
////hit by a projectile its "on_projectile_hit()" is called... 

////A possible plus to the event method is that you could have "default"
////events, so that the engine can provide a bunch of default behaviours,
////but the script writer can override the defaults if necessary.

////> * How does the scripting interface deal with telling the script the
////> position
////>    of the player and other creatures?

////One method you could use is to have a set of query functions 

////get_named_object()
////get_enemy_list()

////or the like and give each object in the game a unique name. you could
////use this to at least partially prevent rogue scripts mucking up your
////enemy data. Or maybe just expose the object list and let the script deal
////with looking at it - that's a grubbier option though.
 
////> * Should scripts be able to communicate with each other?

////If you have named objects, you could have a

////send_message(object_name, message)

////function. Give each object a queue of messages and send_message() adds
////messages to the end of that queue. You could then use
////a get_next_message() function to pull messages off the queue, or if
////you're implementing engine-triggered events for collisions you could
////even allow objects to register an "on_new_message()" event handler.
////Or provide a get_next_message() function that is called from within an
////on_new_message() handler to go through all the new messages in the
////queue...


////> How do existing games deal with this stuff?   Is there a 'classic'
////> game somewhere with a scripting interface that's known for having "Got
////> It Right" ? If so, where do I go to find out how it works?

////One place to look would be the Quake and Quake2 source code, they'll
////probably give you some good ideas to start with. I'd also really
////recommend that you have a look at the sources and receptrons system in
////the dark engine (Thief, Thief2, System Shock 2) which is an immensely
////flexible system. Unfortunately the source isn't available - you'll need
////to work out how they work by using them. There is some extensive
////documentation on S&Rs on Dromed Central at

////http://www.thief-thecircle.com/dromed/navsubject.asp?subVar=STIMU1

////S&Rs combine event handling, messaging and a load of other tricks. If
////you don't have Thief or Thief2 this probably won't be much use to you
////though - you really need to play around with S&Rs to see what they can
////do. There is also some stuff in both Game Programming Gems 1 and 2 (not
////got my copy of 3 yet...) 

////Chris


////    I have a bit of experience here, so I'll take a crack at it...


////> * I could provide (for example) a function to position an object that 
////> 'belongs'
////>   to the script at a specified X,Y,Z,Heading,Pitch,Roll - but should I 
////> instead
////>   make the interface be Velocity+Direction and let the game do the 
////> integration
////>   down to positions - or perhaps the interface should just be a place to 
////> head
////>   towards and a choice of several 'modes' of getting there?

////You'll probably all three approaches. A script might want to add a
////new static object to the world (1), or maybe apply forces to all
////dynamic objects to push them away from an explosion (2) or run a
////pathfinding algo to get from a to b (3). Pathfinding is generally
////too cpu-intensive to be coded in a script.


////> * How should the game handle collision detection for scripted objects?   

////Collision detection should happen in your C code (too slow for
////scripts, and script writers don't want to be bothered). When a
////collision is detected call a hit() function or similar on the
////scripted object and pass it the object that it hit. The script
////can then determine what to do about the contact.


////> * How does the scripting interface deal with telling the script the 
////> position
////>   of the player and other creatures?

////I have a FindEntity() that can locate another object by name.
////The script can store a reference to the entity in a variable, and
////then call GetPosition() etc. as needed. That is, the scripted
////object should ask for what it needs.


////> * Should scripts be able to communicate with each other?

////If you allow this, it should definitely be through some sort of
////indirection like messaging or an event system. That way a script
////can safely ignore events that it doesn't recognize. For game objects
////it's not too bad, because you can standardize the interface to
////a "thing", but for the AI logic it does get kind of fuzzy. The
////best bet is to keep object boundaries clear.


////> How do existing games deal with this stuff?   Is there a 'classic' game
////> somewhere with a scripting interface that's known for having "Got It 
////> Right" ?

////It has been my experience that the *best* way to this stuff is via
////a plugin/component system. No matter how much stuff you give the
////scripters, there will always be something you didn't think of.
////Create a simple base of functionality, a standard object system
////for your scripts, and a standard way to add to it.

////A good place for info on these kind of things is the unrealtech page
////at http://unreal.epicgames.com.

////Jason
////379
-------------------------------------------------------------------------
-------------------------------------------------------------------------
class power grid/array : ComponentArray
weapon array
weapon links (same thing?)
sensor array
life support (ducts, air, pressurization, etc)
engines \thrusters array
	engine controls?
	ship attitude control

if the above are represented into a listing of all items in a particular grid/array/network, then they can contribute to the overall power, or 

firepower, etc and consumers dont need to direclty connect to the providers... dunno yet.  i still need to iron out how i want to do this

engineering ->  This could look very much like  keystonegameblocks\design\TrustSet.jpg
	- AKA like Control Panels\System\Hardware dialog tree where all types are sorted... only we can
	  also have colors propopgate up to indicate which branches have some damaged components in them.
		- THE RIGHT MOST PANE CAN SHOW THE REPAIR QUEUE/PRIORITIZATION QUEUE
	- power grid
	- damage control
	- engine levels, fuel allocation
		- thruster array
	- life support
	
C&C (Helm + Tactical)
	- contacts list  <-- ability to sort by range, class, threat level, etc
	- weapons panel (shows weapon links, their facing, assigned targets or orders (e.g fire at will)
		- if your weapon officer is particular bloodlustful, when ordered to try and capture a ship, he might still end up targeting the reactor and destroy that ship.  But it was your choice to have that officer as your chief tactical officer.
	- Galactic Chart
	- waypoint plotting (both for your ship and your fleet and fighters)
	http://www.youtube.com/watch?v=_QfsYIvJ8pY  <-- watch this from the freeworlds 2.0 vid 
http://www.freeworlds-tow.net/dev/
	- a tab next to weapon panel that is for fighter and bomber and shuttles and transports and other carried craft launching and ordering (sorties and packages and loadouts for them too)  Look at old vids of the amiga 1988 game Carrier COmmand for how you can loadout your Manta fighters as well as launch them individually. Look at the gui for doing that as well.  http://www.youtube.com/watch?v=w_BlO1CJn34
	- look for updates to bohemia interactives carrier command: Gaea Mission too.
	
	
	-----------------------------------
	keep ribbon editor link near our list of gui sections 
	http://www.andypope.info/vba/ribboneditor.htm
Sensors
	- tactial
	- cartography
	- targeting

(Sensors, Weapons, Power Assignments and such should be sub sections of the main C&C view perhaps?)
some of these layouts we're just not going to know until we actually get to playing.  

	
Personnel ->> http://www.bmscentral.com/products/schedule/slideshow.aspx
	- promotions
	- rankings
	- service records \ reports 
	- stations / scheduling / shifts
		- red alert stations (battlestations)- http://www.aesim.com/galaxy/dutylist.txt
		- subordinates can submit requests as well and you can manage it.
			- subordinates can submit for approval/sign off various orders they've issued as well.
			
	- pay
	
operations 
	- orders (responding to received, and creating sub-orders for your own fleet and officers)
		- scheduling flight plan for the fleet and for fullfilling mission objectives
			- including resupply missions, 
			
	- flight plan packages for standard CSP (combat space patrol)
		- refueling in flight
	- crew \ shifts
		- training
		- patrol shifts
		- security shifts
		- station assignments
		- away team assignments
		- boarding team operations
	- maintenance schedules
		- sanitatation
		- plumbing
		- cleaning (mopping)
	- Security
		- keystonegameblocks\design\TrustSet.jpg
			- what if there were a  simple way to define which crew members had access to which areas 
			of the ship?  A way of assigning clearance levels and then making varous doors and component interfaces have a required security clearance level to acces without hacking.
			
Manifest
	- quantities and resupply buy/sell cargo, weapons, ammunitions, pods, fighters, bombers, etc
	- 

File
	Resume
		
	New
		Single Player
		
	Network
		Server IP
		Credentials
		Connect to Lobby
		
	Character
		Create  (multiple characters allowed for campaigns or what?
			or is it more just like a Steam Account handle?
		
	Settings
		
Account
	cretae
		
Planet and SHip Labels
------------------------
These should be done during the final Render AFTER culling has been performend and when we know exactly where everything is.
After rendering, we can then go back thru th elist of entities and render a label if label rendering is enabled.

Deck Plan Edit NOTE
----------------------
The Sims and First Person Shooter Creator simplicity is key.
(Marketing ad slogan - "Lovingly craft capitol ships"
http://msmvps.com/cfs-filesystemfile.ashx/__key/CommunityServer.Blogs.Components.WeblogFiles/valentin.Arcane.Esquisse/6886.test.png
i also saved above image in KeystoneGameBlocks  root path.
Notice the floating tool windows along the left?   The top brush one kinda looks like a nice way to implement a deck selection panel, both for editing decks and switching between them during arcade runtime

- in startrek tng, they have different lighting on the bridge to correlate with daytime and nighttime.  i like it.

LOCALIZATION  (Resource files)
----------------------
http://msdn.microsoft.com/en-us/magazine/cc163609.aspx

----------------------
SWITCHES - LOD, RollOver, Damage, etc

// such as the Control entity having specifically a means of following any specific path down a switch.  But again, im not sure how this is done
// without code... 

// well a simple index value is fine for determining which child item in a switch BUT, what if there's multiple switches, then what do we do?

Typically during traversal, when reaching a switch, the switch should then query the Entity and determine which path... ok... for an LOD switch i can see, for Damage switch i can see... for RollOver switch... hrm... does it just check RollOver?  Is it possible to have a more generic implementation that doesnt depend on the type of switch that exists?

YOU COULD HAVE A SCRIPT ==> that the user sets/types for that entity that when the traverser reaches a switch, the switch then says "Hey Entity, this is my "name", which path do i take?"  and then the Entity responds with the index of the child switch (and if that index doesnt exist the switch goes with default)


NOTE: In gamebryo, they read arguments from a byte array just like i did with my plugins!  And just like with plugins, i can still force the scripts to communicate in a way that goes through our network layer... rihgt?   
Well the only way to really know is to start a test ship that has an engine and an on/off switch. 

Rather than using these ROUTEs, lets just script these node types....  and just like with my plugins, users will actually go through a specific ScriptingInterface and will not direclty modify types.  This way we can handle any ICommand / IRemotable we need.
http://www.youtube.com/watch?v=PoV8sOyXZS8  <-- in fact restricting them to an interface for scripting is exactly what Gamebryo does!
http://www.youtube.com/watch?v=z-EuS1EYk8o  <-- lua in leadwerks
http://www.gamedev.net/community/forums/topic.asp?topic_id=457999  <-- using lua scripts many times... as in on server
http://gamedev.stackexchange.com/questions/3453/would-using-lua-scripts-to-define-game-logic-for-an-mmo-server-be-a-lot-slower-th 
where he says 				
					"L;DR: Lua does have overhead, but if used properly it is negligible and easily mitigated. Don't use it for heavy math operations or transforming geometry. You will probably not see any performance problems at all using it to script a GUI.

						I've done some basic benchmarks regarding Lua's performance as a game scripting language, and it's pretty damn fast. Using tolua++ to bind LuaJIT to my game engine, I spawned 2,000 actors, each actor controlled by a Lua script called every game loop (with a time-delta argument). Half of the actors had a flocking script and the other half were doing a sort of random walk (and were avoided by the flock).

						Turning off the rendering component gave me a bit over 400 ticks per second on my Opteron 170 (2x2.0GHz, though my engine was single threaded at the time). I imagine I could have squeezed out quite a bit more than that if I dug in and optimized, perhaps moving some of the heavy work back into C++. Updating 2000 actors 400 times per second was still pretty impressive, and far exceeded my expectations at the time.

						I now use Lua in all of my projects, and it actually constitues quite a large portion of the actual game code (AI, GUI layout/logic, Events/Messages). Making games is MUCH more fun when you can quickly change something and test it without having to exit, recompile, and reinitialize. I've run into some performance issues from time to time, but those are easily solved by reimplementing the offending code in C++ (and then calling it from Lua).

						While slightly off-topic, EVE Online's servers are written almost completely in Stackless Python (I believe they defer most of their math operations to a C++ lib), which is considerably heavier than Lua, and, based on my own personal research and several available benchmarks, far less performant than LuaJIT. They manage to handle 30k+ concurrent players without too many issues. Granted, they do have a ton of expensive hardware running all of that, but I believe the majority of the cost is in their database cluster...

						Apologies for the wall of text."
						
						The biggest hit in these kinds of systems is usually parsing the scripts, so make sure to frontload that at startup.  coderanger Sep 1 at 21:20
						
AND LUAJIT project is API compatible with Lua5.1 which is what LuaInterface uses and presumably LuaInterface can be compiled against 5.1 and pick up a ton of speed?!!!!   http://luajit.org/install.html
---------------------
On Using Portals vs Hardware Occlusion
--------------------------------------
<Hypnotron> hey steve, you there?
<Hypnotron> not sure how busy you are, but take for instance the ship in this pic
<Hypnotron> http://www.makosoft.com/stuff/kgb_b53.PNG
<Hypnotron> what id like to do is to get a cross section of a specific part of that ship as a 2d image so taht the parts inside the ship are say black and the parts outside are white
<Hypnotron> but actually
<Hypnotron> i want to take several cross sections and get over a nearby range and use the minimum for the final
<Hypnotron> so like imagine a 10 foot tall deck from floor to ceiling
<Hypnotron> so my cross section would encompass samples of the cross section from floor to ceiling
<Hypnotron> and the final cross section should contain all of the others
<Hypnotron> so i guess a Max not minimum
<Hypnotron> a superset of all the otehrs i guess
<Hypnotron> im trying to figure out how to do that easily... considering you'd have to clip triangles
<Hypnotron> or something
<Hypnotron> or i dunno how to do it best
<Hypnotron> anyway
<Hypnotron> once i have the 2d image
<Hypnotron> the siloquette style cross section that represents a "deck"
<Hypnotron> i want to be able to then allow users to draw ontop of it and to be able to do bounds checking to make sure when they draw something they are staying within the black part of the siloquette
<Hypnotron> i would know how to do that using just planes
<Hypnotron> just like a frustum only more planes, that'd be easy
<Hypnotron> but from a 2d image maybe there's another way
<Hypnotron> not really sure how to construct 2d planes from the siloquette so im thinking maybe there's some other way that is similar to an occlusion query against the  silouqette
<steve|work> hrrm
<steve|work> an interesting idea
<Hypnotron> the first part is how to construct the siloquette 
<Hypnotron> wondering if the only way is to iterate thru all the triangles in the model and find the ones that intersect the plane and to build a new polygon connecting all the intersection points
<Hypnotron> ugh, but then i would need to know how to connect them in the right order
<Hypnotron> that's why the idea of being able to somehow rendering a siloquette without even worrying about recreating new polygons from the plane intersections
<Hypnotron> seems better if that's even possible
<steve|work> no
<steve|work> hrm
<steve|work> you can use custom clip planes
<steve|work> which clip in addition to the view frustum
<Hypnotron> that sounds like it would result in fence, although i guess an algo could be used to then fill in the middle
<Hypnotron> floodfill of sorts
-
<Hypnotron> hey steve, no sure if you're afk or not but last week or so we were talking about hardware occlusion as opposed to portals/sectors and then i remembered something that portals/sectors offered that im not sure how you deal with otherwise... since you're traversing from the camera's current spot through portals to other sectors
<Hypnotron> you can pick up the lights as you go and dump them when their range runs out and so you easily know what lights affect what objects
<Hypnotron> and it makes it so easy to have a light not enabled if its on the other side of a wall
<Hypnotron> it also can make it easier to setup pathfinding
<Hypnotron> the pathfinding is no problem since you can just create a navmesh that will store all the connectivity 
<Hypnotron> but what about the lighting, how would you deal with that?
<steve|work> interesting..
<steve|work> well, ideally you'd alerady have a quadtree structure or something similar
<steve|work> and using the hardware occlusion system you'd be able to detect which regions in the quadtree/octree are visible
<steve|work> you would then use the data in the octree to check for lights affecting objects
<HypoAFK> ok. thanks. ill have to research that a bit
<HypoAFK> im almost definetly not using portals/sectors for my ship internals... just on the ship intneral / outside boundary for windows and cargo/landing bays


visibility pass
	- adds list of Lights and there relative Camera positions

Or how about this
	- lets have our Lights, even though they're added to the same list, lets have a seperate Getter to get just lights
	  so that we can always traverse lights first, and then we can treat light management as it should be... hierarchicaly
		
		- in conjunction with this, we should directly include our lighting system so that we're not re-testing visibility of a  mesh to a light if a) the mesh doesnt move b) the light doesnt move (or move outside of a range so that we can have swaying light that has a sweep volume that is big enough to cover all of it's potential area
		
		- so now as we cull, since we have a way to traverse and get just the lights, and actually if we have a special light traverser to subscribe/unsubscribe entities as they are added into the scene and removed or moved, we can usually ignore recomputing things since most things arent moving every frame, but just some are.
		- our culling is highly threadable


NOTE: Deferred doesnt require light management where we track which light affects which mesh
      - shadowmapping does
      - enabling/disabling of lights based on rooms and such does also
          - or is that done only during traversal via states?  
		- when a light is in a node, the portal itself can have properties which define if the light can pass fully or has to go through a frustum formed by the door... in this way you'd have to clip the lighting so that the entire floor isnt lit but just the part that is hit by the door opening.

	- the other nice thing about setting properties on the portal is that we can easily just disable lighting completely through portals for 1.0 and not worry about it.  



so i think there's two competing thoughts
	- a subscription model where items are tracked on movement
	- a traversal model where we try to set state in the draw list 
		- the traversal you just grab the lights and then retest the visible items against the visiblbe lights
		and the idea here is that you'd have relatively few visible lights and visible items to worry about
	

http://aragon-online.net/
	
- triangulation
  - a good thread.  note i did download that poly2tri c# src that the followup commenter posted about
  http://www.gamedev.net/community/forums/mod/journal/journal.asp?jn=447058&reply_id=3621289
  
- scripting		
	- scripted camera
		- how to get something like a dust bubble FX to apply to the current camera, all cameras, disable, etc?
			- and since it could be per camera, changing the mesh points would need to be tracked per camera!  that really sucks.
			Actually that doesnt suck at all.  Same goes for our IMposter System.  Make sure i modify the imposter system to do the same thing.
			All it really requires is that if during cull, our rendering context has the FX enabled, then we use it... and i think this solves where
			the FX might go.. into the RenderingContext object itself.
			
- start up screen
	- loading the intro sequence / screensave
	- transitioning to the network lobby 
	- transitioning to loading a "map"
		- playing
		


	work on my game's universe story.
	- check out GURPS:First In!  for ideas on a xcom style game.  
	- maybe play Silent Storm

	- cant seem to get lighting working for DrawPrimitives
	- then fix initial zoom of isoviews...

- review the later posts on this thread  http://www.gamedev.net/community/forums/topic.asp?topic_id=93699&whichpage=1&#484181
  when revisiting my own perspective and ortho editor mode picking.
- maybe a good time to use Ortho view to draw a scaled view of galaxy and solar systems!  Good for both my moral in terms of adding real game related stuff, and for showing in engine video..  And then being able to edit the system, re-compute stats, libnoise textures, etc
- Manually created EditableMesh is not rendering.  It's picking ok and 
     - ImportStaticEntity typically assigns a Translation using the localPosition, the idea is you drop close and then drag and position.  But for EditableMesh, we are editing in modelspace.  We only convert individual "components" when the user makes the selected geometry group a component.

- MoveOp and moving the mouse off the window causes the command to stop working... how does sketchup deal with that?

- sort mouse picking results because my manips in ortho hit bottom ones sometime
- comprehensive toolbox / selector / gui fixes 
	- mouse icon change when selecting moveTool/Selection/Line
	- ESC or rightmouseclick cancels and switches back to pointer?

   - sketchup requires that you select the things you want to move by entire component or highlighting the geometry (faces, erts, etc)  and then just dragging them.   I think Silo's way is better your select tool can be modified to work with faces/edges/objects by switching the selection mode icon.



text input should respond to WM_CHAR message.  You get unicode and localized keyboard processing automatically this way.
http://msdn.microsoft.com/en-us/library/ms646276(VS.85).aspx


- option to disable rendering of region node boxes seperate from object boundingboxes
- option to render selection box even when boundingboxes are disabled normally
- when switching views, the orthodistance value set to the axis of a previous view is not reset to 0.
- changes to viewport display settings are not updated in the ini file and thus are never saved.
    - they currently have to be changed in the startup ControlPanel
- right mouse click gridon/showbouding boxes checkmarks are not properly restored on startup to match underlying settings
- switching from ortho to perspective doesnt work because for some reason the projection matrix doesnt get recomputed
- clicking a tool doesnt depress the toolbox label item


- move the boxes to minimesh.
	- not sure how that will impact appearanceLOD

- in MeshRenderer.cs RenderDebug()
    testing for Scenes[0] is  kind of hackish.  need a proper way to verify that the mesh who's debug info
   is being rendered is currently mouseover.  I thinkthis shows us that maybe rendering deug here in MeshRenderer is wrong
    and that it should be done from Scene.cs
    the issue with that though is here we can replace the line or face textures, etc draws in the regular meshrender
    if there is debug info that needs to be drawn with it.  Perhaps one way to do that is when setting MouseOverItem
    we can there modify the LastPickResult.HaColided = false when the MouseOverItem value changes to null or a diff mesh
    or better yet, add a .MouseOver property to the entity/mesh that we can check here


- put RegionMatrix from EntityNode as Matrix in SceneNode.  Let's face it, Entities should only deal with hierarchical relative position data.
- think of our SceneNode's and SpatialGraph as part of a seperate library perhaps for collision, visibility and picking

- sceneNode creation/deletion and re-use when adding/remove/moving nodes.  
- sceneNode creation/deletion when straddling boundaries and then not straddling anymore.
	- when this is working during cull traversal, we'll need to flag the other sibling sceneNode as visited so we dont redundantly test.


- NotifyDependants and NotifyChildren needs to be completed...

- translation of the frustum across zones.  Check if planets in the 1st zone always show up correct 

- simple grid snapping system is to round off the final position of something when you get to within epsilon value of that multiple.  So if you round to whole numbers, and get to within .8 of 1.0 you just round .08 to 1 to snap.  if you round in multiples of 5, then similarly if you're at 13 and our epsilon is 2 then we round up to 15.  The only trick though is that if your prefabs lengths and widths are not in the same multiples, then you can't snap based on the center position of the mesh but must snap on where the bounding box edges are based on the direction you are currently translating the object.

- camera is always at origin so we really shouldnt push/pop anymore but i have a bug where for some reason moving th emouse causes the camera to move
  if i comment out the push/pop methods in Camera.cs

- in culler Apply (ModeledEntity entity) i was using
Vector3d entityPositionRelativeToCameraRegion = entity.SceneNode.Position - _relativeRegionOffsets.Peek();
entity.Translation instead of entity.SceneNode.Position and this is wrong because we want region relative positions which sceneNode's use and not entity relative translation with respect to it's parent which is what all entities use!  I should permanently move RegionMatrix to SceneNode as just Matrix knowing that all SceneNode's have region relative matrices as well as moving the BoundingBox region Update computation to SceneNode as well.
WARNING: the only thing to watch for is the fact that eventually we will need multiple sceneNodes i believe for region boundary conditions.  If sceneNodes only have region specific coordinates, then we need seperate ones to represent an entity that is straddling a boundary.. one for each.  So in this case when we want to grab a RegionMatrix or a Position, we need to grab the one from the SceneNode that is within the current region we are in during the traversal.
WARNING2: I think in picker when I traverse i'm also not using for hierarchical children entities the proper camera space translation


- after OnUniverseCreated in formMain, i'm saving the archive to a temp file but then when I reopen it after generation and presumably start paging in data and then try to "save as" to a real name, im only saving part of the overall world and im never copying over the archive which is basically what i should be doing in the first place since there's no way to do a top to bottom re-save of a unvierse so the tmp archive is critical to have and then for the new archive to be open instead. Tmp files though can remain the same i think.

- Regarding our FXMinimeshRenderer
  - two options seems to me.  You can have items subscribe\unsubscribe as they are added/removed from a scene and then during traversal we set the InFrustum flag so we know which ones to draw.  The upside here is that we dont have to add these items to a render list during traversal.  We simply check the subscribed one's flag.
  - the downside to that option is you do have to constantly track subscribed and unsubscribed elements properly, and you do have to itterate serially every subscribed element to find if it's visible or not.  
  - the other option of course is to simply not have any subscriptions and to simply Add items to the proper list in the FXMinimeshRenderer if it's visible and has it's UseInstanceRendering flag set.
  - another 3rd option perhaps is this, we dont really have to "add" items to the list as we traverse and we find a UseInstanceRendering = true.  All we have to do is update the scale,translation,rotation for that element in the InstanceRenderer.  So you'd need something like
  FXInstanceRenderer.AddInstance("instanceKey", position, scale, rotation);
  and what this would do is find the right renderer within the manager and then simply update the array list.  So it seems the options are 3, with the origianl subscriber option and this one being the most desireable.  The downside to not subscribing is you have to reference by the Mesh3d name so there is some indirection here.  If you're directly subscribed and we have multiple FXInstanceRenderer then we simply do geometry.FXInstanceRenderer.AddInstance()  


asteroids
- a mix of tiny insignificant ones
- some that are effectively just like planets, small moons except "maybe" they can have actual orbital freedom like a spacecraft and not on a fixed path like a planet.
- but wouldnt all still be in an octree and thus subject to bounds checking?  ugh.

after looking at http://www.youtube.com/watch?v=O8IwSt_mflQ
http://www.infinity-universe.com/Infinity/index.php?option=com_smf&Itemid=75&topic=5260.0.html

it seems to me that putting these things in an octree seems insane... way too many.  maybe the prominent ones that can be manipulated perhaps, but these should total fairly few... the common tiny ones should be modeled more like grass and perhaps just need a way to be "tiled" around the player as he moves... they can be in a single minimesh and just have their positions adjusted to the visible range... say farplane radius 

Octree
 - normally when you insert an entity into a scene node, it has its own scene node for world position even if it's a child of another entity it doesnt share the parents scene node because only a scene node would have a region centric bounding box for that child.  but the the thought of having scene nodes under octree is a bit scary... its allot of extra mem 

- bah, i remember that one thing about keeping entities attached to standard EntityNodes and then attached to the octree is that i can still have hierarchical entiies with cumulative bounding volumes that way... but meh... then those entities too need scenenodes still... but thats not new.  I cna offload some of the increased memory by removing BoundingBox from entities altogether.  They can reference a box via a property that then points to _sceneNode.BoundingBox

in the view matrix, the lookat vector is subtracted from position to produce a direction vector that goes into the matrix yes?


- now with simple circular orbits working, im not updating the bounding boxes for sceneNodes
- interim fix for scaling is to save the meshes that are built by tv3d during worldgen with different filenames
   based on the body name
- white sphere for star at accurate size?
- manipulator in EditController2 in Pick() is null after loading in galaxy
- controlling another ship via my 3rd person controller
	- controller switching

- planet billboard
- planet position scaling to bring it closer and at smaller scale to compensate so it appears same distance
- flag for disabling farplane cull test... has to be in sceneNode readable from the Entity it hosts
- custom projection

- ship paths and ship steering
- ship to ship collisions


        -view frustum near/far should be saved / restroed from the world's sceneInfo xml


        -Have all sky implementations assert the farplane value is far enough


        //Trace.WriteLine( System.Reflection.MethodBase.GetCurrentMethod().Module.Name + System.Reflection.MethodBase.GetCurrentMethod().Name);
        // StackTrace stackTrace = new StackTrace();
        //StackFrame stackFrame = stackTrace.GetFrame(1);
        //MethodBase methodBase = stackFrame.GetMethod();
        //The call to GetFrame(1) retrieves the stack frame of the immediate caller.
        // So that you can write a function that will always append the Name's and such for you no matter
        // where it's called from.  Of course using the stack trace is sloooow.



// FXBloom needs a seperate instance per Viewport
//   - in general consider how to do this for these sorts of things.
// - ask Arius about post shaders, why not use lastmainbuffer frame to avoid having to re-render everything? should it work?
//
// ask Sylvain about RS cameras.  They seem to default to the first camera rather than even the current camera.
//- he says each camera creates its own RS (just as Mith said).  

//
// FXImposter ideally would as well because you wind up with RegenAngle drastically different between frames and 
//   -- of course in actuallity, we dont really want to allow imposters to render in two because right now our InFrustum checks resets this flag

// fix the RenderCB.Invoke  to handle Far (sky) and Near stuff seperately

// controllers init'ed and switched on demand depending on player or edit, etc
// viewports and proper camera management
//  - when viewport resizes, the underlying renderer needs to resize, but more than just that
//    because right now the primary viewport draws on the full form ok, but the resolution does not change so everything is stretched or shrunk

// proper picking in all viewports NOTE: Resizing our Editor's document requires we recompute the height/width of our Viewport so picking will be correct!


if a Repository item's refcount = int.Min (a negative value) then perhaps that is a special case where the item is known to be a permanent resource that only gets unloaded upon engine shutdown...  but those items would specifically need to be unloaded manually as well since disposing them wont do it...


so any "widget" manager should do this.  Arcballs and portal markers and such should be created through there


On physics updates, i had thought about the issue i have with mouse and low framerate as well as how i would eventually implement physics with a single loop that did not explicitly seperate input and rendering threads yet still allowed physics to run at a constant rate... the answer is actually not new... you skip rendering and keep updating physics until you are running at the proper hertz per second.  Not only that, but those updates should be run at a fixed time-step so that the simulation can be predictable across all clients.  


doing a "modeler" is just allot of shit frankly and more than that, i dont want users to have this much freedom... it'd be impossible to make sure models are "ok."  We need to have a proper balance.  We need limitations but still good freedom.  Vehicles rules are like this.  We need something more like First Person SHooter Creator.  

- I like their animation tree editor -> http://lynxengine.net/blogs/index.php?blog=6
they are able to tie in the animations with a state machine.  Note: dont get confused and think the controller icon represents a user input, it just represents a "state" change and that state change can certainly be done via the keyboard or mouse or gamepad inputs.

- on why blue planet atmosphere is not rendering properly...
<Aion> alpha sorting
<Aion> if your render order is Land ->hair > actor... your hair can only blend with the land

entity explorer
Vehicles

Buildings

Characters

Lights

Heavy Weapons (fixed)

Light weapons (wieldable)

- need to check DeviceCaps on my own at program start and not rely on TV3D.  I believe DeviceCaps can be tested prior to initializing a window.


re: ship regions (decks + sectors)

- when you create a new "deck/sector" you will be asked to set the height of the sector (default is 2.5 meters = ~8 feet.  minimum is 1 meter such as for a crawlspace) and the 
  cubic x,y shape.  minumum is 1 meter x 1 meter, default is 4x4

-the first thing you do is plot out the shape of the region's internals.  I mean it's _always_ rectangular, but you can define the various rooms and such that are contained within it.  The key thing to know aobut a region is that it's page-able so region's should be designed in a way that helps with performance when running a particular ship.

- if you have any wall pre-fabs of the proper size, those can be selected, however they must have proper dimensions.

however, if you want to be able to use the default 



Stand Alone Server Modifications
- what to load, what not to laod
- Zire uses procedural so he can just load on demand
	- we can use procedural in terms of the client knowing how to generate textures and planets, and we effectively use procedural to generate star systems, and can then compute an orbital position based on the current time.  But I think initially in terms of the server or loopback holding the entire universe.. that is at least in terms of holding region arrays, that is something we'd have loaded and to what degree things would be loaded, is more loosely handled (empty region with seed, sphere bounding volumes, ship hulls, and then actual geometry and textures for client...



this.ribbonControl.Expanded = false;  <-- that will hide all buttons, but not the tabs
this.ribbonPanelEdit.Visible = true;
this.ribbonPanelContext.Visible = false;

http://www.gamedev.net/community/forums/mod/journal/journal.asp?jn=345337&reply_id=3661606



http://my.bzflag.org/w/Network_Protocol#Message_types
from BZFlag
A player normally only sends an update when its position or orientation as could be predicted by other players differs from its true position or orientation by a certain tolerance. Other players are expected to use the last known player data to extrapolate the current position and orientation. This technique is known as dead reckoning and has two primary benefits: network traffic is decreased since updates needn't be sent continuously and players on systems with slower frame rates appear to move smoothly to players on systems with faster frame rates. 

Rather than spam position and such, in my game i really should be able to get away with only sending a server update once per second unless my velocity or angular velocity has changed.

----------------------------
RegionNode - RegionEntity
      VehicleNode - VehicleEntity
			EntityNode - StaticEntity (exterior model)
				EntityNode - StaticEntity (turret)
	        InteriorNode - InteriorEntity 
			      EntityNode - StaticEntity
				  EntityNode - StaticEntity
				  EntityNode - StaticEntity
				  PortalNode -
				  
	http://www.livestream.com/nekose/video?clipId=pla_da77550d-8d44-4675-9ff2-934ae890b726&utm_source=lslibrary&utm_medium=ui-thumb
	
Lasers or projectiles that hit the exterior of the ship are transformed by an inverse matrix to put them into interior space coordinates
Culling always has the RegionOffset stack starting from root region and so should interior portals connect to the root
	- the difference is when camera traverses through a portal, we first need to push the camera's region/position, then compute the region/position that the camera would be in for traversing objects on the other side of the portal so that's simply 
	
	/// Portals in the Interior to Exterior connect to the root region and during rendering from interior through
    /// an exterior portal, we render in the local space of the Interior region.
    /// 
    /// Portals from the Exterior to the Interior are attached as children ofthe Vehicle\Container and point
    /// to a destination that is an Interior region within that Vehicle.  At this point during culling or drawing from
    /// exterior to interior we do have to transform the interior entities by the RegionMatrix of the Vehicle
	            //    SceneNode node = Core._CoreClient.SceneManager.SpatialGraph.CreateSceneNode(entity);
            // todo: in the initial case of creating a universe with tons of regions, we dont add the regions to the spatial graph
            // thus there is no _sceneNode to add Star Systems too either so we have to check for null
            //      if (_sceneNode != null) _sceneNode.AddChild(node);

            // what to do about multiple sceneNode parents as you recurse?  which parent does the child scenenode get added too?
            // well i guess there's two types of sceneNodes, there's the basic kind that just encapsulate a bounding volume.. those
            // are usually for non region entities and they always have just one scenenode but it can have multiple parents.
            // the multiple parents then must be a kind of RegionNode or SectorNode.  
            // I had how i was going to handle entities in sectors but im forgetting...
            // i do recall one basic prinicple which is that sectors do NOT have their own coordinate system.  In this respect
            // a Sector is really like a type of spatial node that we DO save to file unlike other types.  Thus, entities
            // in a sector are basically placed under these sector"nodes" without a need for any other type so you have
            // Portals too then can be (maybe?) purely spatial constructs that connect SceneNode's to SceneNodes.  All entity traversal
            // pathfinding, culling, etc is done through the spatial constructs, connectivity graph, etc.

            // So when an entity wants to path find, it must be connected to the Scene (thus have it's own scenenodes) and it must traverse
            // through the spatial graph. Thus lots of things can be relegated to the scenenode's for AI such as paths perhaps and connectivity graph?
            // Consider that with a CG structure contained with a RegionNode, and with RegionNode's being connected to other RegionNodes, then 
            // having CG sectors point to CG sectors in other RegionNode's is a simple matter of ensuring that all edge faces of CG cells
            // that border the RegionNode's bounds, that they result in a traversal to their RegionNode's neigobr and then dynamic pathing can be 
            // used to find the right cell within that RegionNode to continue at.  Thus the main difference between CG sectors/portals is that
            // they arent used for culling because they are too course.  So, they'd need to be sub-graph within a RegionNode seperate from the other
            // Sectors/Portals which in effect are a higher level connectivity.

            // Seems to me then with connectivity of scenenodes (portals would be a scenenode type too) then the whole "connect interior portals with exterior
            // views to the root of the scene is no longer necessary at all because now instead we just traverse via connectivity from inside out.
            // Traversal isnt done through a portal frustum but directly via a list of neighbors.

            // so a question is, isnt easier to just have connectivity done via non SceneNodes as directly Region to Region? Why use SceneNodes for that
            // at all?  Well for one thing, connectivity is a spatial issue not a hierarchical one so aesthetically it belongs in SceneNodes.  But why else?
            // NOTE: Another key difference between connectivity and portal frustum is that connectivity doesnt care about path to a neighboring region
            // it only tells you who the immediate neighbors are.  Thus, a portal that generally says "to exterior" can then create the portal frustum
            // and then start recursing through all exterior neighbors rather than going to the root.  This also means we dont even need a root anymore AND
            // it might simplify camera tracking since a translated camera must traverse through a connected neighbor.  We can use raytest to find
            // the path, and provid collision response for attempts for paths that dont lead to a neighbor (e.g. edge of world)

            // ModeledRegion  <-- shares aspects with ModeledEntity and is treated as NOT having it's own coordinate system because it's position
            //                    and such that it just gets rendered exteriorly like any other entity, however it can conton another region that
            //                    does have it's own coordinate system
            //      Model   
            //      Region Interior;  
            //            SceneNode[] Sectors;  <-- these do get saved to xml.  Portals from here go where?  Recall that portals are in region coords
            //                                  but interior/exterior boundary ones can find themselves needing multiple destinations that are dynamically updated
            //                                  But with sectors inside here like this, doesnt that break our seperation of entity graph and scenenodes?
            //                                  A better way perhaps would be to have Region.Entities[]  and then for each individual entity to have it
            //                                  connected to 
            //                                  
            //
            //            can't recall also how this fits/doesnt fit with our armor and vehicle frame modeling...
            //            actually it seems to work ok.  Frame are the wall and floor segments we lay down and Armor can be layerered onto the exterior
            //            of a frame to provide defense.  So if you have an adjoining room, does that mean the shared wall cant be armored since
            //            their is an interior side?  not exactly.  a bulkhead is basically an armored interior wall right?  or is it just a heavyier frame wall?
            //            Or, if a frame is just the skeleton and armor must be layed as paneling, then that's different.  Frame relates to structural strength.
            //            A room with a weak frame might have limits to how many decks can be above it for instance... and armor weight likewise is limited by 
            //            the strength of the frame as well.
=================================================================================================
=================================================================================================
=================================================================================================

if we simply add the entity immediately without it's underlying resource fully paged in, we could have some easier time dealing with undo/redo... hrm.. 

so we have our seperate scenes and each scene has a simulation, but that seems to me to suggest that all entities must be know to each scene so that during simulation itteration, its only updating entities for that particular scene...  that way scenes can be independantly suspended and not updated... however there is an assumption i think that different scenes are still apart of the same overall "simulation."  Scenes only reflect unique instances... such as instanced missions for example.  The primary advantage of a "scene" is that you can have different fx used on them?  Meh.  i r mixed up on all of this... hope this wasnt all for relatively little advantage.  At least hopefully i can get all the scenenode management working properly :/

<infact> those books just present techniques with extra math background
<infact> get any real paper about physics and the references list should be enough to work with
<infact> http://graphics.stanford.edu/papers/rigid_bodies-sig03/
<infact> http://www.cs.cmu.edu/afs/cs/user/baraff/www/pbm/pbm.html
<infact> http://www.continuousphysics.com/ftp/pub/test/physics/papers/IterativeDynamics.pdf



whenever an entity moves, changes parents, is added or removed, the spatial relationships need to be managed.  This involves determining if an entity needs to maintain a bounding volume under multiple scene node parents when it's bordering
	- move under parent
	- move between parents
	- move into new parent
	- added into new parent
	- added into new parent and removed from old
Well, I need some rules... hierarchical relationships can't be broken except for specific actions
   - an item being carried is dropped or jettisoned
   - an item traverses thru a portal that connects to a seperate coordinate system

WAIT - we can flag an entity as having moved, or added or whatever, and then in .Update() when all moves are finally over can we handle the changes to it's spatial SceneNode including the boundary cases of moving across boundaries and such.  When we "addChild()" we no longer need to do any sceneNode management there... we simply do it in update.  We can recurse children and update those then as well so long as we clear the flag so it's not done multiple times.

=================================================================================================
=================================================================================================
=================================================================================================
=================================================================================================
controllers
=================================================================================================
=================================================================================================
=================================================================================================
I tried to switch to a single edit controller shared between all editor viewport cameras, but there's some issues :/  I could potentially make it work if i stored settings in the Viewport class itself so that the EditorController could always operate within the context of the "state" of that current viewport in a loop over all viewports.

It's very annoying to have a seperate edit controller for every single viewport.  There are some specific settings per viewprot like camera speed, but again, those can be grabbed by the edit controller as it Updates().  Part of it's update is to itterate all viewport cameras it might be attached too.  Now currently there's actually no issue except maybe with camera speed being per viewport... that's because usually you'll only ever have one perspective viewport and the rest orthographic and perspective is the only view that makes use of hte Controller.Update() for continuous movement of the camera....   that said, i wonder if maybe i could have the Keyboard device send time-matic keystrokes for held keys to keep things event driven... but at least now that we are down to 1 edit controller, let's not worry about it.

i think for manipulation mouse + keyboard things on screen, a better method to what i have now is to use an "active handler" as a strategy pattern type object and for handlers to be switched depending on things like picking or mouseover.  If an entity has a controller, and if it's mouseover, then it's controller becomes the active controller until a condition or event makes it inactive and the default handler resumes (e.g. EditController)

  actually, our EditController needs to be modified a bit such that it's a SystemController that has an EditController as the current sub-handler and then other handlers can get pushed on the stack or something.  So SystemController can still do MouseOver per frame if the sub-handler doesnt disable that prior to being released/popped off stack.
	-WARNING: but consider a Gizmo only appears in the scene when something is picked.  


Editor Feature To COpy
--------------------------
http://www.youtube.com/watch?v=N9XsXwIe9mQ    <-- i like the simple fast method of copy and pasting scene elements.

        //// TODO: see below for help on snapping to grid point.  We will use either land or if no land available in a region
        //// we will use our own grid values (which perhaps user can modify) for the grid line calculations.
        //// http://www.truevision3d.com/forums/tv3d_sdk_65/snap_mesh_to_nearest_land_vertex-t17719.0.html
        ////            Core._CoreClient.SceneManager.EntitySelectedCallback.Invoke(pickedEntity);


TERRAIN EDITING
amazing landscape editor. really makes you think "to hell with procedural landscapes"
although procedural is probably still ok for some basic mapping but probably better to write your own code so at least you can ahve it
work on islands and such
http://www.youtube.com/watch?v=B6_J9wOw8ow&eurl=&feature=player_embedded


the cloning, snap to grid and scaling of this editor is great! Definetly things to copy!

http://www.youtube.com/watch?v=xzrr4wZtn_0&fmt=18
http://www.youtube.com/watch?v=awmsY0_U2HU&feature=related
http://www.youtube.com/watch?v=1aGJaqSKyZI&feature=related

I love this modular spacestation design
http://www.infinity-universe.com/Infinity/index.php?option=com_smf&Itemid=75&topic=9495.0


----
chainTo()
http://www.gnu.org/software/classpathx/jaxp/apidoc/gnu/xml/pipeline/EventFilter.html
meh.. just reminds me of how in X3D you can chain things via ROUTE
----

how woudl an NPC activate an elevator button for instance?


Project Explorer - just the loaded stuff (a scene graph but of entities and spatial/pathing info only)
Resources - this is just either viewed from Import open dialog or a dir tree tab
Library - these are available "nodes" - we'll have the ability when wanting to set appearances or entity scripts, etc to always use the current ones that are in the "quick assign" slots... similar to MSPaint's fore/back color slots.  when selecting a resource there is a preview window and its the same preview used for material preview, texture preview, etc?


RESOURCES
-raw resource files like .obj, .tvm, tva, bmp, dds, .terrain, 
DATABASE
but then we also have our saved appearance nodes, material nodes, texture nodes, models w/lods, bonedmodels... basically every IResource type that is NOT an entity.  
-MODELS
-APPEARANCE     <-- should appearance just be apart of the model? We certainly dont want a bunch of GroupAttributes and crap.  Then again, if you have an "appearance" selected already, and you can give it a name like "asphalt" and it's already got the texture and material set to it... then that can simplify things.  hrm.  similarly with walls... being able to treat "appearance" like a complex "brush"
   -MATERIALS
   -TEXTURES
   -SHADERS
LIGHTS
 - http://www.youtube.com/watch?v=p_6eoGIigI4  <-- good light editing ideas
-ENTITIES
Entity Browser is trickier... a ship is basically a hierarchy of entities...


so yeah i think i do need to go back to my original idea where "import" will create the xml-ized versions of things and add them to our 'data' library.  I could keep the xml, and any related texture in the same directory to make it easier to replace them... but thats no good really because when you "delete" an entity from the library you wouldnt want to delete the underlying resource since you might not have copies anywhere else on disk... so you _would_ want to keep the raw files together too... hrm...  But also recall that before i had "Appearance" above a Model because Model's had instance data and then i changed this when i introduced the Entity object which would instead hold isntance data and allow Model's to be.  ANSWER? ->  Material, Shaders, Textures can be saved seperately, but NOT Appearance or GroupAttributes.  Instead, a user can go into an "Appearance Editor" for a Model and choose textures and materials and shaders from the library and import new ones if needed.

So our simplified method of setting "appearance" to a node is all done behind the scenes.  There's no need to list "children" instead we can directly just edit LOD, Appearance, Behavior, etc.  The fact we have a hybrid scene graph underneath is irrelevant.  

data\assets  ?
data\resources
    \resources\textures
    \resources\meshes
data\library\
    \library\vehicles
    \library\buildings
    \library\models
    \library\bonedModels
    \library\appearances
    \library\vegetation


Animation GUI Editor
MindFusion makes the diagram/flowchart component blind used in his fx editor
http://www.mindfusion.eu/


UPDATE: I like the way neoaxis screens has a "resource editor" which i think is basically really a "node" editor for being able to edit "loaded" nodes or library nodes.  I like how it "smartly" decides what set of modifying pages to show based on the type of resource


When editing a boned entity for instance, our property editing is abstracted so we have  
BoneEntity
    - general tab
    - model tab  (can set LOD's and ranges, and appearance (texture, materials, shaders)
    - physics tab
    - behavior / AI tab


=================================================================================================
=================================================================================================
c# physics related
=================================================================================================
=================================================================================================
=================================================================================================

http://www.codeproject.com/KB/directx/BelievablePhysics.aspx

matrix.cpp Invert()
http://nccastaff.bournemouth.ac.uk/jmacey/GraphicsLib/html/_matrix_8cpp-source.html

http://www.nigels.com/glt/doc/matrix4_8cpp-source.html
http://www.truevision3d.com/forums/showcase/earth_moon_65_downloadable_src_media_bin-t11713.0.html


Now that i think about it, our IPhysicsEntity is fine and should contain properties for enablePhysics, affectedByGravity, etc
and really our actual physicsBody should be a PhysicsController?  to be consistant with how we want to have our control logic seperate from our entities just like buttons and such.  Well there is such a thing as a "PhysicsControllre" and I think what we need to do is move some more functionality (like the apply() series of functions) into PhysicsController and have PhysicsBody be much more like an implementation of IPhysicsEntity.  Hrm, controllers are a bit different in bepu's physics.  In his they are created to control collisions and after an object becomes stable they are removed... So controllers are basically offer coherency for collisions objects between frames.  One difference is we could rename Controller to CollisionController and PhysicsBody to PhysicsController


- the long loading times im seeing is cuz of the FileManager write... not good.  The worst part is it seems to take place on the main thread and not the background... grr...

- Infinity (Journal of Ysaneya) deferred rendering... could be something i want to do too)
http://www.gamedev.net/community/forums/mod/journal/journal.asp?jn=263350
he gives  agreat explanation of how it works.


- finish the bepu demos
  - will require a basic IPhysicsEntity so we can verify translation and such work back and forth
  	- need to be able to suspend physics on an object that is being dragged or grabbed by a grabber
          ideally this should be done via the IPhysicsEntity interface to set the IsPhysicallySimulated = false and true afterwards.

- add the Kapow as a type of entity that can be controlled via EditController

- see if we get same good results, if they all work then i think we can say we have fixed all bugs introduced during the integration
	- part of this will entail shooting out an object so we need hardcode probably for that
- would be nice to be able to click on an entity in the editor and change it's physics attributes at runtime


velocity = momentum / mass
linearMomentum = velocity * mass

apply linear impulse simply += to momentum so if momentum = 0 and you applyImpulse of 100, then for a 100kg object, velocity = 1


consider the order of operations 
 - main loop update
     - based on input, udate direction and velocity and such
     - run physics
     	- physics resolves collisions and advances objects
        - physics notifies when an entity has been updated



Entity--------------->SceneNode <-- merge with CollisionPrimitive?  i dont think thats wise...
 \__PhysicsBody
        \__ PhysicsController
        

Entity--------------->SceneNode
\---CollisionPrimitive -->  with references to both Entity and PhysicsBody 
 \__PhysicsBody
        \__ PhysicsController

What is the difference between a CollisionPrimitive and a SceneNode?  
	- Both we'd like to have hierarchical representation in WorldSpace. Right?
        - CollisionPrimitives tend to have specific derivied based on the type of the entity... 
		-so spherePrimitive.  How does this fit 
		- convex hull
		- triangle mesh
		- cylindar
		- capsule

clearly cylinder and capsule and triangle mesh wouldnt be used for culling so a collision primitive is different than a spatial graph node...


Now what TV3D does, and BEPU and I think most games really, is they have the collision and physics data structures as seperate but with an object reference form the PhysicsBody to the Entity, and from the Entity to the PHysicsBody.


There are two downsides there, one of which at least I think i can avoid.  I _can_ share boundingbox data but I don't think hierarchical bounding / spatial structures I can... i'm not 100% sure yet but it seems like it would be difficult...

  hrm... spatially i have sceneNode's which are fundamentally hierarchical bounding volumes.  In many respects, they are like a collisionprimitive except structure...  but then things like RegionNode's and Octree's dont make as much sense...  hrm...



http://cdn1.ustream.tv/swf/4/viewer.110.swf?cid=1/581508&varnish=true

http://www.euclideanspace.com/threed/games/options/timestep/index.htm



=================================================================================================
=================================================================================================
=================================================================================================
=================================================================================================
=================================================================================================
lidgren notes
=================================================================================================
=================================================================================================
=================================================================================================


*** I get how acks are generated.  It'd be nice if stored messages and resends could be made a little more generic so that even if automatic reliability is turned off in the library, the user can externally do their own resends by calling those methods directly.

This way we can also directly alter the buffer if need be, if for instance we want to use delta packets where some new packets will replace previous packets.  However, maybe that is best done outside of the app entirely...  but there's the rub, we would still need to be able to associate those acks, with a buffer that is changing to include more and more accumulated deltas.

**** So how would delta packets be retrofitted?  You have a message that is of a commandID.  If you get a new command that has updated info, you could search the outgoing buffer, update the relevant bytes, and not quite sure about how to adjust the acks because if these are being sent UNRELIABLE, then we need ACKS to be sent anyway... unless for NetChannel.DeltaPackets.  However the CreateAcks() shows us that if we create the Acks on the fly, we can pack them better.  Similarly it seems, if we created the delta packet buffer on thefly using just the commands (outside of the library then) then this could be good.

      *** So again, how would we deal with acks here?  Acks tell us which commands in our history can be removed in the creation of our "delta packet."  So part of what we'd need then perhaps is an option to get an event for when an ack for a deltaChannel ACK packet is received, and to be able to know that an ack with a certain id automatically removes the need for all commands less than a certain timestamp.  So the critical aspect is that we are able to identify the ack.  This is elegant because this way we're still just looking for a specific ack and the trick wrt to the delta packet is to not "store" the message in m_messageSTore because it wont use Reliable.  It'll just be a special UnreliableDelta that will generate an ACK.



- the main server code is single threaded.  
- it uses i think queues only because while that thread is read/sending messages, the calling application of the library can be reading/writing to those queues from any of its threads and so it needs to use locks so that the calling app can be multithreaded.

- so this doesnt change the fact that we will want to use IOCP, but it does reinforce the idea of maintaining a common queue at least until down the line when we might use an external queue such as MSMQ

LIDGREN + COMMAND WRITING & READING
---------------------------------

1\ to host a server, you need to authenticate and then you'll get added as a service that other users can log into
that of course could easily be hacked on the client side with an exception that you can still run server initiated re-checks to authentication
at anytime to ensure that the client is legit... this means they would have to decrypt and sign with a key they were given proving that were able to receive it


Networking Notes - Instances
**************************************************************************************
- x,y,z - w coordinate is for instance id and entities can only see each otehr that are on the same w coordinate.

- get within a meter of hidden objects (things that can be scanned) before the server will send you entity over the wire so you can't hack it.

On AI - A.I  A.I. Artificial Intelligence
---------------------------------------
Anti-Objects
Alexander Repenning' (http://www.cs.colorado.edu/~ralex/papers/PDF/OOPSLA06antiobjects.pdf
http://www.google.com/url?sa=t&source=web&cd=4&ved=0CB8QFjAD&url=http%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fdownload%3Fdoi%3D10.1.1.71.5457%26rep%3Drep1%26type%3Dpdf&ei=1T59TLSLCZDksQPfsuyDBw&usg=AFQjCNFoBz0X_URcw7ko_fVBOEBles0NBQ

- celluar automata grid of the entire universe... in fact our "Sectors" are our sector based grid that our AI uses for determine which sectors are of most value.

- for AI routes, i could have a lower res version of the universe... one that doesnt simulate certain things in real time if there's no users around.

- for AI squadrons, we can use a localized grid that is centered around the squadron leader.
------------------------------------
On saving/loadng campaigns after each lossed battle as people do in Civ
----------------------------------------------------------------------
In GDC 2010 keynote Sid Mier talked about how there are players who will fight a battle and lose it very badly and then reload the previous game
save and replay it and lose and replay nad keep doing it til they get the best possible outcome.  

So in Civ Revolution, they included the game random number ID in the save game and so reloading the game would re-seed it to where it was before and so the outcome will be the same.  I do like this idea.  You can't re-roll dice in monopoly to get a favorable outcome.  However...
in Civ the problem i think was sometimes the flawed way that combined arms works and how the player had little control over battle orders.  That aspect made these large battles feel like the player lacked control.  This was a flaw in Civ i think... like not being able to send in a weak force first instead of your best force that gets annialated early on.

On Ship's Security
-------------------------------------
watching Enterprise reruns and it'd be interesting if sabotage were a key feature in our game how that would 
influence ship design and crew security assignments (patrols, guards, checkpoints, security clearances and access levels to various parts, etc)

On Sensor Buoys, Drones, Satellites
--------------------------------------
Would be really cool to be able to drop various sensor drones and satellites that we can then access and check the logs or even be notified when various ships have been detected as entering/leaving a sector. You get some ship stats (ID if known, otherwise various detection stats) along with current or last known position and headings)  But essentially, i like the aspect of star trek where they come across a ship or drone or something and can access the logs to try and find out what's happened.


On Ship's Armor
----------------------------------------
http://efni.org/armor.htm


IN TERMS OF RELEASING MY GAME FASTER
-------------------------------------
Must prioritize for for a simple 3d version of Begin / STCS and complete that game, test that game then work on extending 
	- lua football style play managment fleets\ships\fighters that you've given orders to
	- Game Development With LUA (Game Development Series) by Mark Manyen

	- networking, communications, website

	I think really nailing the above, no ship boarding (you can disalbe ships and press a button for "boarding/capture/hit&run" etc but it's all just automated on the server with no internal view.

	Save internal views, planet assaults, etc for the Krellan Commander version which could either be the full blown 4x version or just as a Dynamic Campaign engine add-on that gives you missions, manages enemy AI and friendly AI, and manages deployments and such.  Then the 4x version is a game where you get to play as the Admiral of the Space Force and control all strategy, deployments, build requests, etc.

	
Space Fighter's game

i've been thinking of the 4 main games ive had in mind (Begin, Krellan Commander, 4x, X-Com) but after seeing
games like FreeFalcon5.0 vids on youtube that have different jets with different cockpits with every button and guage functional via mouse, it made me think wouldnt it be cool to try and make a real physics space fighter simulator that is just hardcore combat with a realism similar to a hardcore flight sim?  I think it would be pretty fucking awesome and be a good niceh and make use of existing tech im developing.
http://oea.larc.nasa.gov/news_rels/2000/art/glasscockpit/JSC2000E10522.JPG
	- a shuttle like this would be more used as a stealth bomber and a electronics warfare, eye in the sky + jammer + refueler.  It would NOT be well armored or even armed. It's loaded with so much electronics that its really just designed for electronics warfare, jamming, and some variants would be good for transport, refuelers, and various other support roles.

	-HOWEVER, i think the design of our Win32 Ribbon toolbar and floating windows and such should resemble an MFD style display where buttons on the MFD can be remapped to fit with whatever program is running in the display.  This is a good philosophy i think for designing our GUI.
		- Also thinkin gabout the Primary Flight Display  http://en.wikipedia.org/wiki/Primary_flight_display
	and how one thing that would be displayed there isnce there is no "horizon" is to make the primary flight display always be cyclable to be relative to some target such as your carrier's orbit.  That way your primary flight display has a reference point that you can always use to determine where you are in relation to it and where you need to be.  
	- Having relational waypoints as well since a CAP has to form to protect a THING and that thing is often in an orbit so is moving.  So this is actually an innovation in the genre i can make

FIREFLY - MOUNT AND BLADE
------------------------------------
Fascinating seeing the creativity of mods for Mount and Blade like the western mod 1866 and the screen of a soldier in a saloon using the back of a chair as a shield.  Wow, how cool is that?  Makes sense too, a shield and a striking weapon or a gun vs bow... all the basic actions are legal in any time or period.  So why not use the back of a chair as a shield?  Makes perfect sense...

So id love to emulate the modability of a game like M&B and allow users to make their Firefly mods, whatever.

Now the newtonian physics could be modable in my engine to make mod making more doable for different universes.  I can have newtonian orbits, simple newtonian where just momentum is preserved like bablon 5 starfuries, or arcade style play like star wars where you slow down if you're not thrusting and you dont drift forever.

That all said, the part in Mount and Blade that is missing i think is the flexibility of scripting NPC's and triggers and the like... the amount of scripting to more accurately build what alot of mount and blade players feel like they're playing.. a MUD... a 3d mud in a fully simulated world.  VRML style MUD.  But what's lacking is the ability to do more in terms of scripting... 



REALISM - 
------------------
SensorScanTime Option Select - Realistic, Arcade
	- http://www.deepdivision.com/quickstart.htm  <-- checkout that quick start where once you start a scan it actually takes several minutes to complete.
	this is a definite thing about our spacesim i want to at least have option to have... performing a scan both of a planet, an asteroid or scan pattern for detecting enemy ships should take time and be based on the tech of your sensors and such.

Scanvenger\Collector\Cargo Drones - instead of a teleporter or a tractor beam, send out scavenger drones and perhaps even spear nets that can be launched connected to a teather and the net itself uses some advanced "sticky" that grabs things like an octopus and thus can be realed in quickly.

To fasciliate some of this complexity of 
	- docking procedures / protocols
	- contact protocols
	- etc
	- WE can have a dynamic smart help that based on whatever the user is currently doing or wanting to do, it will pop up with all of the shortcut keys, the info they need to play the game properly.  The beauty here is that there's no incentive to not come back and play again because you've forgotten something, the game will remind you.  
		- To keep the realism theme going, it can even be portrayed as the "Procedure Checklist"
	


STAR SYSTEM GEN
------------------------------------

To make spiral galaxies or sphere clusters or whatever, i simply cull those space sectors that dont fit within the sphere or elipsoid prior to attempting to generate a system there.  Simple.

=================================================================================================
stellar systems
=================================================================================================
http://www.mpl3d.com/Featuresv12.htm
	- 	shader: New logarithmic brightness system for the stars and the starfield. It is based on the real apparent magnitude of the stars, that fits the logarithmic perception of the human eye, giving a more natural sensation to the star rendering.
	- shader: Ring system using 1xN lookup
	- shader: Improved starfield, that applies the logarithmic brightness system and is affected by the 'solar filter' option, as well as new textures for star flares and atmospheres, to be applied accordingly.
	- New camera speed algorithm. The camera speed is now directly proportional to the distance to the surface of the closest body. In this way, the closer the camera gets to the surface, the slower it goes, allowing a much better control
	- The brightness compensation algorithm is a part of the new logarithmic brightness system. It causes a 'blind' effect based on the visual magnitude of the brightest body in the screen, and its distance to the center of the screen. It will fade out the brightness of all the dimmer bodies that are in the screen. This option can be set On/Off independently. Default value is On.
	
- PICKING for planets and stars not working.  
	- add debug writeline for all picked objects that are not being edited in realtime... 

Although the gas planets are lumped into one category, there are also subcategories among them. Astronomers differentiate between the classic or traditional gas giants and the ice giants. The traditional gas giants are like Jupiter and Saturn. Jupiter is considered the model for traditional gas giants. In fact, gas giants are sometimes also called Jovian planets after Jupiter. They are comprised of mostly hydrogen and helium. While ice giants do have some hydrogen and helium, they are mostly made up of ices such as methane, ammonia, and water. Methane is what gives Uranus and Neptune their blue color. (Uranus and Neptune are the two ice giants in our Solar System.)

- in order to render all my stars, i have to know all of their locations.  These will be loaded into a seperate type of "skysphere" class I think. When picking the skysphere, internally it will be able to tell us specifically what we've selected.  I think for now all we care about is the name of the star, it's parent system, it's zone and it's position in that zone.  Everything else we can look up if the user wants for instance to get detailed data on the star.
	- part of the reason this starCatalog needs to be seperate is not because we dont want to load the star entities themselves, but we dont want to have to load all of those ZONES that they are in!

 



- would it be a bad idea to have a rule that the closer units are to a majorly populated city, the faster they can regain their fullstrenth per turn.
	- the idea is an army that is far from any friendly city (oh, be cool if they could draw from allies too if that was an established treaty)
		- but the idea is, armies can rebuild from populations and materials and perhaps implement a slight decrease in production in exchange for the faster health

settign screen -> http://apolyton.net/ron/factsheets/info6.php

SOLAR SYSTEM AND NaV
-------------------
	- I think we should use ortho and apply a scaling prior to rendering.  We can use a fixed scaling and allow a degree of zoom/unzoom
        and other typical panning and such.  But trying to position the camera way the hell out is not good i dont think...  So how do we do this?
	
NAV GUI DESIGN  (MFD style  http://oea.larc.nasa.gov/news_rels/2000/art/glasscockpit/JSC2000E10522.JPG)
	-HOWEVER, i think the design of our Win32 Ribbon toolbar and floating windows and such should resemble an MFD style display where buttons on the MFD can be remapped to fit with whatever program is running in the display.  This is a good philosophy i think for designing our GUI.
	- Also thinkin gabout the Primary Flight Display  http://en.wikipedia.org/wiki/Primary_flight_display
	and how one thing that would be displayed there isnce there is no "horizon" is to make the primary flight display always be cyclable to be relative to some target such as your carrier's orbit.  That way your primary flight display has a reference point that you can always use to determine where you are in relation to it and where you need to be.  
	- Having relational waypoints as well since a CAP has to form to protect a THING and that thing is often in an orbit so is moving.  So this is actually an innovation in the genre i can make
------------------------

- this thread has all info to fit the viewport to the star sector's bounds
  - http://www.gamedev.net/community/forums/topic.asp?topic_id=548148
- Star System view i think can work with BoundingBox.GetProjectedDistances()  to determine how far out our camera needs to be looking at the system
   to have it fully in view... maybe?
- FXSkyStarSphere  which gets placed into the FX_SEMANTICS_SKYDOME slot and on .Update() it will reposition.  The main additional is that
              we need a seperate entity associated that will share the mesh and can be used for picking the individual stars

- planetary ring rendering is slow on my fx5200.  i think the answer is to have various versions of the shader for slower systems as well as a non shader version.

- we already have code that we can use to determine the distance to get an entire sector in view...  so we need to for starters
  just have an ortho camera that looks at 0,0,0 from a position of 0,height,0 where height is computed from our calc. 
  Then, we draw orbits and finally replace the stars\planets\moons with... hrm... just scale them perhaps.  I suspect everything sun included will be pretty tiny so we'll need to scale their sizes up significantly.  This is just one option
- the other option which is probably preferable is to place onto the Draw context, a scaling matrix and scale everything so that it fits into the solar system viewport's dimensions.
   - the solar system view will be locked to ortho and have a max zoom IN value and zoom out maybe should be have a max as well.



http://code.msdn.microsoft.com/XMLDocsToWiki

       
   - sketchup does have a scale tool under tools\scale
   http://www.youtube.com/watch?v=I_xqUsZnzJA
   - there are two types of scaling, component scaling and geometry scaling.  Component scaling will set a scaling matrix to the Entity whereas geometry scaling, scales the underlying model space vertex coords directly.  Modelspace scaling of geometry will be easy.  Entity scaling might be trickier cuz it might screw up how i do mouse perfect plotting/moving of low level geometry of the model.


- sketchup allows you to mouse pick an edge that is nearby even if you're not actually ON the face.
- proper vertex handle drawing
- selected face highlighting
	- this requires that we highlight a face if our distance to an edge is far enough away
- IConfigurable


GUI
====================
Looking at my old Bigspace mockups and the crew personel stuff.  Really some halfway decent ideas
- Also the Rules of Engagement 2 screens is great in terms of all the thing syou can do like self destruct, etc
	- would be great if in long term multiplayer, when ship's codes are assigned, if other players can "hack" them and steal them.... either with a spy that has been hired or some other method.... perhaps just guessed/hacked during a boarding party raid.
E:\creative\Specs_All\2d GUI\Figure_23_Rules_messages_FxCop.jpg  is just a basic vs.net properties display but thinking about the crew screen and the tabs along the side i think could be a great fit. as well as PublishTool_lg.gif in the same folder


LOBBY vs MASTER vs STEAM 
==============================


authentication v lobby v master server v steam
- in evo's lobby, when a game is ready to start, the player is automatically sent the info to connect to that game.
- in a dedicated authentication, the only games a user could join would be the 24/7 looping servers that didnt care what users were in the game.  


- master <-- used when no matchmaking is required and anyone not banned can play. (perhaps with some ping restrictions, regional restrictions)
- lobby <-- required for when the particular players allowed are determined through lobby matchmaking
	- buddies

--

Unlike Lenn's game, i will be able to have a server just "start" a game after waiting for a period for users to transition from the lobby... and when the game starts, i can have the servers notify a tracker that updates the kgbtracker database.  Then if a user wants to join another game, after failing the first, they lobby is quickly able to verify with a tracker that the player never started in that game afterall.  In fact similar to Lenns,  players registered to a game will be added to the in progress games tracker but when the game starts and they're not in it, the tracker will be responsible for removing them.  Likewise, the tracker can completely shut down and free all players from a registered game that failed to start at all for any reason for x interval.
--

What if the master server was also an authenticating server?  I guess the first thing i need to remember is that i can quickly ramp up the otehr server types if i just build a lobby that properly supports the different types of server monitoring
	- no global lobby chat, just private chat and table chat.

--
	- as far as users wanting to host their own non 24/7 servers, well we probably have to allow that if we get anything close to the number of users we would ultimately like. (plus we could never offer a good experience to foreign users with just one US server) a user that has  acdkey, starts his server, that server registers with master or lobby, and gets a tracker to upload results and such to.  The one rule we could enforce is that the owner of a dedicated server cant play on his own server from the LAN or directly at keyboard.  He must do so over the internet.
----------

Instant Action Servers
---------------------
for the 24/7 servers, it's just like Counterstrike
	- the games are basically infinetly looping in "levels" or "maps" and either free for all, x versus x, just keep going.  Maps are different for the different game modes.  That is to say, some maps are only compatible with certain game modes.
	- the server browser for these types of games are justlike counterstrike.


Match Servers
----------------------
for the sit-n-go games, it's a lobby

for the long duration persistent campaign games, these are coordinated like sit-n-go games only after they start, instead of being short term scenarios, they use large campaign maps and can potentially last days or weeks or months.


Ladder & Tourney Servers
-------------------------
for the ladder games, the matchups are chosen for you but you can play anytime you like and the ladder play keeps going forever with no utlimate champion like in a tournament.  However, there can be ladders where every player is only allowed to play say 12 matches or 100 matches, etc.  So they can end.

for tournaments, the matchups are chosen as well but there's a limited number of games and the brackets narrow until there is a champion.


any server can then use attributes
	- tracked
	- official
	- private password
	- 

---------------------
Configuration Files
---------------------
Normally when you launch any app, the config is read in at start and those settings are applied.
The Quake model was cool in how cvars were sent to the engine... so in effect, config was read in and the values sent in the form of cvar commands to the command processor.

Now when the editor is launched, we're not just dealing with graphics/networking/game settings, we're dealing with windows application environment settings persistance so this is a bit of a different deal.  Those settings can be saved in the same config, but they're not sent as cvars to the game engine.  

I think we would be taking a loaded property bag and doing
window.DisplayMode = bags.Properties["displaymode"].ToString();

So we're trying to acknowledge that yes there is a difference between windows application settings vs game engine settings.
Well that's somewhat shadey if you consider things like "showboundingbox" "showgrid" which are per viewport

However a clear distinction is the control panel startup whcih allows users to modify the config file
and then the actual launch, and then also runtime editing of settings via cvar commands...

Now whether we re-load the ini from within formMain or pass in initialized ini is a smaller question compared to the more fundamental questoin of how do we deal with xml config data and cvars and menuitems.

// the answer could be to do like Quake does and add a prefix to the cvar so that
                    // "showgrid" becomes  "vp_0_showgrid" and "vp_1_showgrid"
                    // and other commands like "dbg_enableprofiler" has the "dbg" prefix

How do we reconcile our Interpreter (which currently handles keybinds well and invokes
binded functions when a key mapped to an action is pressed) with our CommandProcessor.

Well, for starters our CommandProcessor has each command having the cability within itself to perform a specific task
aschronously potentially with ability to invoke a callback on completion and manage undo/redo stack.  The CommandProcessor
class itself is mostly just a manager for the running of these commands.

This makes the CommandProcessor much better for being extended to work in a network environment.  Yes there are tons of commands but they are simple and each is seperate.  This is perhaps better than having some huge switch statement somewhere

The interpreter on the other hand is a very simple immediate run keybind script that runs a (in the future) potentially scripted handler or a hardcoded one.  It's designed for key/mouse input interpretation and then execution of handlers and is not designed to be used over a network... for that, say a "Fire" input command that needs to be replicated over the network, we could modify our Interpreter's handlers to create Command objects that can be serialized across the network.

Indeed, in my editcontroller, i do use Command inside of MoveTool and LineTOol and such so that
these commands do go through the CommandProcessor, do get Undo/Redo stack management, and can be serialized
across the network transparently by the CommandProcessor.  One of the clear beauties of having a CommandProcessor is that
these commands are funneled thru a single point and can be serialized to network at one point as well as perhaps serialized to a "vcr" playback file.

Now some commands that dont need to be pushed onto the stack like a simple npc entity movement... only "Edit" commands need to have "redo" right?  In any case, how do i differentiate those?  And how do i make it so that these simple commands get executed very quickly... without lots of class creation/destruction?  Well recycling commands in a cache would help... what else?
 
Or if there were some kind of CVAR\INI Interface and each class that needed to handle gui, could directly output\input cvars that were under it's "section" name(s).  So it goes   forms\controls (menus\buttons\textboxes) --> cvarReader\Writer <--> Ini

Consider that eventually a lot of gui intitiated commands for actual gameplay type events should go through as a cvar that can be sent to the server and replicated.  So this really is necessary.  There difference is that those commands wont (typically) need an INI, but i think it's a good working example to use when designing this code.  cvars\commands arriving externally are reformed and added to a queue.  During the gameloop they are processed and handled.  How would a cvar in that case arrive and then get "read" by the IConfigurable so it can be saved to the INI?  I mean imagine a version of our editor that did not have a GUI at all and relied on command line to modify things like showgrid?  Clearly that goes to a command processor first, then somehow gets converted to a command that calls Viewport.Context.ShowFPS = bleh; and likewise calls IConfigurable.ReadConfiguration (string cvar); 

One theory is that if the cvar is created into a full blown command class, then it would have the code to do everything directly... knowing implicitly what it needs to do.   

Consider how a Fire weapon command + script works?  
Keep in mind how +fire and such works with interpreter to invoke handlers
  - this represents some differentiation of commands...?  
What about the difference between a "cvar" setting and a "command" ?

// forcing all gui commands and controls in general through the loopback server would force me to write proper client / server code.


// assuming each configurable class handles it's own ini read/write
// the nice thing about below is that each IConfigurable can write to the ini anything it wants
// and no other classes needs to know what any other class is writing.
IConfigurable
{
	string ConfigurationName; // e.g. "viewport0"
	bool ReadConfiguration (string cvar); // reads a single cvar that could have come externally from console
	bool ReadConfiguration (Settings.Initialization ini);
	bool WriteConfiguration (Settings.Initialization ini);
	Event ConfigurationChanged;  // as the user makes a menuItem change for instance, this can raise an event
}

// in some ways a configuration can be thought of as cached commands, so reading them could in turn send across the network _if_ they are not just local commands.  I guess most configuration commands are local though.  I think the way to proceed is to implement IConfigurable and use those to restore saved settings.

// assuming we use cvars generated by the say menuItemShowFPS_Click(object sender EventArgs args)
// instead we could do

Core.CommandProcessor.Process (string cvar)
{
	// determine the type of the cvar based on it's prefix
  
	// should this cvar be written to the ini

	// should this cvar be sent to the server?

	// 
}



------------------------------------
Aeon's Freedom Star point sprite vid
http://www.youtube.com/watch?v=6Y6pJgM0KSc
i had this working 3 months before he did but what i do think i should change in mind is to have the alpha value for point sprites more transparent so that they are less visible the futher awayt hey are.  I mgith need 3 different point sprite minimeshes or meshes for this to work.  Close ones, medium ones, far ones and super far ones are just not drawn.... and then they will fade in as you get closer.

Ideally, a shader could make it fade in using the single mesh approach and have the amount of fading truely interpolated by distance (using a texture lookup for the double precision position?) hrm... have to think about this more because its really not feasible to have proper distances unless we scale all the distances to fit within the drawable range

FORMATIONS - Fighter Formation Hints from Total War
==================================
NATO codes
http://en.wikipedia.org/wiki/APP-6A   <-- but be warned, this makes the game a lot less casual and thus a lot more niche.
Total War has a very good balance between usability and depth.

Was looking at Napolean Total War vids and staring at the masses of troops engaged in melee and you wonder "how are these formations handled?  And how do you match up units on one side, the swing/attack a unit on the other side?  Then the idea occurred to me that underneath there is probably a tiny sized hex map where only one unit can stand and that takes care of two issues. 
	- Spacing
	- individual target aquisition
	- Path finding within the melee mass and allowing easily the ability for a flanking unit to engulf the enemy unit by pathfinding laterally to the open hex spots near th enemy.
	
		
	Now lets say you have a cavalary charge joing in, initially this will result in potentially more than one unit on a hex and weaker forces will either get pushed back and result in a chain reaction of the weaker army getting pushed back and losing ground, or they'll get killed.
	
	
So the point is this can be extended for fighter squadrons as far as formation based movement is concerned and we can use this to massively reduce the amount of packets we need to send.  We simply have to describe the dimensions of the formation, the indices of units in the grid spots in teh formation,  updates for when one of these units is moving to a different position, and then just the general speed and heading of the formation.

I'll need to sit down and really spec out the precise methods but I think this is a sound approach in general.

Also consider that we can have these fairly simple formations and varied formations and switching formations that allow things to visually appear very dynamic.  Imagine a staggered line formation with a 1km spacing for instance for a bomber squadron.  Then they can switch to a wedge and the bulk of that can be computed knowng just the time the switch to wedge occurred and then the contnuous position and heading updates of the center of the formation.

=================


--------------
Crew Ops 

http://en.wikipedia.org/wiki/USS_Scorpion_%28SSN-589%29

Just thinking about how the accoustic research was done to determine cause of the destruction of the USS Scorpion SSN 589.  It reminds me much more of 

how ToS startrek conducted science stations and sensors and communications... relying on instruments to show them data, and then their own skill to 

intepret what that data meant.   That's definetly something id like to bring back to this simulation... where ship detection, or planet detection around 

a star, or moon detection, or identification of some space junk or abandoned relic... where effectively everything is done at such far ranges, these 

crewmen who read these instruments have to have talent and incredible skill and training.

Software just might not be good enough or reliable enough to take into account tons of changing variables (including but not limited to off axis angles) 

to determine IFF, ship class, etc.  And further, ship captains and first officers would have limited knowledge of the oeprations of other friendly 

ships... (part of why a captain and first officer would never leave the ship to be captured either!)


Crew / Service People on big military vessels in space are treated like Warriors and are given total respect for their discipline and strength and 

because people know they are the best of the best, they are fearless frontiersmen, they keep us safe from aliens by offering the mutual destruction 

capability.  So i think it's important to convey to the user through the game, that when you enter a space station or some colony town, that your crew 

are treated with a reverance that is really cool to see and feel in the game. Sure maybe some of these warriors get drunk, act out, whatever... but there is a clear and unofficial "above the law" granted to them because in the end, it's recognized they are going thru mental hell... the crew responds not by punishing them, but by understanding and helping them.... unless they kill someone... or something totally over the line.  there has to be some line but the line for them is wide.

Inside a Nuclear Submarine
===============================================
http://www.youtube.com/watch?v=HuSs_MsPS4Q 
http://www.youtube.com/watch?v=Z8N9Fi-kFNA
http://www.youtube.com/watch?v=TfjYZUiOkUw

Training Missions
------------------
- a mission where they are to fly silently and undetected along a route.  They are to identify, map, and categorize and clasify varous ships in the area 

(most are tugs, caro transports and such) and then return to deep space.  Simulated recon mission.  User will need to design a ship for this purpose.
In fact, one type of gamemode can be that the user gets x total design points to design a complete fleet, then they get x dollars to buy whatever pieces 

they want... and they then have to complete a simple campaign which equates to a series of scripted missions (simple campaign mode for v1 of campaign 

play)  That could be extraordinarily cool to do.  Users would be encouraged to share their own ship designs and their own campaigns.


Subscription Service
--------------------
was thinking about this more yesterday... a subscription would enable extra features on the social networking side.  Especially as it relates to hosting 

files since that consumes bandwidth

================
http://luaforge.net/projects/luainterface/

http://www.gamedev.net/reference/articles/article2275.asp
	- be nice to be able to allow users to customize the fleet actions via not just the Football paly designer, but perhaps with some direct scripting as well.  The fleet "play" creator is something id liek to do.
	- Would also be cool for designing boarding party attack/defense is a "attack plan"
	- Indeed, this does fit with my goal of focussing on tactics/combat.

http://einfall.blogspot.com/2005/07/using-lua-scripting-for-games.html
http://einfall.blogspot.com/2006/05/scripting-with-lua-in-c.html
http://einfall.blogspot.com/2006/06/more-scripting-in-lua.html
http://einfall.blogspot.com/2005/07/advanced-lua.html

LUAGravity - Concurrent Lua
http://thesynchronousblog.wordpress.com/2008/08/17/a-first-glance-at-luagravity/

- bah, there's still also c# script so i dont know.  *sigh*   http://www.mdxinfo.com/resources/scripting.php


=================================================================================================
DATABASE
=================================================================================================
As my project progresses and as I perhaps start to run into performance problems with my save/load scheme
maybe something like db4o  or this dbfdotnet BTree dBase style project used on codeproject/codeplex  would be good?
http://dbfdotnet.codeplex.com/
hrm, or this
http://www.codeplex.com/fastdbf/

OR NOW there is apparently a .net interface/librarires for MS VFS (virtual file system).  Must test to see if it's faster.

----------------------------------------
KERBEROS FORMAT
----------------------------------------
http://tools.ietf.org/html/rfc4120
http://en.wikipedia.org/wiki/Kerberos_(protocol)
http://www.freesoft.org/CIE/RFC/1510/53.htm
http://social.technet.microsoft.com/Forums/en-US/winserversecurity/thread/04ab94c4-f1d0-4176-beba-ef2355fb1cbf/
http://www.example-code.com/csharp/http_kerberos.asp

Ideally id like to make my tickets and authenticators match the layout of kerberos.  This really should be a simple task taking no more than a day.

Indeed, http can use kerberos and smtp and more.




http://royalexander.wordpress.com/2009/05/31/sending-objects-via-high-speed-asynchronous-sockets-in-c-serialization-socket-programming/
01.[Serializable]
02.    public class Status
03.    {
04.        [NonSerialized]
05.        public Socket Socket;
06.        [NonSerialized]
07.        public List<byte> TransmissionBuffer = new List<byte>();
08.        [NonSerialized]
09.        public byte[] buffer = new byte[1024];
10. 
11.        public string msg;     //the only thing we really send.  
12. 
13.//Usually you shouldn't but these 2 methods in your class because they don't operate specifically on this object
14.//and we would get allot of duplicate code if we would put those 2 methods in each class we would like to
15.//be able to send but to not wind up having to write a couple of utility classes (where these should reside)
16.// I let them reside here for now.
17.        public byte[] Serialize()
18.        {
19.            BinaryFormatter bin = new BinaryFormatter();
20.            MemoryStream mem = new MemoryStream();
21.            bin.Serialize(mem, this);
22.            return mem.GetBuffer();
23.        }
24. 
25.        public Status DeSerialize()
26.        {
27.            byte[] dataBuffer = TransmissionBuffer.ToArray();
28.            BinaryFormatter bin = new BinaryFormatter();
29.            MemoryStream mem = new MemoryStream();
30.            mem.Write(dataBuffer,0, dataBuffer.Length);
31.            mem.Seek(0, 0);
32.            return (Status)bin.Deserialize(mem);
33.        }
34.    }

========================================
 Who does what?
 ===================================
One of the first implementation questions that comes up with this project is deciding where which methods should be stored. There are players who interact with items, areas interacting with players, players interacting with classes, items interacting with items, skills interacting with items... its a mess.My initial thought was to organize the methods as belonging to players (this is, as far as I can tell, the standard approach taken by mud implementations thus far). Following in that fine tradition, players would contain all functionality, and items would contain only data about themselves. The implementation would look something like this:

class Player
  attr :name, :objects
  def initialize(name)
    @name = name
    @objects = []
    @body = {"wielded" =&gt; nil, "torso" =&gt; nil}
  end
  def get(item)
    @objects << item
  end
  def wield(item)
    if @objects.index(item) and item.can?("wield")
      @body["wielded"] = item
    else      raise "Cannot wield #item}"
    end
  end
  def wear(item)
    if @objects.index(item) and item.can?("wear")
      wear_location = item.attributes["wear location"]
      @body[wear_location] = item
    else
      raise "Cannot wear #{item}"
    end
  end
end

class Item
  attr_reader :name, :attributes
  def initialize(name)
    @name = name
    @attributes = {"wear" =&gt; true}
  end
  def can?(action)
    @attributes[action]
  end
end

class Weapon < Item
  def initialize(name)
    super(name)
    @attributes["wield"] = true
  end
end

class Armor < Item
  def initialize(name)
    super(name)
    @attributes["wear"] = true
  end
end

class ChestArmor < Armor
  def initialize(name)
    super(name)
    @attributes["wear location"] = "chest"
  end
end

class LegArmor < Armor
  def initialize(name)
    super(name)
    @attributes["wear location"] = "leg"
  end
end

However, as I sat and considered implementing hundreds more methods in that manner, I realized that this was an awfully complex approach. Sure, it was completely intuitive, but it was going to be about as entertaining as rereading Prelude the Foundation a fifth time. As a bonus, it was going to be a real pain to make changes in, because the behaviors and the data the behaviors acted upon were being stored separately.At about this time the anti-object article drifted up into my conscious mind, and I decided that I would consider a different implementation. I decided that the methods that acted upon items ought to be contained by the items themselves: I would see how well things might work out if I moved all the complexity into the items. Here is my implementation using this approach:

class Player
  attr :name, :inventory, :body
  def initialize(name)
    @name = name
    @inventory = []
    @body = {
      "wielded" => nil, 
      "torso" => nil,
      "legs" =>; nil
     }
  end
end

class Item
  attr_reader :name
  def initialize(name)
    @name = name
  end
  def get(actor)
    actor.inventory < self
  end
end

class Weapon < Item
  def wield(actor)
    actor.body["wielded"] = self
  end
end

class ChestArmor < Item
  def wear(actor)
    actor.body["torso"] = self
  end
end

class LegArmor < Item
  def wear(actor)
    actor.body["legs"] = self
  end
end

There are a variety of benefits over the previous implementation: we are now keeping track of whether or not something can be worn/wielded/got and how to wear/wield/get it in the same spot. This means changes only require looking at one section of code, instead of two are required by the earlier implementation. It also allows us to take advantage of polymorphism (ChestArmor and LegArmor respond differently to the method of the same name).In addition, the default item initialization is sufficient for all the subclasses, because all other data about the object will be stored within its methods (nice and Lispy). Not having to chain together a handful of super calls strikes me as a pleasant improvement (Random Question: do you think if you had a sufficiently deep class hierarchy, you could overflow the Ruby stack? I am thinking yes.).I have some concerns about how the second design appears to depend too much upon the implementation of the Player class; the Java programmer in me wants to build a copious API that completely encapsulates the implementation details. My slightly saner half thinks it is cleaner to leave it as it is. If necessary I can alter the implementation by creating a hashmap-like API over whatever datastructure I would replace the @body hashmap with.Although Im not one to consider lines of code as a metric for quality, the second version is 41 lines to the first versions 68 (I am, however, apparently one to have their cake and eat it too). In addition to being shorter, it also strikes me as being simpler and more understandable (no flow control, and no need to explicitly raise any exceptions, well simply use Rubys reflection capabilities to ask item.respond_to?(wield) and have a simple error message we return to the player if the item has no method corresponding to their command).

----------------------

Graph including dykstras aglorithm
http://www.brpreiss.com/books/opus6/


CSG routine
http://builders.reprap.org/2006/08/polygons-and-csg.html
http://reactos.freedoors.org/Reactos%200.3.8/ReactOS-0.3.8-REL-src/dll/win32/glu32/libtess/README


quad edge
http://www.cs.cmu.edu/afs/andrew/scs/cs/15-463/2001/pub/src/a2/quadedge.html

half-edge
http://www.flipcode.com/archives/The_Half-Edge_Data_Structure.shtml

winged edge
http://www.cs.mtu.edu/~shene/COURSES/cs3621/NOTES/model/winged-e.html


this guy is kinda emulating my component system for vehicles
http://www.gamedev.net/community/forums/mod/journal/journal.asp?jn=333071&reply_id=3484512

 - starshatter graphics video
http://www.youtube.com/watch?v=eJuurm7Olv0




need to create an intermediary structure to render the vertices



- the normals are all f'd up when drawing the decohedron

rules:
  - i maintain a list of free edges. 
 - ugh.  check out this maybe for some help. its delauny stuff tho but it's got some added functions i dont have 
http://tog.acm.org/resources/GraphicsGems/gemsiv/delaunay/quadedge.C
http://en.wikipedia.org/wiki/Polygon_mesh
http://www.openmesh.org/index.php?id=214
http://wscg.zcu.cz/wscg2006/Papers_2006/Short/E17-full.pdf
http://tog.acm.org/resources/GraphicsGems/
  - when plotting points, if no edge is formed (you plot 1 vert and then change out the linetool before a second segment is made) then nothing occurs.  I could enforce a rule where I can't add "vertices" but only edges where one or more points of the edge can be existing coords.
  - everytime an edge is added to an unclosed face, an itteration is performed to see if that newest edge closes the current face at which point any remaining "free" edges are 

   	- in fact, i think one vertex is effectively a closed edge with origin and dest the same vert.
		- the only real necessity here is that we need to tie these to our "IndexedFace" and these have to be tracked
                if they are closed or not yes?  I mean for rendering with any real speed, we need to have these IndexedFaces precomputed and not have to itterate through all our quadedge faces which dont maintain a list of verts but instead uses the quadedge info to find them on the fly.  The thing is, the quad edge structure is meant to be used on the fly for drawing... 
Now since we arent using DrawINdexedPrimitive and just DrawPrimitive, that simplifies drawing a lot, however still, we want to be able to properly track GROUPS and FACES.  Potentially we could expand QuadEdge face to include it's list of Verts but seems if our QuadEdge FAce is 1:1 with our list of IndexedFaces, then that's not necessary.  So in fact, the key is to simply make sure that our QuadEdge faces and IndexedFaces remain 1:1 and that we're tracking in our INdexedFace after each edit operation, whether any faces have been closed.  Part of that does\will require that we do intersection tests to determine if a new line segment is bisecting any existing faces so taht they can be split.

- if new stand alone vertex (no origin precedes it, no existing vertex picked) then we must create a new closed vertex edge


http://www.softsurfer.com/Archive/algorithm_0111/algorithm_0111.htm#intersect2D_SegPoly()\
http://tog.acm.org/resources/GraphicsGems/gems/RayPolygon.c

todo:
- when culling, i should collect light sources with ability to enable/disable the proper light states during draw traverse later on





- in sketchup, it seems that they do in fact send a notification to the EditableMesh itself on which vertex, face, edge is to be rendered a certain way such as "selected" and such.  In fact, if i ever plan to render with textures, im going to have to have more flexibility in this regard anyway.

- on the one hand this does simplify some of the post DebugDraw stuff i currently do.  Still not 100% on how it handles the selected face bit.  Seems they apply a transparent texture to that face that has the hashed sort of lines.

- this is gonna require that the current way i handle my vertices with the seperate face breakdowns differently... i should add a rendering path that just uses the quadedge structure alone and to see if it's going to be feasible...

unless i can find a proper way to integrate it.  I mean right now i am doing draw primitives using a single call against a linelist i've built up.

Or i should just skip that part and get the manipulation working.  Just put in something temp for vertex selection so i can verify i've got one, then add the code to move the edge/vertex/face with the unprojected mouse position

- yeah, skip that part and lets just get face and edge moving.. then ill do vertex with vertex highlighting drawing three 3 pixel lines colored green



DECKPLAN BUILDING  --  AMAZING GUI DESIGN!!!!
=======================================================
E:\creative\Specs_All\3d - Deck Builder\computer_schematic_linernet.gif  
i found the above EXCELLENT graphic at 
http://www.geocities.com/starfrontiers/starships/linernet.gif
http://www.geocities.com/starfrontiers/starships/sfships.html

This of course can be replicated for all schematics for control including power and weapon controls/links!!!

Hell, it might even help for crew schedules.

I'm so glad i found this.  

I'd also like to be able to print out generated cross sections of computers such as
file:///E:/creative/Specs_All/3d%20-%20Deck%20Builder/agshipinfo.gif
file:///E:/creative/Specs_All/3d%20-%20Deck%20Builder/glennainfo.gif

=======================================================

- IMPOSTER SYSTEM BUG - Ah, one other thing about that article...he doesn't seem to take into account screen space vertices that are off the screen in his algorithms, this causes some imposters to blow up and cover the screen.  <-- This quote is from dgreen02 the author of Warbots Online and Urban Empires on gamedev.net.  I have in the past had some issues and maybe that's what it was however I assume now that culling should handle that?  But maybe not if the computed screenspace verts if they are outside of view then somehow that screws up the unproject when creating the 3d coords later in the algo.

- debug to highlight nearest vert
  - debug to highlight adjacent edges

// todo: i think i do need to use ID's otherwise there's just no proper way to communicate
// back to EditableMesh which face or vertex or edge or whatever i need to move.  So
// go back in and make sure IDs work _and_ from now on i wont even worry about id matching index
// there's no point.  I only need to rebase things when i export.  
// HOWEVER, the main problem with ID's is that you have to itterate through the entire list and check id's to find
// the right index.  Maybe this is not such a big deal if itterations can be fast...
// NOTE: Actually if i use Edge, Vertex, Face from the QuadEdge, those are actually classes and could be directly edited...
// without ever having to screw with IDs...
// ARGH: Althought for network editing, ID's would be superior...?  

- load a 2d square .obj
- pick an edge and move it
- pick a vert and move it
- delete an edge - verify in sketchup that this collapses the face and keeps it closed
- delete a vert - verify in sketchup that it collapses the face and keeps it closed and doesnt just leave it open

- plotting verts and creating a new qe structure
- creating new faces
- deleting faces
- bisecting faces
- deleting eddges and merging faces


- plot vertex
- delete vertex

- make edge (no faces yet)
- delete edge (no faces yet)

- make face
- delete face

- bisect face thus making two
- delete shared edge thus merging into one face
    - verify that the two faces are planar

	

material editor
http://www.visual3d.net/webmedia/galleries/GameEngineAlbum/Model%20and%20Material%20Editors/slides/toolset_materialeditor_1.html
http://www.visual3d.net/webmedia/galleries/GameEngineAlbum/Model%20and%20Material%20Editors/slides/ModelEditor%203-fixSpatial.html
http://www.unrealtechnology.com/features.php?ref=editor

todo: when picking, i need to continue and then pick the closest face (potentially) if "CLOSESET" flag is set

todo: when a totally invalid .obj file is loaded, it should fail gracefully and not result in having to restart the app

- normal problem
 - the reason our shading isnt working is because normals arent included in our vertices

we do have a triangle list, but the problem is i think that some triangles have normals that are different for vertices they share
this means we need an intermediary vertex list based on unique triangles... this sux but there is no way around it so we need to comute
our unique triangles based on vertices that are unique when considering triangles and vertices combined

its just intermediary for rendering only... and then for tvm saving too


the answer is our triangle array which already uses indices for both coords and normals and uvs


todo: - add the following note to deckplan spec notes
   - the sketchup file "TDF Ship ARES.skp" is great for showing sort of an overview of the hull generation as well as the entire ship in a exterior mode with translucent skin and all decks visible.  

todo: add the following note about why we need a legit ship builder...
      - looking at the user starships in google sketchup one thing becomes clear, most arent designed to actually "work" using engines, fuel tanks, minimum armor, and certainly not in accordance to any performance statistics.  They just say they work and this is how fast or whatever and that's that.  Our ship builder must be made so that the ships "work" 

todo:
- was pondering how to deal with ConvexHull and whether it should be saved as reference object in the Mesh3d and Actor3d and such. I remembered that PhysicsBody from JigLibX is and must be in EntityBase.  So server side, the physicsBody must have in its save/load in the xml references to what tyep  of collisionskins it needs.  So clearly when creating a physicsBody and attaching it to the EntityBase, it must grab the localcoord version of the ConvexHull. 
  - convexHull must be the one used from JigLibX
  - i must implement the xml save/load in the relevant JigLibX classes
  - 


-1) when paging in a scene initially, there's so much that needs to be paged in, the rendering should be suspended until everything is paged in because otherwise it takes way too long.
0) in universe generation, get the meshes to save/recycle properly using unit sphere mesh or whatever is required.
1) InitScene() in FormMain for when needing to re-create cameras for the primary scene and then assign them to the viewports and assign the controllers


3) we also need to then have Geometry.HullType enums used.  HullType i think is for physics, and perhaps for culling we absolutely need boundingsphere data in our xml and potentially also boundingBox.
4) then we can get our GameServer to run loading just the hull\sphere\box for server side collisions.
5)need to get the pager to create the list of IPageableTVNode resources to be paged in.  We need to sort them and have a way to abort ones for regions that are no longer needed, as well as way to re-sort them on changes in proximity.

- technically there should be no reason why on the server i couldnt technically load the classes for textures and such so long as i never actually try to load the underlying resources.
- Pager - need an alternate Pager for server mode that will load primitives for things but no geometry.
- SceneReader.ReadEntity() - when in server mode, needs to not add underlying TVResources and such...
  needs to skip branches (perhaps with a filter setting) that arent needed since we are using the same .XML level files.  
  - this needs to be considered in the context of how geometry creation on the client is done (ship building\designing)
    as well as how Editor works in localloop.
  
- there's a bug in connectionMaintenance loop in NetServer where CreateBuffer runs out of memory... leak somewhere?
- proper handling of timeouts particulary in gameserver for failed authentication or registration.
- authentication session tracking 
  - could this be useful to maintain a cache?
- dead connections in authentication server seem so fast
- loading of the variables for server startup from xml files
  - these files on the client should be updateable 
  - half life servers i think use a simple xml file that only contains authentication and master server addresses (primary and secondaries)
- logging (security) 
- thread pool for the database connections
- 

Case NetMessageType.Data
	' read first byte and determine the command and have the command deserialize itself
	while (message.Buffer.LengthUnread > 0)
		Dim command As Integer = message.Buffer.ReadInt32()
		CommandProc(command, message)
	end while
	
=================================================				
SMOKE TRAILS
http://www.youtube.com/watch?v=ZXD4N_Mi1iE
Looks badass in this mod

http://www.youtube.com/watch?v=H6gk8GViu4Q

Notice how in the above vids the tactic is always the same... fly up super close and then fire?  WHy?

Because weapon fall off for lasers and particle weapons is too high or too easily intercepted.  If we really want to have long range combat, then weapons need to function much more differently. The big ships must remain stealthy, hidden, the scouts and patrols need to be able to decoy, jam, and provide all the support roles, but they should have very long range intercepting abilities and also rely on stealth and counter measures... but weapon falloff should not be as dramatic as in most games.

Missile Trails
--------------
Periodically record the position of the exhaust in a circular queue. Draw a quad strip from the key frames, but rotate at each pair of verts so it faces the camera. Fade out 

=================================
Custom Animation:  Bye bye TV Actor?  We'll see...
================================================
Havok 6.5 behavior editor has some great ideas  ->  http://www.youtube.com/watch?v=sclYyTiqRrw

(also check out that open source Mount & Blade model & actor viewer i saved somehwere... i forget where offhand but i have it)
http://www.truevision3d.com/forums/printpage.html;topic=18579.0   <- CAL3D + TV3D
Actually after reviewing   E:\dev\c#\XNACal3d
i think its entirely possible to handle this using just TVMesh.
We would handle the skeleton updates for each mesh ourselves and skeleton can be shared with just the matrix states maintained inbetween.

Mesh and Model Format

I decided to go with my own formats because I want to have firm control of what goes into a mesh and a model. Many formats are just too limited and I have no control over them, but with my own I can add or remove things at will. Since I also wrote the export script, anything I can do in Blender I can easily make part of my format and use in the game.

I used Cal3D format for Flora and Fauna, but there were several things I didnt like about it. One, I couldnt easily add to the format. Two, the animation seemed very CPU and memory intensive. I dont think it was implemented efficiently, but also probably because I had to bake the animations, since the per-keyframe animator didnt work. Three, the animation was per-vertex, whereas my animation is per-mesh.

Format structure:

Model is a skeleton and a set of actions.

-Skeleton is a collection of bones and their relative locations. Each bone has a mesh associated with it.

Mesh is a collection of vertices and vertex information (UV coordinates, normals, etc.), faces, and materials. (A material may include texture.)

-Action is a collection of bone keyframes.

Keyframe defines the position of a bone during a certain frame.

Mesh format is very similar to OBJ. I just made some cosmetic changes and added more information (vertex count, etc.) to make it easier to parse.

Model format is standard skeleton animation, except I am not using skinning or anything like that. The reason is: I want to be able to substitute a different mesh in for any other mesh used by a bone. I know this will make the game look less realistic, but that is something I truly dont care about it. Making the game realistic falls pretty low in my list of priorities. Its a lot more important to make the game immersive. I dont believe you need realistic graphics for that.

Mesh Renderer and Animator

I wrote my own mesh renderer. (Woo-hoo, who hasnt?) It could not have been more straightforward. The animator on the other hand took me a day to work out. I had to understand how Blender stores bone parameters, how I can store those into a file, then load them and animate them with minimum effort. I decided to go with simple quaternion animation. Right now the rendering process looks something like this for every bone:

Set the default quaternion rotation. This corresponds to the bone being at rest. It also has a neat effect of changing bones coordinate system, which is necessary for the next step.

Then, for each animation, see if it applies to this bone. If it does, apply the quaternion rotation. The way its stored in the file is in bones local coordinate system. Thats why I had to do the first transformation.

After all is done, translate the bone D units in Y direction, where D is the length of the bone and Y always points along the bone, away from the parent bone. (This means the center of the object always has to coincide with the end of the bone.)

Edit: (The transformations are listed in order they are called in OpenGL. Their application is actually done backwards, so translation is applied first, etc.)

Now, all of this isnt set in stone. I am most likely going to shift a few things here and there, but I think the core structure is laid down pretty well. There was a lot of trial and error setting it up. Quaternion interpolation was especially painful, but I am pretty happy with the result. Now I will have to figure out how I want to handle the animation blending, since several animations can affect the same bone. That shouldnt be too hard







http://www.google.com/imgres?imgurl=http://foodiedani.files.wordpress.com/2006/12/arroz-con-pollo-closeup.jpg&imgrefurl=http://foodiedani.wordpress.com/2006/12/29/arroz-con-pollo/&h=300&w=448&sz=35&tbnid=cHUpxT6XEVJ3dM::&tbnh=85&tbnw=127&prev=/images%3Fq%3Darroz%2Bcon%2Bpollo&usg=__Vh0sMNQf7nqyghtjwuKxDE8T3V0=&ei=tdm6Sa3QJ5LQsAPpjtAw&sa=X&oi=image_result&resnum=6&ct=image&cd=1

paint.net - How to make a nebula star field space background
=========================
menu\effects\noise\add noise

menu\adjustments\invert colors

menu\layers\add new layer

menu\effects\distort\pixelate




XENOCODE POSTBUILD NATIVE EXE - VIRTUALIZED  March.9.2010  build I GOT THIS WORKING!  --> bin\Obfuscation\xenocodeconfig2.postbuild
-------------------------------------------
Add _ALL_OF_THE_ dlls  from  E:\dev\c#\KeystoneGameBlocks\Editor\bin\Debug  or Release
	- MTV3D65.dll 
	- d3dx9_36.dll
	- ZipForge.dll
	- DevComponents.DotNetBar2.dll
	VorbisDotNet.dll
	- Settings.dll <-- this one im not sure about.  I copied and pasted a non xenocoded one after the fact because i thought maybe it was bitching about 
	- JibLibX.dll
	- Lidgren.Network.dll
	- MHull.dll  (no StanHull.lib since that is compiled in MHull.dll i think - althoug i havent run any code that tests MHull in this native exe)
		
the following if not added to the virtual file system, must be included in the install directory (thats why they should be added to the virtual file system)
C:\Program Files\Microsoft XNA\XNA Game Studio\v3.0\References\Windows\x86\Microsoft.Xna.Framework.dll
C:\WINDOWS\Microsoft.NET\DirectX for Managed Code\1.0.2911.0\Microsoft.DirectX.Direct3DX.dll
C:\WINDOWS\Microsoft.NET\DirectX for Managed Code\1.0.2902.0\Microsoft.DirectX.Direct3D.dll
C:\WINDOWS\Microsoft.NET\DirectX for Managed Code\1.0.2902.0\Microsoft.DirectX.DirectInput.dll
C:\WINDOWS\Microsoft.NET\DirectX for Managed Code\1.0.2902.0\Microsoft.DirectX.DirectSound.dll
C:\WINDOWS\Microsoft.NET\DirectX for Managed Code\1.0.2902.0\Microsoft.DirectX.dll



EXCEPT you do not need the KeyEdit.vhost.exe  obviously.


------------------------------------

Cal3d loader used by jmonkeyengine.com is 

<model>
  <skeleton>data/cal3d/cally/cally.csf</skeleton>
  <mesh>data/cal3d/cally/cally_chest.cmf</mesh>
  <skin></skin>
  <material>data/cal3d/cally/cally_chest.crf</material>
  <meshes>
      <submesh>
          <mesh>data/cal3d/cally/cally_calf_left.cmf</mesh>
          <skin></skin>
          <material>data/cal3d/cally/cally_skin.crf</material>
          <visible>true</visible>
      </submesh>
      <submesh>
          <mesh>data/cal3d/cally/cally_calf_right.cmf</mesh>
          <skin></skin>
          <material>data/cal3d/cally/cally_skin.crf</material>
          <visible>true</visible>
      </submesh>
      <submesh>
          <mesh>data/cal3d/cally/cally_foot_left.cmf</mesh>
          <material>data/cal3d/cally/cally_skin.crf</material>
          <skin></skin>
          <visible>true</visible>
      </submesh>
      <submesh>
          <mesh>data/cal3d/cally/cally_foot_right.cmf</mesh>
          <material>data/cal3d/cally/cally_skin.crf</material>
          <skin></skin>
          <visible>true</visible>
      </submesh>
      <submesh>
          <mesh>data/cal3d/cally/cally_hand_left.cmf</mesh>
          <material>data/cal3d/cally/cally_skin.crf</material>
          <skin></skin>
          <visible>true</visible>
      </submesh>
      <submesh>
          <mesh>data/cal3d/cally/cally_hand_right.cmf</mesh>
          <material>data/cal3d/cally/cally_skin.crf</material>
          <skin></skin>
          <visible>true</visible>
      </submesh>
      <submesh>
          <mesh>data/cal3d/cally/cally_head.cmf</mesh>
          <material>data/cal3d/cally/cally_skin.crf</material>
          <skin></skin>
          <visible>true</visible>
      </submesh>
      <submesh>
          <mesh>data/cal3d/cally/cally_lowerarm_left.cmf</mesh>
          <material>data/cal3d/cally/cally_skin.crf</material>
          <skin></skin>
          <visible>true</visible>
      </submesh>
      <submesh>
          <mesh>data/cal3d/cally/cally_lowerarm_right.cmf</mesh>
          <material>data/cal3d/cally/cally_skin.crf</material>
          <skin></skin>
          <visible>true</visible>
      </submesh>
      <submesh>
          <mesh>data/cal3d/cally/cally_neck.cmf</mesh>
          <material>data/cal3d/cally/cally_skin.crf</material>
          <skin></skin>
          <visible>true</visible>
      </submesh>
      <submesh>
          <mesh>data/cal3d/cally/cally_pelvis.cmf</mesh>
          <material>data/cal3d/cally/cally_pelvis.crf</material>
          <skin></skin>
          <visible>true</visible>
      </submesh>
      <submesh>
          <mesh>data/cal3d/cally/cally_ponytail.cmf</mesh>
          <material>data/cal3d/cally/cally_ponytail.crf</material>
          <skin></skin>
          <visible>true</visible>
      </submesh>
      <submesh>
          <mesh>data/cal3d/cally/cally_thigh_left.cmf</mesh>
          <material>data/cal3d/cally/cally_skin.crf</material>
          <skin></skin>
          <visible>true</visible>
      </submesh>
      <submesh>
          <mesh>data/cal3d/cally/cally_thigh_right.cmf</mesh>
          <material>data/cal3d/cally/cally_skin.crf</material>
          <skin></skin>
          <visible>true</visible>
      </submesh>
      <submesh>
          <mesh>data/cal3d/cally/cally_upperarm_left.cmf</mesh>
          <material>data/cal3d/cally/cally_skin.crf</material>
          <skin></skin>
          <visible>true</visible>
      </submesh>
      <submesh>
          <mesh>data/cal3d/cally/cally_upperarm_right.cmf</mesh>
          <material>data/cal3d/cally/cally_skin.crf</material>
          <skin></skin>
          <visible>true</visible>
      </submesh>
  </meshes>
  <animations>
    <anim>
      <name>walk</name>
      <anim>data/cal3d/cally/cally_walk.caf</anim>
    </anim>
    <anim>
      <name>strut</name>
      <anim>data/cal3d/cally/cally_strut.caf</anim>
    </anim>
    <anim>
      <name>kick</name>
      <anim>data/cal3d/cally/cally_tornado_kick.caf</anim>
    </anim>
    <anim>
      <name>jog</name>
      <anim>data/cal3d/cally/cally_jog.caf</anim>
    </anim>
    <anim>
      <name>idle</name>
      <anim>data/cal3d/cally/cally_idle.caf</anim>
    </anim>
  </animations>
</model>


=================================================================================================
=================================================================================================
obsolete Code for StateBlocks which was a concept before I decided on serializing PropertySpecs
==================================================================================================
==================================================================================================
        // todo: so ReadXML reads from file or xml stream, ApplyState reads from stateblocks
        // ReadBuffer reads from IRemotableType where the entire object is always streamed.  Usually reserved 
        // for ICommand implementations and not types derived from Node.  We'll see but for now we wont
        // worry about implementing IRemotableType
        public virtual NodeStateBlock ApplyState(NodeStateBlock stateBlock, bool capturePreviousState)
        {
            NodeStateBlock prev = null;
            if (capturePreviousState)
            {
                // todo: should the "this" target actually be cached in the stateblock at all?  seems that info should be available
                // either in the ICommand wrapper or easily available to the IPlugin
                prev = new NodeStateBlock();

            }

            return prev;
        }
		
and from Material.cs where i overrode applynodestateblock

//public override void Read(Lidgren.Network.IRemotableType remotable)
        //{ 
        //
        //  what about the difference between a remotable and a command?  
        //  Is the Material IRemotable and the command not?  I think we definetly want commands
        //  to be remotable as well because they can be smaller than a full blown node instance
        //  But there's a difference between Reading our own type here (Material) and applying
        //  a Command.  I think thus to apply a command we should have an ApplyCommand() 

        //  if the source is Plugin, we will not need to notify that plugin
        //  if the source is NOT a plugin and the current plugin's target is this, notify the plugin
        //   so it can refresh with changes
        //   BUT if we're running on the server, there's no plugin to notify... 
        //   Perhaps the CommandProcessor should do that after Read() is called?
        //   
        //   Assign the changes through the property setter since it contains the call to modify the
        //   tv material.

        //   todo: since all changes to nodes should be funneled through this Read method
        //   we should make all the Setter's private.  
        //}

        /// <summary>
        /// 
        /// </summary>
        /// <param name="stateBlock"></param>
        /// <param name="capturePreviousState">Irrelevant?  We should always capture previous just so we can unroll if there's an exception</param>
        /// <returns></returns>
        public override Keystone.States.NodeStateBlock ApplyState(Keystone.States.NodeStateBlock stateBlock, bool capturePreviousState)
        {
            // todo: this ApplyState() doesnt actually need to be here at all... it could be in a Provider
            // similar to what I did with Evo.  Then i can write different storages depending.  What is the difference
            // afterall of having these things here or external?  Eitherway my two goals of
            // 1) having a funnel where i can control the access to modifying properties
            // 2) 
            // but 3) I'd lose hierarchical base class save/load inheriting of common base read/write code

            // todo: thread sychronize ApplyState so for any given node, only one thread can update it?
            //         or is the lock really necessary since we plan on only calling ApplyState at the end of our threaded update
            //         and just prior to single threaded Render... although, if we were to multithread the ApplyState
            //         we could have multiple statesblocks in the queue for a given node and there a lock would definetly be reqt
            //lock (mLock)
           //{
                if (stateBlock == null) return null;
                if (stateBlock.StateCount == 0) return null;

                Keystone.States.NodeStateBlock prev = null;
                if (capturePreviousState)
                    prev = new Keystone.States.NodeStateBlock();

                try
                {
                    // note: typically the server is sending most game states, whereas players are sending more commands
                    // however, player will also send some state particularly as it relates to position, velocity and we'll need
                    // to figure out how the server validates prior to allowing the state to update the underlying object
                    for (int i = 0; i < stateBlock.StateCount; i++)
                    {
                        switch (stateBlock.States[i].ID)
                        {
                            // ugh... im basicaly talking about recordsets here arent i? Then
                            // the benefit here is that the plugins could just talk in typical ado.net db language with no
                            // care in the world about Keystone types

                            // ugh2.. you know it would be a helluva lot simpler to simply serialize the entire state 
                            // Let's assume we change the diffuse color, we send it as a recordset of sorts, it goes over the wire
                            // received by the server which parses the field name and determines which value to update.
                            // It then either updates the entire record or constructs sql to update just that field.
                            // 

                            // todo: would it be better to have a ton of different states that handled this themselves?
                            // im thinking no... this would have much better performance 
                            // full state (nice thing here is just a single NodeState within the NodeStateBlock object can contain the full state


                            // specular power only
                            //prev.Add (new Keystone.States.NodeState (, Lidgren.Network.NetBitWriter.WriteByte()) ));

                            // opacity only

                            // diffuse only

                            // ambient only

                            // specular only

                            // emissive only

                            // default is to ignore
                        }
                    }
                }
                catch (Exception ex) 
                {
                    // unroll the state change.  Return null for the previous State so the caller will know that
                    // the apply failed
                    System.Diagnostics.Debug.WriteLine(this.TypeName + ":ApplyState() -- " + ex.Message );
                }
                return prev;
            //}
            // todo: wait, a command typically gets executed and run and will apply things
            // directly... this necessitates setters be internal (at least) first of all
            // second, id somehow rather applyCommand allow us to get the data from the command
            // 
            // but wait, we do want these commands to be put on/off the stack... as well as 
            // the ability to store these commands so they can be applied all at once inbetween render loops
            // so that we can properly thread things without having a ton of interrupts while rendering... they get applied all at once instead

            // ok, first lets think... IRemotable means somethign can be sent over the wire and 
            // the only remtoable type that any object can deal with is of it's own type.  Otherwise it's an error.
            // So our "commands" in addition to going through a processor, and added to undo/redo stack
            // I think we'd like to be able to implement them similar to messageproc  with eventargs, sender, and
            // ability to read the eventargs based on the sender and the type of command...
             
            // SendMessage (lparam, wparam, msg)  
            //  switch msg.Type
            // 
            //   <-- so can a message be wrapped in a command perhaps? or
            //  be a type of command?  Would ApplyCommand need an UnApplyCommand for undo? since
            // if this is not a command, then how do we store previous results for undo...  would the ApplyCommand
            // arg..

            // KM_Diffuse
            
            // KM_Material_Opacity

            // maybe a Command type that encapsulates messages 
            // so how would the "undo" get created?  ICommand.UnExecute ();
            // 
            // the setters perhaps should be Internal, not private... this way the command can
            // 

            // priorities
            // 1) tiny size over the wire for single sends like Position, Rotation, and such
            //      - connectionID <-- so we know who sent this
            //      - targetID       <-- so we know which ship or enity they are moving or whatever
            //      - messageCountForTarget
            //      - messageID   <-- WM_Move, WM_Rotate, etc
            //      - value
            //       Repeat messageID / value up to messageCountForTarget and then read next argetID and messageCountForTarget
            //       

            // 2) Undo/Redo
            // 3) plugin notifications and event registeration
            // 4) HOw might I add ability to do Delta Packets?
            //      a) You'd need a DeltaMessage type where we can update values
            //      b) it only works for unreliable UDP
            //      c)  the calling application (to Lidgren) must be notified when an Ack is received for a UDP so we can
            //          clear the ackowledged data from the deltapacket

            // IRemotableType interface is very flexible... just read/write binary buffer, a commandID and the channel (reliable udp, sequenced, ordered, etc)
            //
            // A StateBlockContainer can contain a bunch of states being sent by one player and the idea is that
            // a StateBlockContainer is distinct because they typically just modify\update scene elements and game entities... 
            // class StateBlockContainer : ICommand, IRemotableType
            // {
            //     // what distinguishes a StateChange from a command is that 

            //      NodeStateBlock[] mStateBlocks;  //derives from IStateBlock
            //      bool mIsDeltaStateContainer = false;
            //       uint mStateBlockCount;
            //
            //      public StateBlockContainer (bool isDeltaStateBlock) 
            //      {
            //      }
            //      
            //
            //      void AddState (stateBlockTarget, stateID, value) {} // if mIsDelta, see if we can replace the value of an existing piece of data 
            //      
            //      void Read (NetBuffer buffer)
            //      {
            //          // while reading the targetID, we assign an array of references
            //          //  to store which message is to which object reference (a node like Texture, Material or any Entity)
            //          
            //          
            //      }
            //      after the message is read, by the network, it gets pushed to command processor
            //      which then calls the this.Execute() 
            //      
            //      void Execute ()
            //      {
            //          for (uint i = 0; i < mStateBlockCount; i++)
            //              for (uint j = 0; j < mStateBlocks[i].StateCount ; j++)
            //              {
            //                  // rather than stateBlock.Capture()  it must be
            //                  StateBlock undo = mStateBlocks[i].Target.Capture(mStateBlocks[i]);
            //                  mStateBlocks[i].Target.ApplyState(mStateBlocks[i]);
            //                  // because the above allows each node to handle the parsing of relevant stateblocks
            //                  // and state types it can deal with.  Just like WM_  handling with a message proc
            //                  // we simply ignore those messages we can't handle 
            //
            //                  // similar to how D3D state blocks work
            //                  mUndo[j] = mStateBlock[j].Capture(target[i]);
            //                  mStateBlock[j].Apply(target[i]);  // todo: how do we compute the UnDo for this message?  We need to be able to cache the current values before we change it.  That should be done prior to sending the message to the node's message proc
            //                  
            //              }
            //      }
            // }


        }

=================================================================================================
=================================================================================================
=================================================================================================
Database related
=================================================================================================
=================================================================================================
=================================================================================================

http://www.codeproject.com/KB/directx/BelievablePhysics.aspx

matrix.cpp Invert()
http://nccastaff.bournemouth.ac.uk/jmacey/GraphicsLib/html/_matrix_8cpp-source.html

http://www.nigels.com/glt/doc/matrix4_8cpp-source.html

customers 
     contactinfo (primary mailing info)
     billinginfo
     profiles
     licensed\purchased products 

purchases (contains keys to orders in the orders table)
   customerID orderID

products and skus(bundles of individual products)

orders

JVIPER'S CODE FOR DRAWPRIMITIVES WITH A TVSHADER  from this thread http://www.truevision3d.com/forums/tv3d_sdk_65/tv3d_and_cal3d-t18579.0.html
=============================================
Dim D3DDev as Device      'DirectX Device
Dim D3DVrtBuff As VertexBuffer   'DirectX Vertex Buffer
Dim D3DIndBuff As IndexBuffer    'DirectX Index Buffer
D3DDev = New Device(TVInternalObjects.GetDevice3D)  'Pass DirectX Device Pointer to DirectX Device contructor to retrieve the DirectX Device TV3D is currently using.
                
On Error GoTo NoRender  
D3DDev.TestCooperativeLevel()  'Check whether the DirectX Device has not been lost. Usually if a DirectX Device is lost because the window has bee re-sized. If this is the case, we skip the rendering 
On Error GoTo 0

'Now  we create our DirectX instances of our Vertex and Index buffers
D3DVrtBuff = New VertexBuffer(GetType(Typ), VertexArray.Length, D3DDev, Usage.Dynamic, Vertex.D3DFormat, Pool.Default)
D3DIndBuff = New IndexBuffer(GetType(Integer), IndexArray.Length, D3DDev, Usage.Dynamic, Pool.Default)
D3DVrtBuff.SetData(VertexArray, 0, LockFlags.Discard)
D3DIndBuff.SetData(IndexArray, 0, LockFlags.Discard)

If (Not (D3DIndBuff Is Nothing)) And (Not (D3DVrtBuff Is Nothing)) Then
    D3DDev.Indices = D3DIndBuff
    D3DDev.VertexFormat = VrtFormats 
    D3DDev.SetStreamSource(0, D3DVrtBuff, 0, SizeOf(GetType(Vrt)))
    'Here we passed the size of your Vertex Type in bytes
    'The SizeOf function comes from the System.Runtime.InteropServices.Marshal namespace.

    'Now we are ready to render 
    'Here we can render with DirectX fixed pipeline, or with a shader
    'If you pass a valid shader to this function, it will render with the shader
    If Not (refShader Is Nothing) Then
        '!!!!!!IMPORTANT!!!!!!
        'MAKE SURE YOU UPDATE THE SEMANTICS FOR YOUR SHADER!
        'You'll be using alot of TVShader.SetEffectParam..... functions.
        For pn As Integer = 0 To refShader.GetPassCount - 1
            TVInternalObjects.Shader_Begin(refShader, pn)
            D3DDev.DrawIndexedPrimitives(PrimitiveType.TriangleList, 0, 0, VertexArray.Length, 0, CInt(IndexArray.Length / 3))
            TVInternalObjects.Shader_End(refShader)
        Next pn
    Else
        'Otherwise we'll just render using fixed pipeline
        D3DDev.RenderState.Lighting = True
        D3DDev.RenderState.SpecularEnable = True
        D3DDev.DrawIndexedPrimitives(PrimitiveType.TriangleList, 0, 0, VertexArray.Length, 0, CInt(IndexArray.Length / 3))
    End If
    D3DDev.Indices = Nothing
    D3DDev.SetStreamSource(0, Nothing, 0)
End If

NoRender:
    If Not (D3DVrtBuff Is Nothing) Then D3DVrtBuff.Dispose() : D3DVrtBuff = Nothing
    If Not (D3DIndBuff Is Nothing) Then D3DIndBuff.Dispose() : D3DIndBuff = Nothing
    If Not (D3DDev Is Nothing) Then D3DDev = Nothing

=====================================
	     
*************************************************************************************************
Game DotNetBar items - Potential list and is from http://www.deepdivision.com/overview.htm
System commands

    * cds enable/disable/restart onboard computers
    * sol enable/disable solar arrays
    * master reset master caution alarm
    * menu, help (submenu) user manual
          o manual input search
    * log information
    * system information
    * database information
    * cls clear screen

Environment commands

    * als enable/disable life support
    * cablight enable/disable cabin lights
    * dock enable/release docking
    * airlock open/close [selection menu] outer hatch
          o Enter host [selection menu] action
                + Exit action
                + Refuel spacecraft (host-dependent) action
                + Access station log action
                + Search for cargo [selection menu] action
                      # Exit action
                      # Load item to cargo bay action
                + Acquire local positions data action
                + Acquire this station (host-dependent) action
          o Remain action
    * host information
    * host board enter host
    * cargo [selection menu] cargo bay
          o Exit action
          o Unload cargo action

	Communication commands

    * com (submenu) TX/RX data
          o id.. docking request docking
          o id.. location request information
          o id.. status request information
          o id.. locals request surroundings

Navigation commands

    * nav enable/disable navigation subsystem
    * eng enable/disable engines
    * burn level [selection menu] thrust
          o items selection
    * burn (submenu) burn options
          o 0.. msec burn duration
          o 0.. cruise cruise velocity
          o 0.. grams xenon amount
          o ma manual
          o retro kill velocity
          o disable stop burn
          o 0.. count (submenu) timer
                + burn burn options
          o abort timer
    * location [selection menu] heading
          o items selection
    * destination (submenu) heading
          o manual input coordinates
    * heading id.. destination by id
    * scn (submenu) scanner setting
          o manual input range
    * scn enable/disable scanner
    * timer start/stop/reset utility
    * info enable/disable flight information
    * radar enable/disable navigation radar

Game commands

    * world [selection menu] complexity setting
          o items settings
    * audio enable/disable game sound
    * about information
    * quit end game

Blind User support
=-=========================


=================================================================================================
reality engine features (bought by Epic for Unreal 3)
Author  	Artificial Studios  	 	
Graphics API 	DirectX 	Operating Systems 	Windows, Xbox
Programming Language 	C/C++ 	Status 	Inactive
Documentation 	Yes 		
Features 	
	General Features 	Object-Oriented Design, Plug-in Architecture, Save/Load System, Other:
 	Standardized high-quality OO C++ with heavy inline documentation. Full Game Implementation source included.
	Scripting 	
 	Full integration with .NET scripting languages, allowing programmers and artists to write fully debuggable, IDE-integrated code in your favourite language, from C#, C++/CLI, to VB.NET without the need for a compiler
 	Cross-platform support through Mono Compiler
 	Python support, as an alternative or addition to .NET support, ensuring maximum choice and compatibility
 	Core engine is fully standardized object-oriented C++ with an extremely high level of inline documentation
 	Full compatibility with Xbox, Xbox2, and modular rendering and OS components allow for support of other consoles such as PS3
	Built-in Editors 	
 	No compile times. Click "Play" to instantly switch between edit mode and in-game action!
 	Visual placement and editing of gameplay objects such as players, NPC's, inventory items, AI path nodes, and light sources -- with a full realtime view of their appearance, including 100% dynamic shadowing. Includes a data-driven property editing framework, allowing level designers to easily customize any game object, and programmers to expose new customizable properties to designers via script.
 	Fully-featured GUI Designer that allows you to assemble menus visually (including Tab-pages) exactly as they appear in-game.
	Physics 	Basic Physics, Collision Detection, Rigid Body, Vehicle Physics:
 	Use of NovodeX FX multi-scene management to take advantage of the upcoming Ageia PPU (Physics Processing Unit).
 	Ragdoll character animation, allowing you to mix physics with animations for dynamic effects such as character damage.
 	Integrated physics editing inside of Reality Builder, supporting creation of optimized collision primitives for models and skeletal animated meshes; constraint editing; and interactive physics simulation and tweaking in-editor.
 	Fully integrated support for physics-based vehicles, including player control, AI, and networking.
 	Volumetric "physics zones" allow differentiation of constants like inertial damping, for instance objects accelerate slower in water
	Lighting 	Per-vertex, Per-pixel, Volumetric, Lightmapping, Radiosity, Gloss maps, Anisotropic:
 	Per-Pixel Lighting and shading with support for PS3.0, PS2.X, PS2.0 and PS1.1.
 	Precomputed Radiance Transfer (aka "Realtime Radiosity") support, allowing for Real-Time Subsurface Scattering and Soft Shadowing.
 	Unified dynamic world lighting and shadowing, including day/night cycles. Heavily optimized for maximum performance in huge, complex scenes.
	Shadows 	Shadow Mapping, Shadow Volume:
 	Real-Time Subsurface Scattering and Soft Shadowing and using Spherical Harmonics and Precomputed Radiance Transfer
 	Shadow & masked-light map projectors, and soft drop-shadows
	Texturing 	Basic, Multi-texturing, Bumpmapping, Mipmapping, Projected:
 	Total integration with popular commercial editors allows artists to create environments, view & configure shaders and lighting, and implement powerful Python-driven scripts directly from their native environment.
	Shaders 	Vertex, Pixel, High Level:
 	Support for PS3.0, PS2.X, PS2.0 and PS1.1. Shading includes dynamic projection mapping, normal mapping, Phong specularity, per-pixel reflection mapping, refractions, virtual displacement (parallax) mapping, animated textures, mix/detail shaders, fabric, anisotropic scattering, water, and other configurable pixel & vertex shaders.
	Scene Management 	General, Occlusion Culling, LOD:
 	Open-ended world structure places no limits on environmental design, with full artist-driven and procedural Level-Of-Detail support.
 	Per-pixel Occlusion Culling. Occlusion is automatic, fast, and accurate to the pixel.
 	Integration with popular 3D editors (Max, Maya) allows artists to create environments, view & configure shaders and lighting with realtime viewport feedback, and implement powerful Python-driven or C#-driven scripts.
 	Reload Scripts on the fly to see your changes without having to restart the application
	Animation 	Keyframe Animation, Skeletal Animation, Animation Blending:
 	Character Normal Mapping, Spherical Harmonics, Rag Doll Physics, skeleton-based multi-weighted.
 	Seamless transitioning between physics & keyframe animation. Physics-based character bone influences also allow for procedural animation
	Meshes 	Mesh Loading, Skinning, Progressive:
 	Character Normal Mapping & Spherical Harmonics, with skeleton-based, multi-weighted-bone vertex shader animation.
 	Characters can contain any number of arbritrary pixel & vertex shaders on multiple materials
 	Export tools for 3D Studio Max, Maya for bringing weighted meshes, skeletons, and animation sequences into the engine.
 	Precomputed Radiance Transfer data & lightmaps automatically mapped to Level-Of-Detail meshes.
 	Instance any mesh for efficient batch-rendering.
 	Optionally Bake or Instance PRT to save memory.
	Special Effects 	Environment Mapping, Lens Flares, Billboarding, Particle System, Depth of Field, Motion Blur, Sky, Water, Fire, Fog, Weather, Mirror:
 	Image Post-Processing (stackable) including Depth of Field, Night Vision, Motion Blur, Light Blooms, Volumetric Lighting, and non-photorealistic rendering.
 	Water system with procedural waves, per-vertex and per-pixel refraction and reflection of the surrounding World
 	Arbritrary Render Target on-demand usage
 	FX-system manager with automatic render-batching, optional z-sorting, & vertex & pixel shader-driven systems
	Networking System 	Client-Server:
 	Optimized Client/Server-Authoritative networking incorporating latency prediction & adaptive data degradation
 	Includes Voice Communication.
 	Platform-independent networking component to power Linux or MacOS dedicated servers.
 	Networked game state allows multiple users to connect to a design server and make changes to the game world using the full power of Reality Builder.
 	Allows truly simultaneous workflow - anyone can log in and spectate, design or play.
 	Server doubles as a CVS - synchronizes all prefabs and game assets contained in the level upon connection.
 	Replaces need for CMS tools such as AlienBrain
 	Integrated voice chat
 	Distributed lighting calculations - users can calculate PRT data on their own machines and update the server upon completion.
	Sound & Video 	2D Sound, 3D Sound, Streaming Sound:
 	Environmental Audio with EAX and 5.1 Surround.
 	Ogg Vorbis sound streams
 	Videos can be used as any texture, in any shader
	Artificial Intelligence 	Pathfinding, Decision Making, Scripted:
 	Intelligent pathfinding, both predetermined and dynamic with obstacle avoidance
 	Decision-making based on adaptive state machines.
 	Reactions to stimuli such as sight and sound
 	Completely written in Reality Script, easy to extend to any custom behaviors
 	AI can be run on the Server, with the Events replicated to Clients
	Rendering 	Fixed-function, Render-to-Texture, Fonts, GUI:
 	Built with DirectX 9.0 from ground-up to take full advantage of cutting edge technology developments, while fully scalable to DirectX7/8 generation hardware.
 	High-Dynamic Range Rendering Using Floating-Point buffers, allowing for Tone Mapping, Exposure Adaption, and Blue Shift, for camera/eye perceptual rendering.
 	Powerful fully "What You See Is What You Get" Scene Editor running on Reality.
 	Includes material library, entity library, shader configuration, physics setup, entity setup, rendering setup, sky configuration, redundancy-filtered PRT lighting compiler, all with realtime visualization as lights and meshes are moved around the scene.
 	Advanced mesh-instancing capability to cut down on scene memory and rendering overhead



// Infinity Quest for Earth -  Monday, August 30, 2004 journal entry   
----------------------------------
// http://www.gamedev.net/community/forums/mod/journal/journal.asp?jn=263350&cmonth=8&cyear=2004
I finally fixed the impostor bug. The formula i used was wrong, i was not calculating the frustum field of view angle correctly. It was a bit tricky to understand why, but revising my trigonometry helped a bit. For those interesting, the code looks like this: for a viewer position located at ViewPos, the impostored object being represented as its bounding sphere Center, Radius,

float d = distance(ViewPos, Center)
float fov = asin(Radius / d)
float l = d * tan(fov)
matrix4x4 viewMatrix = buildLookAtMatrix(ViewPos, Center)
viewMatrix = buildTranslateMatrix(-ViewPos) * viewMatrix.transpose()
matrix4x4 projMatrix = buildProjectionMatrix(fov, 1, znear, zfar)
matrix4x4 worldMatrix = buildIdentityMatrix()



To render the impostor, set your camera properties to projMatrix (the argument 1.0 is the aspect ratio, it's 1.0 since the impostor texture is square), viewMatrix and worldMatrix and render your object in a texture.

To display the object as a textured quad, use this:

matrix4x4 rotMatrix = buildLookAtMatrix(ViewPos, Center)
vector3d xAxis = vector3d(l, 0, 0) * rotMatrix
vector3d yAxis = vector3d(0, l, 0) * rotMatrix
vector3d vertex0 = -xAxis - yAxis + Center;
vector3d vertex1 = xAxis - yAxis + Center;
vector3d vertex2 = xAxis + yAxis + Center;
vector3d vertex3 = -xAxis + yAxis + Center;



The quad being defined by (vertex0, vertex1, vertex2, vertex3) with tex coords (0, 0), (1, 0), (1, 1) and (0, 1) respectively.



from InfinteUniverseEngine
----------------------------------
E:\dev\cpp\Samples\InfinteUniverseEngine\iue
JWObject.cpp GetScaledModelMatrix
CDoubleMatrix C3DBase::GetScaledModelMatrix(C3DBase *pCamera)
{
	// This code scales the planet's size and distance to the camera down when it's too far away.
	
	// This solves a problem with many video card drivers where objects too far away aren't rendering properly
	// It also alleviates the Z-buffer precision problem caused by having your near and far clipping planes too far apart.
	static double MAX_DISTANCE=(double)16000000.0;		// Distance to desired far clipping plane
	double MAX_DISCERNABLE;
	static double HALF_MAX=(double)(MAX_DISTANCE*0.5);	// Everything between HALF_MAX and MAX_DISCERNABLE is scaled exponentially between HALF_MAX and MAX_DISTANCE
	CDoubleMatrix m = GetModelMatrix(pCamera);
	CDoubleVector v;
	C3DBase *commonParent = C3DBase::GetCommonParent(this, pCamera);
	v = (GetFullPosition(commonParent) - pCamera->GetFullPosition(commonParent));
	
	double dDistance = v.Magnitude();
	if(dDistance > HALF_MAX)
	{
		// Beyond this distance, everything is rendered at MAX_DISTANCE
		MAX_DISCERNABLE = Max((double)MAX_DISTANCE, (double)(1000*boundingRadius));
		v /= dDistance;
		double dFactor = MAX_DISTANCE;
		if(dDistance < MAX_DISCERNABLE)
			dFactor = (double)(HALF_MAX + HALF_MAX * (1.0 - exp((HALF_MAX - dDistance) / MAX_DISCERNABLE)));
		else
			dDistance = MAX_DISCERNABLE;
		
		v *= dFactor;
		m.f2[3][0] = v.x;
		m.f2[3][1] = v.y;
		m.f2[3][2] = v.z;
		dFactor /= dDistance;
		m.Scale(dFactor, dFactor, dFactor);
	}
	return m;
}

=================================================================================================
=================================================================================================

some pseudo preliminary entity group selection box code by me.  need to work on more
------------------------------------------------------
// entity box selection
const float fardistance = 1000000;
TV_3DVECTOR resultMinNear= new TV_3DVECTOR();
TVMaths.Project2DPointTo3D(mouse2dStartX, mouses2dStartY, 0, ref resultMinNear);
TV_3DVECTOR resultMaxNear= new TV_3DVECTOR();
TVMaths.Project2DPointTo3D(mouse2dEndX, mouse2DEndY, 0, ref resultMaxNear);

// to avoid perspective being applied to our pick ray for the far points, we'll just extend these points straight out
// in the camera direction
TV_3DVECTOR dir = Normalize(camera.Pos - Camera.Look);
TV_3DVECTOR resultMaxFar = resultMaxNear + (farDistance * dir);

TV_3DVECTOR box.Min = resultMinNear;
TV_3DVECTOR box.Max = resultMaxFar;

// if either the min max bounds of your entities are in the selection box, the entity is visible
foreach entity in myentities
    if ((entity.minx > box.MinX) and (entity.minx < box.MaxX) and (entity.miny > box.MinY) and (entity.miny < box.MaxY) and (entity.minz > box.MinZ) and (entity.minz < box.MaxZ)) ||
	((entity.maxx > box.MinX) and (entity.maxx < box.MaxX) and (entity.maxy > box.MinY) and (entity.maxy < box.MaxY) and (entity.maxz > box.MinZ) and (entity.maxz < box.MaxZ))
       return true;
     else
        return false;


--------------------------------------------
// unit rectangle RTS selection box test
If Inp.IsMouseButtonPressed(0) = False Then
                If MouseB1 = True Then
                    Mouse2Coor.x = MouseX
                    Mouse2Coor.y = MouseY

                    Mouse3Coor.x = Mouse1Coor.x
                    Mouse3Coor.y = Mouse2Coor.y
                    Mouse4Coor.x = Mouse2Coor.x
                    Mouse4Coor.y = Mouse1Coor.y
                    MouseB1 = False

                    'select units
                    CollResult = Scene.MousePick(Mouse1Coor.x, Mouse1Coor.y, MTV3D65.CONST_TV_OBJECT_TYPE.TV_OBJECT_LANDSCAPE, CONST_TV_TESTTYPE.TV_TESTTYPE_ACCURATETESTING)
                    Mouse1Coor.x = CollResult.GetCollisionImpact.x
                    Mouse1Coor.y = CollResult.GetCollisionImpact.z
                    CollResult = Scene.MousePick(Mouse2Coor.x, Mouse2Coor.y, MTV3D65.CONST_TV_OBJECT_TYPE.TV_OBJECT_LANDSCAPE, CONST_TV_TESTTYPE.TV_TESTTYPE_ACCURATETESTING)
                    Mouse2Coor.x = CollResult.GetCollisionImpact.x
                    Mouse2Coor.y = CollResult.GetCollisionImpact.z

                    tMouse1Coor = Mouse1Coor
                    tMouse2Coor = Mouse2Coor
                    For u = 0 To MaxUnits
                        'Unit(u).IsSelected = False

                        If Mouse1Coor.x < Mouse2Coor.x And Mouse1Coor.y < Mouse2Coor.y Then
                            tMouse1Coor.y = Mouse2Coor.y
                            tMouse2Coor.y = Mouse1Coor.y
                        ElseIf Mouse1Coor.x < Mouse2Coor.x And Mouse1Coor.y > Mouse2Coor.y Then
                            tMouse1Coor = Mouse1Coor
                            tMouse2Coor = Mouse2Coor
                        ElseIf Mouse1Coor.x > Mouse2Coor.x And Mouse1Coor.y > Mouse2Coor.y Then
                            tMouse1Coor.x = Mouse2Coor.x
                            tMouse2Coor.x = Mouse1Coor.x
                        ElseIf Mouse1Coor.x > Mouse2Coor.x And Mouse1Coor.y < Mouse2Coor.y Then
                            tMouse1Coor = Mouse2Coor
                            tMouse2Coor = Mouse1Coor
                        End If

			// itterate through all items nad perform unit in box test
                        If Unit(u).IsUsed = True And Unit(u).Team = 1 Then
                            If Unit(u).GetPosition.x > tMouse1Coor.x And Unit(u).GetPosition.x < tMouse2Coor.x Then
                                If Unit(u).GetPosition.z < tMouse1Coor.y And Unit(u).GetPosition.z > tMouse2Coor.y Then
                                    Unit(u).IsSelected = True
                                End If
                            End If
                        End If

                    Next
                End If
            End If


public static Matrix Inverse(Matrix m)
{
assert(m_r == m_c);
00087 
00088     Matrix res = *this;
00089 
00090     int i,j,k;
00091                     /* Locations of pivot elements */
00092     int *pvt_i, *pvt_j;
00093     double pvt_val;                     /* Value of current pivot element */
00094     double hold;                        /* Temporary storage */
00095 
00096     pvt_i = new int[m_r];
00097     pvt_j = new int[m_r];
00098 
00099     for (k = 0; k < m_r; k++)
00100     {
00101         /* Locate k'th pivot element */
00102         pvt_val = res(k,k);            /* Initialize for search */
00103         pvt_i[k] = k;
00104         pvt_j[k] = k;
00105         for(i = k; i < m_r; i++)
00106             for(j = k; j < m_r; j++)
00107                 if(fabs(res(i,j)) > fabs(pvt_val)) {
00108                     pvt_i[k] = i;
00109                     pvt_j[k] = j;
00110                     pvt_val = res(i,j);
00111                 }
00112 
00113         if(pvt_val==0) {
00114             /* Matrix is singular (zero determinant). */
00115             delete [] pvt_i;
00116             delete [] pvt_j;
00117             assert(!"Matrix is singular.");
00118         }
00119 
00120         /* "Interchange" rows (with sign change stuff) */
00121         i = pvt_i[k];
00122         if (i != k)                     /* If rows are different */
00123             for (j = 0; j < m_r; j++)
00124             {
00125                 hold = -res(k,j);
00126                 res(k,j) = res(i,j);
00127                 res(i,j) = hold;
00128             }
00129 
00130         /* "Interchange" columns */
00131         j = pvt_j[k];
00132         if (j != k)                     /* If columns are different */
00133             for (i = 0; i < m_r; i++)
00134             {
00135                 hold = -res(i,k);
00136                 res(i,k) = res(i,j);
00137                 res(i,j) = hold;
00138             }
00139 
00140         /* Divide column by minus pivot value */
00141         for (i = 0; i < m_r; i++)
00142             if (i != k)                   /* Don't touch the pivot entry */
00143                 res(i,k) /= ( -pvt_val) ;  /* (Tricky C syntax for division) */
00144 
00145         /* Reduce the matrix */
00146         for (i = 0; i < m_r; i++)
00147         {
00148             hold = res(i,k);
00149             for (j = 0; j < m_r; j++)
00150                 if ( i != k && j != k )   /* Don't touch pivot. */
00151                     res(i,j) += hold * res(k,j);
00152         }
00153 
00154         /* Divide row by pivot */
00155         for (j = 0; j < m_r; j++)
00156             if (j != k)                   /* Don't touch the pivot! */
00157                 res(k,j) /= pvt_val;
00158 
00159         /* Replace pivot by reciprocal (at last we can touch it). */
00160         res(k,k) = 1.0/pvt_val;
00161     }
00162 
00163     /* That was most of the work, one final pass of row/column interchange */
00164     /* to finish */
00165     for (k = m_r-2; k >= 0; k--)  /* Don't need to work with 1 by 1 corner */
00166     {
00167         i = pvt_j[k];        /* Rows to swap correspond to pivot COLUMN */
00168         if (i != k)                     /* If rows are different */
00169             for(j = 0; j < m_r; j++)
00170             {
00171                 hold = res(k,j);
00172                 res(k,j) = -res(i,j);
00173                 res(i,j) = hold;
00174             }
00175 
00176         j = pvt_i[k];           /* Columns to swap correspond to pivot ROW */
00177         if (j != k)                     /* If columns are different */
00178             for (i = 0; i < m_r; i++)
00179             {
00180                 hold = res(i,k);
00181                 res(i,k) = -res(i,j);
00182                 res(i,j) = hold;
00183             }
00184     }
00185 
00186     delete [] pvt_i;
00187     delete [] pvt_j;
00188 
00189     return res;
00190 }

