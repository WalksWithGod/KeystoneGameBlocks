
In the seventeenth and eighteenth centuries, those in power were having trouble with their white indentured servants. The servants were asking for too much, were too rebellious, and they came from the same culture more or less. So the powerful tried to replace them with Native American slaves, but the Native Americans died from disease too easily and quickly and were also rebellious; plus they knew the land so well they could just vanish without a trace. So the powerful brought in African slaves because they were stronger, more resistant to disease, and would be strangers to the New World. Problems quickly developed when the slaves and indentured servants would band together and run away to join Native American nations. So the elite began giving indentured servants more freedom, a little money, and land to make it so the poor homesteaders would come into conflict with the Native Americans, as well as be motivated to own slaves themselves. This way poor whites became a buffer between the powerful elite and the slaves and Natives they were oppressing. The biblical bullshit was just propaganda used by the elite to indoctrinate the poor, illiterate whites.

It's all in Howard Zinn's A People's History of the United States, as well as Chris Harman's A People's History of the World.



Welcome to the Truevision3D game engine official chat!  

SKETCHUP .OBJ EXPORTER NORMALS
-----------------------------
I think the exporter is ok.  The problem is the users dont set the faces properly.
To check, select MONOCRHOME lighting and then flip all the blue faces by selecting them with mouse and then right clicking that face to bring up popup menu then reverse face.  

a whole life's effort has revolved around Eve, 9 letters? pagan,  Endeavour

http://thepiratebay.se/torrent/5510720/POWER_ISO_4.7_[thethingy]


http://photoshoptutorials.ws/photoshop-tutorials/layouts/modernistic-navigation-module/?singlepage=1
http://photoshoptutorials.ws/photoshop-tutorials/layouts/blue-black-navigation-bar/?singlepage=1

	http://youtu.be/UZ-d700iOI4 <-- better seahawks anthem

	who gets to decide what the English word for a foreign name will be?  For instance, who decides that Deutchland becomes Germany and why change it at all?  


	- Coding Philosophy: On wanting a perfect blue print...
		- coding is writing the blue print while simultaneously building the final house.  
			- the house analogy therefore doesnt really fit because the way you write applications is by designing the blueprint and that involves writing the code.
				- it's more like carving something. 
			- this is why you dont save time by trying to think of everything.  thats just not how
			- this is why as a process, there are further implications to things like KISS and not prematurely optimizing than the inexperienced developer realizes.  They think that these concepts only come into play middle to late in a project, when in fact it comes into play immediately. 

http://en.wikipedia.org/wiki/.NET_Framework
.NET 4.0 requires XP SP3, Win2k3 SP2, Vista, 7, or 2008(R2)
.NET 3.5 requires XP SP2 or newer.
.NET 2.0 requires Win2K SP(3?) or newer.
==========================
"Really decent people have a tendancy to bring out the worst in the rest of us..."
	- The Last Detective - Ep 2 "Dangerous by Moonlight"
	
Mungo Jerry - Summertime
Smiley Lewis - I hear you knockin'
Stuck in the Middle WIth You - Steelers Wheels

MUSIC DESIGN
----------------------------------------------------------------------------
Oldboy Sound track is great.  It has this manga Robotech sound mixed with late 70s sound.

This really fits with the art design i want to have for this game of the golden age of scifi
-----------------------------------------------------------------------------
music and art design inspiration - Tangerine Dream
http://www.youtube.com/watch?v=T_QXc5duq-4
http://www.youtube.com/watch?v=QuMYV6e18VQ
http://www.youtube.com/watch?v=iYUh88gr7DI
Tangerine? Dream "The Big Sleep In Search of Hades

Autumn Leaves Start To Fall - Eva Cassidy
http://www.youtube.com/watch?v=55p8JHjSACw
	- this song is so melancholy and the instrumental melody sounds like a really good song for when the user's ship is destroyed under Canon Saga...
	or when a mission is lost in general.  You get this forlorn sound of inevitability... that our human condition is to fight and die and here, you die in the cold dark vaccuum of space.
	"Cold Dark Vacuum" would be the title of my similar melancholy song that plays when mission has failed.
Sting - Fragile
	- http://www.youtube.com/watch?v=C3eD3HmFLmM
	
MOZART 	String Quartet No.23 in F, K.590 "Prussian No.3"

http://www.youtube.com/watch?v=WlzY6cWpoMQ <-- smokey robinson - Cruising
Theme Song
	- Regina Spektor - Blue
- Mass Effect - Uncharted Worlds
- Mass Effect - Vigil
	
Jacob Bronowski's - The Ascent of Man (1973) - YouTube
carl Sagan's - Cosmos
David Attn  - Corpus
	
waterman's address
Post address: 	
Nissbacksvägen 7 E 61
02780
ESBO
FI Finland 
stormwind.fi
=========================================	
COMPANY NaMES?
=========================================	
HighQ Media
HighQ Interactive


"Objects in Space" - a space trading simulation with submarine style navigation and maneuvering
http://www.rockpapershotgun.com/2015/10/31/objects-in-space-cockpit/

=========================================	
TITLES?
=========================================	
Canon Saga: Facets (face - a small plane surface (as on a cut gem) )


ommatidium - om·ma·tid·i·um
	noun \?ä-m?-'ti-de-?m\
	:  one of the elements corresponding to a small simple eye that make up the compound eye of an arthropod 

The Quiet
Black
Canon Saga : Version 3.11 (Copyright Great Age Media)  <-- software version numbers as matching our Canon time lines.  
Canon Saga: Battle School
Canon Saga: Red Flag
Canon Saga: Biocide  - the invasion of a powerful race that is wants to eliminate sentient competition and preserve non sentient diversity for itself
Rennaissance ?
starfarer rennaissance
perrigrine (name of ship?)
Starship Perrigrine - but the Eagle and Raptor animals still represents west... wht we need is an animal class that represents the new age.
=========================================	
Dragonhood?
====================================
I am dragon - battle dragon model awesome
http://www.the3dstudio.com/product_details.aspx?id_product=608220

   - name instead of I Am Dragon?
   http://www.youtube.com/watch?v=7fRT7cu7DhY  <-- i like the style of that for "I Am Dragon"  game (<-- register that domain)
	- to help market the game, have lots of vids of user's dragon character flying and torching troops and cities and bridges and ships and such.
	- also in our intro screen background, for when users download the demo, have it show gameplay recorded path of dragon flying high somewhat like a flight sim, only you're a freaking DRAGON!  This will also set the stage for users accepting less than awesome low level graphics.. the awe of flying high in the sky and going to new contents.  Seeking out thermails and jetstreams.  Using magneticsphere sensors like birds to have perfect sense of direction and heat pits to detect thermals... imagine the visuals... we can make the screen / world appear as a drdagon would see it which is another first.  Not nearly as bad as predator though.
	- heat shaders that warp the view a bit... cool graphics as far as the dragon and dragon's capabilities, but otherwise mount and blade modest.
	- Also show the lairs and ability to create lairs and traps and use spells to defend your lair, hide your lair, etc.
	- develop an amzing dragimonicon type lore.
=========================================

	- female aiko model should be scaled down to 0.025 and re-saved within the archive.
		(that was our original maintains it's scale.  we should rename it to say _toscale)
		70.098meters * 0.025 = 1.75245 meters
							 = 5.74951 feet.
	- reznok = 50.86 meters * 0.042 = 2.136 meters 
							= 7.007874 feet.
	- spinebreaker = 0.19 = 6.6 feet 
	
list of honorable planets
- JMS 001 <-- Star System in honor of JMS of b5
	- perhaps have two stars A & B and then a planet 1 - 9 with planet JMS B-5 the most prominent.
http://www.makosoft.com/stuff/capitalisms_war_on_democracy.html

LIST OF GAME ENGINES
C4 engine
Shiva
Leadwerks
http://www.panda3d.org/manual/index.php/Features
http://indiegametools.com/ranking/
http://slimdx.org/features.php
http://www.opentk.com/
sharpDX // competitor to slimDX
sharpGL
openTK

LIST OF SCI-FI BOOKS TO READ
---------------------
Old Man's War, In Death Ground, The Shiva Option, Lost Fleet series, etc. etc.
(Forever War (watched))

http://www.pornhub.com/view_video.php?viewkey=1963344095
http://www.pornhub.com/view_video.php?viewkey=485957554
http://movies.netflix.com/WiPlayer?movieid=70153447&trkid=8379860&pt_request_id=687dd4fb-72b1-4287-8d15-f69ca93bfb30-121786&pt_rank=0&pt_row=0&pt_location=WATCHNOW#MovieId=70179977&EpisodeMovieId=70153453


http://thedailywtf.com/  
LOVE THE NEW COLOR SCHEME OF THE DAILY WTF.  I WANT TO COPY THAT FOR MY SIGHT RATHER THAN SOME DARK SCIFI SITE

pramiracetam and alpha-GPC -- uses to treat alzheimers, dimentia... gives regular people improved memory

Read more: http://www.brainyquote.com/quotes/authors/a/aldous_huxley_3.html#ixzz1OUDlkZVb

Feral Dogs 14 pack leaders... a myth i dreampt of last night 6/12/2011 early am dream.

Gary's Mod users would be a good group to advertise to for Canon Saga

Aurora Trek Star Trek
http://www.auroratrek.com/episodes.html

proper government - http://www.youtube.com/user/Bantokfomoki#p/u/9/JF5OWm-wtHI   <-- a really good / simple system 
http://www.youtube.com/user/Bantokfomoki#p/u/8/67wiw7dJTaI   <-- part 2/2


Penne Pasta - this reminds me of how mcuh more i should be doing with pasta.  Rice is getting boring.  
http://www.youtube.com/watch?v=vJeJELexpDg

Chicken Divan and Tetrazzini
http://www.youtube.com/watch?v=ouiyPm_o0DM

Beef Stroganoff
http://www.youtube.com/watch?v=s2d2r3-evaU

Yakisoba
http://www.youtube.com/watch?v=x_KdI6BJlAE

Beef Stew
http://www.youtube.com/watch?v=_tm129P-DiA

Arroz con Pollo
http://www.youtube.com/watch?v=tCCPmM90s-4

Sandwiches
 
Rice Roni dishes
	- brocolli & cheddar
	- spanish rice
 
Songs 
	- somewhere over the rainbow/wonderful life hawaii sound
	- tony bennet 


buy his book -"A Time for New Dreams" which contains the poem "The Romance of Difficult Times" 
- Ben Okri 
 
12. When we are successful we believe in the rightness of our whims and thoughts.  We believe the most inflated things about ourselves.  We mythologize our abilities.  We think of ourselves secretly as gods.
This can last only so long either in the life of nations or individuals and this is disasterous for true groth.  It prepares a fall sooner or later.

- perhaps this gentlemans's extra verboseness helps to guide us because our intellect has diminished
or perhaps our knowledge too complicated, that we cant grasp terse sayings.

19) It is in difficult times that the great times ahead are dreamt and built brick by brick with maturity and the hope that comes from wise action 

Like every other good thing in this world, leisure and culture have to be paid for. Fortunately, however, it is not the leisured and the cultured who have to pay. 



"Principles of Naval Weapons Systems"
	- I love the font.  I love the geeky formality of it.  I would love for this sort of tone and appearance to be apart of all Canon Saga games.
	- That our games arent mindless fun they really are for learning and that fun is about learning and our philosohpy at Great Age Media is to make games where more than just a little of what you learn is applicable to real life.  It's may not be all or even 50% but definetly a respectable amount.
	- i like the idea of having real tomes like that to sell as part of game universe.
		- that our types of "game books" have a feel that is really technical and geeky despite being totally ficticious.
		- Manuals

http://spacesimcentral.com/forum/topic/3180-enemy-starfighter/#entry34074
	- looks cool these sort of simulated explosions	


Underrail -  http://www.youtube.com/watch?v=KXyCpVbKEKw

- scifi corridor 
	http://www.youtube.com/watch?v=bVN4Sfr58c4&feature=related
	
	#236547   
Sci-Fi Corridors Construction SET - Indie Commercial licence
39.60 
This pack contains 63 models (including all collision meshes). There are 32 unique models. Some of them are based on down-scaled textures from the sci-fi 4 textures pack. 
- Interstellar Marines too -> http://www.youtube.com/user/ZeroPointSoftware
- HMS Diptera FPS Creator http://www.youtube.com/watch?v=I-BoL4sK2RM

=======================================================
MARKETING 
=================================
  - jomsocial example site to copy perhaps   http://www.xxxgamingclan.com/
  
=======================================================
GUI
=======================================================
Looking at my old Bigspace mockups and the crew personel stuff.  Really some halfway decent ideas
- Also the Rules of Engagement 2 screens is great in terms of all the thing syou can do like self destruct, etc
	- would be great if in long term multiplayer, when ship's codes are assigned, if other players can "hack" them and steal them.... either with a spy that has been hired or some other method.... perhaps just guessed/hacked during a boarding party raid.
E:\creative\Specs_All\2d GUI\Figure_23_Rules_messages_FxCop.jpg  is just a basic vs.net properties display but thinking about the crew screen and the tabs along the side i think could be a great fit. as well as PublishTool_lg.gif in the same folder

- keep ribbon editor link near our list of gui sections 
	http://www.andypope.info/vba/ribboneditor.htm
	
toolwindow buttons title bar buttons window caption title bar control box
 http://www.thecodeking.co.uk/2007/09/adding-caption-buttons-to-non-client.html
 http://stackoverflow.com/questions/2841180/how-to-add-an-extra-button-to-the-windows-title-bar
 http://www.codeproject.com/Articles/42223/Easy-Customize-Title-Bar
 
Asset Browser - HCG Asset Browser is awesome
http://www.youtube.com/watch?v=wY4Entr3UXY&feature=related
http://www.youtube.com/watch?v=wY4Entr3UXY&feature=related

cryengine3 asset browser
http://www.youtube.com/watch?v=-IBe3zxePgw

material editor
http://www.visual3d.net/webmedia/galleries/GameEngineAlbum/Model%20and%20Material%20Editors/slides/toolset_materialeditor_1.html
http://www.visual3d.net/webmedia/galleries/GameEngineAlbum/Model%20and%20Material%20Editors/slides/ModelEditor%203-fixSpatial.html
http://www.unrealtechnology.com/features.php?ref=editor

	http://www.codeproject.com/KB/cpp/CollapsiblePanelVB.aspx  
	http://www.codeproject.com/KB/miscctrl/CollapsibleGroupBox.aspx
	http://www.codeproject.com/KB/miscctrl/collapsiblepanelbar.aspx
	
	http://stackoverflow.com/questions/3840898/treeview-to-control-panels <-- what we'll use only we'll maybe just use a listview?
	- although, what if we got rid of the tabs altogehter and used a treeview with a single depth level of children so
		now we have Physics, Appearance, Animations,   directly 
			and then as children for appearance for examples we have our Groups?
				- but ugh i dont want a horrible long list of groups really do i?  maybe its not so bad as long as its in that plugin and not
				- i mean maybe better to see those groups than to then have a drop down selector like in modelview 
				
Editor Feature To COpy
--------------------------
options screens
http://wiki.secondlife.com/wiki/Deferred_Rendering_Test#Deferred_rendering_prefs_UI
http://www.runescape.com/kbase/guid/controls_display_options
		
xna editor
http://www.youtube.com/watch?v=6PBoEaY8u7E

stem cell editor
http://www.youtube.com/watch?v=BxjuBsahNXE
		
http://www.youtube.com/watch?v=boqHWm3fQmc  <-- Hero engine

http://www.youtube.com/watch?v=N9XsXwIe9mQ    <-- i like the simple fast method of copy and pasting scene elements.

TODO: see below for help on snapping to grid point.  We will use either land or if no land available in a region  we will use our own grid values (which perhaps user can modify) for the grid line calculations.

http://www.truevision3d.com/forums/tv3d_sdk_65/snap_mesh_to_nearest_land_vertex-t17719.0.html
Core._CoreClient.SceneManager.EntitySelectedCallback.Invoke(pickedEntity);


TERRAIN EDITING
amazing landscape editor. really makes you think "to hell with procedural landscapes"
although procedural is probably still ok for some basic mapping but probably better to write your own code so at least you can ahve it
work on islands and such
http://www.youtube.com/watch?v=B6_J9wOw8ow&eurl=&feature=player_embedded


the cloning, snap to grid and scaling of this editor is great! Definetly things to copy!

http://www.youtube.com/watch?v=xzrr4wZtn_0&fmt=18
http://www.youtube.com/watch?v=awmsY0_U2HU&feature=related
http://www.youtube.com/watch?v=1aGJaqSKyZI&feature=related

I love this modular spacestation design
http://www.infinity-universe.com/Infinity/index.php?option=com_smf&Itemid=75&topic=9495.0

settings screen -> http://apolyton.net/ron/factsheets/info6.php

http://code.msdn.microsoft.com/XMLDocsToWiki

Graph including dykstras aglorithm
http://www.brpreiss.com/books/opus6/

this guy is kinda emulating my component system for vehicles
http://www.gamedev.net/community/forums/mod/journal/journal.asp?jn=333071&reply_id=3484512

 - starshatter graphics video
http://www.youtube.com/watch?v=eJuurm7Olv0

=======================================================

- dds format, would be nice to implement pure c# dds loader like the Targa one from codeproject	
http://www.xbdev.net/image_formats/dds/index.php

zbuffer w friendly projection for log z?
http://msdn.microsoft.com/en-us/library/windows/desktop/bb147302(v=vs.85).aspx

- video using GIMP to add grayscale heightmap into alpha channel of normalmap (keywords height map normal map alpha channel)
	http://www.youtube.com/watch?v=pGPJhT5lUpE
	
// offset rotation quat 
http://www.arcsynthesis.org/gltut/Positioning/Tut08%20Quaternions.html
http://wiki.truevision3d.com/hlsl_phong_sample

	
===================================================================================		
- network time sych add to lidgren
http://www.mine-control.com/zack/timesync/timesync.html
===================================================================================	

alien breed
http://www.zonejeu.info/2010/01/test-alien-breed-evolution-episode-1.html
	- i like the floorplan graphics but this vid made me think... you know what's missing?  fear?
	your avatar should show/manifest fear visibly in terms of shaking, fumbling while reloading or changing weapons, being shocked when something comes out the side, etc.  This is something not done in games and should be done... your characters are not mindless, let the player feel their fear from their characters actions as well... screams, rocking in the corner... not wanting to leave a hiding place...
	all of these things the player will grow attached to their character because they have to coax them out, slap themselves in the face... psyche themselves up, maybe even take drugs..
	
	- of course this needs to be playtested to be fine tuned so as not to make the player constantly dying because their character freaks out and panics... instead, the gameplay needs to allow for panic and maybe that means fewer enemies... i dont know yet, but really... when was the last time any game had the player's avatar acting afraid?  it's just not done but it is done.  So even a tough guy bad ass marine corp soldier today would feel fear and you would hear it, you would see it even if they acted courageously.  PTSD, tremors, complete shell shock...   no imaginary fantasy war, REAL war... its ok to portray war if you portray it accurately, but if you dont you're just glorifying it. 
	
System Shock 2 in game inventory system is nice.  I think maybe every crew can have inventory items and that paves the way for a turn based combat in doors potentially.  Or maybe not as i really prefer crew to be autonomous and which can only be given more general orders unless they are in the room with you... your avatar.  Then you can micromanage more. But to a point.. these are people not robots.  Thy may not do things correctly, they may become shell shocked and frozen, they may panic, they may be impetuous and rush to action and disobey somewhat.



=========================================================================================
- ALIENS
---------------------------------
- Fundamental
	- aliens in Trek and even in Babylon 5 are very often presented as 2d archetypes who because they are 2d are effectively mentally ill and so many episodes are about how they become more "human" or fully rounded... wise, intelligent, rational, but not emotionless and spiritually dead.
	
	- this is why these aliens are never really "aliens"  they are dysfunctional human athromorphs.
	- when NOT showing aliens this way, scifi tends to make them just animalistic instead with no higher intelligence.  "aliens" for example.
	- humans are always shown as the defacto model universe citizen and all aliens are psychologically or sociologically screwed up.  This is a bit less true in TNG where you have more alien underdogs just trying to survive against some threat which the Enterprise crew saves them from, but still...
	- that said, if going against this trend where perhaps Humanity is portrayed in the future as gray as they are presently, then we i think we do set ourselves up for a series that is more about politics and intrigue than it is about united humans versus the universe.
	
	
-  ENVIRONMENTS - EXPLORATION FOCUS
---------------------------------
	- http://www.youtube.com/watch?v=M-HMGLHVXV4
	- one of the things i hate about Planetary Explorers is how in the end it doesnt look very alien and there's no exploration.  In my project we have a real opportunity to make exploration inspiring and fun and really varied.
	- http://www.youtube.com/watch?v=m31MmtejOH8
	the above fake cel shading gives us an idea too of ALIEN ENVIRONMENT taht say gives the user some unexpected experience by changing the shading used when they enter some area.  It would be campy and trippy but add to this sense of "what will i find when i go to this place!"  
	and in this sense im inspired by the "color outside the lines and then let the user add color too!" philosophy of games like Saints Row 3 and 4.
	- these sorts of alien experiences provide a great juxtoposition between the basic look of the players ship.

- Stronghold Crusaders 2 - exterior landing party sim scales... very much like our tile system!
http://www.rockpapershotgun.com/2013/08/22/royal-crumble-stronghold-crusader-2-trailer/

- i like the text and line markers that point out planets, jumpgates, etc in this xna game
  http://www.youtube.com/watch?v=zrfq5hjKoWk
	- additionally, we can add some other data to that marker bar to indicate moons, space stations, and perhaps who owns the planet and such 
	in other words similar to a 4x game.
	- as well as different markers for different types of entities.  Remember that our viewport is basically a 3d sensor and spatial system.
	http://www.youtube.com/watch?v=6kpMHOfHJMs  <-- perhaps our zoom tactical scaling map can do similar... also similar to our solar system / nav map
	view where we scale things up but scale distances down.

http://www.turbosquid.com/3d-models/3d-ships-stateroom-model/404996  <-- awesome low poly look & feel to my ships.  Thats a good artistic yet simulation style look and feel for my art direciton 

- i like this halftone shader test for cut scenes and could use useful at least if thinking in terms of how we can make the player feel like completing a quest or mission is like the end of an episode. This could even be used for our transitions to/from planet to spice it up and give a cinematic quality.  This is all about "HOW to not implement something.. HOW to take the easy out in a way that is now adding polish and quality as opposed to just taking the easy way out of not adding complicated features.  Here we can avoid adding a complicated feature (eg. space to planet surface transition) but do so in a highly polished way.
	http://www.youtube.com/watch?v=9tr3clQutR8
---------------------------------
Future Alien Design
---------------------------------
The Spores. 
	- http://sketchup.google.com/3dwarehouse/details?mid=238c74fdd35447658377f8adca97cbe0
	- http://sketchup.google.com/3dwarehouse/details?mid=b3446feb12ec44a78377f8adca97cbe0
	
	The spores are a type of virulent / fungi hybrids that have been around forever.  
	They seek to find the perfect host in which to evolve.  They infect all sorts of species and then those species go to war with each other (but not non infected) to determine dominance.  There can be only one.  They are dubbed the highlander viruses.  After dominating another species, that new highlander race will undergo a mating and spawning phase and the new hybrid spores will  become part of their weapons as they head out into the stars looking for new worlds in which to pass on their spores.
	
----------------------------------
Alien Design Meta System
----------------------------------
- think in terms of Vehicles for Aliens.  Vehicles is based on the combined knowledge of scifi & fantasy film/tv/books vehicles
as well as real vehicles using real technology.
	- so too then should alien designs.  Look at all animals past and present and future evolution, and look at all aliens and robots from scifi
	and develop a design system for making aliens that is similar.  by similar i mean the sub-components of the body are guaranteed to work together because theya re choosing from a pool of designs.  What it does not do is just try to invent unimagined forms of motion, or eating, or attacking, etc
	- this vastly simplifies how we go about designing aliens
- similarly, we can modify the lengths of limbs and such and use parts that mesh together and joints by using same number of verts. Thus a neck can always fit a body by joining with a joint that always has same verts.  it's then just a matter of scaling the end points the same to fit.
	- this should start as a side project that only gets integrated after it works
=========================================================================================
Narrative
=========================================================================================
You are a captain for a Starfleet style faction and you are entrusted with exploration and making discoveries for your faction on the fronteir of space.  The more discoveries you make, the more knowledge, the more friends and future allies, the more charting, etc, the bigger you will be in the  history books in the Rogue Like campaign.

This is a type of campaign that is randomly generated and doesnt require a campaign.  This could in a way be our pre-Canon narrative where Canon has not been founded yet.  

So this is part of the challenge of narrowing the scope of our 1.0 so we can make money.
- Krellan Commander - roguelike in terms of the planets you discover and colonize, but a fixed enemy... the Krellans.
- Having a key enemy starting off maybe is not a bad thing.  The Krellans in a sense are like the Klingons.  
- multiplayer only battle simulation
-------------------------------------------------------
"I agree with nstutt.
The heart of Traveller far more? than trade & space battles...it is about adventure (Twilight's Peak), exploring the unknown (Shadows and Annic Nova), finding political & corporate allies, walking through a hidden Ancient complex on an asteroid, being hired by NPCs (76 Patrons), and misjumping & crash landing on a Gamma World-like planet only to find unstable AI computers & eccentric andriods...while playing as a scientist, Marine, noble, or the *ever-favored* IISS scout..." - steamworks1881 on youtube

FIREFLY - MOUNT AND BLADE
------------------------------------
Fascinating seeing the creativity of mods for Mount and Blade like the western mod 1866 and the screen of a soldier in a saloon using the back of a chair as a shield.  Wow, how cool is that?  Makes sense too, a shield and a striking weapon or a gun vs bow... all the basic actions are legal in any time or period.  So why not use the back of a chair as a shield?  Makes perfect sense...

So id love to emulate the modability of a game like M&B and allow users to make their Firefly mods, whatever.

Now the newtonian physics could be modable in my engine to make mod making more doable for different universes.  I can have newtonian orbits, simple newtonian where just momentum is preserved like bablon 5 starfuries, or arcade style play like star wars where you slow down if you're not thrusting and you dont drift forever.

That all said, the part in Mount and Blade that is missing i think is the flexibility of scripting NPC's and triggers and the like... the amount of scripting to more accurately build what alot of mount and blade players feel like they're playing.. a MUD... a 3d mud in a fully simulated world.  VRML style MUD.  But what's lacking is the ability to do more in terms of scripting... 
	
Space Fighter's game
------------------------------------
i've been thinking of the 4 main games ive had in mind (Begin, Krellan Commander, 4x, X-Com) but after seeing games like FreeFalcon5.0 vids on youtube that have different jets with different cockpits with every button and guage functional via mouse, it made me think wouldnt it be cool to try and make a real physics space fighter simulator that is just hardcore combat with a realism similar to a hardcore flight sim?  I think it would be pretty fucking awesome and be a good niceh and make use of existing tech im developing.
http://oea.larc.nasa.gov/news_rels/2000/art/glasscockpit/JSC2000E10522.JPG
	- a shuttle like this would be more used as a stealth bomber and a electronics warfare, eye in the sky + jammer + refueler.  It would NOT be well armored or even armed. It's loaded with so much electronics that its really just designed for electronics warfare, jamming, and some variants would be good for transport, refuelers, and various other support roles.

	-HOWEVER, i think the design of our Win32 Ribbon toolbar and floating windows and such should resemble an MFD style display where buttons on the MFD can be remapped to fit with whatever program is running in the display.  This is a good philosophy i think for designing our GUI.
		- Also thinkin gabout the Primary Flight Display  http://en.wikipedia.org/wiki/Primary_flight_display
	and how one thing that would be displayed there isnce there is no "horizon" is to make the primary flight display always be cyclable to be relative to some target such as your carrier's orbit.  That way your primary flight display has a reference point that you can always use to determine where you are in relation to it and where you need to be.  
	- Having relational waypoints as well since a CAP has to form to protect a THING and that thing is often in an orbit so is moving.  So this is actually an innovation in the genre i can make

	
NARRATIVE: The Narrative of Morena is CRITICAL!
	- The narrative of the BUILD interior should be one of a designer not of aethetics, but of cold hard utility
	- the narrative of the exterior is one of command information so taht the player can make decisions
	- the narrative of the interior is that you are on the bridge, when your avatar passes players they will show respect and you will be the big dog
	on that ship visibily by how your crew's body language is around you.
	- Star Trek 25th Anniversary Edition narrative was also about exploration and mystery.
	http://www.youtube.com/watch?v=IQ6frFkKZYs
	- showing working systems, working bridge, proper duties, working power and engineering and repairs, all of that
	really is about narrative.
		- every type of scanner has a unique sound on the bridge to indiate it's active
		- incoming coms from earth or hales have a distinct sound so there's an audio cue to it and not just visible from reaction of comms operator
		- the point is, if NARRATIVE is critical, then we have to think of how our simulation is not just functional, it's reinforcing the narrative and that is the key to player engagement and creating gameplay that can keep people engaged for hours.
	- real challenges with difficulty ratings
	- ability for users to create missions for one another, rate them and assign a difficult value
		- many puzzles may require users to use google or to research a topic
		- their are different conceptual types of puzzles
			- logic puzzles
			- analytical
			- hunts (not really puzzles at all but exploration)
	re: World of Magic narrative. Their arena demo feels like a prototype.  I wasn't expecting polish but I wasn't expecting such a sterile feeling game.  
	These guys really need to focus on developing narratives for both sides.  I don't mean full fledged storylines, I actually am talking about a narrative that is presented solely through the art, sound, and style of the game.  I think when we talk about "art styles" we really (to be more precise and precision is so important to have to convey what you want to the team) are talking about narrative!
	
NARRATIVE : Opening Intro
	- a ship, damage controls is done, return fires, etc
	- an opening intro can be really important for revealing an attractive narrative that users will want to experience interactively

Captain Design as it relates to narrative
	- if you assign odious traits like "amoral" then you can engage in slave trade, but this now means your ability to trust your own crew is diminished because you are feared but not truely respected and followed out of virtue.
	- but if you are "moral" you not only cannot buy/sell slaves, you will feel compelled to help those that are trying to run away.
	
Freelancer still alive initiative
--------------------------------
http://www.youtube.com/watch?v=ZXD4N_Mi1iE    <-- love the dynamism here and the aliveness of the space station traffic and the trails and particles and everything is high class.  Id love to have graphics that great.
http://www.youtube.com/watch?v=iErvfmqClb8&NR=1
http://www.youtube.com/watch?v=ZQIwupha8Rc
http://www.youtube.com/watch?v=Myw_2niQ6zQ

- BUT AS FAR AS capital ship sizes, look... scifi flicks have way oversized ships for the reqts of destroying other big ships.  Nukes see to that.  the main qualities would be submarine like stealth, some good armor to help them survive long range engagements, and for us our chatter, crew ops, atmosphere centric will make up for the vast ness of space.

- We will thus create a new genre of scifi and who a new type of space combat in depth and frankly define space combat... inconjunctin with our comic we will release to tell our narrative.
	- perhaps the comic updates can be a bonus of subscriptions... but i dont think so, i want the story to be known and to be free to see even if you dont like to play games.




Victory COndition for dynamic generated campaigns
=================================================
- these should be in a sense, give the player a feeling of a level.
- players should have to accomplish certain missions or quests which may result in playign 20 sub-missions in order to finally accomplish the final victory.
- these missions should be de-signable by users and then uploaded and rated and with an option of being included in a mission volume which is a collection of user created campaigns.  


======================================================================
ACTOR ART STYLE, NARRATIVE and DWARF FORTRESS IN SPACE (PROCEDURAL GENERATION SINGLE PLAYER CAMPAIGN)
====================================================================
I think ideally what i'd like is to have a bunch of diferent body and face types and kind of construct a modern LEGO
version of a person. Only unlike current legos where swapping parts is limited, i want much more mix/match flexiblity.

Furthermore, to be able to construct aliens using the same system but with perhaps a limitation that aliens initially are
all humanoid.  But wookies, sleestak, etc users should be able to design a "race", populate a star system's home world with their race
simulate their race's advancement through the stars, construction of starbases based on how much time has passed and then start playing the single player
scenario based on that procedural construction.  The game will also generate procedural alien races like Birdmen, etc.

Basiclaly we're tlaking dwarf fortress in space only you're the captain of your own ship of "dwarves."

And i would LOVE to be able to do our own instanced skeletal animation
http://http.developer.nvidia.com/GPUGems3/gpugems3_ch02.html
I know the batching is doable but the bone weight stuff im not sure
http://www.videosurf.com/video/real-time-shader-rendering-for-crowds-in-virtual-heritage-95920418
http://www.horde3d.org/
cal3d?
libAX?
animadead?

You know, just as minecraft has spearheaded a return to a proper sim where only things that are functional are rendreed and purely decorate crap is not
then so can we too go back to a type of rendering of humanoids that doesnt use skinning but instead strictly skeletal with keyframes and physics and with
each race/actor able to be generated from a toolbox of lego-esque parts.  A poor man's Spore but with more simpler generation of sentients.

sketchup wearhouse ragdolls
http://sketchup.google.com/3dwarehouse/details?mid=1f80bcb77cd7b54e810bb49588f6cc52&ct=mdrm


Max Gruter <-- This guy on sketchup has i think a style i might like to use in my sim for my take on a lego-esque character gen
http://sketchup.google.com/3dwarehouse/search?uq=1601659553860618556857140&scoring=m
Wow his stuff is so awesome.  It's simple but has such a retro throwback style.  The woman are good too.  Like.. industrious looking.  
The people are not at all drunkards, addicted, losers.. these are real adults before the nation became arrested developed across the boards.
	- LOL he's got one named "Nasa Experimental" and it's some crazy looking suit... IMAGINE THAT IMAGE ON A BANNER AD!  "Canon Saga: Experimental"
	
	As far as narrative, id love to bring back a narrative of exploration, of real men not whiny overgrown bitches, of a captain kirk in a alt earth time
	where we still built things to last, we did honest work and for a fair price and where that was our motto and we didn't worship the filthy rich who didnt give back
	and hoarded.
	
	THESE ARE THE PEOPLE OF CANON!  Max Gruter's style is great.
	
	
SHIP ART STYLE
- i like the interiors of "Enterprise" because it's a good blend of Trek and Current Tech.  Many of the computers are very much what we see today in glass cockpits.  And the bulkheads are good blend as well.  For my interiors i should focus too more on the gray interiors and bolts and rivets of military ship, or like an industrial use ship like a freighter.

even online planet screens
http://www.kevinsthoughts.com/2011/10/eve-planetary-interaction-pi-after-incarna-very-long-post/
	NOTE: the round icons are actually icons for structures on the surface of the planet!
	
+=========================================================
**************************************************************************************
AUDIO - Ambience
**************************************************************************************
Was thinking about what type of audio music or whatever to have as a theme and it occurred to me what i really really want is how Falcon 3.0 made
me feel.  It had realistic sounding comms traffic for fighters, and in our game id like to have realistic comms with fighters (like you also had in the new Galactica) and real sounds in terms of shift changes (beeps and tones to notify crew of upcoming changes as well...even like 15 minute warning beeps).  Also a day night cycle on the bridge, whirring of engines, ocmputers, fans, and such.

To the extent we can make this sound musical would be a challenge.  SOmething that is NOT annoying is key.  How to make non annoying audio?  What sounds \ frequencies and such are good to hear?  Relaxing?
+=========================================================
Subscription Service
+=========================================================
was thinking about this more yesterday... a subscription would enable extra features on the social networking side.  Especially as it relates to hosting 
		
=================================================================================================
Game Design - Characters
--------------------------
Real characters who are not necessarily these suave lady's mans or gorgeous women who have brains as well.
- The Morse character from the british detective series is a very peculiar character and comes across as just quirky enough to be real.  He's intelligent, intuitive, but not like Sherlock Holmes with his magical deductions.
Mostly his loneliness and inability to form relationships with women is what makes him a real human being... flawed in many ways, but still doing the best he can through this life.  I'm not sure how we create a game that is full of these sorts of characters.  I think the key to making these characters work and to not be repulsive is these characters must be moral and virtuous and have principles of some kind... a code.  They would be repulsive if they were flawed and fully immoral, unprincipled and full of vice.  With Morse, in the end you know that even though he's not a fighter, he would put himself in harms way to protect the weak.  He's chivalrous in many ways even if he is a bit snobbish and prejudgemental.

Game Design - Creatures
----------------------------
Crysis 2 had crabs, schools of fish, birds and other animals that were interesting because you wanted to see how they moved, how well they were simulated, what behaviors were they given... that is genuinely interesting
- so thinking about trek type discovery, these alien vistas with alien worlds i think could be quite amazing if done properly.  the trick though i think would be to postpone that for a future version because we'd want to get the procedural creature gen done right for many creatures, not just a few. And from microsocop to the macro so we can simulate biological infections and contaminations
http://www.youtube.com/watch?v=Wxauz2QsB3A



----------------------------------------------
GAME MODES

- Play by Email could use a central email service that we run.  Running an email server would be trivial.  This way, all users would have an account and so the email system wouldnt require any seperate apps or any special email plugins.

- Free For All / Last man standing Game Mode (more than just 1v1, you can have 16 players all against each other)
	- a multiplayer game mode where all players enter the procedural universe and the player with highest score who is still alive at the end works.  The reason highest score matters is, if say 2 players tied, each will have to continue to score points or else will fall behind and then that player who's ahead can wait until x max game time is reached.  So last man standing, but perhaps the opposing players can attack you as well so hiding may not help you if you're being hunted.
	
	- but the key here is the procedural nature of the universe... players who die aren't missing any special scripted content.  they can replay the game and see if they can survive longer.
	- two different victory modes, most tonnage destroyed and last man alive

Defend / Seige
	- defend homeworl
	- defend / protect starbase

	Tokamak reactor design
http://energyphysics.wikispaces.com/Tokamak+Thrust+Engine

Kerbal Space Program ->  Design idea to make our sim more "fun"
	- when designing ships, have our sims react to bad designs 
	- make combat very emotional with sims being scared, brave, heroic, etc
		- make our users become attached to each member.
			- this means balancing sims... a scared sim should at least be great at fixing things.
				- they should also be ashamed and need encouraging.
				
On saving/loadng campaigns after each lossed battle as people do in Civ
----------------------------------------------------------------------
In GDC 2010 keynote Sid Mier talked about how there are players who will fight a battle and lose it very badly and then reload the previous game
save and replay it and lose and replay nad keep doing it til they get the best possible outcome.  

So in Civ Revolution, they included the game random number ID in the save game and so reloading the game would re-seed it to where it was before and so the outcome will be the same.  I do like this idea.  You can't re-roll dice in monopoly to get a favorable outcome.  However...
in Civ the problem i think was sometimes the flawed way that combined arms works and how the player had little control over battle orders.  That aspect made these large battles feel like the player lacked control.  This was a flaw in Civ i think... like not being able to send in a weak force first instead of your best force that gets annialated early on.

Mission Idea
----------------------------------------------------------------------
Recurring mission where you're hunting for a famouse pirate or some famous ship/captain.  There could be lots of drama cat and mouse and tension and awesomeness when user finally disables the captain's ship, boards it and captures him.


------------------------------------
Aeon's Freedom Star point sprite vid
http://www.youtube.com/watch?v=6Y6pJgM0KSc
i had this working 3 months before he did but what i do think i should change in mind is to have the alpha value for point sprites more transparent so that they are less visible the futher awayt hey are.  I mgith need 3 different point sprite minimeshes or meshes for this to work.  Close ones, medium ones, far ones and super far ones are just not drawn.... and then they will fade in as you get closer.

Ideally, a shader could make it fade in using the single mesh approach and have the amount of fading truely interpolated by distance (using a texture lookup for the double precision position?) hrm... have to think about this more because its really not feasible to have proper distances unless we scale all the distances to fit within the drawable range


files since that consumes bandwidth

Training Missions
----------------------------------------------------------------------
- a mission where they are to fly silently and undetected along a route.  They are to identify, map, and categorize and clasify varous ships in the area 

(most are tugs, caro transports and such) and then return to deep space.  Simulated recon mission.  User will need to design a ship for this purpose.
In fact, one type of gamemode can be that the user gets x total design points to design a complete fleet, then they get x dollars to buy whatever pieces they want... and they then have to complete a simple campaign which equates to a series of scripted missions (simple campaign mode for v1 of campaign play)  That could be extraordinarily cool to do.  Users would be encouraged to share their own ship designs and their own campaigns.


AWAY TEAMS / AWAY MISSIONS / FIRST-IN MISSIONS / PLANETSIDE OPERATIONS
star trek away team
http://www.youtube.com/watch?v=myUsRo5bc44
http://www.youtube.com/watch?v=2gTsLa8x_0Y&feature=related   <-- star trek elite force
http://www.youtube.com/watch?v=BVg9FvZ_Yjs&feature=related <-- star trek legacy
floorplan bugs so far

Unclaimed WOrlds - Away Team <-- LOVE HOW THIS IS DONE.  ORDERS GIVEN AND THEY CARRY OUT 
E:\My Pictures\_KGB_PICS\unclaimed worlds 2 - tasks.png
	- Auto-Resolve Away Mission, Play Away Mission
		- abstract "your away team has discovered X."
		- unclaimed world - task system is nice
		- E:\My Pictures\_KGB_PICS\astrobase_command_gallery_3132_158_546789.png
			Even on this organizational chart, roster duties are assigned as TASKS not as stations!  We leave it to the AI to determine where they should be (i.e. which station) to perform their tasks.
		- Auto-Resolve Away Mission?  Play Away Mission?
			- can offer dialog that has the "Play" with help icon that says "feature unavailable at this time.  check in future patches."
			- you can assign rules of engagement perhaps 
				- some crew may break those rules and you'll have to decide how to handle that... if you catch it.
	
--- SURFACE PLANET AWAY TEAMS FIRST IN
Zomboid game
Zomboid
http://www.youtube.com/watch?v=3PBWujY9oW0
Zomboid has really good interior and surface planet look and feel.  I mean, i can see a surface party type game
where the crew are solving puzzles, crafting like a lucas arts adventure and thus discovering secrets to artifacts that way.
- our crew can fight not zombies, but native beasts, hostile primitives, and intelligent enemies, but also find friendly natives that need our help and in return can help us.
- and just look at how big the worlds are when you go tile based
- and interactivity of the world trumps graphics
- AND SIMILAR TO SHIP INTERIORS we can have MASSIVE SHIP INTERIORS because the graphics are
going to be mostly redundant, but what we lose in visuals, we make up for in this awesome simulations with 
so many agents and massive boarding assaults and defense that have amazing strategy for the user in terms of
setting up defense of the ship.
- crew can gather surprise from derilict ship, or forage on new worlds similar to zomboid
 then return to ship and store the booty
- crew can use shuttles and transports to fly from one settlement area to another in the world.
- they get into the shuttle and can select an "area of interest" from the planet map provided they have fuel
to reach it and still return to the carrier.

rpgs
	fallout tactics  - http://www.youtube.com/watch?v=p34tcA77p3Q
	
	Valkyria Chronicles 
	xenoblade chronicles  <-- amazing vistas, but seems not enough low detail of things to do...
		- http://www.youtube.com/watch?v=UmhJzZ8PoD0
		- but i do like that it has some huge monsters that you simply cannot fight and thus dont try.  you avoid and go about your business.  Why afterall in RPGs do people try to kill EVERYTHING?!
			
	


-------------------------------

On Ship's Security
----------------------------------------------------------------------
watching Enterprise reruns and it'd be interesting if sabotage were a key feature in our game how that would 
influence ship design and crew security assignments (patrols, guards, checkpoints, security clearances and access levels to various parts, etc)

On Sensor Buoys, Drones, Satellites
----------------------------------------------------------------------
Would be really cool to be able to drop various sensor drones and satellites that we can then access and check the logs or even be notified when various ships have been detected as entering/leaving a sector. You get some ship stats (ID if known, otherwise various detection stats) along with current or last known position and headings)  But essentially, i like the aspect of star trek where they come across a ship or drone or something and can access the logs to try and find out what's happened.

On Ship's Armor
----------------------------------------
http://efni.org/armor.htm


IN TERMS OF RELEASING MY GAME FASTER
----------------------------------------------------------------------
Must prioritize for for a simple 3d version of Begin / STCS and complete that game, test that game then work on extending 
	- lua football style play managment fleets\ships\fighters that you've given orders to
	- Game Development With LUA (Game Development Series) by Mark Manyen

	- networking, communications, website

	I think really nailing the above, no ship boarding (you can disalbe ships and press a button for "boarding/capture/hit&run" etc but it's all just automated on the server with no internal view.

	Save internal views, planet assaults, etc for the Krellan Commander version which could either be the full blown 4x version or just as a Dynamic Campaign engine add-on that gives you missions, manages enemy AI and friendly AI, and manages deployments and such.  Then the 4x version is a game where you get to play as the Admiral of the Space Force and control all strategy, deployments, build requests, etc.


============================================================================
BEGIN PROCEDURAL GENERATION IDEAS


ANIMALS - Super, Advanced, High Intelligence, Medium, Low, Primitive, Animal
	- Advanced - Intelligence, reason, logic, has dominated emotion and primitive carnal desires and genetic predisposition.  Cultural is the key to transforming High Intelligence to Advanced intelligence.  Advanced Intelligence is able to solve major issues concerning the development and prosperity of their people.  If the culture is wiped out, this advanced intelligence can revert back to high intelligence.
	- Super - True equality and power to all individuals.  Culture is no longer required to yield a being that is predisposed to thought and an incredible desire to understand the world in which it lives.  It is impossible for this race to revert back to a period where lack of culture would wipe out it's gains.
		- they are comfortable in their place and do not assume or aspire to be "the" greatest of all races.  they are non xenophobic and are aware of their limitations 
		Unlike warhammer40k universe humans might create, these super races create peace and diversity.  Humans they view as needing to be sheparded lest they cause great harm. Humans are simply so competitive.
		
	- Primitive - beginnings of complex social structure
	- Low - the age of Kings
	- Medium - abstract systems of control such as institutions that give more power to more folks
	
------
- take a generic body type
	- optionally seperate this into two parts, torsoe and abdomen
	- this body type provides the basic movement animations
- combine with generic head type
	- this head type provides the generic movement animations
- combine with generic paw/hoof types

- All body parts (body, head, have hardpoints that can contain useful tools (claws, teeth, tusks, horns, venom sack, etc) or decoration (main, frills)
		
- Apply some scale variations based on the properties we want for this alien.
- Determine behavior
	- carnivore
		- pack, solitary
		- status on predatory food chain (this is based on the other predators on the world)
		- scavinger
	- herbivore
		- heard, solitary, small groups
	- omnivore
		- small groups, solitary
		- scavenger

- Naming Convention
	- rat head + dog body = rat hound
	- rat body + dog head = rat hound too potentially unless that name is chosen.
		- in that case, the discover might add his name as prefix "Jacobson's Rat Hound" 

PLANTS - procedural

GOVERNMENTS - procedural
- politics
- social structure

Citizens - procedural 

==================================
NATO codes
http://en.wikipedia.org/wiki/APP-6A   <-- but be warned, this makes the game a lot less casual and thus a lot more niche.
Total War has a very good balance between usability and depth.

Was looking at Napolean Total War vids and staring at the masses of troops engaged in melee and you wonder "how are these formations handled?  And how do you match up units on one side, the swing/attack a unit on the other side?  Then the idea occurred to me that underneath there is probably a tiny sized hex map where only one unit can stand and that takes care of two issues. 
	- Spacing
	- individual target aquisition
	- Path finding within the melee mass and allowing easily the ability for a flanking unit to engulf the enemy unit by pathfinding laterally to the open hex spots near th enemy.
	
		
	Now lets say you have a cavalary charge joing in, initially this will result in potentially more than one unit on a hex and weaker forces will either get pushed back and result in a chain reaction of the weaker army getting pushed back and losing ground, or they'll get killed.
	
	
So the point is this can be extended for fighter squadrons as far as formation based movement is concerned and we can use this to massively reduce the amount of packets we need to send.  We simply have to describe the dimensions of the formation, the indices of units in the grid spots in teh formation,  updates for when one of these units is moving to a different position, and then just the general speed and heading of the formation.

I'll need to sit down and really spec out the precise methods but I think this is a sound approach in general.

Also consider that we can have these fairly simple formations and varied formations and switching formations that allow things to visually appear very dynamic.  Imagine a staggered line formation with a 1km spacing for instance for a bomber squadron.  Then they can switch to a wedge and the bulk of that can be computed knowng just the time the switch to wedge occurred and then the contnuous position and heading updates of the center of the formation.	

=========================================================================================
Inside a Nuclear Submarine
=========================================================================================
http://www.youtube.com/watch?v=HuSs_MsPS4Q 
http://www.youtube.com/watch?v=Z8N9Fi-kFNA
http://www.youtube.com/watch?v=TfjYZUiOkUw


http://en.wikipedia.org/wiki/USS_Scorpion_%28SSN-589%29

Just thinking about how the accoustic research was done to determine cause of the destruction of the USS Scorpion SSN 589.  It reminds me much more of how ToS startrek conducted science stations and sensors and communications... relying on instruments to show them data, and then their own skill to intepret what that data meant.   That's definetly something id like to bring back to this simulation... where ship detection, or planet detection around a star, or moon detection, or identification of some space junk or abandoned relic... where effectively everything is done at such far ranges, these crewmen who read these instruments have to have talent and incredible skill and training.

Software just might not be good enough or reliable enough to take into account tons of changing variables (including but not limited to off axis angles) to determine IFF, ship class, etc.  And further, ship captains and first officers would have limited knowledge of the oeprations of other friendly ships... (part of why a captain and first officer would never leave the ship to be captured either!)

Crew / Service People on big military vessels in space are treated like Warriors and are given total respect for their discipline and strength and because people know they are the best of the best, they are fearless frontiersmen, they keep us safe from aliens by offering the mutual destruction capability.  So i think it's important to convey to the user through the game, that when you enter a space station or some colony town, that your crew are treated with a reverance that is really cool to see and feel in the game. Sure maybe some of these warriors get drunk, act out, whatever... but there is a clear and unofficial "above the law" granted to them because in the end, it's recognized they are going thru mental hell... the crew responds not by punishing them, but by understanding and helping them.... unless they kill someone... or something totally over the line.  there has to be some line but the line for them is wide.
	


--------------------------------

(see Zomboid zombie survival game for gui hints)
c&c 
	- fleet orders
	- crew orders
	- squadron orders (if applicable for fighter squadrons)
	
Simulation
	- simulated battles (for user to know if they can defeat a certain type of enemy or to try out new tactics and formations)
	- simulated drills
	- simulated 
	
Tactical
	- formations
	- battle plans
	- weapons /targeting
	- world targets or spacecraft
	- boarding parties
	- colony and station strikes
	- away teams

security
	- access logs (doors and terminals)
	- permissions
	- prisoners
		- interrogations
	- defense
		- marines
		
communications
	- diplomacy
	- orders
		- fleet
		- crew
		- sorties
		
Navigation

science
engineering
	- power 
		- reactors 
		- batteries
	- engines
	- special drives
	
operations
personnel, administration
	- duty rosters & shifts
	- personnel records
	- awards/commendations/promotions
	- hiring/firing/salaraies/contracts
	
medical
	- checkups 
	- personnel medical histories
	- immunizations
	- medical bay / medical supply management
	- quarantine procedures
	
manifest/cargo
	- food stores/supplies
	- passengers
	- 
database				  

	
Build
	EDGE
		- Walls, Fences
		- Doors, Windows
	FLOOR
		- Floors
		- Hatches
		- Ladders
		- Stairs
		- Lifts
	Structural Support
		- Columns
		- Arches

Plumbing
	- sinks
	- toilets
	- showers / tubs
	- decontamination showers
	- linkages to water sources
Power
	- batteries / capacitors
	- reactors
	- generators
	- linkages to consuming devices
Propulsion 
	- Rocket Engines
	- Reactionless Thrust
	- Maneuvering Thrusters
	- Jump Drive
	- linkages to fuel if applicable
Storage
	- Fuel
	- Food storage
	- Cargo
	- Containers
Electronics
	- Sensors
	- Communications
	- Computers
	- Ship Systems Diagnostics software
Accommodations
	- Stations
	- chairs
	- tables
	- bunks
	- *medical bunk
	- *
Commodities
	- Supplies
	- Fuels (various listed by name)
	- Water
	- Food Stuffs
	- Medicine
		- radiation poisioning treatment
		- venom treatments
		- chemical poisoning treatment (liver pills)
		- disinfectants
		- antibiotics
Support
	- Lighting
	- Life support (oxygen scrubbers, air recyclers, contaminent filters)
	- Fire extinguishers

Medical
	- medical database software
	- diagnosis equipment

Weapons
	- beams
	- missile launchers
	- kinetic weapons
	
Entertainment
	- 
	http://spacestation13.com/?page_id=9
    Atmospheric gas system
    Dynamic Lighting
    Totally overhauled interface and GUI
    Fully destructible station
    Realistic organ based health simulation
    Individual job based player objectives
    Robust combat system (2.0)
    Jobs: AI / Captain / Head of Personnel / Security / Geneticist / Engineer / Atmospheric Technician / Medical / Chemist / Toxin Scientist / Roboticist / Janitor / Assistant /(Other jobs pending confirmation)
    Game Modes: Traitor / Nuclear / Revolution / Malfunction / Science & Industry

=================
	- crew \ shifts
		- training - unclaimed world - task system is nice
		- patrol shifts - unclaimed world - task system is nice
		- security shifts - unclaimed world - task system is nice
		- station assignments - unclaimed world - task system is nice
		- away team assignments - unclaimed world - task system is nice
		- boarding team operations - unclaimed world - task system is nice
	- maintenance schedules
		- sanitatation
		- plumbing
		- cleaning (mopping)
	- Security
		- keystonegameblocks\design\TrustSet.jpg
			- what if there were a  simple way to define which crew members had access to which areas 
			of the ship?  A way of assigning clearance levels and then making varous doors and component interfaces have a required security clearance level to acces without hacking.
			
Manifest
	- quantities and resupply buy/sell cargo, weapons, ammunitions, pods, fighters, bombers, etc
	- 

File
	Resume
		
	New
		Single Player
		
	Network
		Server IP
		Credentials
		Connect to Lobby
		
	Character
		Create  (multiple characters allowed for campaigns or what?
			or is it more just like a Steam Account handle?
		
	Settings
		
Account
	cretae
Sensors
	- tactial
	- cartography
	- targeting

(Sensors, Weapons, Power Assignments and such should be sub sections of the main C&C view perhaps?)
some of these layouts we're just not going to know until we actually get to playing.  

	
Personnel ->> http://www.bmscentral.com/products/schedule/slideshow.aspx
	- promotions
	- rankings
	- service records \ reports 
	- stations / scheduling / shifts
		- red alert stations (battlestations)- http://www.aesim.com/galaxy/dutylist.txt also at E:\dev\c#\KeystoneGameBlocks\Design\dutylist.txt
		
		- subordinates can submit requests as well and you can manage it.
			- subordinates can submit for approval/sign off various orders they've issued as well.
			
	- pay
	
operations 
	- orders (responding to received, and creating sub-orders for your own fleet and officers)
		- scheduling flight plan for the fleet and for fullfilling mission objectives
			- including resupply missions, 
			
	- flight plan packages for standard CSP (combat space patrol)
		- refueling in flight
		- training for crew and fighter squadrons / drills to improve efficiency
		FORMATIONS - Fighter Formation Hints from Total War
	
	
engineering ->  This could look very much like  keystonegameblocks\design\TrustSet.jpg
	- AKA like Control Panels\System\Hardware dialog tree where all types are sorted... only we can
	  also have colors propopgate up to indicate which branches have some damaged components in them.
		- THE RIGHT MOST PANE CAN SHOW THE REPAIR QUEUE/PRIORITIZATION QUEUE
	- power grid
	- damage control
	- engine levels, fuel allocation
		- thruster array
	- life support
	
C&C (Helm + Tactical)
	- contacts list  <-- ability to sort by range, class, threat level, etc
	- weapons panel (shows weapon links, their facing, assigned targets or orders (e.g fire at will)
		- if your weapon officer is particular bloodlustful, when ordered to try and capture a ship, he might still end up targeting the reactor and destroy that ship.  But it was your choice to have that officer as your chief tactical officer.
	- Galactic Chart
	- waypoint plotting (both for your ship and your fleet and fighters)
	http://www.youtube.com/watch?v=_QfsYIvJ8pY  <-- watch this from the freeworlds 2.0 vid 
http://www.freeworlds-tow.net/dev/
	- a tab next to weapon panel that is for fighter and bomber and shuttles and transports and other carried craft launching and ordering (sorties and packages and loadouts for them too)  Look at old vids of the amiga 1988 game Carrier COmmand for how you can loadout your Manta fighters as well as launch them individually. Look at the gui for doing that as well.  http://www.youtube.com/watch?v=w_BlO1CJn34
	- look for updates to bohemia interactives carrier command: Gaea Mission too.
	
// Administrative Tab - Chief of Staff / 2nd in Command
        //   Administrative list of personel, plugin details of selected crew member
        //      - personal bio, service record, awards and accomendations, demotions/demerits/reports, performance evaluations
        //
        //   Administrative duty roster, plugin details duty of selected crew member
        //
        // Engineering Tab - Chief Engineer
        //   - ship systems (excluding weapons)
        //   - 
        // 
        // Sciene tab - Chief Science Officer
        //     - star or world list and comet/asteroids and vessels for current sector 
        //    - detail scan information on current target
        //
        // Security Tab - Chief Security Officer
        //  - list of all prisoners
        //  - security camera locations and status in a schematic view
        //  - ability to click on a schematic location and view that location thru camera in viewportdocument
        //  - locations of enemy boarding party or unindentified life signs
        //  - diagnostics for secure stations and access logs
        //  - diagnostics and logs for door accesses
        //  -
        // Weapons Tab - Chief Weapons Officer
        //      - weapon status / targets assigned
        //      - standing orders / rules of engagement
        //      - munitions 
        //
        // Marines Tab
        //   - outstanding missions and status and etas and assignments
        //   - issuing and assigning new missions
        //
        // Carrier Tab (if applicable) - 
        //      - flight operations status (etas for returns etc)
        //      - sorties information
        //      - issuing and assinging new missions
        //
        // Cargo Tab
        // 
        //
-------------------------------------------------------------------------
     
*************************************************************************************************
Game DotNetBar items - Potential list and is from http://www.maddocman.com/spaceprobe/overview.htm
System commands

    * cds enable/disable/restart onboard computers
    * sol enable/disable solar arrays
    * master reset master caution alarm
    * menu, help (submenu) user manual
          o manual input search
    * log information
    * system information
    * database information
    * cls clear screen

Environment commands

    * als enable/disable life support
    * cablight enable/disable cabin lights
    * dock enable/release docking
    * airlock open/close [selection menu] outer hatch
          o Enter host [selection menu] action
                + Exit action
                + Refuel spacecraft (host-dependent) action
                + Access station log action
                + Search for cargo [selection menu] action
                      # Exit action
                      # Load item to cargo bay action
                + Acquire local positions data action
                + Acquire this station (host-dependent) action
          o Remain action
    * host information
    * host board enter host
    * cargo [selection menu] cargo bay
          o Exit action
          o Unload cargo action

	Communication commands

    * com (submenu) TX/RX data
          o id.. docking request docking
          o id.. location request information
          o id.. status request information
          o id.. locals request surroundings

Navigation commands

    * nav enable/disable navigation subsystem
    * eng enable/disable engines
    * burn level [selection menu] thrust
          o items selection
    * burn (submenu) burn options
          o 0.. msec burn duration
          o 0.. cruise cruise velocity
          o 0.. grams xenon amount
          o ma manual
          o retro kill velocity
          o disable stop burn
          o 0.. count (submenu) timer
                + burn burn options
          o abort timer
    * location [selection menu] heading
          o items selection
    * destination (submenu) heading
          o manual input coordinates
    * heading id.. destination by id
    * scn (submenu) scanner setting
          o manual input range
    * scn enable/disable scanner
    * timer start/stop/reset utility
    * info enable/disable flight information
    * radar enable/disable navigation radar

Game commands

    * world [selection menu] complexity setting
          o items settings
    * audio enable/disable game sound
    * about information
    * quit end game

	
class power grid/array : ComponentArray
weapon array
weapon links (same thing?)
sensor array
life support (ducts, air, pressurization, etc)
engines \thrusters array
	engine controls?
	ship attitude control

if the above are represented into a listing of all items in a particular grid/array/network, then they can contribute to the overall power, or firepower, etc and consumers dont need to direclty connect to the providers... dunno yet.  i still need to iron out how i want to do this

Known TV Bugs?
===============
http://www.truevision3d.com/forums/tv3d_sdk_65/help_me_with_setgeometry-t20712.0.html
SetGeometry bug i might run into eventually
==========================================================

	

http://www.gamedev.net/topic/574435-perspective---orthographic-projections/



Graphics Examples
-------------------------------------------
http://www.youtube.com/watch?v=BHDWukWE4Hg   <-- a mod with babylon 5 ships... which mod is this?
----------------------------------------------

CREW COMMANDS -  - Disobey or Question Order
--------------------------------
 - Crew may sometimes question your orders and this can provide feedback for when you are doing things that one or more does not like.  perhaps there are secret options, maybe all options every time any crew questions you must pick one

BOARDING PARTIES
--------------------------------
	-old school naval way is to cripple ship then pull along side and then swing or jump across
	- why not a similar mechanic?  This will prevent defender from being able to camp the small breach in hull and mow down invaders as they pour in.  
	- other option is to disable sensors and then breach quickly before enemy knows where the breach is taking place.
	- other option is a swarm of breaching pods and forcing the enemy to hole up at most critical areas to
	defend the ship and inviting the invaders into traps where areas can be depressurized, or flooded with 
	gas,e tc.
	
COMMS - Chatter to add to atmosphere and offset some of the emptyness and vastness
--------------------------------
--> need real proper space chatter like if ther'es a COMMS tab and we're talking to other ships or have an estabilished frequency between fleets, these comm chatter should come in automatically
--> AS WELL AS ONBOARD CREW CHATTER TALKING TO THEIR CAPTAIN AND EACH OTHER, confirming orders, first officer relaying the captains commands as feedback as well (similar to total war where you hear yoru general barkng the orders and units confirming.  Crew saying Aye Aye Sir"  "Changing course to x,y,z captain"  "Course now x,yz, eta to elta at current speed x time"


=========================================================================================
On AI - A.I  A.I. Artificial Intelligence
=========================================================================================
Anti-Objects
Alexander Repenning' (http://www.cs.colorado.edu/~ralex/papers/PDF/OOPSLA06antiobjects.pdf
http://www.google.com/url?sa=t&source=web&cd=4&ved=0CB8QFjAD&url=http%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fdownload%3Fdoi%3D10.1.1.71.5457%26rep%3Drep1%26type%3Dpdf&ei=1T59TLSLCZDksQPfsuyDBw&usg=AFQjCNFoBz0X_URcw7ko_fVBOEBles0NBQ

- celluar automata grid of the entire universe... in fact our "Sectors" are our sector based grid that our AI uses for determine which sectors are of most value.

- for AI routes, i could have a lower res version of the universe... one that doesnt simulate certain things in real time if there's no users around.

- for AI squadrons, we can use a localized grid that is centered around the squadron leader.
----------

AI War AI notes
-----------------------
http://www.gamerswithjobs.com/node/45270

essentially he uses simple individual flocking type logic but with a sub-commander logic to determine where fighters should target and the individuals flocking logic produces emergent breaking up and splitting of swarms and such.

==========================================================================
REALISM - 
==========================================================================
SensorScanTime Option Select - Realistic, Arcade
	- http://www.deepdivision.com/quickstart.htm  <-- checkout that quick start where once you start a scan it actually takes several minutes to complete.
	this is a definite thing about our spacesim i want to at least have option to have... performing a scan both of a planet, an asteroid or scan pattern for detecting enemy ships should take time and be based on the tech of your sensors and such.

Scanvenger\Collector\Cargo Drones - instead of a teleporter or a tractor beam, send out scavenger drones and perhaps even spear nets that can be launched connected to a teather and the net itself uses some advanced "sticky" that grabs things like an octopus and thus can be realed in quickly.

To fasciliate some of this complexity of 
	- docking procedures / protocols
	- contact protocols
	- etc
	- WE can have a dynamic smart help that based on whatever the user is currently doing or wanting to do, it will pop up with all of the shortcut keys, the info they need to play the game properly.  The beauty here is that there's no incentive to not come back and play again because you've forgotten something, the game will remind you.  
		- To keep the realism theme going, it can even be portrayed as the "Procedure Checklist"
	

==========================================================================
UNIVERSE GENERATION
==========================================================================

To make spiral galaxies or sphere clusters or whatever, i simply cull those space sectors that dont fit within the sphere or elipsoid prior to attempting to generate a system there.  Simple.

=================================================================================================
stellar systems
=================================================================================================
http://www.mpl3d.com/Featuresv12.htm
	- 	shader: New logarithmic brightness system for the stars and the starfield. It is based on the real apparent magnitude of the stars, that fits the logarithmic perception of the human eye, giving a more natural sensation to the star rendering.
	- shader: Ring system using 1xN lookup
	- shader: Improved starfield, that applies the logarithmic brightness system and is affected by the 'solar filter' option, as well as new textures for star flares and atmospheres, to be applied accordingly.
	- New camera speed algorithm. The camera speed is now directly proportional to the distance to the surface of the closest body. In this way, the closer the camera gets to the surface, the slower it goes, allowing a much better control
	- The brightness compensation algorithm is a part of the new logarithmic brightness system. It causes a 'blind' effect based on the visual magnitude of the brightest body in the screen, and its distance to the center of the screen. It will fade out the brightness of all the dimmer bodies that are in the screen. This option can be set On/Off independently. Default value is On.
	
Although the gas planets are lumped into one category, there are also subcategories among them. Astronomers differentiate between the classic or traditional gas giants and the ice giants. The traditional gas giants are like Jupiter and Saturn. Jupiter is considered the model for traditional gas giants. In fact, gas giants are sometimes also called Jovian planets after Jupiter. They are comprised of mostly hydrogen and helium. While ice giants do have some hydrogen and helium, they are mostly made up of ices such as methane, ammonia, and water. Methane is what gives Uranus and Neptune their blue color. (Uranus and Neptune are the two ice giants in our Solar System.)

- in order to render all my stars, i have to know all of their locations.  These will be loaded into a seperate type of "skysphere" class I think. When picking the skysphere, internally it will be able to tell us specifically what we've selected.  I think for now all we care about is the name of the star, it's parent system, it's zone and it's position in that zone.  Everything else we can look up if the user wants for instance to get detailed data on the star.
	- part of the reason this starCatalog needs to be seperate is not because we dont want to load the star entities themselves, but we dont want to have to load all of those ZONES that they are in!



- would it be a bad idea to have a rule that the closer units are to a majorly populated city, the faster they can regain their fullstrenth per turn.
	- the idea is an army that is far from any friendly city (oh, be cool if they could draw from allies too if that was an established treaty)
		- but the idea is, armies can rebuild from populations and materials and perhaps implement a slight decrease in production in exchange for the faster health



- FXSkyStarSphere  which gets placed into the FX_SEMANTICS_SKYDOME slot and on .Update() it will reposition.  The main additional is that
              we need a seperate entity associated that will share the mesh and can be used for picking the individual stars

- planetary ring rendering is slow on my fx5200.  i think the answer is to have various versions of the shader for slower systems as well as a non shader version.

- we already have code that we can use to determine the distance to get an entire sector in view...  so we need to for starters
  just have an ortho camera that looks at 0,0,0 from a position of 0,height,0 where height is computed from our calc. 
  Then, we draw orbits and finally replace the stars\planets\moons with... hrm... just scale them perhaps.  I suspect everything sun included will be pretty tiny so we'll need to scale their sizes up significantly.  This is just one option
- the other option which is probably preferable is to place onto the Draw context, a scaling matrix and scale everything so that it fits into the solar system viewport's dimensions.
   - the solar system view will be locked to ortho and have a max zoom IN value and zoom out maybe should be have a max as well.

      
- sketchup does have a scale tool under tools\scale
http://www.youtube.com/watch?v=I_xqUsZnzJA
- there are two types of scaling, component scaling and geometry scaling.  Component scaling will set a scaling matrix to the Entity whereas geometry scaling, scales the underlying model space vertex coords directly.  Modelspace scaling of geometry will be easy.  Entity scaling might be trickier cuz it might screw up how i do mouse perfect plotting/moving of low level geometry of the model.

- sketchup allows you to mouse pick an edge that is nearby even if you're not actually ON the face.
- proper vertex handle drawing
- selected face highlighting
	- this requires that we highlight a face if our distance to an edge is far enough away

=========================================================================================
==========================================================================
Inverse Kinematics 
==========================================================================
http://www.ogre3d.org/tikiwiki/SoC2007+Animation
http://www.openprocessing.org/visuals/?visualID=9453
http://www.gamasutra.com/view/feature/3456/animation_blending_achieving_.php

This is a basic implementation of IK using CCD method. Jeff Lander's paper 'Making Kine More Flexible' was used as reference.
 The second chain has joint constraints.
 
==========================================================================
FONTS -  Keep It Simple Stupid (K.I.S.S KISS)
==========================================================================
So i was going to implement line fonts and stuff right away and then i thought no, i want to just get it working with the least amount of code first and then if necessary we can go back and rewrite it... and in doing that with our DebugDraw.cs ive now got a simpler method where our DebugDraw commands are not fed directly to the RegionCullingInfo and so are sorted for us already along with other 3d visible items that share the same projection and view matrices.

Fonts
----------------
Consolas 
users\documents\fonts\
-------------

Line Fonts
----------------------------------
ttp://drdave.co.uk/blog/archive/tag/XNA?page=4
It is possible to extract vector definitions from the "Modern", "Roman", and "Script" Windows Fonts. I took the approach of pre-generating the line primitives for a given label at load time and passing them to the shader with a given scale and offset per frame. This proved slightly more performant than the SpriteBatch approach, and provided a good option for scaling the text to large sizes without occluding any objects in the background. Examples are shown in Figures 2 - 4.
-- and here this person provides his code
http://blogs.msdn.com/b/manders/archive/2007/01/12/stroke-based-text-rendering-in-xna.aspx
-end line Fonts
http://roundline.codeplex.com/
==========================================================================

http://blogs.msdn.com/b/shawnhar/archive/2007/08/21/motion-blur.aspx  <-- xna motion blur

http://drdave.co.uk/blog/archive/tag/XNA

http://xnameetingpoint.web.officelive.com/EnglishTwinklingStarBackdrop.aspx

http://www.gamedev.net/blog/1137/entry-2250225-devlog-5-stars-make-up/

Visual Studio .NET custom font scheme
------------------------------------
Tools\Options\Environment->Import and Export Settings
 - then download and select a .vssettings file.  I keep them in
 - User\Hypnotron\Documents\fonts
 
DevComponents DotNetBar  Docking Concepts page
------------------------------------------------
http://www.devcomponents.com/kb/questions.php?questionid=67
the above page finally helped me solve the zorder issues with docking.  in fact i didnt even realize it was zorder related
until i accidentally tried "send to back" and "send to front" on my plugins which were having similar issues.



========================================================================
asteroid fields
=========================================================================
- i think if we create a ring(s) of zones around the planet at the proper inner/outer ranges we can prevent from having to try and move individual asteroids in/out of zones to neighboring zones.  Instead, asteriods are fixed in their zones (for 1.0 at least)
- each asteroid field can then be represented as inner/outer/segments/seed  
	- then, each individual segment when generated uses as it's seed,  segmentSeed = seed + segmentIndex; 
	- then we partition the segment which is basically brick shaped into say 10x10x100 and so the finest grained partition is 10x10x10 but some partitions can be merged to hold bigger asteroids.  The point is though, using this partition system to populate the asteroids prevents
	any overlap (asteroids ontop of otehr asteroids) and guarantees a good spacing.  Perhaps the first thing we can do is create an array 10x10x100, and then start by filling in the biggest asteroids and tagging all of those array elements as filled.  Then the medium, then the small, and tiny.

	- and then each indivudal segment uses that segmentSeed to determine which of the internal partitions will contain an asteroid, what kind and what rotation (a vector velocity)
		
- a mix of tiny insignificant ones
- some that are effectively just like planets, small moons except "maybe" they can have actual orbital freedom like a spacecraft and not on a fixed path like a planet.
- but wouldnt all still be in an octree and thus subject to bounds checking?  ugh.

after looking at http://www.youtube.com/watch?v=O8IwSt_mflQ
http://www.infinity-universe.com/Infinity/index.php?option=com_smf&Itemid=75&topic=5260.0.html

it seems to me that putting individual asteroids in an octree seems insane... way too many.  maybe the prominent ones that can be manipulated perhaps, but these should total fairly few... the common tiny ones should be modeled more like grass and perhaps just need a way to be "tiled" around the player as he moves... they can be in a single minimesh and just have their positions adjusted to the visible range... say farplane radius 


Awesome asteroid field (XNA)
- http://www.youtube.com/user/RudiMedia#p/u/19/zbSbx5y5ORk
"I'm currently trying to create an asteroid belt... 
The low frame rate is due to FRAPS, I usualy get arround 60 fps on my old system (AMD X2 6000+ ; ATI HD2600)
The belt itself consists of 500,000 Pointsprites and 25,000 Asteroids, each made of 301 Polys .
I also corrected the wrong specular highlights and added normal maps."
Songs

http://www.youtube.com/watch?v=ZQIwupha8Rc  <-- must remember to copy them.  increase alpha big time of the 2d ring when anywhere near close and
insert lots of dust billboards along with the field itself.
also look at the infinity april 2010 tech demo vid! search youtube
-------------------------------------

=================================================================================================
SceneNode Management - Moving Entities Between Regions
-------------------------------------------------------

- put RegionMatrix from EntityNode as Matrix in SceneNode.  Let's face it, Entities should only deal with hierarchical relative position data.
- think of our SceneNode's and SpatialGraph as part of a seperate library perhaps for collision, visibility and picking

- sceneNode creation/deletion and re-use when adding/remove/moving nodes.  
- sceneNode creation/deletion when straddling boundaries and then not straddling anymore.
	- when this is working during cull traversal, we'll need to flag the other sibling sceneNode as visited so we dont redundantly test.
- NotifyDependants and NotifyChildren needs to be completed...

if we simply add the entity immediately without it's underlying resource fully paged in, we could have some easier time dealing with undo/redo... hrm.. 

so we have our seperate scenes and each scene has a simulation, but that seems to me to suggest that all entities must be know to each scene so that during simulation itteration, its only updating entities for that particular scene...  that way scenes can be independantly suspended and not updated... however there is an assumption i think that different scenes are still apart of the same overall "simulation."  Scenes only reflect unique instances... such as instanced missions for example.  The primary advantage of a "scene" is that you can have different fx used on them?  Meh.  i r mixed up on all of this... hope this wasnt all for relatively little advantage.  At least hopefully i can get all the scenenode management working properly :/


whenever an entity moves, changes parents, is added or removed, the spatial relationships need to be managed.  This involves determining if an entity needs to maintain a bounding volume under multiple scene node parents when it's bordering
	- move under parent
	- move between parents
	- move into new parent
	- added into new parent
	- added into new parent and removed from old
Well, I need some rules... hierarchical relationships can't be broken except for specific actions
   - an item being carried is dropped or jettisoned
   - an item traverses thru a portal that connects to a seperate coordinate system

WAIT - we can flag an entity as having moved, or added or whatever, and then in .Update() when all moves are finally over can we handle the changes to it's spatial SceneNode including the boundary cases of moving across boundaries and such.  When we "addChild()" we no longer need to do any sceneNode management there... we simply do it in update.  We can recurse children and update those then as well so long as we clear the flag so it's not done multiple times.

 Terrain - Cells  http://spacesimcentral.com/ssc/topic/3719-colonies-online/
-------------------------------------------
I like the idea of making the exterior colony / world / moon / asteroid exploration maps be not necessarily as to scale as XCOM.
	- there the scale is a bit more RTS scale.  I dunno yet.  
	- in any case, since id prefer combat ranges be more realistic like in Close Combat, one way to help users visualize who players are fighting if its turn based combat like XCOM especially (but at realistic ranges) is to place a "site camera" when the current player is active and this way we see what they are looking at and we can follow an attack through a FPS view of hte bullet even.

	
- CelledRegion
	Chunk[] Chunks;  <-- each can be streamed in/out on demand.  They all share same coord system as parent CelledRegion
	                     and each can be simulated using a broadphase lod simulator to update it's entity occupants.
						 In this way, entities can transfer between Chunks using a broadphase simulation of their actions
						 rather than fine grained simulation.
					<-- Chunks for now are not necessary until we have a better idea of things.
						In the meantime, we can just assume that CelledRegion's can exist in an array of CelledRegions
						within a Container object and thus CelledRegion's are already independantly streamable.
		            <-- chunk is a modeled entity that hosts Segments/Structure


=========================================================================================
SOLAR SYSTEM AND NaV
=========================================================================================
	- I think we should use ortho and apply a scaling prior to rendering.  We can use a fixed scaling and allow a degree of zoom/unzoom
        and other typical panning and such.  But trying to position the camera way the hell out is not good i dont think...  So how do we do this?
	
NAV GUI DESIGN  (MFD style  http://oea.larc.nasa.gov/news_rels/2000/art/glasscockpit/JSC2000E10522.JPG)
	-HOWEVER, i think the design of our Win32 Ribbon toolbar and floating windows and such should resemble an MFD style display where buttons on the MFD can be remapped to fit with whatever program is running in the display.  This is a good philosophy i think for designing our GUI.
	- Also thinkin gabout the Primary Flight Display  http://en.wikipedia.org/wiki/Primary_flight_display
	and how one thing that would be displayed there isnce there is no "horizon" is to make the primary flight display always be cyclable to be relative to some target such as your carrier's orbit.  That way your primary flight display has a reference point that you can always use to determine where you are in relation to it and where you need to be.  
	- Having relational waypoints as well since a CAP has to form to protect a THING and that thing is often in an orbit so is moving.  So this is actually an innovation in the genre i can make

- this thread has all info to fit the viewport to the star sector's bounds
  - http://www.gamedev.net/community/forums/topic.asp?topic_id=548148
- Star System view i think can work with BoundingBox.GetProjectedDistances()  to determine how far out our camera needs to be looking at the system to have it fully in view... maybe?
=========================================================================================
 	
- sprite batch http://msdn.microsoft.com/en-us/library/bb203866.aspx
- http://www.berecursive.com/2008/c/sprite-sheets-in-xna-the-basics
http://www.hard-light.net/wiki/index.php/Multimedia_Files  - freespace 2 file formats info
	- http://www.hard-light.net/wiki/index.php/ANI_Formal_Definition
	
- freespace 2 model format
	- http://www.hard-light.net/wiki/index.php/POF_-_Formal_specification
		- includes info on glow points, thruster points, etc


- Smooth Mouse look with spherical lerp - "Switching to a simple linear interpolation (LERP) of position and spherical linear interpolation (SLERP) for orientation bahaves well at lower frame-rates, and also gives the impression of momentum and inertia. I no longer track manipulation speed, nor continue inertia when the interpolation is complete."
 

  
FOCUS ON EXTERIOR  - Solar System, Lights, Shaders, Skybox/Starfields, gas clouds
- light parameters for planet shader.
	- the orbit behavior script will set these parameters for now.
	- comment out the semantics in the planet shader that sets light color and direction
	- assign this value in script instead.

- starfield
	as well as recomputing the position of the pointsprites representing stars about the viewpoint... 
		- we can add a special kind of mousepick to detect pointsprite billboards yes?
	
========================================================================================================				
Lighting
========================================================================================================
NOTE: Deferred doesnt require light management where we track which light affects which mesh
      - shadowmapping does
      - enabling/disabling of lights based on rooms and such does also
          - or is that done only during traversal via states?  
		- when a light is in a node, the portal itself can have properties which define if the light can pass fully or has to go through a frustum formed by the door... in this way you'd have to clip the lighting so that the entire floor isnt lit but just the part that is hit by the door opening.

	- the other nice thing about setting properties on the portal is that we can easily just disable lighting completely through portals for 1.0 and not worry about it.  

so i think there's two competing thoughts
	- a subscription model where items are tracked on movement
	- a traversal model where we try to set state in the draw list 
		- the traversal you just grab the lights and then retest the visible items against the visiblbe lights
		and the idea here is that you'd have relatively few visible lights and visible items to worry about
		

light.Flags = dirtyOnMovie
	- for stars, set this to false and only
	- but some of these flags may be relevant in forward renderer but not deferred
	
entity.Flags = requeryLightsOnMove
	- for planets and ships within a sector, we may only requery on region bounds cross (including entering a new region)
	

Light Volume Clipping - Deferred - 
    - http://frictionalgames.blogspot.com/2010/12/tech-feature-light-masking.html
    - it ends up being very similar to stencils for doors
	- http://hacksoflife.blogspot.com/2011/12/stencil-optimization-for-deferred.html
	
LightManagement
		- we can do quick tests for interior vs exterior lights and entities
		- somehow especially if we have a ton of visble point lights, we dont want to go through
		every item to discover which lights touch it
	- for exterior lighting of missiles, vehicles, asteroids(?), ships, worlds this could be good enough though?
	- note remarks on Ogre for shadowmap and LightList queries
	    - http://www.ogre3d.org/docs/api/html/classOgre_1_1MovableObject_1_1Listener.html
	
- It is possible to do shadowmap using multiple light sources
  - http://www.riemers.net/eng/Tutorials/DirectX/Csharp/Series3/Multiple_lights.php

========================================================================================================
SHADERS
========================================================================================================
Arius deferred
http://www.blitzbasic.com/Community/posts.php?topic=89138

Deferred Rendering tutorial -XNA Very well explained and awesome!
http://www.game-developers.org/node/177

http://www.gamedev.net/topic/562818-xna-deferred-rendering---performance-issues/

- combining lights in the shader is easy
	- http://rastertek.com/dx10tut30.html
	- you just return saturate (color1 + color2 + color3 + color4) * textureColor
	
- get our deferred test shader working again and on our collossal carrier
	- place point lights around it manually and they should automatically be used by the carrier
		- allow option to have random light color when we add a new pointlight
- get our deferred test to support dir lights also using the DirectionalLight.fx and deferred_combineFinal.fx


ProgrammableAppearance
	- no Material 
	- no Texture
		- just a shader with parameters that appear in a grid that can be edited
		- but  what about groups?
			- shader has to be assigned optionally to every group?  well, normally no, just the main
			but then you'd allow tv to update the semantics for the texture slots.  
			In fact there's no way to do that yourself...  i mean i dont think you can render just a group
			
	- You know what, i think i have to go back to my previous implementation where I add textures, materials and whether thye are used or not in the shader is dependant on a) if a shader is set b) if the semantics are used.
	- I think we can still enforce that the default or some otehr shader is always used though, but that'sall.  When iterating thru the shader's parameters we simply SKIP textures and material semantics.  In fact we skip ALL semantics and only use parameters the user's app code will set, not the ones TV sets.
		- the only real problem with this method is the Texture Mod settings.  those must be set in 
		the shader parameters list and not on the texture notecard.  In this respects, the texture notecard is obsolete because all it does is show us the texture.  To change it's mod, that must be done in the shader parameters.
		
		
		modes:
		-------
		Actor
		Mesh
		Minimesh
		
		Deferred
		Forward
		
		Diffuse Map
		Diffuse Map with Specular Power in Alpha
			- NOTE: in this case the specular power is used in conjunction with a material specular color
			- The alternative is to use a dedicated specular map + alpha for containing specular color per pixel
			  and intensity per pixel
			  When doing lighting, you calculate the diffuse term, and, if the object is "shiny", a specular term as well. The lightspot on a billiard ball is a typical example of specular lighting.
			// http://www.gamedev.net/topic/482021-what-are-specular-maps/
			The whole ball is made of the same material. So the reflection is the same on all places. But what if the object is made of multiple materials that have different light reflection behavuar? Vampyre_Dark gave some examples. That belt for example, leather will reflect differently than the metal knobs/buckle on it.
			- More/less reflection
			- The reflection color (white, blueish, brownish, etc.)
			- Shininess (how is the reflection spread out? A small spot, or all over the surface?)

			You can encode these values per pixel in a texture. The same principle as a normal map. I ussually take the alpha channel in a normalMap as the reflection intensity factor ( finalSpecular *= normalMapPixel.alpha ). But if you want, you can also take a RGB(A) texture. Where RGB is the specular color/intensity, and alpha the shininess factor for example.

			The calculation of the specular light stays the same in the shader. The only difference is that some of the values are variable and come from a texture now:
			 specularMapPixel = tex2D( specularMap, uv ).rgba;
			 specularColor.rgb = specularMapPixel.rgb;
			 shininess = specularMapPixel.a;
			 specular = pow( dot(reflectVector, lightDir) , shininess ) * specularColor.rgb * lightSpecularColor.rgb;

 
		NormalMap
		NormalMap w/Heightmap in Alpha
		
	
ShadowMap, Deferred... what we need to do is make these into types of
Renderers
IRenderer and allow us to plugin the renderer we want to use and to have that renderer
be able to reload resources using current renderer settings.
So before with ShadowMap we had it as an FX, but that's really not correct.
ShadowMap is a renderer.  So will be Deferred.
	- Perhaps our ScaleDrawer is re-implemented? 
		ScaleDeferredDrawer (bool shadowmapsEnabled)

		
- atmosphere shader
- clouds shader
- rings shader
- star
	- when adding pointlights which will be our Stars to the planet shaders or any external object using forward rendering
		- how do we place those lights into the correct semantics?
		- the up to 4 point lights with ranges == region radius are those lights.  But we can't do that in shader.
			- other point lights with smaller range but still affecting the mesh wont for example affect atmosphere
				- also wont result in ring shadow casting
				
	
		- star light occlussion for moons behind worlds 
			- is occlussion done by light manager? where worlds register as occluders?
			
	- see bi-directional lighting on http://http.developer.nvidia.com/GPUGems3/gpugems3_ch19.html
		- this is very simple method. If the lightDir and surface normal means that the item is unlit, we just apply the negative light with no specular, or fancy fx.
		
	- defineable global ambient
	
- placementtool accidentally selects directional light as a target.  Lights should be filteredwhen placing things.


- we need to be able to edit the color of a light in our plugin

- sole purpose of sceneNodes is hierarchical bounding volumes
	- otherwise entities only have their own bounding volumes, not those of their children
	- models will have to hold their own region space bounding volumes though to have their own
- FIXED. Model has to have matrix and worldmatrix.
	- FIXED. model needs a way to have it's own local position, rotation, and scale so that one entity can have multiple models that are offset from the origin.
		- model's bounding box is more important than the entity's.  
			- how does this affect scenenodes? scenenodes per entity vs per model?
				- i think during cull traversal, we must seperately test culling of models if entity.Selector != null 
			- scene node overall must use all sequence nodes and only first lod of lod nodes
				- perhaps we can have conditional compile flags to determine how our scene node overall box
				is computed.
			- bounding box computation of Entity has to be able to use Switch nodes, currently it only assumes Model or child Entity

Animation panel
	- i finally get how blending animations works and why it can work with spherical interpolators.
		- you compute the resulting vector or quat from both animations, then you multiply them by a weight and you interpolate between the two to get a blended result.



- when adding a Direction Light to each of a edit workspace and a floorplan workspace, the scaledrawer setlightposition throws access violation

- thread isnt stopped when closing app

- ability to assign edit a Domain Object script and save it and have it update the display.

- Components should have a specific kgbcomponent  extension so they can be filtered.
	- so that our floorplan creator will only show files of that type.
	- also components should set a mFlag that it's a component.  these flags are only useable by
	the scripts and custom front end code so arent' fixed.  can be app specific.
	
- Workspaces
	- Bar
		- DockContainerItem
			
	- definition files will restore bars and dockcontainer items including their names.
	- ive verified that if i delete all of the bars from the formMain.Designer.cs  that they will
	   get generated for us.  However, we then have to allow for our Workspace implementation to then
	   attach any panels and controls.  Panels are good if you want multiple controls assign to a DockContainer.Control = panelThatContainsManyChildren.
	   Otherwise, you don't need the panel.  Panels are not stored in a Definition or Layout file.
	   
	- so the question is, what do we share between views?  like if a Exterior Edit view is a tab away
	from the Floorplan Edit, then we can't load a new definition because we will lose our Bars which means
	we'll lose our viewport.
	- so our workspaces really are a collective for the most part.  But lots of it is hidden.
	-
	-  For example, when going from code edit to debug running your app. the toolbox window will disappear.
	there's no way to access it at runtime.  But also, the immediate mode and watch windows will appear.
	Interestingly, the immediate mode and watch windows will appear within the existing bottom dock.  Is that just a matter of the layout being restored?  Perhaps?
		- so that view also knows then how to hide it's specific windows and how to maintain the rest.
		- does this mean that there is crossover where both workspaces can share certain windows? 
		like the layout restore doesnt really change the locations of any windows that were existing in
		the previous workspace
			- IF ALL WORKSPACES SHARE SAME DEFINITION, THEN PERHPAPS ITS A MATTER OF HIDING/SHOWING
			- various DockContainerItems and Bars but always having them loaded.  So to show the Immediate
			Window and DebugWatch items simply shows them.  The layout then too is restored only once.
			There is no seperate layout for every workspace.  It's just hiding and showing.
	
	- treeview for floorplan and edit is currently being shared and not kept sepearte
	- definitions shareable?
	- toolbar buttons hide/show enable/disable
	- 
	- get checks in to make sure can only edit floor plan when in floorplan view 
		- can only place objects, cannot modify underlying scripts for them or dimensions via widgets)
	- can only edit exterior when in exterior edit view 
		- can also create and modify every aspect of an object including it's domain object script
	

	
Improving Rendering Performance 
http://forums.create.msdn.com/forums/p/90000/539613.aspx

- position calculations should always round to nearest .001  
	- all placing and rotations and scaling should be to nearest .001 
	
- component (like Engine) vs particle system vs laser vs explosion vs engine plume system (glow, halo, animated plume)

	- Modifiers
		- for a normal Entity, i can script the "update" method
		- but that is a bit limited... requires that I rewrite entire chunks just for a slightly different
		  update code to run....   what if instead, our update called our ModifiersCollection
		  that was same style as the Mercury ones and could be used on particle systems too...
		  but instead of passing an array of particles, i pass just the single entity...???
		  
	- Behavior vs Update (transformation and appearance) Modifiers 
		- but what about some particles that update all the time (like laser bolt entities) and those that
		only update when visible?  That is to say, some are part of overall simulation, others are just non interactive
		visual decoration.
		- I THINK THE PRIMARY ANSWER HERE is that a laser bolt would have to be a real entity dervied from Entity
		and fully simulated... so that any collision response could be had...  (but dont we pre-compute hits based on
		simulated dice rolls?)
			- but the main point is that they should still be able to use the same minimesh rendering system?
			- so we have an UpdateScript that can contain any code the user wants and exists in DomainObject
			- but also an array of Modifiers that can be assigned as part of the collection of code blocks to
			update the entity.  These modifiers can be 
		

- I think at the transition point of large frustum and small frustum, there is a space where a ship mesh gets clipped by the large frustum's near plane and so is briefly invisible.




=========================================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
MINIMUM VIABLE PROJECT - AI is player as coach, not a micromanager
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
MINIMUM VIABLE PROJECT - AI is player as coach, not a micromanager
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
MINIMUM VIABLE PROJECT - AI is player as coach, not a micromanager
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
MINIMUM VIABLE PROJECT - AI is player as coach, not a micromanager
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
TITLE: Morena's Verse
	- Player ship is the Morena and it's a firefly-ish looking ship
	- players can customize the deck layouts
	- they can add crawl spaces, have 3 decks or two
	- they can beef up armors, etc
	- upgrade engines
	- hire / fire crew from various outposts, colonies, etc
	- take on passengers
	- etc
	- single player only like FTL
	- DEMO MISSIONS
		- salvage operation
			- find salvage
			- retreive
			- find buyer
			- make the exchange
			
	- FULL GAME MISSIONS
	
icons - http://www.designbyjustinsmith.com/
	- gui layout help
Categories[    ] combobox, changing it will change the ribbonbar filters
                         , filters for each category are remembered from instance to instance

			
----------------------------------------------
2 MONTH PLAN - Flesh out this plan to include more specifics of each step
----------------------------------------------
Quick Look Star / Star System
Quick Look World
Quick Look Crew Member / Passenger / Prisoner / Corpse 
Quick Look Vehicle/Target
Quick Look internal component (sensor, engine, weapon, reactor, stations, door, etc)
Quick Look Relic
Quick Look Missile


	
engine - thrust emitter feedback
	- states
		- on/off
			- register fx\unregister fx
				- perhaps the registration itself can automanage spoolup/down 
		- on/off time <-- from this we can guage spool up / down animation reqt
		- emitter gets attached at engine.Translation + "offset" in BUILD option + 
			- when placing engine, show plume location.. hrm..
	
Engine
- Monday
	- exhaust (so we can see if the ship helm responds)
	- basic implementation using models and a vibration animation (random scaling)
	- particle system implementation
	- glow billboard 
	- lasers
	- Missiles

		
- wednessday 
	- placement of worlds if star is present, places the world in orbit around closest celestial body in the current region.  If no celestial body, place normally.
	- placement of starship places starship in orbit around closest celestial body
	in the sector.If no celestial body, place normally.
	
- Thursday
	- import new interior components
		- import new walls, a must to make our interior look better
		- import new floors
        - crates for cargo room
		- bunks
		- stations
		- ladders
		- hatches
- Sunday
	- start on crew management tab
	- side quick look bar that is customized for each type of ship structure 
		- floor <-- armor options, thickness, frame strength, material, craftsmenship, etc
		- walls <-- armor options, thickness, frame strength, etc

	
- Global Ambience
- Shaders
			- fix exterior ship shader
			-
- Crew - a single set of crew, hard coded added to ship and assigned to stations
		- no ability to re-assign stations, they will permanentaly stay there 

- Systems - Reactor, Engines, Stations for Helm
	- ability to link reactor power gen to engines
	- ability to link Helm to maneuver controls (eg maneuvering thrusters and main thrusters)
- Nav - ability to select a target to move to and ability to orbit at certain altitude
- Weapons - POSTPONED UNTIL AFTER MVP
- AI - an AI controlled ship that can follow, and flee, orbit
- Animation
	- animated weapons rotations, tracking postponed
- Scene Scan
	- world and star information that resembles aspects of our Crew Managment sidebar
- Missions
	- combat ship to ship
	- combat on ground with ground missions to explore recover artifacts or some such
		- player as captain can give general orders.  Can give a list of objectives in descending order of priority, and from there your crew will attempt to achieve the objectives.  
		- as far as training is concerned, training your crew can help them do better on real missions.  During training, you can introduce new formations, new tactics for various objectives.
	 
 
 
SCHEDULE & REQTS 4 MAKING VIDEOS **********************************************************************
	- plan
		- what kind of game would planetside missions be like?  RTS? Turn based like Fallout 2?
		- the AI reqts are massive i think... what can i do to release 1.0 that is more reasonable?
		- just newtonian exploration and combat like Krellan Commander?

		- what is my game really about and what will sell a 1.0 version?
			- these are the things i need to focus on
			- what am i trying to say with this game?  I want to bring back the hope of the utopia and the philosophies out there held by others that can show us the way.
			- what am i trying to show with boarding parties?
			- what am i trying to show with planet exploration missions?
				- should i postpone to just ship exterior and interior and make the planetside and starbase/station missions strictly abstract menu driven?
				- what kind of game can i have without planetside missions?
					- abstract "your away team has discovered X."
						- unclaimed world - task system is nice
						- Auto-Resolve Away Mission?  Play Away Mission?
							- can offer dialog that has the "Play" with help icon that says "feature unavailable at this time.  check in future patches."
					- you have met "Race X" Do you wish to?  
						- act like Conquistodor Cortez? Steal their gold? enslave them?
						- how will your crew selection affect the type of captain you can be? and the type of game you can play?
						- will you make enemies this way?
						- boarding party defense against pirates?
						- What kind of universe will you spread?  
							- will there be other crews out there doing different things?  Do you help those races?  Do you help return them home when they've been captured?
							- do you return relics or do you sell them on the black market?
						- TRAVELLER and less CANON SAGA?  
							- mining surveyors, resource surveyors, colony sites
							- Canon Saga can still happen in some future date?
							- will you allocate your own crew and possibly sacrifice them in order to accomplish greater good?
								- because these sorts of actions are part of what Trek was about.  Part of what being in Trek required.
								- if we get rid of planetside exploration as well as stations for 1.0, then we can focus more on allowing different factions in game (military, corporations, private research companies (non corporate backed, but backed by wealthy man), religious missionaries, spies, etc
									- and simulate those more abstractly.
									- we will NOT try to simulate bullshit like mining, production, and shit in any significant way.  because thats not the bullshit capitalistic mindset we want to perpetuate.
								[01:01.49] <Hypnotron> going to cut planet side missions
[01:02.00] <Hypnotron> you'll still have them but in an abstract menu way
[01:03.02] <Hypnotron> like in Civ "You ahve encountered the FLargh. Doyou wish to: [open diplomatic relations] [espionage - steal technology]etc
[01:03.18] <Hypnotron> just menu based with just outcomes being "this iswhat happened..."
[01:03.23] <micmanos> didn't understand a thing (which is fine if youjust need to blab) :)
[01:03.24] <Hypnotron> so more like a grand strategy game

		
http://nssdc.gsfc.nasa.gov/planetary/factsheet/sunfact.html
Bulk parameters

                                     Sun          Earth      Ratio (Sun/Earth)
Mass (1024 kg)                     1,988,500.      5.9726      333,000.    
GM (x 106 km3/s2)                    132,712.      0.3986      333,000.  
Volume (1012 km3)                  1,412,000.      1.083     1,304,000. 
Volumetric mean radius (km)         696,000.       6371.      109.2
Mean density (kg/m3)                1408.          5514.        0.255       
Surface gravity (eq.) (m/s2)         274.0         9.78        28.0     
Escape velocity (km/s)               617.6        11.19        55.2     
Ellipticity                         0.00005        0.0034       0.015
Moment of inertia (I/MR2)              0.059       0.3308       0.178      
Visual magnitude V(1,0)              -26.74       -3.86          -  
Absolute magnitude                    +4.83
Luminosity (1024 J/s)                384.6
Mass conversion rate (106 kg/s)     4300.         
Mean energy production (10-3 J/kg)     0.1937
Surface emission (106 J/m2s)          63.29
Spectral type                         G2 V

Model values at center of Sun:
Central pressure:     2.477 x 1011 bar                 
Central temperature:  1.571 x 107 K
Central density:      1.622 x 105 kg/m3

Rotational and Orbital parameters

                                          Sun        Earth      Ratio (Sun/Earth)
Sidereal rotation period (hrs)*         609.12       23.9345     25.449     
Obliquity to ecliptic (deg.)              7.25       23.45        0.309
Speed relative to nearby stars (km/s)    19.4

*This is the adopted period at 16 deg. latitude - the actual rotation rate varies with latitude L as:
( 14.37 - 2.33 sin2 L - 1.56 sin4 L ) deg/day
North Pole of Rotation

Right Ascension: 286.13
Declination    :  63.87
Reference Date : 1.5 Jan 2000 (JD 2451545.0)

Sun Observational Parameters

Apparent diameter from Earth
        At 1 A.U.(seconds of arc)  1919.
        Maximum (seconds of arc)   1952.
        Minimum (seconds of arc)   1887.
Distance from Earth
        Mean (106 km)              149.6
        Minimum (106 km)           147.1
        Maximum (106 km)           152.1

Solar Magnetic Field

Typical magnetic field strengths for various parts of the Sun 

Polar Field:  1 - 2 Gauss 
Sunspots:  3000 Gauss
Prominences:  10 - 100 Gauss
Chromospheric plages:  200 Gauss
Bright chromospheric network:  25 Gauss
Ephemeral (unipolar) active regions:  20 Gauss

Solar Atmosphere

Surface Gas Pressure (top of photosphere): 0.868 mb 
Pressure at bottom of photosphere (optical depth = 1): 125 mb
Effective temperature: 5778 K
Temperature at top of photosphere:  4400 K
Temperature at bottom of photosphere:  6600 K
Temperature at top of chromosphere:  ~30,000 K
Photosphere thickness:  ~500 km
Chromosphere thickness:  ~2500 km
Sun Spot Cycle:  11.4 yr.

Photosphere Composition: 
    Major elements: H - 90.965%, He - 8.889%
    Minor elements (ppm): O - 774, C - 330, Ne - 112, N - 102
			  Fe - 43, Mg - 35, Si - 32, S - 15
			  
			  
// http://www.uiowa.edu/~acadtech/phonetics/english/frameset.html
// http://www.uiowa.edu/~acadtech/phonetics/
PhoneticNameGenerator
{
	char[] consonants = new char[]{'b','c','d','f','g','h','j','k','l','m','n','p','q','r','s','t','v','w','x','y','z'};
	// combined phonetics which will act as a single consonent
	// hash completed word so we can test easily for collisions in a dictionary
	// 'ch', 'sh', 'ph', 'th', 
	
	char[] vowels = new char[]{'a','e','i','o','u','y'};
	
	int syllabelCount = rand (1, 4);
	int letterCount = rand (2, 9)
	
	switch (letterCount)
	{
		case 2:
				// always special case 'y' when used as consonant
				
	}
}
		
Linksys WRT54G version 6
l:admin
p:fr33domdev 
WPA personal network key:
abigmanknowsthemeaningofasmallcoin!


Competition -** It's annoying seeing all these games use Unity3d to save time, but many use the minecraft blocky graphics and i think it hurts their narrative.  My game isn't about crafting as it is about modding with ingame tools like Sims3 and crew psychology, management and exploration, and philosophy.
	Universe Edge - https://www.kickstarter.com/projects/rebellion534/universe-edge
		- universe edge material library/picker i like! ive not gotten around to way of doing that for walls and floors
		as well as i should so its a good way perhaps
	The Mandate - https://www.kickstarter.com/projects/1964463742/the-mandate
	Rodina - http://www.youtube.com/watch?v=QoKxtq4G1RI
	Wayfarer: The Outer Reaches - http://spacesimcentral.com/ssc/topic/4217-wayfarerthe-outer-reaches/
	Pulsar: Lost Colony - http://www.youtube.com/watch?v=vjnMZzsV03Y#t=0
	Space Engineers -http://www.youtube.com/watch?v=4rCNKF5JlLs
	StarMade - http://star-made.org/
	Maia - http://maiagame.com/
	Wayward Terran Frontier - http://www.spacesector.com/blog/2014/01/wayward-terran-frontier-kind-of-an-mmo-space-arpg/
	Drifter - http://www.youtube.com/watch?v=RPZSdERPUh8
	Limit Theory - http://spacesimcentral.com/ssc/topic/3120-limit-theory-an-infinite-procedural-space-game/
	Interstellar Rift - http://www.youtube.com/watch?v=bx6Edz8BprQ

	- "Rebel Galaxy" by former Torchlight devs seems to be a Privateer remake with Firefly motif and an NPC dialog system with memory persistence.  Aliens you meet will remember you if you cross them, etc.
		- unfortunately, the game seems to be lacking what i think next gen sandbox games require... procedural system, aliens, government, stories, and multiple roles for the player to play, mulitple jobs to apply for like in Space Station 13.  The best way to do this is focusing more on low end graphics and a grid system.  Even the ASCII privateer type games have a better ability to do well in making really cool universes.
		- in other words, games like Rebel Galaxy do little to simulate - and that means they don't really allow the player to imagine themselves in it.  They are "gaming" and not really "simulating" 
		
		
	THEME ROLLER PANEL -> http://jqueryui.com/themeroller/
	
	- nav overlay icons (orbit selection)
		- trajectory plotting / kerbal
		- computing orbit insertion velocity
		
	- new planet textures -> a pool to select from for now 
	- FX 
		- planet ring shaders / shadows mostly
		- lasers and particle beam weapons
			- exhaust (ships & missiles)  <-- MOSTLY LETS FOCUS ON SCRIPTING with CONE MESH, NOT PARTICLE SYSTEMS
		- trails, flares, and plumes
			- flares visible like a moving bright star helps in detection as game mechanic when other ships are burning and not coasting.
		-> SMOKE TRAIL and SOUND future reference
		-> http://www.youtube.com/watch?v=MT7wJq50n1Q
		http://www.youtube.com/watch?v=9R40-ghf3Ws
	- I/O - verify save load of exterior universes 
		- fixes to allow KGB to load New scenes after generating or loading new/existing ones
		- fixes to prompt  save of "untitled" unsaved databases on close
		
	- AI 
		- pathing 
		- character animations to match AI state
		- instead of trying to create a logic for AI that can choose appropriate actions, it may be easier to create AI profiles that govern tendancies of how they'll react under certain circumstances.  So for example, one AI might always look to avoid combat because its not warlike.  Another will only engage in combat if it has overwhelming advantage.  Another will always fight and do so kamikazi style and never retreat, etc.  Same can be done for grand strategy AI as far as tendencies for building economy and units.  One may build small, cheap, low tech swarms.  Another may build for super high tech, expensive but devestating death stars.  etc.
		- Rules 
			http://www.youtube.com/watch?v=ZLbpu6FDIQ0
			in Aurora 4x, the tasks / orders creation also contains standing orders that may or may not also have conditions that limit their execution.
			   - standing orders are basically "rules" like rules wizard on outlook.  an event occurs, a rule for that event is checked, if exists, conditions are evaluated and the rule is either performed or not.
			   - AI for crew can perhaps become this really massive list of rules that are triggered upon receiving events.
				- maybe that can simplify things.
	- HTML Renderer improvements
		- http://en.wikibooks.org/wiki/Special:RecentChangesLinked/Wikibooks:Reading_room
		http://quhno.internetstrahlen.de/myopera/csstests/collapsible-paragraph.html#url
		http://www.w3schools.com/jquerymobile/jquerymobile_collapsibles.asp
		http://coding.smashingmagazine.com/2007/01/19/53-css-techniques-you-couldnt-live-without/
		http://www.exoplanets.org/plots  <-- CONTROLS
		http://exoplanet.eu/catalog/   <-- compact view
		http://exoplanet.eu/catalog/all_fields/
		http://www.hzgallery.org/
		http://astro.psu.edu/astro-research/centers-and-institutes/center-for-exoplanets/publications2  <-- peer reviewed publiciations listing.  I kinda like the idea of having articles the player can download and read and have their crew contribute too (automatically)
		https://www.cia.gov/library/publications/the-world-factbook/geos/ve.html
		http://getbootstrap.com/components/
		
		Sol 
		
		[Tasks][Characteristics][System][Anthropology]
		
		Dependant Tasks
			http://www.manageengine.com/products/service-desk/help/adminguide/requests/tasks-for-requests.html
			http://jsfiddle.net/JQK2A/1/
		Tasks vs Catalog
			- Geology 
				- Seismic Scan
				- Geothermal
				- Minerology Scan
			- Equatorial Scan
			- Atmospheric
				- chemical composition
				- meteorogolical
			- Hydraspheric
				- chemical composition
			- ElectroMagnetic 
				- Emissions
				- Planetary Fields
			- Biological
				- Microbrial
				- Macro Flora / Fauna
				
		How will the task Database be used?	
		- GUI -> DB access for retreiving records for display 
				DB access for storing records that are modified via forms 
		- AI -> DB access for discovering what tasks they've been assigned.
				DB access for modifying tasks they've either completed or were forced to postpone or cancel along with reason
				DB access for AI creating new Tasks based on what they've discovered.	
				- if they've discovered something has broken, they will add the task to the Canon computer 
				- if they've discovered a valuable food source, they will create a task that may be a request, to start recovering that food source and brining into the ship's stores.
				- unassigned tasks
				- assigned tasks
		Star & Planet
			Tasks - Target of a NavigateTo task assigned to Helm
				  - Target of a Science Scan task assigned to Science Officer or Science Team 
				
		Vehicle
			Tasks - Proxy "Assignee" for all Navigation Tasks
				  - Proxy "Assignee" for all Weapons Targeting/Firing Tasks
			
		How will the library Database be used?
			- what does/does not go in XML anymore?
				- how do we break up these custom propertyspec[] and sql db?
				
				
			Planet sample collection and study... package and return to earth for analysis. Botanical missions

	  
		- get mouse events for collapsable show/hide working
		- get actual collapse/uncollapse for show/hide working
		- get mouse events for sortable table headers working where icons are specified as style
		- get actual sorting working (delayed - this is mostly StringTemplate stuff 
		- get our timer based counter fields running again
	- ideally have this based on actual simulation code such as planet distance 
	
	- HTML Component scripting
	- Procedural Generation Galaxy
	- C# Component scripting
	- Missions Scripts and Procedural Generation
	- Exterior physics
	- Waypoints and Navigation
	- Interior Floorplan polish
		- tools (copy / paste, undo/redo
			
	- star digest
		- picking of stars fails after moving camera from origin
		- goto fails because picking star isnt setting entity
		- can we make the writing of generated universe regions faster?
		because i think right now, the writes are a huge bottleneck.
			- if i took my xml file format further, id have a seperate file for every
			unique node.  doing many writes at once without each constantly running into locked 
			blocks of code is now much more possible now. Indeed, we could use the same type of
			synclock by "id" that we use in Repository.
			- of course, at this point its not XML anymore.  It's a bunch of blocks of data referenced  each other
			as children.
			- this could be something we can research on some future date...  and rather than using files we could use 
			a binary file that had random access to fixed size blocks... or something
				- much like a blackboard
				- even a db that consisted of fixed length blocks in a "list" where now we can refer to entities
				by index in the list and where each list element had a little bitflag indicating whether it was deleted or active
				- "list" replaces what we know of as a "table" in a traditional database
					- the main difference is that a list has two blocks, neither of which contain sub-fields.  The structure
					of the data itself is still specified in the formatting of the text.  
						- the 1st block is the data, the 2nd block is the index to an entire "list" 
						that contains a unique list of every child.  Thus the indices of children are in their own lists.
						- this isn't that bad really so long as we can dynamically manage their size allocations
						- adding/deleting list entries?  
				- we can now read/write lock on individual list items...  
					- can even have lists that contain pointer to seperate lists 
				- we are less concerned in 1.0 of being able to do queries directly on the list entries.  
				
		
	- Reactor 1.0
		- scripting
			- sounds & fx
			- exterior wiring of plumes to engines
				- engine script interface mockup

				Mesh common.zip|meshes\effects\plumes\Thruster1_interior_assembly.obj 
				5 groups. 
				00:00:00.1822240 seconds
				9147 vertices
				3049 triangles. 

				thumbnail
					Name:
					Health:
							
					power reqt [current / max]

				Operations:
					On/Off
					throttle
					
				Repair 	
					Total Damage
					Compression Coil
					Catalytic Converter  (1 supply, 1.5 hours)
				Build
					output
					Quality 
					Tech Level
					
				Statistics
					cost
					weight
					volume (i think volume and surface area are not needed because we already define the exterior size)
					surface area
					
				Engine entity
					- drag and placed from interior floorplan
					- can raise and lower the height 
					- when clicked on interior, shows up on quick look bar and
						- Build vs Runtime properties / interface
						- Build 
							- engine output can be configured
							- price shows
							- weight and cost shows
							- volume shows
							- maintenance sub-parts list
							- times to repair the sub-parts
						- we need a 3-views of exterior to allow better positioning of the engine plume
							- can specify from this view the engine plume position and type
							- scaling the volume of the engine will increase output
							- increasing or decreasing the output will increase or decrease the volume (scale)
							- "Technology Level" "Power, weight, volume, cost, surface area"

						- RunTime
							- on/off throttle
							- Tick() - consumes power / fuel
							- Damage
					- drag and drop the engine as an entity for now
						- position it manually
						- add animations to vibrate the plume
						- script events
							- start()
							- stop()
							
					- Entity Test - Engine Explosives 
						- they can emit heat perhaps
						- and blast damage perhaps


	- scaling
		- rounding of numbers for stats
		- calculating of overall vehicle stats / performance
		- a +/- button for scaling uniformly... no drag and drop at all
		
	- resolve how the html and templates are loaded - from script using path or just embedded html?
		- i think at some point i do need to ditch zip archive for mod and switch to dir paths
	- FIXED compute actual stats based on volume of the engine
	- production and consumption of engine power in runtime should update at a fixed frequency
	- update the quicklook power usage in realtime
		- apply a nominal variance to the figure which is tied to efficiency ratio
	- FIXED - show the links of components connected to the reactor
	- INTERFACE - BUILD UI in Arcade vs html UI for Runtime
		- Build component statistics
		- Build options (eg scale, quality, craftsmanship -adds time to build and cost but increases what?)
			- html tab?  build/simulated runtime/runtime
		- Build vehicle statistics
			- clikc off component and onto any floor perhaps and it shows vehicle stats instead?
		- Build -simulation- mode for showing what arcade runtime will look like
			- WHILE IN SIMULATION - no actual production/consumption
			- that includes no actual thrust
		- button for turning on/off
		- slider for adjusting output
		- interface that will show the damage and output and load
			- why not in the HTML?  well... that is causing us problems for starters
			and im more interested in getting scripts working than interface
	- output, load, but what about potential load of devices connected but not necessarily enabled?
		when designing in design mode user will want to know
	- Build Commands
		- how do we know when we're in build mode
			- reqts of build mode? 
				- buildstatus enum - design, redesign/refit, repair, building, built 
				- vehicle reactor offline
				- engines offline
				- docked or landed somewhere be it a spaceport, landing site, shipyard, etc
				- build timer (time to construct/repair)
				- build/repair mode must be entered into with brand new vehicle being
				  placed into that mode initially by default
			- when to show build UI?
			- what does buidl UI look like?
			- where do we show stats for reactor (component) and overall vehicle performance?
		- responding to intrinsic property value changes
			- these values such as scale/translatiion/rotation can be modified by physics,
			by script, by plugin, by gizmo manipulation
				- but scale cannot typically change unless in build mode and only for items with footprint that is autogen
		- rounding build values to nearest 100 if > x value.  to nearest ten if < 100 but > y, nearest 1.00 if less than y value, etc.
		- scaleable, minScale, maxScale, scaleIncrement, 
			- consider that sim with the fractal gui
		- component scaling for components where Scaling is allowed can only occur during design mode of reactor
			- this means only when placed in interior as well and during "design" of that component and not during repair of it or placement of it if salvaged or bought as is.  However if you are buying one made to order then it can be sized during placement.
		- build options that can be modified can all be added as icons in the main screen and not as "properties" 
		
		
Vehicle
	Engine 
		- thruster emitter
			- The thrust functions in Simulation.cs will determine how much thrust and direction and such
			based off the DomainObject's settings.  
			- has direction in DomainObject that will be queried by Simulation.cs
				- can be vectored within range limit
			- has position in DomainObject that will be queried by Simulation.cs				
			- these effect the top most container prior to encountering a Region (a different coordinate system)
				- thus it will encounter the Vehicle container
			(eg has not been shot off or ejected / seperated from the main vehicle)
		- sensor receivers
			- has a shape be it spherical, conical, ray
			- has ability to pick up those emissions which are specified
			
Queries on Vehicle can return
	- Query (root entity (eg vehicle)
	- all types from all subassemblies
	- specific types from all subassemblies
	- all types from specific subassemblies
	- specific types from specific subassemblies
	

- add Zaks visual profiler code.  Ultimately i need more detailed info on culling and script processing
- but first try to the free profiler.
- normalize all meshes such that
	a) no scaling is needed
	b) front of interior mesh faces +Z
	c) front of imported ship mesh faces +Z as well
		"front" is defined as the
	part of the ship that is most forward in the direction of travel.
	Decks can still be designed to stack up towards this direction (doesnt require artificial gravity 
	while accelerating) 
	or Decks can be designed to stack orthogonal to the front in the +Y axis 
	- TODO: SOme geometry manipulation tools would be nice to modify the .obj or .tvm or to save the .obj as
	.tvm within the mod .zip and to update the model to reference that geometry instead.
	- other geometry manipulation - recenter origin
	- rotate 
	
Model Selector
	- I think a "GeometryType" has to be part of the ModelSelector's own descriptions of it's child models because there is no inherent "type" that is relevant to a Geometry resource or Model.  It's only a matter of how we want the Selector to treat it.
		- i think this answers our question regarding ModelSelector fundamentals.
		
	selector flags / selector type
	SwitchMode\Selector parameters for each selected type
	GeometryType (for each model entry in grid)
	- would it make more sense to have a selector store some selector info in a parallel array
	to the list of sub-models and that way CSGStencil, CSGPunch, etc GeometryType is now set there 
	and there is no dependancy on the Model node itself.
Model
	GeometryType - CSGStencil, CSGPunch, Normal, CollisionHull
	
Mesh3d - changes to a resource must be implicitly global.  You are not making per instance changes.
       - these are global changes that affect everything that uses this resource.
	   - also these changes dont ever get set to a "Translation/Rotation/Scale" upon change of the up/down
	   controls because Geometry nodes dont inherit from Transform.cs and so dont even have those properties.
	   Instead, changes to translation/rotation/scale will be set upon "Apply" of those changes.
	format, 
	save copy as,
	rename,
	export
	lod tools
	generate hulls (and export to disk or save hull to mod.zip) 


	
NEEDED - Importing new geometry should popup an intermediate dialogue that lets us convert .x or .obj to .tvm first

BUG - my sychronized queue (aka single linked list) is not as fast as i think it should be
      - http://www.altdevblogaday.com/2011/03/09/lock-free-queue/
	  - http://hackcraft.github.com/Ariadne/
NEW - Sychronized multithreaded culling using threadpool workitems.
			
- ship hud icons
- add moons to all sol system planets
- add gravity transmitters to stars and worlds
http://www.gamedev.net/topic/481263-c-particle-to-particle-gravity/

- ensure bounding volumes are updating properly in EntityNodes hierarchically
	- also for minimesh fields, i think the entire field's entitynode is not updated
	- each individual minimesh element is not bounding properly
- bounding volumes for hierarchical systems are dependant on star
	- sub-stars off stellar systems disappear if primary star is not visible
	- planets disappear if the star they orbit is not visible
	- so this is an issue of hierarchical culling 
- start with our ship and updating it's prefab to be a ship with an engine and thruster components and
ability to modify our orbits
- BUG : I suspect when compiling shader before normal map is loaded and added to GroupAttributes that
  the re-creating of the DEFINES is not properly resulting in the shader being recompiled
	- i think one of the solutions is that we should compile a new shader and then remove the old shader node
	  and add the new one.  I'm starting to think all that should be done in the GroupAttribute/Appearance and NOT in the procedural shader.  Or at least, the internal shader should be treated as a legitimate seperate node that is
	  added/removed child... because currently i dont believe it is.
	  
- picking across boundaries
- fix docking layouts and asset browser and plugin

FIXED - CULLING BUG - Not a culling bug at all.  Was an issue with our zone center offsets.
- Picking across zones if buggy
- Viewpoint gets saved during editing when another entity is added to the scene causing that region's save file to be updated.  The viewpoint should be skipped.  
	
COMPUTING STARTING VELOCITIES AND SUCH!!!!
http://www.gamedev.net/topic/447624-calculating-an-initial-velocity-for-desired-planetary-orbit/  
- moving planet and moon orbits
	- http://www.orbitsimulator.com/gravity/articles/simu.html
	- eliptical orbit for pluto
	- eliptical orbit linestrip calc for tvmesh


- dust field - HUD momentum indicators
		- MotionField is now a part of our HUD and we can have seperate ones for each viewport.
	    (maybe eventually we can put that move update into script, but for now it's just not important.
		I mean it's good enough for now that it's isolated and not special case within ModeledEntity
		- line list version where the lines can increase
			- need to preserve vertices via as array where every even = start, odd = end vert	
		- dust fields quad line version
			- quad lines scale by velocity
		- point field spawn distance in front of camera increases with velocity 
		
			
- rotating planets (all have animation automatically added)
	- all scripts loaded
	- scripts assign our gravity transmitters
	- scripts perhaps can assign our animations
	- scripts can assign procedural texture generation settings
	
- orbiting stars 
	- stars in multi-star systems all orbit center of mass and they rotate at same period .
		- stars do NOT also orbit their planets because there's too many too take into account
		and it'd have to be an n-body system.  Thus Planets cannot orbit stars but only centers of stars or the
		overall system.
		
	- binaries orbit center of mass beteween them and can in turn orbit the center of mass between other stars in the complex system.  But these points are pre-computed and the orbits are then keyframed elipitical.
	
- planets with atmos/cloud/rings should not have those items added as seperate entities, but as Models in sequence
- add Earth moon
- add all moons to our auto sol system and use correct textures

- add nicer Earth texture
- rotating cloud layers

FIXED - update grid to use LINELIST mesh
- hide/show celestial grids
FIXED - hide/show labels

- starfield digest / dynamic update of visitable stars
	- picking of stars
	

- lasers from laser coords set on ship
- engine plumes from coords on ship
- engine trails

FIXED - hud icons for contacts
- nav map work 	
- navigation/engine gui controls
- movable turrets 	
	- turrets have a rate of rotation
	- turrets have constraints 
	- turrents can follow targets and shoot in the right direction
- atmospheres that match the planet's atmos settings
- procedural textures gen'd properly

- fix ring shader at long distances
- fix vehicle pixel shader 
- fix light info not added to rings when light added before the rings
- fix culling bug
	- look at projection functions and 
- smooth our mouse camera  in preparation for making videos
	- http://www.gamedev.net/topic/427197-third-person-camera-system/page__whichpage__1%3f
	
- http://www.meshweaver.com/tutorials/Thrusters.htm


COMPONENT WORKFLOW 
---------------------
- launch sketchup 8
- export model via File \ ObjExporter 
- if using freeware version of obj exporter, import the .obj into Silo3d and fix face normals
- import into keystone game blocks asset browser (todo: should a .component be an entire self contained .zip?)

	
	FIXED.  create an entirely seperate "HingeDesignWorkspace"
    that we then switch to for purposes of editing the hinge and allow users to then
    switch back to normal scene when done.
		
	FIXED. RenderingContext.cs mViewpoints stack is using same viewpoint for every
    viewport and this results in inability to seperate out the positioning of one
    of the viewports from the other.  
			
	- grid should draw perpendicular to orthogonal viewports
	- rotate widget doesn't work
	- constant screen space size broken in orthographic views
	- make zoom extents of ortho views more robust

	HINGE AS RENDERING CONTEXT GUI ELEMENT
	- during pick operations, they are temporarily added to the scene
		- well, we could possibly generate our own regionpvs item for it by knowing the parent but...
		- temporarily adding them may just be the most simple way...
			- will it work if it's done 3 times in one iteration of the loop without a chance for
			the notify messages to get processed?
			
	- after pick operations on that viewport, they are removed
	- On render, they are tempoarily added to the scene
	- after render on that viewport, they are removed.
	- this is probably good for physics lib in the future where we dont want gui widgets being in the scene.
	
	
	- the hinge icon needs to be directly moveable and NOT result in the underlying target moving!
		- the hinge icon should be a target for the hinge Animation of the target.
		- thus, how to manage this.
		- the target should not be moveable so long as the hinge is showing
		- whenever back into hinge edit mode, the target should be fixed at origin with 0 rotation and scale.

		
	
-  FIXED. when multiple mViewportDocuments visible (eg multiple workspaces open) the 
static method Viewport.GetMouseOverViewport()  will return the viewport of a non visible workspace tab
unless we viewport.Enable = false on it!
	
	
	
TODO: If you export every .obj to origin, then within KGB, configure one model with an offset and child of another and then transform the parent object, does the child translate/rotate properly with respect to it's parent and offset?
TODO: And how would you deal with a type of animation like a "retract door" where it's only valid at specific LODs... yet the script makes the call and the state must be updated somwhere.  Is that state a custom parameter in the Entity file?

TODO: Rather than articulating in a robotic way, with joints and such, how about just simple keyframe matrices and interpolation?  

IMPORTANT: Recall the main purpose of a "model" is to share instances and to have LOD management built in.
For LOD actors, the keyframes have to be the same, but as Sylvain indicated, you can have fewer bones in the lower LOD actor.  So lower LOD geometry and lower LOD bones but same number of keyframes and animations.  This is good.  We can do this. HOWEVER, the different bone ID's for attaching things could be annoying... but maybe not as bad if we go by bone "name" and then do a mapping across the LODs.

for LOD actors or Sharing Actors, we can sync them by getting/setting the proper KeyFrame stored in the per instance parent Entity object

NOTE: We would only want to deal directly with Get/Set BoneMatrix if we were animating our actor through physics or something.  But if we're only using keyframe animation, then this is simplest/best way.
    
	http://www.truevision3d.com/phpBB2/viewtopic.php?t=15261

on the Geometry actor3d's update (EntityBase entity), it should store the resulting keyframe in the entity.Keyframe = result; 
prior to rendering, the keyframe will be set to the Geometry.
 
        internal Actor3d _actor
        {
            get { return (Actor3d) Geometry; }
            //if (Geometry is LODSwitch) 
            //        // todo: this is kinda wrong.
            //    // we sometimes want the first child but other times for updating
            //    // animations and such we want the proper LOD _if_ its an Actor3d and say not a Billboard...
            //    // so how to handle all this?  I suspect for a BoneModel no billboard would ever be used?
            //    // but assuming this, how do we select the proper child?
            //    // if we get rid of this private method and force the caller (e.g. Simulation.Update)
            //    // to select the child and to then handle all the proper animation handling ... then this could work.
            //else
            //    return (Actor3d)Geometry;
        }
	
				
==============================
- LODs and Appearance?
	- lods are currently shared so can't store Appearances...
		- Appearances are not shared... because they store state for texture mods for instance
			- so fundamentally, part of the issue is that appearance stores state... that there is no more "Model"
				- but lets not get sidetracked.  Our only concern now is dealing with different appearances for LODs and damage.
				So i think in that context we have a mirrored appearance.  Maybe this also means we need a mirrored HashCode
				So if there is no appearance at an index, then none is used.  
					- also what about nested LOD's?  I think its necessary because we have SwitchGeometry 
		
FIXED - overwrite of existing prefab not working in xmldb
- deferred rendering of stencil punches works?
	- we need a seperate technique for STENCIL
		- seems this must be set in Appearance because it requires a seperate shader IF we do it in shader
			- but it's just a Technique so we maybe dont need a seperate DEFINE.  Just seperate techniques we set.
			- technique Deferred_Stencil_Target, technique Forward_Stencil_Target
			- technique Deferred_Stencil_Source, technique Forward_Stencil_Source
- set up new test meshes for walls and floors that uses normal mapping and verify it works
	Color rgb Specular Intensity A
	Normals rgb Heightmap A
	
	View rgb, Depth A -- 8 bit depth?  ugh.. no way!
	
	-verify specular masks work
	- verify emissive masks work
		- seems emissive intensity u can put into alpha channel like specular
		and for emissive color you use the diffuse textures color which seems right.
		- the downside is if you want to then disable emissive (a light that is broken) and
		then maybe now you dont want the diffuse that color at all.  but in most cases, even
		that should be fine as the "off" state is dull.
	- shader work to verify material works in forward (defines work when material is added to a GroupAppearance
	- Import needs to create our ProceduralShaders
		- note: Should ProceduralShader be merged with GroupAttribute?  If the shader is not null
		it gets applied to that group of the mesh.  If there exists a default shader, that gets used.
			- but how then do you decide what is the default shader to be loaded?  Or why not manually load
			the shader when designing the prefab entity?
			- The default/overall appearance always gets a default shader created on creation.
			when Geometry is IMported.  The sub-groups do not, although one can be added.
			
	- Defines need to save be saved out to xml in our GroupAttribute just like GeometryType
		- adding a Material to an Appearance updates defines
		- adding a NormalMap texture automatically updates defines
		- adding a SpecularMap automatically updates defines
			- there are two types of specular maps
				- there's the intensity map (which still requires either colormap or specular material color)
				- there's the colormap (which replaces specular material color)
					- colormap works with deferred.
					http://forum.unity3d.com/threads/70614-Color-specular-shader
					http://forums.cgsociety.org/archive/index.php/t-608056.html
		- adding an EmissiveMap automatically updates defines
			- http://www.gamedev.net/topic/364875-emissive-mapping/
			- Should emissive be done in a seperate pass since emissive is hardly used and specular is more important.
				- emissive will take up relatively little screenspace.
				- maybe even combine emissive with bloom pass?
				
		- etc.  Just like geometry type its automatic 
		- adding normal map adds the normal map, ditto for parallax checkbox in alpha
			- i think this answers the question for us for when lightingmode gets set
		
		- eventually test removing normal map and such and verify lightingmode changes and such 
		- eventually switching them to instance renderer works to compile new minimesh specific version 
			- verify we can associate original appearance with the minimesh's cloned version so changes in original can change minimesh
				- this may require on AddInstance() that we supply appearances or something... not sure.
					- maybe the minimesh appearances are special types that maintain that reference and look for changes... dunno yet
				- sorting of minimeshes by hashcode to see if we can enablearray and then change appearances inbetween
				- or maybe not necessary, instead we have seperate minimesh instances in our FXInstanceRender for each
				hashcode variation and not just tied to one mesh instance. so keyed by both mesh and hashcode
					- or maybe a hashcode that takes into account the meshes resourcePath as part of hashcode formula computation
				
- configure in assetbrowser all new assets from DexSoft
	- create the combined normal map + heightmaps in GIMP
	
- save as, allow double click and click of the selected file to overwrite
	- and clicking should fill in the filename box

	
	http://wiki.truevision3d.com/hlsl_phong_sample
	http://fabiensanglard.net/bumpMapping/index.php
	http://rbwhitaker.wikidot.com/bump-map-shader-2
	http://www.bencloward.com/resources_shaders.shtml
	http://knol.google.com/k/shader-fx-parallax-mapping
- shaders show up on "Defaults"
	- should single grouped geometry only have a default appearance tree node?
	
- how to know which layer and on which meshes/actors/landscape chunks to settexture(-1)
  after removing a texture?
	- if Appearance nodes were not shareable, then this would be easy.  Instead of just a hashcode
	we could reference the list of deleted texture layers until we were ready to apply the change
		- layers are already not shared right?  texture mod info can be seperate?

			
- FX tab should go back to primitives and with all our primitives now fit into a gallery control.
 - Re test scene save load
 - Re test prefab save/load

 - LightingMode setting?  Where to put?
	- lighting mode and mesh format are essentially the same thing.
	- thus lighting mode should be tied to the specific geometry
	we load and based on the graphics setting the user has enabled.
		- changing lighting mode means changing setting and requires
		unload/reload of geometry.
			- this is especially important because minimeshes cant have
			lighting mode changed without re-creating from their tvmesh 
			which has the lightngmode to use set.
			
- Where is lighting mode assigned
	- remove from Appearance and move to Mesh3d and Actor3d as
	  - checking the box in General tab to have "Bumpmapping format" and "offset"
	    will re-load the mesh.  User will be prompted whether they want to do that.
		- thus, the same mesh resource must be given a new name if they don't want it 
		also affected.
		- warn them of this and suggest copying the resource with a _bump.tvm 
- Where is the minimesh shader applied?
	- when assigning a new mesh to "UseInstancing" the various properties of the mesh
	  including it's geometry.LightingMode should be viewed and the shader chosen on that
		- but what about various combinations of normal maps, specular, emsisive
		etc?
	- somehow this must be configurable in the editor and NOT via 
	  the Minimesh system automatically. Thus, what we need is some way to assign
	  the minimesh shader via the Mesh3d... something like...
	  - in Shader {get;set;} 
		-  if (UseInstancing, 
			we check not which shader is applied, but which shader options
			as far as normal map, emissive, diffuse, heightmap, etc
			just like TV uses a "mode" we have to have a group of "modes"
			the user can set and then the shader is selected dynamically.
			This way there the equivalent minimesh shader is also chosen
			dynamically.
	-  It'd be nice if i could have a single shader and let the path
	between mini and tvmesh or tvactor be automatically chosen.
		- well, there's no way to have a single Shader node that is shareable between
		both unless it contains within itself seperate shaders for both TVActor, TVMinimesh, TVMesh
			- or unless perhaps the defines that switch between mesh,tva, mini are used
			to define the shader path.
			- but im thinking better to have that shader maintain 3 tvshaders instead?
				- what about paging in/out?
			
- GeometryEdit
	- MeshFormat
	- FaceCulling
	- ComputeNormals
	- LOD Sub Edit
		- Create New LOD
		- Distance Setting
		- Mask
	- Geometry Switch Edit
		- CSG Stencil Mask
			
 
- FIXED. save/restore the childModes in xml and then resave the door prefab
- FIXED.  mHost.ChangeNodeProperty -> this must 

- Import new .obj mesh into mod db.
	- when importing new .obj that has textures and then trying to load an instance of this newly added .obj into the scene, Repository.IncrementRef() will report that the texture does not exist in the scene.  This is because we are i think re-using the Texture with the old name and then changing it's name and trying to add the version with the new /mod  name.  I think...
		- so in our .importer i think what we need to do is de-reference the texture after we've renamed it.  Same goes for any resource that we've had to modify the path too.
	
- When removing Mesh and adding it, if appearance still exists, the Appearance change flags must be reset for that Entity.
  - easiest way is to just have mesh/lod/etc addchild result in the changeflag for appearancechanged.
 - ClearPanels is occurring on the recursion for Geometry so the LODSwitch gets erased and then the Mesh3d added
 
- FXInstanceRender - this perhaps should not be treated as an FXProvider.  It is really just an alt renderer and so should be
  callable from within the Render() method where we render near/far/2d while  iterating through RegionCullingInfos.
   - this way we can control the order in which these minimeshes are rendered and vary it for different minimeshes as required
    - One way could be to have info.InstancedRenderedItems instead which is actually our FXInstanceRenderer.


- FIXED. Entities can have "ignorescenesave" flag set. -Yardstick is being saved and then errors trying to load it.  
- FIXED - xml writer error  (Saving the PlayerVehicle first prevents these errors.)
	- Not sure what is going on here.  Turning off exceptions in debug options shows that everything appears to work even with all these exceptions
	- Almost positive now this is because we do not first save the PlayerVehicle during our Auto create PlayerVehicle button click so attempts to then
	save changes to the celledRegion fail.  

- save/load verification
	- CellIndex is restored, but no event for DomainObject deserialization occurs when loading cold celledRegion from disk and deserializing it's interior componens.
	  Those components are AddChild() prior to their own DomainObjects and DomainObjectScripts have deserialized.  The CelledRegion must be notified when
	  one of it's children has it's DomainObjectScript deserialized and ready for initialization calls and queries.
- FIXED. PropogateChangeFlags recursion error
	-  this might have something to do with how i change parents at the  beginning of our EntityPlacer's message proc which means i could be changing the parent
	midway, when instead i should only ever switch parents after an operation is completed?
	- in fact, im probably not even allowing some operations to complete properly since i switch parents and dont even clean up and then just try to switch parents again or something.

- drag and drop mateials and textures onto group of plugin
- deleted textures do not seem to clear that material on the mesh
	- this is part of why hashcode is needed and why i think i cannt delete it.  It's an optimization to test whether
	the existing shared mesh's hashcode is same as required by current entity's appearance.
- behavior plugin tab needs tweaking after modifying how we update the panels
- aniamtion plugin tab needs tweaking after modifying how we update the panels

FIXED - In multi-zones, MoveTo is broken
	
- FIXED. when changing name/tag values for menu item, i broke normal tree node delete.  
  Worker_NodeRemove() will eror cuz the child will be null


- FIXED - Matrix & RegionMatrix
	FIXED - Matrix is currently updating every frame and not just when dirty.
	
- FIXED. Large Culling - I now have a 5km long ship which is probab max size for any station as well
  - how far away does it have to be with more regular culling before it's invisible?
     - that is a good gauage for how to determine moons and things for far rendering distance.
	    - or do i compute seperate max visibilities based on radius and screen scale factor from
		context.GetScaleFactor
		
- FIXED.  override GetRegionalTransform in Zones.  
	- first version will be re-implementation and just verify it all still works
	- second version will accept a translation offset that is the camera relative offset
	so that hopefully we can keep our best possible precision as well as remove a step
	in our cull code that attempts to adjust for the camera offset after the fact
	

- SwitchViewpoints
	
- add option during load call, when lodaing .obj or .tva or .x or .tvm, if an existing material with a different name has otherwise the exact same params, share it.
	- UPDATE: Fixed for .OBJ.  I'm fairly sure that every unique material has to have a unique non null name. So shouldn't be any other cases.
	- Not yet fixed for tvm/.x/tva because those cases i think you can have null names and yet same material values.
		- a fix could be to have option if name is null, to check material values and see if it matches existing, if not, create generic unique material name and continue.  but never allow name to be null


- trying to place an asteroid field in a Zone that is too small will attempt for the Simulation to "Move" the asteroids but it may find that some of the Zone's arent paged in and if there's a ton of asteroids this could mean a ton of exceptions to try and ignore.
	- I should check the size of the destination taking into account any offset of the field's translation and determine if the field will fit and if not throw exception before placement is allowed in the first place.
	
- saving not occurring so when zone pages out it wont page back in

- do not let plugin's edit Region's translation.  Regions are fixed.

- test applying of the same rotation script to every single asteroid
              //  entityInstance.RotationMatrix = rotationMatrix;
                //this vibrates the blade
                //_mesh.ScaleMesh 0.8 + Rnd() * 0.4, 1, 1
				- add this laser vibration script to a laser when fired

- test applying of a "damage" quake script to our Viewpoint when our ship takes damage


- FIXED. Interior really isnt necessary I don't think.  (But "CelledRegions" are)
	- since all Regions are fixed, Interior is no different.  The only
	defining aspect of an interior Region is that the Region is placed
	in a container and is designated as being "Interior".  That is it.
	So I should simply use an EntityFlag for that that gets set as the child
	is added to a Container.

- FIXED. fix culling of far objects at least to the point where nothing is rendered twice

- FIXED. Container derived entities when computing their bounding volume should only take into account
the Exterior children, not inner Regions because our inner regions dont really exist within the
the ship spatially, only logically via hierarchical relationship.  This is why our bounding volumes
are screwed up for them.

- FIXED. DrawLines and all DebugDraw should accept a ViewMatrix  <-- actually now we control the render order based on which view/projection is set on the camera.

- FIXED. all prefabs currently have no SceneType.Prefab stored so need to be deleted and re-added
- FIXED. editing the translation via edit card does not update bounding box. Scale and Rotation do however.


if (hashcode == GetHashCode()) return _hashCode;
	- in DefaultAppearance if texture mod for a texture changes, the appearance hashcode does not change.
	

- fix minimesh deckplan wont remove from repository when app closes
- fix clear our archive and add our ships and things all over again.
	- be nice to get some ship interior stuff (more walls, fixtures, crates) from FPSCreator
- fix picking planetoids works but floor and decks no.  I think maybe its 2d walls and floors are failing boundingbox collision test. Need 3d walls and floors.
	- or our 3d code needs to handle 2d collisions

- fix our widget is not translating properly when trying to select other entities to get the widget to move
	- it appears as a bounding issue?
- fix when enable\disable in plugin an entity, it wont re-enable and i think it's because .update events dont take place and the entity
  never gets added back to mActiveEntitiesd
- Add a delete right mouse click for entities already!
	- delete key response as well
	

- load gun
- place gun on bone
- load particle system
- place particle system on gun
	- plugin to scale the particle system and position it

	

	
	  - do mesh / actor groups have names?  we should definetly load names and if possible allow them to be renamed.
		- if they can be re-saved we need to re-save them to our archive... perhaps a two part step of save to disk then replace in archive
	  
	(Animation node?  Get rid of BonedEntity and just add an Animation node instead? hrm...)
		 

- fix our widget's translation/rotation/scaling
	- this requires our picking be able to give this widget priority
	
- make it easier to initially position something with our alt material version of the loadedEntity in ThrowObject rendering with some alpha
// - we do need to load our actor and place a child weapon entity on her
            // and test the scenarios
            //      - add weapon to actor
            //          - im thinking our same code, only pressing ALT will highlight
            //            individual bones you can attach the item to... 
            //             - also perhaps in the plugin you can drag and drop it onto a bone?
            //              or perhaps better, in the TreeView we list the bones and allow user
            //              to drag an entity and reposition it's Parent to a bone.
            //          - also about time i added ability to clone / paste actors in the scene
            //            by selecting them and then ctrl+c and spawning a new instance in place
            //            with ability to drag it elsewhere with widget that appears instantly.
            //              - maybe make my throwtool a bit smarter by if the picker is over
            //                the widget, then just use that widget tool then when done
            //                revert back to the place tool to allow more pasting.
            //          - actor plugin needs a ton of work for animation configuring 
            //      - interior to exterior
            //      - interior to other interior (boarding)
            // - once we have this bounds stuff done, load up a tiny multi zoned
            //   world and get the exterior zones all rendering with our changing
            //   camera matrices that orient to each region ...why does the code work
            //   for Exterior to Interior but not exterior to exterior neighbor regions?
            //  - verify interior to exterior works too (the opposite of the working ext to int)

			
			
			
		import dialog for meshes
        what about textures, shaders, materials
        - there are three types of texturs perhaps.  
             - textures in use
             - the best part about having access here is since they are shared, you can modify one and have it affect all. that's actually a great thing including changing the texture itself and having that affect globally.  Also from that gallery, you can get a list of meshes \ entities that are using that texture.  
              - textures in our mod resources path
              - textures that are not in use or in mod resources and exist on hd/network and are being imported in  by virtue of being applied to a mesh\group attribute and need to also be moved to resources path.
        If a texture does not exist in the "in use" gallery or the resource browser, we can browse anywhere.  
        So perhaps resource browser + browse anywhere are same regular "Open" dialog.

        save as a prefab (using current mod, select a category)
          - shouldnt actually allow any directory browsing
          - allow gen and select rotation/distance of a preview icon
         save 
              - particle systems can be saved as prefab
              - actors can be saved as prefab
         



------------
* recursive delete from archive
- deleting folders while then trying to read the contents of the directory results in io exception when the save after delete (or add) is blocked.
	- need to progress dialog when these ops are occurring
	- need to better queue (funnel) all zip io thru the threadpool group name so they get serialized but problem there is
		that's not what happens on just reading to populate gallery.  So that's why i need the progress dialog.
		- verify then im already using a single group name based on zip file name to serialize write operations to zip especially
- when loading models or textures or whenever we have progress up, we should lower priority of the main rendering.
	- or potentially fixed framerate / vsync
- need some type of .bak of our archive somehow?  and that .bak needs to have it's integrity verified.
	- users should be prompted to save a .backup periodically.

- like the Ribbon Style drop down, i can make mod selection and creation like that and then the main tabs simply switch between the different .zip's that make up that mod.  or something along these lines	 depth buffer inbetween planets and grids... am i clearing it a second time when i shouldnt be?
	- bounding boxes for Vehicles with portals are messed up cuz they arent drawn using the proper view matirx
- our Grid is fixed at 0 height.   It looks weird for the grid to suddenly disappear when you move up or down.
	- our grid and presumably other 2d immediate gets drawn after depth buffer is cleared for world rendering... bad...
	- maybe in addition to grid spacing getting larger based on speed, it should get larger based on distance... greater of the two.
    - maybe in game grid should be parallel to an orbit around the planet's equator and aligned with it's axial tilt.
		- in other words, the grid needs to be relative to whatever coordinate system the user's ship is set to.
			- navigation by user (npc helmsman) will require changing coordinate systems for easier navigation		
	- when traveling faster, our grid's spacing should expand proportionally!

* our code editor tab, procedurla texture all have proper tabs... but our Main rendering viewport does not.  It should be enabled by default now as 3D-View.
- our asset gallery's minimum size should update with resizing of the viewport so that whens witching dirs in an archive, the width of the gallery and popup is always the same.
	* remove all of those other gui buttons on the primitives ribbon tab

- clicking on an entity event script that doesnt exist.. shoudl prompt user and NOT silently fail
	- results in the fake script event adding a scriptnode to the entity which then isnt' removed from repository.

* right mouse click menu for script in asset browser should bring up "edit" menu item popup as well as delete
		* editing script then hitting "save" should update archive
		* when do we recompile assembly?  On save and only if that script is also a resource in repository which means it's assign to an entity
			- do we update the resource if the compile errors?
		- show compile error output somewhere!  maybe in a popup text file or textbox they can copy to clipboard
		- ditto for shaders as well
		
http://www.gamedev.net/topic/47159-lets-talk-about-some-real-3d-isometrics-no-more-bs/page__st__20__p__2280344__hl__camera+distance+full+view+model__fromsearch__1#entry2280344


- add ability to dynamically alter the grid spacing 
	
snapping
		- snapping with 1:1 meter square cells is simply truncating all projected mosue world coords.
		- draw a red grid cell on that spot last to verify it works
			
- placing a new ModeledEntity in the orthographic view should put that entity on whatever the perpendicular plane value is.
	- this perpendicular plane value may be different for different levels on the ship's deckplan
		

* maintain our own cache of scripts so we can do proper tracking of the most up to date version of a particular script.  It's the only way.
* script assginment updates on "save" of script
	* existing script and scriptnode replaced (previous scriptnode released from repository)

- get events from an entity so we list the proper ones
	- regions shouldn't have many events (least not the same ones)
	
- update plugin with the currently selected entity	
- plugin get's focus when loading
	- replace the blank plugin place holder with an actual plugin that we can swap out

	
	- our Primitives gallery then should be able to drag and drop things contextually
	- changing a mesh by dragging onto the Model's mesh image box
	- changing textures by dragging onto a groupattribute boxes
	- changing scripts by dragging onto a .css box
	- changing .fx by dragging onto an appearance shader box


- ImportGeometry isnt differentiated for Vehicles and other types.
	- i think part of the thinking was that a vehicle may not necessarily be a full ship, but some small fighter, or a missile or a drone, etc.
	  and in that case, what we want is to be able to attach the chase cam to any such thing.  
- when too close to planet rings, i get what appears to be flicker of ring in/out near plane.  Maybe i have to widen the alpha transparency part
  - 
 - ref counting not occuring
	- ScaleTool's manipulator needs to have the control access it's children through children[] and not through a seperate 
	 scaleTabs[] array that is disconnected from the scene completely.  Thus getting a cached copy of Control will never fill the
	 scaleTabs array that is in the ScalingManipulator class.
	- in general, i'm not properly ref/dereffing nodes.  ONce we figure out the plan implmeenting this should be trivial.
	  


- Mouse DX input exceptions i think as a result of picking issues.  Really slows down framerate.  I think this will get fixed when i add picking
  code back in.

- VIewports dont report acurate Width when dockpanels are on left or right, only works with top and bottom docked panes.  WTF?  Used to work before i refactored the RenderingContext stuff.
- Definetly copy Sunburn video how textures are dragged and dropped easily to change them.  And how you can select a group or part of a mesh and easily as well see what meshes are used visually, not just by some stupid name.
		http://www.youtube.com/watch?v=yv03HefZ39U&feature=related

- copying of resources to our mod name path during galaxy generation
	- need to supply a mod name when galaxy generating first
- copying of resources to our mod name when importing new resources	
	
- undo for all new commands
- editor commands (first get the near/far culling working and interior/near/far culling)
- physics nodes update to work as Nodes.


when in a "deck" placing things is constrained by the bounds of that deck...?
but the "deck" entity is a good start to start coding this deck design i think... 
maybe look up some The Sims youtube house design vids but also first person shooter creator i think the key "design" of a deck is simply the level at which it's built.  
though still not sure how ramps are done...   perhaps a ramp is similar to a ladder... they have to connect different decks?

				
	- loading the same xmldb   (level)
	
	
I think several things
	- if we have the ability to load in the gallery existing models and entities that are paged out, then yes we can enforce that changes to the live model will obviously (during edit mode) get saved in the xmldb 
	
	- so when loading from a resource.zip (not the xmldb) then those should be treated as new and seperate instances.

	

		bug - jquery with QuickLook for sliders, buttons, textboxes, dropdowns, radio buttons
		bug - 3d preview window rendered in top left wont scroll
		bug - hud retained elements are never detached between renders of multiple open viewports so hud renders on both
===================================================================================
**************************************PRIMARY**************************************	 
- verify appearance sub-nodes call changeflags when modifying properties.
- verify all node types set their various change flags for various things.  comprehensive list needed
- scaling of hte region seems to work, in general, but the scalefactor we compute is too tiny and is resulting in some significant scaling of the position.  
- occlusion of things by planets
- occlusion culling
- portals thru portals of joined Interior regions?  Is that even allowed that we can have a vehicle with multiple interiors?
- occlusion of ships - http://www.gamedev.net/community/forums/topic.asp?topic_id=116859
- occlusion of star light
	- if our ship decks are in a single octree partitioned region then we gather the lights as we
	traverse the octree and we do that by testing against their light volumes which we'll generate and update as the light moves.
		- 
- picking issues further away from origin as well?
	- FIXED. picking issues resolved - all along its a precision related issue.
		- external rendering i should set the near to maybe 100
		- moving the app window requires "ResizeViewport" occur or else picking screen to viewport coords will be fubar
		- planet picking is almsot definetly a result of the Model's scale not factored into the mesh during AdvancedCollide... hrm, though it is
	   	during rendering since i call model.Matrix * Regionmatrix
			- and i think the idea is if i go back to limiting one model per entity, but child entities are allowed, then the entity should include
			  the model's matrix in it's own Matrix calculation.
	- i could implement my own overriden sphere AdvancedCollide pick for planets.  That is the easiest solution, although
		then getting the face index of the actual sphere mesh gets trickier...
	- the box for the planet works on picking, but the mesh.AdvancedCollide does not
- FIXED. picking planets

- get camera to align with the "front" and "up" of the ship model. (the ship should be required to face in a particular direction)
- modifiy the viewport zoom and speed gui to look more like the pdf viewer zoom with the +/- and a box where you can directly edit AND
	- where you can specify km or even au to speed thigns up... 

	- use Enums for Commadns in KeyPlugins
	
	- option to REVERSE winding order of an .obj i load.... perhaps a flag in the Geometry plugin.  I think Sims2 .obj exports reversed.
		- or at the very least in the editor, mesheditctl reverse winding order and then re-export, overwrite, reload w/replace option to replace existing Repository item of same name (internally this unloads the TVResource and re-loads new file)
		- way to export the .mtl file for .obj by right mouse clicking on the Appearance itself.  
	- Export TVM for Mesh3d edit
			
	- TreeView state of collapsed/uncollapsed needs to be preserved
	- copy / paste
	- Rename 
	- Title bar of plugin container should be set by plugin
	- Translate / Rotate / Scale Entities 

	- Light Plugin Edit
	- Actor Plugin Edit
	- Particle System plugin
	- Terrain Plugin Edit
	- LOD Mesh Plugin
	
	- Where do Add Prefabs get positioned by default?  
	- Portrait of prefabs generated automatically
	
----------------------

- when compiling a finished level, there will be option to archive resources, but otherwise we should be able to handle either or.
   During editing clearly it's easiest to not have to deal with archiving.
  
  - instead of the File \ Import StaticEntity, BonedEntity etc, we should simply be able to select a Primitive from a gallery!  Save real estate!
    add a new empty Vehicle, Building, Prop, FixedPositionProp (doesn't react to physics or anything), BonedEntity, etc using a default template (crash dummy for actor, box for static, tank with square wheels for vehicle) and then allow the user to modify it by adding underlying resources,behaviors, etc.
	- in other words, let some of the Prefab options be hardcoded buttons to load these placeholder entities.
		- to add an atmosphere entity layer and or cloud entity layer, simply right click and Add Child Primitive and select a sphere of the proper type.  Alternatively you may select an LOD level.
		So bottom line is this, no more "Importing" of entities cuz that never made sense anyway.  Instead now, we import resources only.  
		When importing resources, we must always copy to our resources as well as allow user to select what kind of resource it is so it knows where to copy the files.


mods can be in archive or out archive
	- thus a scene can be opened via the .scene file or the .sceneInfo xml file
	- this is important for server side since server may need mulitple scene readers/writers with ability to access
	  parts of the scene database independantly. THis cant be easily inside the zip, so better for server to have uncompressed version.

	- load a scene, new archive.  A folder is created data\mod name
		- under this folder is either mod name.scene  or mod name.sceneInfo if extracted
			- when importing a prefab, the nodes will obviously get saved if in edit mode to the scene but
			  the extracted resources must also get added to the \mod name\texures  or whatever folders and have the resource paths
			  adjusted... and deal with overwriting dupes and such...
				- i mean, i dont think we want to just copy the prefab over to a prefabs directory under data\mod name\prefabs ?
				although... for user ships...  data\mod name\shipX\prefabs  ?  no cuz ship design is integral to our game even without mods
				

				Prefab Final Design
				------------------------
				1.  Imports of meshes or textures merely adds them to our modname\resources\
				2.  Save As Prefab saves to modname\prefabs
					- These prefabs are all cloned.  Even materials, appearances, are cloned.  Essentially only meshes, actors and textures are NOT cloned.
					- Once a prefab is made on disk, it's immutable.  It can be loaded, deleted, or saved-over, but it can't be loaded just for editing.
					Without cloning it while loading it into yourscene, modifying it, and saving over the existing.
				3.  There is no special "library" 
				3.5  Creating a new Entity starts with getting a GUID from the server for that entity?  Why is that necessary?
					If editing, guids are unique so why not let client create it?
				4.  If you want to share a part of your scene that exists also as a prefab, you do not load the prefab again, 
					intead you must copy the instance from the \level or scene .zip (or unzipped) data.  
				5.  There is no real new code i have to write to support any of this, only two tweaks
					a) The import must import to our modname\resources.  
					b) You will then be given an option to load it into the scene and create a prefab of it.
						- the prefab will then go into modname\prefabs.
							- but the loaded prefab will now be independant of that prefab and changes to it will not update the prefab on disk.
					c) Our various ICOmmands must now handle import to resources, ask you what sub-path you want to save it to
						e.g. walls, floors, furnitute, props, etc and then it'll store them to that dir under \meshes or \textures respectively.
				6.  During games using any set of mods, users are limited to using resources that already exist and can create new prefabs based on primitives or existing resources only.  Otherwise, new mods need to add support for any new resources and then all users must use this mod to play in the same game.
				
			
Common\Lights  (candle, torch, street lamp, directional sun, flashlight, headlight, search light, 
	- to the lights tab, add enable specular, and global ambient settings?
      \Materials  <-- both can be set up as gallery items to pick from.
	  
About this gallery vs Aion's style with a custom control...
	- the key is the difference between active and library browsing... i might still want a custom control for browing and again, i need to see if i can enable drag and drop OR WAIT!!!!
		I can simply close the gallery and then center the mouse on the screen and change the icon, set a global "Painting" state 	and wait for the user to click again to apply the texture.  THey can keep painting until right mouse click or ESC.
	-   We can fascilate this by adding a "Paint" tool and placing the selection tool to the Paint tool automatically.
	     
Textures from the Gallery can be dragged and dropped directly onto the Entity tree's Appearance or Group Appearance where the user will then be prompted to add as Diffuse\NormalMap\Specular\EmissiveMap
- by holding down CTRL, when dragging the texture over a valid entity, you can select sub-groups instead
- if drag and drop is not possible, actually it must be... should be, otherwise canceling the operation is too annoying.

To add a texture that doesnt exist, you must select the entity and click the "Import Texture".
	- importing a texture that is in-use, you'll be prompted if you want to clone it instead and if yes, must select a new name for it to be copied to.

- Ability to merge materials when loading so re-used ones dont all have different id's, merge textures same deal.  Our importer should do a better job of re-using existing. Maybe it is, verify guids are the same.
	
1) Option to dynamically change the near/far planes of our frustum until we properly add the auto switching for world/star rendering.

3.5)  then finally position the rotation and distance for snapshot icon.
4) verify relative paths work in the prefabs when loading and saving , 
	verify relative paths work during paging.

- Right mouse click menu ability to add Material to Appearance
	- Add Shader to Appearance and GroupAttribute
Rename GroupAttribute to GroupAppearance and have it inherit Appearance
	- add texture layer's UV tiling to Appearance.
		- layers are always 4 slots but some are null and they associate directly with tv's layerIDs.  
		  So if a Diffuse child exists, it's uv is taken from UV[0] 
	- GroupAppearance can only be added to an Appearance
	
6) editor widget tools should flawlessly 
	- when Importing and Moving, display a grid overlay (perhaps 8 corners of bounding box like UFO Terrestials) that shows
	where the imported entity will be placed.  However we may not have accurate bounding volume information if the item isnt already in cache
	so just an square will suffice.  This visual feedback is important.
	- the scale tool is fubar, wont disappear when switching tools, wrong location
	
	- better grid altogether, especially suited for deckplan creation
	- grid snapping.
5) Update all ICommands for undo/redo and transmission over loopback and verify each works
7) finish all major plugins.
8) particle systems, actors
9) turrets rotations and beam billboards
Wiring up power conduits, fire control links, etc, treat it like in SimCity where you paint the squares connecting from one thing to another
rather than the Tronics style in N8bit.
10) AI

12) Then with the extra space, add a Help \ Documentation, Help \ About,  Help \ Tutorials <-- with sub-list link to videos 
no, prefabs do not have their own dir structure, just normal xml database
- so, when creating a prefab, you have to select mesh and textures and such from the library and if the path is not, you will be prompted to import it.  That's actually what will happen when you import... plus on import, you should be prompted to save as Prefab as well.  

		
		
	
Edit Commands
	Drop At Intersection - drops a mesh _IF_ after a raytest, there is geometry below it.  Otherwise the item will stay where it is. (so it doesnt drop off the map)
	Randomize - takes a collection of minimeshes for instance and randomizes their scale and rotation.
	Show Debug Labels - generates a lable billboard for objects and perhaps even group attribute id's.
	
Vehicle Build COmmands

Game Commands

In the context of validating messages that arrive on the server.. we should work backwards from there.  


Rules / Business Rules  Business Logic 
WeaponFire.BeginExecute()

Ok, im thinking that the rules based approach is going to work.  Validating an action/method is no different than validating a property
and our rules can be scripted (or maybe hardcoded in the beginning).
But a command to "join" a lobby would first require that the user is registered in the lobby and that only happens if they are authenticated.
But this is the rules based approach to our design... and this basis will hopefully allow us to create our 4x games and a host of others... by
scripting our business rules validation as well as the actions to be called on this entities.
	- so for a property change, normally you'd first 
		- get the entity that is to be modified.	
		- make the call to change the value via Node - public virtual void SetProperties(Settings.PropertySpec[] properties)
		- run the rules
			- return error(s) if fail
			- return null if success
	- so similarly then to perform an action, it's the same process... has to be.  
		- get the type of object we want to perform an action
		- make the call to perform the action with the various args
		- run the rules
			- if successful
				- carry out the action
					- return results/response
			- if fail, return errors
	- NOTE: To perform an action on an entity it's easy to bind these to scripts since our scripts are stored in the entity in a collection that uses the name of that action.  
	- NOTE: But to perform an action on some other domain object, like our LobbyManager, we will just use the hardcoded methods based on the type of the COmmand/Message sent
	
	So going back to our commands (requests) where do our delegates sit? I mean, do we stop using Command.Execute? since they are requests and no
	Command has been authorized yet?  Well, i think that requests should be assumed good unless we get a response of an error.  Though we will get some success responses that includes the results of an action.   So the question remains, what is the execute process after receiving a request?
	- consider a request to turn on an engine.  The server would find the vehicle in question, include that reference to the entity.PerformBehavior ("turnon", vehicle) so that the script can use that reference to check things like whether the engine is connected to a working power source and if there's enough power to send to that engine...
	
	- our first step i think then is to just comment out all the commands that are currently broken.  get back to compiling then just implement ONE new request that calls a behavior that uses scripts and another request that has to work on a lobby and uses a fixed function.
	- OUR FIRST STEP MAYBE CAN RATHER BE, disabling ALL of those and just rewriting a new set of Messages and Commands and then we can just delete the obsolete versions.
	  BUT HOW DOES UNDO/REDO work then?  We would need an Undo Command created that then accepted a new NetMessageBase that contained the undo info to use when executing that command?
		- Afterall, Undo before has each command knowing exactly what unexecute function to link to but i think perhaps the key is that the Undo Message wrapped in our Generic  command is what gets pushed onto the stack and not the original message itself.  
		So if a command is "undoable" and we're in Edit mode, then we create the Undo and push it.  And thus there is no concept of Undo just Execute and the undo message itself is crafted to undo some previous command.
			- but the advantage perhaps is that we actively MUST construct the Undo if we have Undo enabled in order to push anything on the stack
			
			
**************************************SECONDARY**************************************

- planet shader work
	maybe done entirely in shader from light params (star location, color)
	- gas and ice giants dont need the normal mapping crap or emissive and specular really...


- rings should be cut in half and rotated to have a half that is towards camera and in front of planet and one that is behind planet so alpha sorting is fixed

- FX/Add Star, blue planet, gas giant, asteroid belt (NewWorld, NewStar, NewPlanetoidBelt dialogs)
		- switch the FX Planet and asteroid fields and such to use queued command loading
		- ability to drag/drop a treenode of a planet to be under a star system, set it's orbit update script and now it's apart of that system
			- perhaps have ability to recalc planet's stats based on star / system it's been moved to.
			- ability to add a world to the orbit around a star
				- the orbital speed and path is precomputed (well, movearoundpoint)
			- ability to add a moon to the orbit around a world
			- ability to attach a new planet to an orbit or replace an existing with a new generated one with configurable parameters
	
- star/world/moon Names toggle or when mouse hover
- ring lookup texture generator that creates the empty areas of the ring in the right spot based on the inner and outer radius of the entire ring system
	- for instance Neptune 49528 diameter 17x earth mass
		Inner diameter 82000 diameter
		Outer diameter 125860 diameter
		- thus we'd scale our 1 unit diamter mesh to 62930 and since 41900 represents 66.581916415064357222310503734308% of the diamter
		we would have 0.0 alpha component in the texture up until the ~66% pixel so in a 1024 long texture it'd be ~675th pixel
	- for Saturn (120,536 km diameter 95x earth mass)
		inner diameter 133796
		outer diameter 361936  (outer ring is 2x planet diameter)

	- for uranus (51,118 km diameter 14.5x earthmass)
		inner diameter 76000  1.4x
		outer diameter 196000 3.8x  but the 2 outer most are extremly faint

	so from these, we see that the outer ring is usally 2.5 -3.8x the diameter of the planet and the inner rings are
	1.1 to 1.65 diameter of the planet
	


- fixing issue of rotation changes updating the physics body as well
	- RotationMatrix and Matrix in general and translation should be set directly
		via  Entity.RotationMatrix {get {return Helper.ToMatrix(this.PhysicsBody.GetOrientation());} set {this.PhysicsBody.SetRotationMatrix()}}
- moving ship with physics
	- we should be able to add some preliminary thrusters?  what would that entail?
		- what about a type of physics for exterior that is more built on the stimulus/emitter/receptron/detector Thief model?
	- simple collision that just checks if the swept boxes intersected during the step

**************************************TERTIARY**************************************
- solar system view / nav map <-- ability to change scale, orthographic, and ability to pick planets and stars and ships and such which are not to scale
	- cycling through vehicles as controller
	- switching back/forth from Vehicle control to Edit camera
	- OK, for now lets assume im going to generate a star system, and render it as star system view in my main view with no worry about
	 having a seperate viewport for now.  We'll just work from our primary.

- rescale the planets and stars?
- Main issue is we want to keep the same scene and same entities for coherency between what the user picks and their navigation 
	- but to be able to apply a scaling to the models...  
	- scale down the distances (positions) to fit in the ortho view and scale up the models so they are visible
	   - with perhaps custom scaling values for stars which would otherwise be too huge.
		  - perhaps if we have a "zoom" value and if on a nav screen, we can zoom out and scale planets up as we zoom and scale distances down... 
		- actually we'll be scaling the distances down similarly to the scaling to get it to fit in the frustum but then we have to scale models up if we want to be able to see them... 
		And then we also want to render proxy's for the planetoid belts and proxy's for ships and space stations or 2d hud icons.
		In fact, proxy's might be the best way all around for the star/planet/moon scales as well
			- so how would that work.  Put our camera at  0,+RegionRadius,0 lookat 0,0,0
			  compute a scale that fits RegionDiameter in the viewport
						  
- regions and validating culling and rendering, camera/ship movement, targeting physics across zones

- lighting pass 
	- needs to on/off with portals
	- use the list of Lights and add to the VisibleItemInfo.LightingState each light that is relevant
	- use our culling to get the objects affected by each light

	
in the view matrix, the lookat vector is subtracted from position to produce a direction vector that goes into the matrix yes?


- FIXED - now with simple circular orbits working, im not updating the bounding boxes for sceneNodes
- interim fix for scaling is to save the meshes that are built by tv3d during worldgen with different filenames based on the body name
- white sphere for star at accurate size?
- FIXED - manipulator in EditController2 in Pick() is null after loading in galaxy
- controlling another ship via my 3rd person controller
	- controller switching

- planet billboard
- FIXED. planet position scaling to bring it closer and at smaller scale to compensate so it appears same distance
- flag for disabling farplane cull test... has to be in sceneNode readable from the Entity it hosts

- ship paths and ship steering
- ship to ship collisions


-view frustum near/far should be saved / restroed from the world's sceneInfo xml


-Have all sky implementations assert the farplane value is far enough


//Trace.WriteLine( System.Reflection.MethodBase.GetCurrentMethod().Module.Name + System.Reflection.MethodBase.GetCurrentMethod().Name);
// StackTrace stackTrace = new StackTrace();
//StackFrame stackFrame = stackTrace.GetFrame(1);
//MethodBase methodBase = stackFrame.GetMethod();
//The call to GetFrame(1) retrieves the stack frame of the immediate caller.
// So that you can write a function that will always append the Name's and such for you no matter
// where it's called from.  Of course using the stack trace is sloooow.



// FXBloom needs a seperate instance per Viewport
//   - in general consider how to do this for these sorts of things.
// - ask Arius about post shaders, why not use lastmainbuffer frame to avoid having to re-render everything? should it work?
//
// ask Sylvain about RS cameras.  They seem to default to the first camera rather than even the current camera.
//- he says each camera creates its own RS (just as Mith said).  

//
// FXImposter ideally would as well because you wind up with RegenAngle drastically different between frames and of course in actuallity, we dont really want to allow imposters to render in two because right now our InFrustum checks resets this flag

fix the RenderCB.Invoke  to handle Far (sky) and Near stuff seperately



On physics updates, i had thought about the issue i have with mouse and low framerate as well as how i would eventually implement physics with a single loop that did not explicitly seperate input and rendering threads yet still allowed physics to run at a constant rate... the answer is actually not new... you skip rendering and keep updating physics until you are running at the proper hertz per second.  Not only that, but those updates should be run at a fixed time-step so that the simulation can be predictable across all clients.  


doing a "modeler" is just allot of shit frankly and more than that, i dont want users to have this much freedom... it'd be impossible to make sure models are "ok."  We need to have a proper balance.  We need limitations but still good freedom.  Vehicles rules are like this.  We need something more like First Person SHooter Creator.  

- I like their animation tree editor -> http://lynxengine.net/blogs/index.php?blog=6
they are able to tie in the animations with a state machine.  Note: dont get confused and think the controller icon represents a user input, it just represents a "state" change and that state change can certainly be done via the keyboard or mouse or gamepad inputs.


entity explorer
Vehicles

Buildings

Characters

Lights

Heavy Weapons (fixed)

Light weapons (wieldable)

- need to check DeviceCaps on my own at program start and not rely on TV3D.  I believe DeviceCaps can be tested prior to initializing a window.

FIXED - LODModel vs SimpleModel
	- merge to one and just use constructor arg that can't be changed and which sets flag + abilty to set minimesh instance

verify deletenode as it is now does not delete children from repository?

		
- triangulation
  - a good thread.  note i did download that poly2tri c# src that the followup commenter posted about
  http://www.gamedev.net/community/forums/mod/journal/journal.asp?jn=447058&reply_id=3621289
  

	- cant seem to get lighting working for DrawPrimitives
	- then fix initial zoom of isoviews...

- review the later posts on this thread  http://www.gamedev.net/community/forums/topic.asp?topic_id=93699&whichpage=1&#484181
  when revisiting my own perspective and ortho editor mode picking.
- maybe a good time to use Ortho view to draw a scaled view of galaxy and solar systems!  Good for both my moral in terms of adding real game related stuff, and for showing in engine video..  And then being able to edit the system, re-compute stats, libnoise textures, etc
- Manually created EditableMesh is not rendering.  It's picking ok and 
     - ImportStaticEntity typically assigns a Translation using the localPosition, the idea is you drop close and then drag and position.  But for EditableMesh, we are editing in modelspace.  We only convert individual "components" when the user makes the selected geometry group a component.

- MoveOp and moving the mouse off the window causes the command to stop working... how does sketchup deal with that?

- FIXED. sort mouse picking results because my manips in ortho hit bottom ones sometime
- comprehensive toolbox / selector / gui fixes 
	- mouse icon change when selecting moveTool/Selection/Line
	- ESC or rightmouseclick cancels and switches back to pointer?

   - sketchup requires that you select the things you want to move by entire component or highlighting the geometry (faces, erts, etc)  and then just dragging them.   I think Silo's way is better your select tool can be modified to work with faces/edges/objects by switching the selection mode icon.



text input should respond to WM_CHAR message.  You get unicode and localized keyboard processing automatically this way.
http://msdn.microsoft.com/en-us/library/ms646276(VS.85).aspx


- option to disable rendering of region node boxes seperate from object boundingboxes
- option to render selection box even when boundingboxes are disabled normally
- when switching views, the orthodistance value set to the axis of a previous view is not reset to 0.
- changes to viewport display settings are not updated in the ini file and thus are never saved.
    - they currently have to be changed in the startup ControlPanel
- right mouse click gridon/showbouding boxes checkmarks are not properly restored on startup to match underlying settings
- switching from ortho to perspective doesnt work because for some reason the projection matrix doesnt get recomputed
- clicking a tool doesnt depress the toolbox label item


- move the boxes to minimesh.
	- not sure how that will impact appearanceLOD

- in MeshRenderer.cs RenderDebug()
    testing for Scenes[0] is  kind of hackish.  need a proper way to verify that the mesh who's debug info
   is being rendered is currently mouseover.  I thinkthis shows us that maybe rendering deug here in MeshRenderer is wrong
    and that it should be done from Scene.cs
    the issue with that though is here we can replace the line or face textures, etc draws in the regular meshrender
    if there is debug info that needs to be drawn with it.  Perhaps one way to do that is when setting MouseOverItem
    we can there modify the LastPickResult.HaColided = false when the MouseOverItem value changes to null or a diff mesh
    or better yet, add a .MouseOver property to the entity/mesh that we can check here



- simple grid snapping system is to round off the final position of something when you get to within epsilon value of that multiple.  So if you round to whole numbers, and get to within .8 of 1.0 you just round .08 to 1 to snap.  if you round in multiples of 5, then similarly if you're at 13 and our epsilon is 2 then we round up to 15.  The only trick though is that if your prefabs lengths and widths are not in the same multiples, then you can't snap based on the center position of the mesh but must snap on where the bounding box edges are based on the direction you are currently translating the object.


- Regarding our FXMinimeshRenderer
  - two options seems to me.  You can have items subscribe\unsubscribe as they are added/removed from a scene and then during traversal we set the InFrustum flag so we know which ones to draw.  The upside here is that we dont have to add these items to a render list during traversal.  We simply check the subscribed one's flag.
  - the downside to that option is you do have to constantly track subscribed and unsubscribed elements properly, and you do have to itterate serially every subscribed element to find if it's visible or not.  
  - the other option of course is to simply not have any subscriptions and to simply Add items to the proper list in the FXMinimeshRenderer if it's visible and has it's UseInstanceRendering flag set.
  - another 3rd option perhaps is this, we dont really have to "add" items to the list as we traverse and we find a UseInstanceRendering = true.  All we have to do is update the scale,translation,rotation for that element in the InstanceRenderer.  So you'd need something like
  FXInstanceRenderer.AddInstance("instanceKey", position, scale, rotation);
  and what this would do is find the right renderer within the manager and then simply update the array list.  So it seems the options are 3, with the origianl subscriber option and this one being the most desireable.  The downside to not subscribing is you have to reference by the Mesh3d name so there is some indirection here.  If you're directly subscribed and we have multiple FXInstanceRenderer then we simply do geometry.FXInstanceRenderer.AddInstance()  

  
**************************************************************************************
shader extra
	- sun as a post process http://www.sgtconker.com/2010/04/article-sun-and-lens-flare-as-a-post-process/
http://www.creativecrash.com/marketplace/3d-models/weapons-armor/projectiles/missile/c/rocket-exhaust-trail
**************************************************************************************

	
- FIXED: Previewing a model loads the red material into it so then placing it will clone it using that same material.  So i think this means the bug is that im not unloading the model that ive loaded into the preview!
			A) First we should not even be using that material in preview
			B) That entity should be unloaded if there's no other instances anyway.
			
- FIXED: Resave all prefabs with Model.cs  InheritScale = true;
	- simply re-open them all and save them.

- BUG - seems back face culling of the door is messed up from reverse angle... are these doors not two sides?
	
- BUG: Shader.cs line 516 commented out errors... argh
- BUG: EntityNode.cs  line 102, those lines are causing octreequadrants to collapse when they should not.  why?
       particuarly when moving the wall placement marker, when leaving a quadrant it causes it to collapse even though that quadrant or one of it's descendants should contain an entitynode
		

BUG - trying to "Reset" center/rotation/scale of a .OBJ file will result in a TVM being saved with .OBJ extnesion and our loader unable to load it resuling in an empty .tvm mesh3d instance that renders nothing.
BUG - light ambience needs a way to modify from plugin.  
	- the reason i suspect some imported objects in my scene are rendered differently is because the light ambience is expected to be different. (particularly with sketchup models) 

BUG - asset browser (filetree or imagebrowser) does not refresh the current filetree when folder is added or deleted
BUG - asset browser does not refresh imagebrowser when items are added or deleted
BUG - asset browser preview wont reload twice
BUG - Asset browser docked tab has no caption
BUG - plugin does not put the current selected entity in title bar.
NEEDED: Filter for assetbrowser.  Especially when in floorplan mode, we should only see finished entities and no textures, meshes or other resources.

bUG - seems saving of prefab can throw exception if the zip is accessed by treeview reads during the time of trying to save the prefab within the zip.

BUG - Interior light seems to go on/off when the floor placement marker is active?
		- i think the light when dragged (dir or point or spot) is not properly being added to CelledRegion but rather the Root.   We need to modify our drag and drop of toolbar items to preview immediately and if over celledregion (and is placeable on interior) to show up there

BUG: Deleting an entity in the scene that has model that uses Minimesh fails.

NEEDED: MOdel Selector type checkboxes needed for ModelSelector panel in plugin
NEEDED: Model's under model selector needs to have CSGStencil, CSGType, LOD options _if_ the parent ModelSelector is
        set as LOD, etc

- floorplan root should be 2x size of the floorplan or some way to allow viewpoint to travel beyond the bounds of the interior somewhat.

- Collaborative Diffusion
	- place a Chair component
	- place two boxes and have one entity pathfind to the other
		- allow scripts to have one box transmit "power" to another.
	- place a temp actor box mesh
		- have actor navigate collaborative diffusion grid through a maze style room design towards a goal.
			- moving the goal gets the actor navigating to it the new location.
	
- OnAddedToScene - change domainobject Register to OnAddedToScene
- OnRemovedFromScene - change UnRegister to OnRemovedFromScene
	
- saving/loading of our interiors
	- works but still not restoring component within it's proper cell properly
- Advanced CSG
	- doors or windows that take up two or more wall tiles instead of 1 (eg cargo bay doors, fighter bay doors)
			
 - Entity Stacks - How do we implement this?  
	- Walls & Doors & Windows
	- Other entities
	- Actors - actors move, what if they straddle two cells?  Why not just do dynamic lookup for actors like with tvterrain height(x,z)
- Dictionary<uint> Stacks // key'd by cellID
	private struct Stack
	{
		public Entity[] Entities;  // ordered by layer - floor first, ceiling last
	}

- BUG - Loose Octree\Quadtree
	- verify that we're still using loose octree or quadtree for components even if we're not using them for structures since 
	using the grid to find visible wall segments and then enable\disable in the minimesh is prohibitively slow
	or maybe there's issues with my code.  
	- i do think im using the loose quadtree still for components when adding to CelledRegion.
		- maybe my tree depth is too deep.  i should experiment more with that.
		- at Keystone\QuadTree\QuadtreeCollection
		  and CelledRegionNode does -> mSpatialNodeRoot = new Keystone.QuadTree.QuadtreeCollection(celledRegionEntity);
		  - i really need to add performance profiling code inside the quadtree so i can test performance of various operations
		  particularly once we have more moving objects.
		  - http://conkerjo.wordpress.com/2009/06/13/spatial-hashing-implementation-for-fast-2d-collisions/
		  - the above 1d spatial hash seems very much like the behavior tree article i read for flattening a tree into a flat static structure.
		    - the problem i think is that for efficiency, the structure is not really dynamic... i mean sure entities can move between the buckets
			but the layout of the buckets seems fixed.
			- but for a flat grid perhaps this is not a problem.  
			- http://dl.dropboxusercontent.com/u/832464/Code/MatrixSpacePartition.cs   <- similar to a 1d hash?
	
- AI - Jobs
	- how are worker jobs generated, where are the kept, are they assigned to stations or individuals?
		- we need for jobs to be handled by priority by workers who are qualified/can do the job in least amount of time with highest skill provided they are not already occupied with higher priority function.
		- further, cant have them wandering length of ship to do such things... the queue should be smart enough to calculate those trade offs based on future jobs that need to be done too, not just the current one.

 
BUG: Placing Light into CelledRegion does not work.  Places in Root instead.

BUG: Placing a Planet should have that planet orbit the star or star system within the current zone or root

BUG: Placing a planet from toolbar should start preview of that planet and the orbital tick should be computed to coincide with the current placement. eccentricy and inclination should both default to 0.

FIXED: When placing entities into tiles, thread sychronization issue when first adding an item the renderer keeps going obviously and it culls and accesses the EntityNode.BoundingBox which results in call to UpdateBoundingVolume since it's initially dirty bound volume.  This updateBoundingVolume results in call to OnEntityResize!  
	- i think we should prevent this initial call to
	this.SpatialNode.OnEntityNode_Resized(this);	
	which initiates a Move within the Quadtree!  This is completely bad because now while we are adding a ton of floors items, we 
		- why isnt the bounding volume already computed correctly upon being placed?  cull\render should never even get to it until it's placed...
			- if it's calculated correctly, the EntityNode.SpatialNode.OnEntityNode_Resized(this) shoudl exit before attempting to recurse
			because it will fit in the current quandrant 

- why when mouse over exterior box of PlayerVehicle, the EntityPlacer tool is trying to add to the Exterior.
It should only add either to CelledRegion or normal Region and not to any other entity type that the mouse if over.  
	- Having a red outline of the Entity and Mesh Group / Bone that is being attached to for visual feedback would be great.
		`- assuming we did allow this and didnt force user to instead drag and drop entity under new parent.
		
NEEDED: Exterior placed hardpoints must appear within the interior deckplan and then must be "connected" or "wired up" from interior.  Otherwise they are completely inactive and unused.  So, the good news is, it allows us perfectly placed exterior hardpoints, engine glows, etc, but then also allows us to wire them up internally to make them active during simulation.
	- ACTUALLY, hardpoints are placed from within either exterior or interior and are hud rendering items however our interior workspace can split screen to show exterior views to help place hardpoints from both interior or exterior widget controls at the same time.

- like Sims3, let's just have the viewport and asset browsers completely change to a mode that is specific to
ship design.  In fact, our asset browser will filter out many of the trees and only show those branches useful for	ship design or ship component placement.
- THis is afterall the ultimate way ship design will be.  Users wont be able to edit new components without creating a mod.
During actual gameplay they will be restricted to the items in the mod.  
Pillars - As a "Frame" component that can be placed by walls or in middle of rooms to add strength and break up blockiness of rooms

		
- perspective mode is nice too as far as the side views go... looks really cool in sidescrollers so too in this
	
- grid on the other isometric views needs to be perpendicular to the isometric view
	- grid should always cover up the entire screen in ortho view if the grid is enabled
- in isometric view, allow planar translation of entities on the deck along with snapping.  Snapping should be done where... in the tool itself?  Thinking yes for now.
- omg, isometric side three views of deckplans will be awesome too.... oldboy-ish, krellan commander-ish.  just ahvng the option is wicked cool.

- add a portal to our floor/walls prelim deck

- rework flags given ive modified wall vertical support and floor vertical support flags to now be distinct so they never conflict on the tilemask
- start adding toolbar icons to route power
- get simulation to work with on/off of power plants and then devices using them like engines
- 
- add to drop down / toolbar "show hardpoint icons" axis indicator, celestial icons		
- fix motion field
- viewpoint jumping freedom long overdue
	- behavior node classes need to accept delegates

Canon 0.1A  (name using a revision convention?)

- the long loading times im seeing is cuz of the FileManager write... not good.  The worst part is it seems to take place on the main thread and not the background... grr...

- Infinity (Journal of Ysaneya) deferred rendering... could be something i want to do too)
http://www.gamedev.net/community/forums/mod/journal/journal.asp?jn=263350
he gives  agreat explanation of how it works.


14. Fix our shaders->  http://xnameetingpoint.weebly.com/shader3f31.html
http://digitalerr0r.wordpress.com/tutorials/
15. Try implementing toon shader for interior
	- this seems to require cellmap textures though.
	- but maybe if we focus on the outline without the toon aspect, it'll be like sketchup and all we really want to achieve a real simulation look and feel.

- universe gen i need to cache IPageableNodes (domain object scripts, textures, meshes) during generation.	- how?  
- star view ORBIT camera so manipulating view is not like flying, but like manipulating a globe or a rubicks cube
- nav toolbar buttons for back, up, style browser buttons
- stars projected onto 3d ship exterior view too as part of our background backdrop which we can update dynamically.

12) Fix starmap 
	- work with changes made to date
	- works with a single star system
	- works even when there are NO star systems
NPC Pirates digest - primary foe.  Pirates can be of various random species.  But by referring to them as pirates,im acknowlding that we handle them as ENCOUNTERS and not as strategic geo political campaign style AI.


BUG - SOMETIMES, Planets like saturn are being rendered without proper shader functioning.  If i go in and modify the DefaultApppearance to use a different blending mode, it fixes it.  When it fails, if i look in the debug log, it shows the worldshader.fx loaded but without the proper [GEOMETRY, 0]_[FORWARD, ]_[DIFFUSEMAP, ]_[NORMALMAP, ] listed.  And when selected the DefaultAppearance in plugin, the specular power is not listed in the procedural shader card.  
		- this is all just very weird.  
	
FIXED - Repository.Get() does lock our cache however, IPageableNode.Create() can result in the creation of a node just after the lock is released and a key of a conflicting id is already added to the Repository.  So take a look at the static Create() for things like Mesh, Textures, Material.. because there is a race condition vulnerability there.  We have to keep the cache locked during the entire Create() call
			
BUG - AttributeGroup - when modifying child nodes (materials, texture layers and shaders) a call to ClearDefines() occurs andthen an attempt to dispose the shader and reload it... and THAT winds up never recreating the shader.  I'm not sure why we're seeing exceptions thrown though.  I think it's because the shader is still assigned to the Mesh yet it's disposed.
	

FIXED - comprehensive testing of prefabs
	- prefabs saved will always have "id" that is same as archive resource descriptor
		- todo: verify all scenarios where we can save a prefab does this
FIXED - prefabs saved inline with XML scene file
	- prefabs saved in all possible ways we save them
	- if we click an entity in scene and try to "copy and paste" it, if it is not referencing a prefab
	  itself, then we must prompt the user to save it as a prefab first.
	  - then when we do "paste" it, we recreate the ref link AND we must also copy over any overriden property values
	  and when saving the scene, those values must be stored for the pasted version as well as the instance taht was copied.
	- deleting certain sub-nodes of a instanced prefab should break the prefab link
BUG - ability to select in Scene treeview an entity and make it a prefab, prompt the asset browser 
	for saving, then make the live instance into an instance of the prefab (this is what we already do when we save prefabs so should be trivial)
BUG  - when reading scene or prefab i should be suspending writes... i think i am but not sure.

BUG - nested prefabs ok?
BUG - multiple 1st level siblings in a prefabs ok?
BUG - saving vehicles with interiors inside of any Zone in multizone ok?
BUG - our Sol System drop should generate a prefab on the fly and then load it as such
	  and this way all prefabs will at least use the normal command and allow the scene file to be saved.
	  Currently when we add a SOl System is it not triggering the Save of the the system and so we cant reload from save file 

BUG - ClearDefines() and/or changing of Defines and re-compile of shader in GroupAttribute is not implemented
BUG - mouse over deck with wall where footprint test is being done causes massive slowdown
FIXED	- verify chair with footprint has it's footprint applied to cellData properly when added to deck
FIXED - verify chair can straddle cells so long as it's footprint does not collide with existing

BUG - lock camera angle verticle angle in floorplan view
	- http://www.youtube.com/watch?v=A08w65yeQNI
BUG - when trying to save scene that contains a Sol System, (eg add a new entity after sol system is loaded to trigger a save operation) fails.
	 
FIXED - I/O of the footprint data we've changed (eg. save entity should save this footprint property as base64)
FIXED - Footprints that span multiple cells don't work.
	- todo: i think the idea of breaking up footprints into "cells" is wrong.  I should stay in footprint global space where
	the indices range x = 0 to CellCountX * 16  y = 0 to CellCountZ * 16
		- in other words, limiting by Cell is what is making it weird trying to work with footprints that span multiple cells... they dont have to
		span anything!  The "Cells" are only useful in visualizing footprints so we know how they compare to a full sized cell floor
FIXED - should be able to select a footprint dimension that is in incrmeents of 16 for x and z axis independantly
FIXED - should be able to set select the footprint offset for which of the "cells" is the "home" cell.
BUG - transparency of target component in orthoviews to help paint footprints
FIXED - atlas shader .fx needs to be passed shader parameters for tileCountX/Z and gridWidth/Height, etc
BUG - GroupAttribute needs to save/restore in our xml prefabs, the shader parameters
BUG - panning orthoview seems to have an available mouse drag window that is smaller than what we see
BUG - ortho zoom starting value should be set when configuring the viewport based on the dimensions of the target
	  - the min zoom and zoom multipliers should also be configured then
BUG - Add X, Y, Z text letters to the axis indicator 
	
BUG - floorplan control toolbar option to Hide/Show mask grid bit values
		- View \ Footprints
			   \ Power
			   \ Fuel
			   \ NPC Paths

BUG - ability to alter wall texture or wall mesh if the style has changed
	- need ability to select the mesh style
	- need ability to select the mesh texture
	
FIXED - Picking models with our model space picking is broken.... sometimes.  It seems to work very well for worlds and stars.
FIXED - Indeed, the bounding box and bounding sphere works in all cases it seems, but it's the mesh/actor.AdvancedCollide that seems to fail.  Seems if I don't use  Accurate tvtest type for picking it works.
FIXED - convert our tile mask painting to a network command just like segment painting
	  
BUG - Translation, Scaling, Rotation widgets are broken... again.

BUG - domain object changes require all my prefabs to be re-saved.
	- actors
	- stairs
	- ladders
	- bed
	- chair
BUG - actors feet are below deck
BUG - verify ceiling/floor seperation is ok

FIXED - vehicle and world icons are rendered as Billboard3d just as star coronas and I think they should be rendered as 2D textured quad overlays.
		- currently star coronas can occlude the vehicle and world icons. planet rings would invariably do the same.
		- so we do have 2d controls that are clickable and we shoudl use that i think.
BUG - mouse should capture input when starting over viewport and then moving off the bounds of the viewport until mouse release.
BUG - on some crashes it seems with zipfile in use, the zip file will get corrupted and not work on subsequent tries!  this is horrible
	  - keeping a backup means that we doulbe disk reqts, but it might be safest option

BUG - toolbar gui options for showing & painting different tile mask layers
BUG - plugin perhaps for defining the footprint layer for imported components
	
		
BUG: Background RegionPVS ends up drawing non background items!

- NEW: Production and Consumption of Gravity and Thrust implemented.
 
	Kim Novak
	
Gameplay
- when i think of minecraft, i think of the crafting system as the mechanics behind construction.  The game didnt just say "hey collect stuff and you can make stuff."  It introduced a bit of work where the player has to learn how to craft and then perform the crafting.  It's not just a sink.  There's a psychological reason that crafting of gathered resources to make things appeals to folks.  It's what transforms the app from a modeling tool to a game.  It's a rather pure game in terms of sandbox, but with resources, and decisions for how to employ those resources.
	- so when i think of Canon, i want to transform the app from a pure, dry simulation, and make sure it's got game elements without it feeling game-y.  The main areas of the game are ship design, crew management, tactical combat, and perhaps secret sauce is career choice.  What is the player's goals.  They can have outward goals and secret goals.  Outward goals are what the crew knows of their mission.  Secret goals are possibly benign personal goals, but also perhaps contradictory to what you inform the crew.  
		- But the career mode i think is what gives the player the ability to define their own purpose and to play the simulation the way they see fit given the rules of the system.  Crew are resources and who is hired for what reasons and capabilities is important.  Managing a crew may not always be about having the best at every position, chemistry may matter.  
		- Careers - do you steel artifacts from native cultures, loot their treasures, or do you research them, collect plant and animal samples, etc.  Do you try to be a bioterrorist and act as a mad scientist with a small loyal crew of sycophants? Are you a man who would be king of primitive inhabitants on newly discovered distant worlds?
			- first career though is as a rebel soldier turned privateer
		- so Crew as resources... information as resources... your ship as a resource... and you employ them to push an agenda of your choosing
			- victory conditions thus can be dependant on the campaign /career mode.  Certain career mode campaigns can be custom modded campaigns that users can download and play.  for instance, Mad Genius Campaign #4 by Hypnotron can define the specific victory conditions and thus provide a more guided user experience where they need to accomplish certain goals.  Since all who play inthis mode must accomplish the same primary goals, we can script certain events around them to provide a stronger narrative for players who prefer that sort of thing.
				
Canon Saga: Supergalactic
	- http://en.wikipedia.org/wiki/Supergalactic_coordinate_system
	Because the races at the United Worlds conference could not agree on how the galactic coordinate system should be aligned, they decided to use a supergalactic coordinate system instead using the nearest 200 galaxies
Canon Saga: Compendium
	
BUG: zbuffer - moons zfight with parent planet
	- http://outerra.blogspot.ru/2012/11/maximizing-depth-buffer-range-and.html
	
Robot Caesar: Base Defense TODO list
The core of my game is a unit based, base defense where the narrative is
one of survival and teamwork.  Are there mechanics we can invent whereby combined unit fire
works better than single fire.  The player receives more units (they can call in what types they need) during resupply but there's only 6 slots on the transport.  Those slots can be composed of supplies, material, soldiers or engineers. 
Further, this game will try extremely hard to not come across as generic and that's why Robot Caesar himself will be a big part of the narrative.  In other words, these won't be just generic marines (even if they look like it content wise - im on a budget and have to make do with 3drt.com models.)  Think films like the first Riddick "Pitch Black" and other films where a few soldiers have to try and defend off against all odds an invasion.

- The game must still be simple... what's allowed to be complex is the interactions that occur autonmously.  The emergent. But otherwise, we don't want to make a big complicated mess of what is a very simple design - tower defense.  This is why things like sound design is going to be important... so that our agents talk to each other just as if they were in a real warzone.
http://www.gamasutra.com/blogs/CurtissMurphy/20160211/265594/Quest_Accepted_A_Visual_Guide_for_Flow_and_Simplicity_in_Games.php

Humblet's 


There's no need for a "flag" to capture in the base, once all player's units are gone, the mission fails. 
--------------------------
- walls - should these become part of structure's octree?  yes, but we don't have to place them in center of Tiles.
	- we can still place walls on "edges" right?  Can we still place a floor tile there too?  Ideally yes.  The edges then... hrm, how do those fit nicely in octree leef nodes?  Placing center of wall along edge so that the wall hangs over two adjacent octants, means in some cases even parent octant can't host because it could be on major octree boundary... of which there are 8.  What if we placed walls on center of octant so that it fit... could we still add floor?  Yes because the floor exists on octants that are beneath the wall.
	- walls are not placed on edges anymore? How do we get platforms that npc's can stand on like ramparts if the walls are not on the edges?  I guess those platforms wind up being placed on the adjacent row of tiles?
	- how do we get walls to draw using "wall placement" stick tool rather than the ground paint hud.
		- selecting the "wall placement" tool will create the wall placement stick.
		- will the tool create the Yardstick mesh or will the HUD know which mesh to load and use
		based on current tool?  I think it's better for the Tool to do it and then it can have
		null marker entity too.  The problem there is, the tool then also needs to update the position? or not?
		
			- graphic appearance of walls should have ambiguous "front" and "back" appearance since
			the same wall meshes will be used to represent either side.
			- this allows us to drag in one of two axis.  
			- allows us to orient the wall based on the axis that the stick is being dragged along.
			
	- wall mesh is not using proper materials. seems to use same greenish material of terrain segment.
	- do we allow walls to be placed in double rows?  Or do we enforce there must always be 1 empty terrain between parallel walls?
	
- 2.5 x 3 x 2.5 meter box vs 1 x 1 x 1
	- the 1 x 1 x 1 needs a lot more tiles to complete a tileable set?
		- no not at all.  it's the same amount.
	- units need to stand on top of wall or on platform behind it
	
- what if we design the base ourselves, and have the player move from "map" zone to the next, as sort of cross between Berzerk/Binding of Isaac/Zelda, and SmashTV/Gauntlet with a little bit of Syndicate and XCOM and Fallout 2 thrown in.  
	- we could use the larger scale Humblet's terrain sizes.
	and prefab buildings.
	
- or Roguelike, 3rd person Doom clone.  A sort of Dante's Inferno.  In it, you play Robot Caesar who crashed onto a hell'ish planet and is trying to find a way off.

- FIXED. make default actor orientation constant.	Creep should face same way as Aiko
- FIXED. health of newly placed actors is 0 after previous actor of same type dies in game.  
	- the values for persisted properties should be unique amongst actors.
- units need to "rotateto" the target they are attacking - both creeps and Aikos.
- Aiko move towards an "exit" point on the map... a goal
	- this would mostly be to test pathing and avoiding falls down terrain
- creep destination needs to stop before merging ontop of aiko	
	- do we test adding obstacles to the steering method?
	- if we pathfind to a tile that is unoccupied, how do subsequent creeps find next available (unoccuppied) tiles?
	- for melee units - find all tiles adjacent to targetNPC
		- starting at NPC's tile, find adjacents and determine which is closest and walkable.
		- eliminate tiles that are not at same height level
		- each iteration, if selected tile becomes occupied by another NPC, then find next closest
		- 
	
- tweak creep acceleration so it reaches top speed when running faster
- scale actor sizes
	- decide on tile sizes is 2.5 x 3 x 2.5 ok for exterior terrain segments?
- if no target, wander + idle	
- if at final waypoint, stop moving! 

- unit spawn points
- unit run, walk, shoot, death animations
- load/save with spawn points and player units at base
- load/save terrain modifications
- DirLight is added to saved scene
- DirLight is added to root
- terrain generation - produce better terrain at 8y tile count height limit
- maplayer - obstacles - walls added to terrain written to obstacle layer
	- Death Zone Blank Floor Kit.skp
	- Mars Base.skp
	- hubs.skp <- robot base
	- PDV.skp
	- podbot-1.skp
- ai - player agents only fire at creeps not each other
- ai - continued pathing fixes
	
Physics Bug
	- MUST do something about .translation AND .LastTranslationStep 
		- that lasttranslationstep having to be set is bullcrap and a constant source of errors
		when u forget to set it.  i shouldnt have to.  
	- FIXED. physcs dynamic and collision flags
	- NEW .Dynamic & .Collidable to "general" tab in plugin
	
Orbit Paths
	- orbit paths, never finished these using hud integration!
		- atmosphere zones are rendered as planar dotted line circle texture  about the planet
			- can be used for aerobraking, but also very dangerous... ship can tumble 
		- gravity well (point of no return where you'll crash and not escape) zone rendered similarly as 2d texture
			- it varies depending on the velocity of the vehicle, and delta-V 
		
	- is nav view also a HUD mode where celestials, ships and such get rendered as proxies?
		- if we add a scale factor to the root zone to scale down distances, but then leave sizes either unaffected or scaled with a different value
		and ships too a different value still, we can do more interesting rendering effects.
			- problem here is, a planet will be visible if it's size is scaled up, where it might be offscreen otherwise so the culling
			needs to take into account the difference in scaling.
				- and we want it all elegant...   
					- we want it all to be temporary, not effecting the actual scene.  just the visual rendering AND the resulting picking too
					because this mode obviously affects picking too
		- Context.Settings["Zoom - Distance"] <-- for Nav Profile, these values are no longer 1:1 scale
		- Context.Settings["Zoom - Stars"]
		- Context.Settings["Zoom - Worlds"]
		- Context.Settings["Zoom - Ships"]
		
		- perhaps they are proxies... as proxies, they are rendered and picked rather easily...  they can just be 3D proxies instead of 2D ones
			- we could render them for instance as monochrome bodies with no shading that is generated by the HUD.  Blue background and black bodies for instance.  
			- im still not sure how i solve the issue with the planet that is visible at large proxy scale but not visible when it's real sized counterpart gets culled thus preventing the proxy from ever getting drawn.  
				- in a sense, during this mode, worlds are rendered from a sensors and predictive perspective anyway... not a 3d camera culling one
				
				
		- when our camera is positioned far out from solar system, can we do a better job of rendering that system or sub-system (for planet moon systems like Jupiter) that makes it easier from a tactical perspective to visualize the spatial relationships of ships and bodies in that system
		- in other words, we we start to zoom out, can we start to do this automatically in the short term so that this sort of tactical view is 
		a path we can choose or not choose dynamically based on coditions/user settings
		
		ZOOM
			- google d3d view scaling
				- id still prefer to scale view then scale root node
			- there is no difference between scaling distances down while keeping sizes the same, and scaling sizes up while keeping distances the same.
				- but its easier to scale distances down AND sizes down
			- when zooming in/out of map mode, the camera distances are at fixed locations based on total fit view at max zoom out and a orbital view around a moon at the max zoom in
			- in a 2d galaxy, its a bit easier as zooming in on every star system always is same depth away, but with 3d galaxy, not all depths are same when camera is directly overhead or across
			- when zooming out of entire galaxy, our pointsprite mesh will have all it's stars moved out away.  perhaps it can work but perhaps not because they'd get clipped by farplane
			- culling is not done by what we see here exactly since farplanes and tiny sizes and sensors show us things that otherwise would not be visible
				- so in this sense, frustum traversal is not necessarily the right way to go
				- in a way, our Zoom view, is largely a HUD construction of an overlay/artificial scene and i think this is how we should approach it
			- still undecided about how i feel about seperate nav view from the default 3d view or whether the default zoom can dynamically switch between them in a continuous way
			- already I can zoom out of our solar system easily, but we don't scale up the worlds.
				- and we don't really want to modify their scales permanently, only on render and for picking
				which is why its better if our proxy generation handles that dynamically
			- what happens if we try to zoom out of entire world?
				- and can we leave a buffer of zones around so our camera can move outside far enough?
				- keep in mind that right now our stars are pointmeshes on a Background3D model that follows camera! 
				Their positions are projected!
					- and we'd want the ability to orbit camera around the entire galaxy representation and have no paging
					stuff occurring in background...  so i guess at some point, zooming out of a system is one thing, zooming out
					of a galaxy is another... and that is the switch we need to handle.
						- because at that point its not just about moving the camera from one system to the next, nav requires special
						scaling to occur.  So whether we're in a "Nav view" or the "default view" i should be able to configure the view
						however i like.  I should be able to configure each VIEWPORT the way i want.  So "Nav View" with a seperate workspace
						isn't quite what i want.  I want it to be more of HUD mode switching.
						- so this is a good reason to build it into our default editor workspace 
							- HOW?  a mode for "zoom" that is not just %, but also galactic, system, planetary (which includes satelites), and world (does not include satelites)
								- so with zoom 1, it's camera move and proxies are 2D.
								- at zoom x10, camera moves, proxies are 3D scaled up x10.  camera is expected to remain in planetary distances
								- at zoom x100, camera moves, proxies are 3D scaled up x100.  camera is expected to remain in system distances
								- let's not focus on anything else beyond that for now
									(such as whether to use sphere culling to ensure planets are visible when scaled up when they should be) 
			- for nav why not fix the camera angle to some isometric-like view angle?  
				- with option to switch to top or bottom view
			GOOGLE - are most solar systems planar to the galactic plane?  For example, is Sol?
			
			- multi-zone sector Zoom testing.  we have single zone working now, so next is multi zone and key there i think is to verify
			  that the root region's scale will affect child zone.  
				- scaling of our background3D starfield fails
				- viewpoint does not seem to be notified when ZoneRoot scales and so the viewpoint position never reflects the change in scale
					- i think this is because Zone's dont automatically inherit anything from ZoneRoot.
						- their globalMatrix DOES take into account scale, rotation, translation, but not their
						regional matrix and it's their regional matrix that is used by their child entities during Render.
						- but im confused, why should planets be affected and not viewpoint?
							- seems to me planets cannot be effected else viewpoint would also...
							
					  But perhaps they should make an exception for scale?  The alternative is we directly set
					  scale to each Zone if camera zoom is modified.  
					  
					  
				// grid will always be at origin and in same plane as it's repsective target
				mViewportControls[0].Viewport.Context.Hud.Grid.InfiniteGrid = false;
				mViewportControls[0].Viewport.Context.Hud.Grid.AutoScale = false;
				// galaxy grid spacing
				galaxyOuterRowCount = zoneRoot.RegionsAcross * 2;
				galaxyOuterColumnCount = zoneRoot.RegionsDeep * 2;
				galaxyRowSpacing = (int)(mScaledZoneDiameter * zoneRoot.RegionsAcross / galaxyOuterRowCount);
				galaxyColumnSpacing = (int)(mScaledZoneDiameter * zoneRoot.RegionsDeep / galaxyOuterColumnCount);
		
				// system grid spacing // fits one entire system
				systemOuterRowCount = 8.0d;
				systemOuterColumnCount = systemOuterRowCount;
				systemRowSpacing = mScaledZoneDiameter / systemOuterRowCount;
				systemColumnSpacing = mScaledZoneDiameter / systemOuterColumnCount;
				
				// planetary grid spacing // fits one entire planet and it's moons
				
				planetaryZoom = systemZoom * 10 (or * 100)
				systemZoom = 500k AU to meters / farplane distance = zoom for a system
				universeZoom = systemZoom / 10 (or / 100)
				
				// satelite grid spacing  // fits moon or notable asteroid, comet, etc
			- VIEW SCALING
				- is equiv to scaling camera position.  Otherwise, afaik, there's no way to scale the view
				without scaling root node and so what we want is to not save the root scale during scene save.
			- better iconization to indicate stars and planets (ownership, habitation, satelittes) 
			- orbit camera should allow more control than just fixed -15 view angle.  maybe +- view angle of 45?	
				- the main reason we tried fixinig the view angle is so we dont incur any z-axis roll when contactenating rotations	involving x and y axis.
			- add a grid for the scaled system
			- make our grid fit the region entirely such that it's using actual region dimensions and then striving to have 100 inner lines
			  and 20 outerlines with inner 5 AU apart and outer 25 AU apart
			FIXED - verify entire system is visible using just small frustum
				FIXED - this means we have to determine which scales are needed for the various views.  There are min/max limits 
				- or at certain limits, the grid spacing/row/column counts must change in such a way as to not have noticeable drop off of the grid rendering 
			FIXED - altitude lines above/below grid
			FIXED - orbit lines
			- interior vehicle while zoomed... not sure what happens there? zoom should be ignored
			- we need to prevent dust field from showing up in wrong viewports
			- we need to hide dustfield when no motion
			- a 2d movement field would be better i suspect?
		
http://msdn.microsoft.com/en-us/library/windows/desktop/bb147302%28v=vs.85%29.aspx
		
PRIORITY 
- random starfield is not visible when zoomed. 
				- perhaps it's ok for random starfield to be used always with same technique, we just have to scale it UP not down
				  if we want to keep it around the camera at same distance.
					- but star digest, minimesh might make more sense?
	- if our HUD creates a seperate model for scaled star proxies, then why not?  
		- but our normal StarDigest is annoying in that it cant easily cope with camera Zoom
		and auto updating GlobalTranslation values.  We would perhaps have to try to keep DerivedTranslation
		as our Regional Translations while also storing in the record, the regionID and regionOffsets so we
		can compute a global for each record whenever the scale changes.
	
- star digest starfield is not visible when zoomed
	- we DO still want the digest to be owner of the renderable model.
	- currently star digest is rendered as Background3D bound to camera that is always at origin.
	- those stars no longer can be Background3d with position moving with camera. They must remain at world origin 0,0,0 and not just cameraspace origin.  This way when we zoom out all are still visible
		
	- each individual star is a mesh vertex and if at origin, we can just scale it, but if camera following background3d we must manually move each star.  how do we go from one to the other smoothly especially when the zoom is changing?  well, if we have a destination zoom and a starting zoom, and a time to interpolate, we can just use interpolation
		- so the star digest must transition from following the camera and having it's pointsprites moved relative to it, to going to origin and now having the pointsprites all in global coords and relying on scaled down mesh3d to allow them all visible
		- the transition shouldn't be too difficult	
			- animations to interpolate between views as our transition method
		- fixing the view angle to an isometric type of view
			- fixing the up vector perhaps to cancel out the camera roll
			- implementing orbit view
								
// TODO: lables for stars in close enough sectors are rendered with the "real" star 
//       - we need to disable those labels when we are rendering them
// TODO: should we create labels in HUD for our starmap when using the HUD version of our starmap?
//       - i think we should
// TODO: our floor grid needs to draw on correct frustum based on zoom level and i dont think i do that yet
			
// TODO: when our culler invokes VisibleItemFound, any labels should be created Context.OnVisibleItemFound... not in RegionPVS.cs
			
// TODO: show starmap should be disabled in hud for quicklook viewport

Waypoint Bugs
FIXED - when CreateRotationTo() and start/end quats are nearly same, NaN quat will result.  Return 0,0,0,1 default 0 rotation quat in those instances instead.
FIXED - when right mouse clicking, selection tool will set as source the entity that is picked.
	FIXED - this entity will get it's own handleevent called if it is IInputCapture.
		- that entity can also set it's capture flag = true so that it will hog input
		until released.
	- BUT, how then do i launch a popup and have that gain capture from the Selection tool?
		- i think it requires a GUI Manager perhaps in our HUD
		- i think it probalby requires that we call a .Popup(entity)
		on the selection tool directly?
		- or, perhaps a bit saner is we have the scene.ShowDialog(Control)
		  or scene.ShowMenu()			
		  and then the scene can manually prohibit mouse intput to anything but that menu
		  including disregarding the normal input controller aliases.
			- perhaps Show() uses a temporary input controller onto context.Workspace.IOController = menuController and then reverts backt o the previous controller when the dialog/menu is closed.  Perhaps it can even wire an event to the close, which Control/Dialog classes automatically fire.
			BeginShowDialog()
			EndShowDialog()
				
	- i dont really want to make edit style waypoints... yet if at all.
		- i want to make waypoints that a user is going to assign to his ship or those in his command.
		- as we move mouse to place waypoint, a line is drawn and text showing the distance to the nearest body	as that waypoint will be relative to it.
			- this line will show distance to surface, and certain snap points for geostationary orbit and such will occur depending on distance.
	- editor - mission design
		- select a ship
			- this will show existing waypoints - similar to crytek engine
			- a tag point is a "waypoint" that is not owned by any ship, but which a ship
			can dynamically adapt.  Logic can be used to have an AI utilize a route that is defined by tagpoints.
				- tag points stay in the scene and do not change. 
				- consider these part of the scene graph.
				- regular "waypoints" are dynamically assigned and do not belong
			- clicking on an owned waypoint will also select that vehicle and it's waypoints
			will be treated as sub entities 
				- this way, when placing waypoints, to modify the waypoints, we can just click on them
				and not necessarily the ship that uses them.
				- so we will create a toolbar section along side celestial/lights/etc
				where can place AI objects like tagpoints and position them.
					- thsi will help us figure out how about orbits.  waypoints must be child-ed to a body usually because they must remain relative to a parent.  Further, the waypoint should be
					defined by an orbit altitude (2d) rather than (1d) point because you can't really have a ship stop at a waypoint that way... it is relative 
					- i think the idea is simple enough in that a waypoint has a property where it's defined as being relative distance from some body.
						- i think this waypoint then should also provide assistance to an AI for determining intercept vector.
						
		- create and position waypoints and define waypoint properties
			- perhaps when in waypoint edit mode, it is now no longer possible to
			
	- toolbar NOT toolbox icons for waypoints?
		- toggle show waypoints
		- toggle waypoint labels
		- delete waypoint
		- add waypoint (by default appends to end of route)
		- right mouse click
			- insert waypoint, inserts a new wyapoint before the selected waypoint
			- delete waypoint
			- properties
				- patrol (first supported type is just patrol)
				- cargo 
				- 
		- should be very similar to our placementtool, only now we are placing waypoints and these waypoints
		get added to a Vehicle
		
	- todo: i should be able to initially plot waypoints by using popup menu when selecting stars/worlds/moons/ships
		- but what to do when reaching the waypoints?  orbit?  just "stop?"  
			- i think default is you orbit 
				- how do you select the orbit altitude?
					- low/medium/high/polar/geo/etc options in menu
				- what about for a ship as target?
					- match orbit
					- intercept (attack run followed by fly by)
					- shadow
					- evade (use planet or body to get out of line of sight of attacker)
				- what about an angle tool popup to select the orbit plane?
				- the idea is, players can travel fast with say "warp" drives, but not near gravity wells
				the warp fields cannot form or remain stable.
				- so once close to large bodies, ships warp fields collapse and can cause damage 
				even catastrophic damage which perhaps is more likely the later you come out of warp near large gravity wells.
				- also you dont instantly decelerate from warp velocity.  you must still slow down, although
				that can be done relatively fast.
	- todo: Additionally, i should be able to move waypoint cubes, have the ETAs at each waypoint visible in a mouse over label.
	- todo: what about 3views?  I think for a proper 3d perspective view, its probably not necessary so long as the scaling of the view is such that we can place our waypoints where we want.
	- todo: add a circular region plane.
	
GRID 
	- grid scale should vary based on the higher value of distance and velocity length between frames
	- render order, grid lines are rendering over planets
	- the y height will eventually cause the grid to go beyond frustum.  the y must be scaled
	similar to how we scale models... using a scale factor to scale distance down and size up to compensate
	for it being moved closer.
	
Single player Time "Skip" FF mechanic like XCOM
	- in single player many events are to take a while.  in proper roguelike fashion rather than make those events take unrealistic short time,we implement a mechanic to skip ahead until an event warranting attention occurs
	

- TODO: I've been cutting a lot of features that I initially wanted for a hard-sci-fi universe.  Things like orbital mechanics for example... seems 
	to not only be difficult to implement, but not core to a good design considering we are trying to make a captain simulator not a starship simulator.
	Krellan Commander was much better in this regard... and I should remember this lesson when designing all other aspects of this simulation.
	
NAV MAP BUGS

- FIXED. moons should stop hud icon when too far because it's impossible to read those moon labels
- FIXED.  i could disable culltest for the icons so that they always render and if offscreen, change the icon to use a 2d one on the edge of screen.
- FIXED. icons disappear when behind planets, this is rendering order issue i think.  icons should render with overlay perhaps.
- Nav Map must be associated with a vehicle.
	- or, if there is no vehicle, we cannot see radar contacts because radar contacts are from the perspective of some ship.
- option to show orbital paths of ships
- option to show previous path of ships
	- seperate histories for system to system plots vs within system plots
- FIXED. Pick Scaling has solved tests against far planets.  Picking in general "seems" really fixed now.
I've gone over the modelspace ray conversion and it seems fine.
- FIXED. fix grid
	- FIXED. wider grid spacing
	- FIXED. normally the grid follows the camera, this grid we want fixed at 0,0,0
	- FIXED. Grid line render order so they work with alpha blending in nav view (eg planet rings and star billboards)



	
- toolbar
	- bugs
	- entity flag PROXY if set, should set the refEntityID as the pickresult entity.
		
- view waypoints toggle
	- tool to delete and create new waypoints / plot course
	  - toolbar button - show path histories (eta with ghost view of future locations at that time)
		 view course history
		 view course histories for other vessels
		 overlay and view course paths/histories for minefields, etc
		 modify the plane of the navigation view
		 - flight plans that allow for avoidance of dangerous obstacles (stars, asteroidfields, )
		
- Ships/Satelites/Contacts proxy icons
	- FIXED.  nav contacts (see notes at Hud.cs Pick())
	- ability to drag a 2d box to group select 
	- FIXED.  individual picking of contacts and nav icons
	- how are these dynamic things added to our nav view?  Query the scene
		- i mean where is the info about them retreived?
			- systems that are loaded into repository
			- xmldb cached systems? sqlite db?
				- fixed satellites, but what about dynamics ones? I suppose we could pull it from
				server and treat it as a paged in system that needs to query server for updated info?
- altitude lines
	- should be easy.  find position, subtract radius from y component, draw to 0 y.
	- disregard whether the world is visible or not

- orbit lines
	- these are not perfectly alined to planets.  why?
- What about how we intend to draw trails and paths and orbit circles?
- if we start with trails and knowing these are somewhat seperate things compared to
the entities themselves, does the solution for drawing them lead to a general solution for other hud/mfd style iconography? (because in a sense, a trail can be a hud hint too)used by player to determine tactics and make guesses about the enemys' future course based on it's previous tracked course
- for instance, labels, tracking overlays, trails can be kept in seperate arrays and culled seperately...   they could be a type of artificial entity or FX like IMposters?

- can trails and other fx be managed in script similar to lens flares managed by star scripts?

- adapt pointlight shader for planets, for ship exteriors
 
- avoid camera z axis rolling when concatenating two quats (google z axis quaternion camera roll)

- sub-stellar systems stars dont seem to have translation scaled properly
	- verify this is in fact a problem
- FIXEd. planet lighting is off (as in not on at all)
- planet rings transparent
	- yet they block out grid lines
	
- be nice to auto center on the current star in a multi star system

Exterior ShadowMapping
	- assign Ambient to lightingengine for AMBIENT semantic
	- assign texture, normal mapping
	- (FIXED) Actor Shader for PSSM
	- (FIXED) minimesh shader for PSSM
		-  need to work on how we assign this shader when the source Mesh3d is using a different shader file for meshes not minimeshes.
		- recycle our Minimesh2 AddInstances for subsequent passes
	- culling improvements on splits
	- blurs - Toasters added blurs but Mietze's does not
	- test different split distances so maybe we cut off shadow range even more 
	- check values of Model castshadow/receive shadow properties to avoid adding to PSSM things like background meshes
		- and to avoid floors casting shadows on itself perhaps since most times its not needed. Some terrain mountains might cast on itself in a noticeable way, but a floor in a building does not.
	- PSSM Mietze http://http.developer.nvidia.com/GPUGems3/gpugems3_ch10.html
	        each viewport must have it's own shadowmapping
			- thus each RegionPVS and it's buckets have to be tied to a specific context\

Interior Point Light Shadowmapping
	- toasters cubic version.. similar to Blind's version
	
Large Frustum Change
	- seems that maintaining two frustums is not really necessary.  Instead, for any planets near enough to warrant needing the large frustum 	we should use a custom frustum just for each of those worlds.  Then there is no need for this "large" frustum at all.
	- also for further away worlds, we should scale them down, construct a billboard and update it infrequently as it rotates and camera changes
	- it's similar to how light matrices are created in shadowmapping to fit encompassed area perfectly.
		
		
DayNight Cycle
	- dynamic ambient lightingEngine.setambient must be called in entity script
	- flares added t daynightcycle_sun.css
	- draw order of sun, moon, clouds, atmosphere and blending
	- TVLight direction is never actually updated in the Script to match the new computed direction

 Volumetric Clouds
	- https://www.youtube.com/watch?v=P-Nw4CANeBc
	- http://randomchaosxnaadventures.blogspot.co.uk/2012/07/volumetric-clouds-in-xna-40_11.html
	- 
	- these clouds can be used as nebula by simply having the clouds render at a different movement scale.  They will still render at normal size scale, but when the camera moves, the resulting movement as far as the clouds are concerned will be scaled down big time to match relative scale variable of the clouds.
	
- Zone Octree for Terrain / Vegetation and such
	- for terrain, octree use can potentially be very useful for enable/disable array management
	- the last time i implemented something like this, i would iterate scene, and if a Model was 'instanced' then i would call Model.Geometry.AddInstance() or something to that affect and skip the normal .Render() call.  I would only then render the minimesh when that mini was full or no other instances remained to be added.  One big problem with this method is it required constant calls to AddInstance() to update element matrices[] arrays... rather than simply enable/disable an element that already existed.
	- the new version we will strive to enable/disable array only and make it more specific to our Structure and hopefully this version of the octree itself wont need to store much
		- the enable/disable of individual elements is the primary purpose since
			we found that a single Minimesh for _ALL_ structureLevel's was more memory efficient than
			one minimesh for each StructureLevel.  Remember that we needed a minimesh for each segment type for each level!
			- the ability to know that if a higher octant is entirely visible, then all child octants are visible
			and thus any minimesh elements that reside in that entire sub-branch are also visible.
			- the ability to know that if a higher octant is entirely NOT VISIBLE then all child octants are NOT visible and thus any minimesh elements that reside in that entire sub-branc are also NOT visible.
	- How does traversal work and enable/disable of minimesh elements?
		- HARDWARE OCCLUSSION OCCURS DURING CULL SO CULL oF OCTREE ALSO OCCURS "BEFORE_CLEAR" 
			- the surface used for occlussion queries must be shared by all Zones.
			- the node.IDs generated should include differentiators by zone, segment, elementIndex
			
		- let's say we recurse the octree, in Zak's version he adds an instance at a particulr position, scale and rotation.  We want to avoid having to addInstances like that.  We want to be able to enable/disable existing instances.  This is especially necessary for us since we auto-tile.   
			- in our version, we simply enable instances based on the tileInfo (segmentIndex, miniElementIndex)	set for that leaf.  
				- the octree visibility needs to be done per rendering context.  
				- the octree visibility can further be pruned through hardware occlusion so that the enable minimesh element pass will contain even fewer 
					- this may require a mirror hierarchical structure created that contains the visibility pass info. or a stack of visibility results
					
				- the octree when created, should only have children created when the segment != empty or null model.  This should further make traversal faster since interiors of mountains wont be represented by octants at all.
					- this guides us by telling us that it's Structure.cs that should contain the octree...
					or perhaps a special SceneNode for Structures..  well.. except again, LOD models wont need them...  but for LOD models that don't need the octree visibility and occlussion information, then that code just won't run for non MinimeshModels.
					- the visibility and occlussion info should also be available for shadow passes
									
	- the new version must also work with LOD potentially... so should occur after LOD is first chosen
		- potentially, one type of LOD will be imposters for extremely far terrain zones
		- this suggests that the Culling of Tile Segments should occur under the Model since we want to be able to have different LOD Models.
		
	- we also will want to do occlussion queries since particular when inside caves, its invaluable
		- we need to make sure occlussion queries can be used between all zones
		- Model.IsOccluder = true
		
	- i do like the idea of doing the cull just prior to render... but i worry how that allows us to share occlussion query results
		- occlussion queries MUST BE DONE BEFORE CLEAR!
			- we know we can also limit our queries to nodes that have segment style > 0
			
			- Model.IsOccluder = true
				- MinimeshModel <- special Model type for MinimeshGeometry perhaps that can track occlusionID per instance?
				
			
		- if i can, what if instead of having to do with any particular minimesh type, i instead occlude entire TILES?  Once i know which tiles are occcluded, i can skip rendering of anything on them...
			- vegetation, terrain, npcs...
		- zone.Octree.Cull <-- which can give us enables... in the PVS
			- how then do we associate each tile with minis?
			- then zone.Octree.Occlude() <-- limited to enabled only
			
- Procedural Generation
	- a simpler system is needed.  
	a) let's say first i create a proper 8192x8192 world texture with water and such.
		- from there i need to normalize a "working copy" that gives values between -halfLevelCount and +halfLevelCount
			- from this map, i create a biome map. or perhaps i can compute on the fly based on adjacents when i sample.
			- from this normalized map that is only used internally (the full color version used externally as "pretty map") i can generate pseudo-random zone based terrains and vegetation based on biome and based on a hand crafted algorithm to generate playable landscapes based on that biome type. 
			- Grass / Vegetation
			- from a single biome for a zone, i think we can come up with fairly simple procedural code
			for vegetation.  
				- for grasses, start with seed + unflattened zone ID, then for a particular biome, we have list of vegetation and likelihood of each type, and density.
				- bomes also have all rules for min spacing (for trees especially) and we just iterate each tile and compute odds that various vegetation should go there.
				- but the point is the map can be generated as the zone is loaded.
				- what does the vegetation map generation and "entity" creation look like in context of scene?
					- is it like a spawn node? like our RandomVector nodes
				
				Zone
					SpawnLocation 
					{
						monster types: 
						emitter types: point, rectangle, sphere, polygon
						rate:
						maxcount:
					}
					ProceduralGenerator
					{
						int Seed;
						MapGenerator
						BiomeGenerator
						TerrainGenerator (seed, biome, elevation, adjacentBiomes, adjacentElevation)
							- caverns, lakes, rivers, paths/passes 
								- these should all occur as secondary passes? but how do we avoid having to load adjacents unnecessarily into memory?  i mean how does a river connect properly to ends in adjacent zones spanning many many zones? how does a road?
								- the normal solution would be that you'd sample at higher resolution...
						VegetationGenerator (seed, biome, 
						NPCGenerator
						KingdomGenerator (seed, area, race, 
						VillageGenerator
							- scout for high terrain, near fresh water, fertile soil, forests for wood fuel, sea port (fishing), river, defensible position
					}
				
				
	- http://developer.download.nvidia.com/books/HTML/gpugems/gpugems_ch07.html
	- http://developer.download.nvidia.com/books/HTML/gpugems/gpugems_ch07.html
	- http://xnauk-randomchaosblogarchive.blogspot.com/2012/07/volumetric-clouds-source.html
		- i think grass per zone using minimesh is fine and using a vegetation layer is correct
		since we dont have to store any geometry and we always get same vegetation layout even if we're just storing a seed value to generate layer at runtime to avoid storing lots of textures.
		
	- KeyStandardLibrary.Perlin
		- let's say i generate a noise texture such that each 32x32 segment zone in the overall texture is represented by 1 pixel.   Thus, a 8192x8192 texture would give us a world that is
		262,144 segments square at 2.25meters square = 655,360 meters square or over 350 miles along one side.  
		- taking any one pixel and then re-running the perlin function against it to get a finer resolution, and then using adjacents + overlap to align the borders, perhaps we can create a decent world.  
		- in theory, we shouldn't even need to cache that 8192x8192 texture.  For any given 32x32 zone, we should be able to find the value of it's 8192 pixel, and adjacents if necessary and then find the values for each and any of the 32x32 sub-pixels
		
		
		
		- once we have the basic 8192x8192 zone, we then want to page in visible zones
			- generate noise for each visible zone using pixel of overall noise map as start value
			- we need to clamp ranges from -63 to 64 
			- for each heightmap we've generated
				we now need to create layers that are essentially, 3-D textures.
				- for every x,z in heightmap
					value = getValue(x,z)
					for (int i = 0; i <= value; i++)
					{
						// convert each value to a renderable floor level by substracting 64
						// this level will have a terrain segment at that location
						
						// todo: but in the past, we simply didn't add that level if
						// the area below sea level was fully terrained.  
						// Every level below sea level only gets added/created
						// a) any level below it is not fully terrained.
						// b) it is not fully terrained.  
						// The opposite is true above sea level.  Every level above sea level is only generated if 
						// a) any level above it is generated or
						// b) it is not fully empty
						// 
						// so we're always having this annoying battle between what is simulated
						// and what is drawn and what data needs to be available for either... 
						// and of MVC - seperation of model, view and controller
						
						// LibNoise does seem a bit better designed when it comes to sampling
						// without generating a full image.  It suggests more readily i think that
						// we can procedurally sample, rather than persist any images at all.
						 
						//
						
					}

 
 
Interior Building Ceilings
	http://www.youtube.com/watch?v=DBKqmxfPbcs#t=555
	Antilia game does same thing as me and SIms3 and has a simple way of dealing with the interior
	mesh/appearance of ceilings!  You simply edit them from the top (floor) side with a switch   
	http://www.antilia-game.com/index.php?page=Blog:80
	- we use a system to define edges based on grid points in order to make it easier for users to build
	things!  It's not about game designers/modders building things offline.  It's for players to build thing
	online.  A grid simplifies all that.  The pathing advantages is secondary.
	- before we defined edges by row column, but that makes it difficult to use pieces which want to go from
	- 1) the main point is not to have 100% custom shapes and layouts.  The point is to have it flexible enough
	to allow users to make what they want, but to still be able to navigate that structure easily for AI
	and for other processing of the map.  It's like the idea of building the world for the robots and humans adapt
	vs building a world for humans and making robots adapt

	- 3) easy creation of a traversal graph
	- 4) picking - finding tiles & verts mouse is near is easy, but converting this to a type of edge...hrm
		- especially when we want some of our segments to be double segments.. for performance reasons? 
		- every wall configuration from a tile has an INDEX into a lookup
			- the style for each wall is also a lookup index 
	


	
Terrain 
- file:///C:/Users/Hypnotron/Documents/My%20Pictures/_DRACULA/Morrowind%20Construction%20Set%20Landscape%20&%20Region%20Tutorial.htm
	Skyrim Tamriel Worldspace: 3808 x 3008 [ 119 x 94 TES4 size cells ] = 6.9km x 5.4km = 37.6 sq km = 14.5 sq miles
	Oblivion Cyrodiil Worldspace: 4288 x 4128 [ 134 x 129 TES4 size cells ] = 7.7km x 7.4km = 57 sq km = 22 sq miles
	Morrowind Vvardenfell World: 2688 x 2816 [ 84 x 88 TES4 size cells ] = 4.8km x 5km = 24 sq km = 9.3 sq miles
	Fallout3 Wasteland Worldspace: 6304x6400 [ 197 x 200 TES4 size cells ] = 11.3km x 11.5km = 130 sq km = 50 sq miles
	Fallout3 New Vegas WastelandNV: 4096x4128 [ 128 x 129 TES4 size cells ] = 7.3km x 7.4km = 54 sq km = 21 sq miles

	Highest Map Points:

	Skyrim Tamriel Worldspace: 4924 THU (39392 Game Units) = 561.336 metres [Cell (13,-13)]
	Oblivion Cyrodiil Worldspace: 6581 THU (52648 Game Units) = 750.234 metres [Cell (52,58)]
	Morrowind Vvardenfell World: 2369 THU (18952 Game Units) = 270.066 metres [Cell (3,8)]
	Fallout3 Wasteland Worldspace: 10897 THU (87176 Game Units) = 1242.257 metres [Cell (-86,83)]
	Fallout3 New Vegas WastelandNV: 2584 THU (20672 Game Units) = 294.576 metres [Cell (-30,26)]

	NB. Skyrim's north coast is well below normal sea level: approx -14,200 game units, about 200 metres. So relatively speaking the highest peak in Skyrim's Tamriel worldspace matches the same height as in Oblivion's Tamriel worldspace. Pedantically this means Skyrim still only consists of pointy hills, not mountains. /wink.gif' class='bbc_emoticon' alt=';)' />

				
	Jersey - 
	http://en.wikipedia.org/wiki/Geography_of_Jersey
	http://www.gov.je/Leisure/Jersey/Pages/Profile.aspx
		12 Parishes (12 other vampires)
		143 meters max atltidude
		118.2 square kilometers
		Length 	14.5 km (9 mi)    = 116 blocks @125 meters long  <-- these are comparable to Oblivion where they have 119 blocks (they call cells) that are ~58.5 meters each
		Width 	8 km (5 mi)       = 64 blocks @125 meters wide   // Oblivion -> Each exterior cell is 4096 units by 4096 units or 192 feet by 192 feet or 58.5 meters by 58.5 meters.	
		Population 	99,000
	
	Great Britain
	http://en.wikipedia.org/wiki/Great_Britain
		229,848.0 square kilomieters 
		dimensions if it were a perfect square
		Length: 480 km    = 3,850 blocks @125 meters long
		Width: 480 km     = 3,850 blocks @125 meters long
		
	Zone MapLayer Grid Allocations
		MapLayer[,,] mGrid = new MapLayer[sizeX, sizeY, sizeZ]
		3,850 x 128 x 3,850  = 1.9 Gigabytes of space just to hold the MapLayer references for a world map the size of Great Britain
	1	28 x 128 x 128      = 2 Megabytes of space just to hold the MapLayer references for a world map the size of Jersey.
								- that's not too bad... 
		
		- for a world the size of Jersey, it can make sense, but obviously makes no sense for world size of Great Britain
		
		
	- my picutures/_dracula/Landformsmap.jpg
	
	- flat, mound, hill, mesa (mesa has no transition from other terrain types), mountains, volcano, butte, plateu, plain, sand bar, divide, tor, etc... should be thought of as seperate types of segments for our terrain.
		- originally i was thinking this way, but somewhere along the line i got confused into thinking that all terrain should be one segment type and that the only distance was "height"
			- but the thing is, if we have flat ground and we create a hill and later we wish to delete the hill
			how do go back to the terrain underneath?  I think we do this by simply keeping that terrain there
			underneath the hill that is built ontop? but then still using the script to disable/enable appropriate minimeshes.  Afterall, within the map layer, we dont lose anything by having terrain on a layer and
			hill on layer above it.  But what about transitions?  the transitions too can be auto
		- but consider an ASCII version of the map.  the ascii shows terrain types but visually is where we represent transitions.
		- so transitions are main problem to solve.  If we enforce that we always build in layers
		then a "hill" stops being a hill once it flattens out?  and then becomes a mesa?
			- actually, the more i think about it, the more it seems to me we need to somehow signal an elevation change
			in the tool and then to have logic for placing the appropriate model at the transition from one elevation to the next.
			- raise lower similar to an excavate/raise tool in sims
				- perhaps when raising or lowering, we show a +1/-1 or +N/-N value to indicate what leve
				we are raising to.  This way there's no case where if we click on a +1 level that it then raises
				another +1.  Instead, it stays at that level until the tool is set to +2
				Visually, we can show what the terrain will look like where the mouse is and this also
				reinforces the concept in the user.
			
	- Zone traversal testing including paging in/out data and canceling pages in and pages out
	- terrain Mesh
		- tools for LOD generation of our meshes that automatically update in thread 
	- dragging dropping flat terrain will show us the available zones we can drag too
		- HUD normally is in charge for drawing these HUD visual aids
			eg. HUD is responsible for loading and adding these temorary elements to the rendering pipeline
			
	- land splatting
		- alpha textures for blank terrains should have alpha texture generated and updated on save.
	- edges of terrain (zones) can be done in shader too just like brush
	- terrain shaping tools
	- tile mask / data structure for underlying map
	- Initial zone needs to have a data mask of some kind
	
	- Terrain cells should be treated like painting a full segment with EXTERIOR walls and a floor above it
		- and only if we use excavation tool to create tunnels will we add INTERIOR walls and ceiling.
	- Exterior "great" walls should be treated like solid terrain too.
	
	- MIN/MAX levels for Region structures.
		- how do we insert new structures above below existing levels?

PROCEDURAL TERRAIN 
	        	// diamond square
        	// http://danielbeard.wordpress.com/2010/08/07/terrain-generation-and-smoothing/
        	// http://www.gamedev.net/topic/618808-perlin-noise-and-procedural-generation/    <-- ascii map
        	// http://www-cs-students.stanford.edu/~amitp/game-programming/polygon-map-generation/
        	//   E:\My Pictures\_DRACULA\voronoi-land-ocean-lake.png
        	//  http://www-cs-students.stanford.edu/~amitp/game-programming/polygon-map-generation/demo.html
        	//
        	//
        	// we can first generate a few base terrains for mostly flat terrain
        	// - first we just determine coastal outlines
        	// - then we seed mountains and valleys
        	//   - then we determine max mountain height, min valley height
        	//   - mountains should peak at 100 meters.  valleys should peak at - 100 meters
        	// 		- we can now designate the sizes of mountains and valleys
        	//		- fist step actually should be to first define any mountain ranges which results in a line
        	//        along which the mountains extend.  we can do parallel ranges too
        	//        - volcanos can be placed within that line
        	//      - after ranges are made, we can make canyons and isolated volcanos
        	//      - WE CAN MAKE THESE FEATURES HAND PLACEABLE INITIALLY RATHER THAN PROCEDURALLY PLACED
        	// 
        	
        	// then we will seed the flat terrain with areas that will receive special terrain features
        	// eg. we build up our hills, mountains, etc using a set prefab of pieces and then can place
        	//     those pieces to replace existing pieces.  
        	//     - we can also build caverns at this stage both under water and above water 
        	//       as well as entrances to the same cavern system above and below water
        	//     - caverns can exist as structures that are walled off from the outside except for entraces from
        	//       other levels.
			
TERRAIN NOTES

	// http://www.gamasutra.com/blogs/AndreyMishkinis/20130716/196339/Advanced_Terrain_Texture_Splatting.php
	// http://www.rigsofrods.com/wiki/pages/Alpha_Splatting
	// http://scrawkblog.com/2013/06/04/massive-terrain-in-unity/
	// http://www.truevision3d.com/forums/tv3d_sdk_65/best_splatting_terrain_and_shader-t21730.0.html
	// http://forum.unity3d.com/threads/155185-ats-color-map-ULTRA-shader-RELEASED/page20
	// http://gamedev.stackexchange.com/questions/54276/a-simple-method-to-create-island-map-mask
	
	// Philip Fortier XNA work is really good
	// http://mtnphil.wordpress.com/2012/10/15/terrain-triangulation-summary/
	// http://mtnphil.wordpress.com/2012/08/25/water-flow-shader/  http://www.youtube.com/watch?v=zfhu-VfJ_To
	
	// The more I look at tile based terrains, it seems full blown plod terrains are really best for
	// flight simulations... not for a small adventure style game.  Even the Sims, i think using a full
	// blown terrain means too much gets rendered offscreen.
	
	// Actually, Waterman is using TVMesh and he takes 2.2 x 2.2km portions of the heightmap to update the verts 
	// and also to generate different LODs on the fly.  This is a really clever way of being able to page in data
	// from an underlying source, but to keep each terrain patch as a seperate Terrain Entity that can have it's own LOD.
	// So next question is, are "chunks" of any value?  I think no because our 2.2 x 2.2km 
	// Waterman uses relatively low res chunks though... 200x200 verts along the side for 2.2 x 2.2km is ~1 vert per 10 meters
	// - editing of terrain patches is done within the same 9x9 camera sphere.  The LODs are generated on the fly.  We always only
	// edit in full resolution.
	// - so question is, are we dealing with 9x9=36 terrain entities that all read from an underlying datasource similar to how
	// floors in our Interior all read from a single data source?
	// - perhaps there is a single Terrain Entity, and now our version of a "chunk" is a child "model" like our interior floors.
	// The terrain Entity Update() manages the LODs.
	// Keep in mind that Region can hold Terrain Entities and thus a terrain can't span
	// regions.   It would need to be seperate ones in each.  Could potentially share same data src though. Just offset into the heightmap
	
	// So can we start with smaller, area, and proof of concept?
	//  - START WITH REGION, determine what our Terrain Entity looks like, model/lod child structure
	//		- how are we editing the underlying data via terrain tools?
	
	// - Region  
	//		- Terrain <-- a single heightmap 
	//			LODSelect
	//				Model - full heightmap - full resolution
	//				Model - full heightmap - down sampled
	//				Sequence - chunks
	//					LOD 
	//						Model - 200x200 vert sample
	//						Model - 50x50 vert sample   <-- wait, arent these autogenerated based on distance from full resolution src?
	
	
	// THE ABOVE SYSTEM MUST RELATE TO HOW PAGING OF ENTITIES THAT SIT ONTOP OF THE LAND OCCURS! 
	// - normally paging is done by Region.  But if there is just one huge region, then our paging of trees, rocks, roads, exterior of buildings, etc
	//   cannot be done in this outward concentric paging system we want.  Ideally the logic is driven simply by LOD structure of the scene branch.
	
	// - it has to be tied to how our scenegraph handles LODs though.  So this may also mean each of our 2.2x2.2 is a "region" and perhaps
	// not necessarily with unique coordinate systems?
	//   - or perhaps a "Chunk" is an internal partition that allows normal paging of a region to be handled in a special way by the
	// region that hosts them.
	//		- the main idea here is a Chunk is like a Region but without the seperate coordinate system.
	//		- Region probably makes the most sense because we already will only load those when they are visible
	//      and unload when no longer visible.  
	//		- regions have their own underlying dbs and maps
	//		- paging is automatically supported
	//		- But what if a "Volume" is exactly the same as Region only one difference... it does not change coordinate systems and inherits the parent coordinate system instead?
	//			- but otherwise, it can contain and manage databases, data maps/layers, and host child Entities that get paged in only when the Volume is paged in?
	//			- this requires as well that Volume will page in/out just like Regions.
	//      - the heightmap as a sort of database where terrain data is paged in...
	//             - the heightmap itself is still a single contiguous part, but we read only parts of it at a time
	//
	//      - a zone/region can inherit perhaps from a type of PageableBranch perhaps and that way our Pager isn't just looking for Zones, but any pageablebranch node
	//      and knows these nodes can be paged in/out in their entirety
	//			- we can continue perhaps to use a naming convention to kow where within a heightmap db, the terrain belongs
	//	
	// Terrain using TVLandscape vs TVMesh
	//	- the main benefit to a TVLandscape is for plod, and quadtree that is used to cull faster
	//  - when using chunks, it may also work better with eliminating seams.
			
	//  - waterman recycles his TVMesh geometry rather than creating a new instance when he wants to fill it...
	//		- it's definetly better than recreating vertex buffers.
	//		- using TVMesh here is also good cuz you can more easily vary the vertices instead of relying on TV's unpredictable PLOD
	//		- a "terrain renderer" like our MinimeshRenderer can be something we use here...
	//			- also TVMesh allows us to store the verts ourselves.
	
	// 1) Toolbox - add and place a zone with a visible box of where it goes
	//			  - ability to modify it's dimensions
	//			  - ability to clone it and add more
	//				- do not allow intersections.. allow snapping of edges?
	//  2) ability to drag a terrain patch onto a zone
	//		- can camera stay in root if not in zone? since zones may not encompass full size of root node?
	//
	//
	
Floor Tiles Data Structure
	- painting of trees, bushes, off limit areas onto underlying tilemask grid.  TIlemask grid
	will be higher resolution one than interior one.
	- y is such that bottom of wall or floor is at 0 for that level.
	- or, maybe we should just center all models so we can easily use them anywhere?
	- the "model" can bake in the offset for a given tile size
	
Autotiling - Walls - Structure
	- walls are 6", 1', 2', or 5' thick (though a 5' thick wall takes up entire tile so is really a "solid"
	version of 4 walled tile with floor and ceiling all of same material/texture.
	- walls are 9 feet + 1 foot for floor = 10 feet
		- total distance from 1 floor to next floor is 10 feet
	- structure tile spacing is 5' x 5' 
	- the generica castles were created each on a 360 by 480 grid
	  which is 72x96 tiles (5'x5') = 6912 total tiles
	  - in this example, the "zone" would be 360 x 480 and the internal "structure"
	  entity of that zone would have at least one bitmap map layer representing tiles that was
	  72x96 pixels.
	- autotiling - http://www.squidi.net/three/entry.php?id=166
	- how do i get rule to use same model but then to rotate that model by some amount
and have that rotation applied in the AddMinimeshElement?
		- ideally, the MinimeshGeometry would be created from Mesh3d and not Model and then the rotation grabbed from Model.  
		TERRAIN ELEVATION
			- If a flat terrain and a full height terrain are distinguished by an "elevation" attribute, then when autotiling an attempt to build
			ontop of full height, we can know to modify that full height adjacent layer tile.  
				- this solves the issue of having to try and treat the upper tile as having a "floor" or for the lower tile to have a "ceiling"
				No.  There's still just the one floor of the lower tile and the upper tile is completely empty.  Yet when players stand on the full height 
				floor, they will extend into that upper layer'ed tile.
				
			- flat, 1/4, 1/2/ ... full
			- seperate layer?
			- this is visually represented in tilemap too   
				- so this means a model Index for a particular segment Index is dependant on an Elevation 
				and maybe in our script, we not only look at segment Index but we look up the elevation index
				and we then choose our model index.  
					- so given this, does it make sense to put elevation in a seperate 8 bit layer or to put it in 1 bit of the style map.  Or does it go in 1 bit of the segment index or does it go in it's own seperate layer?  Style isnt needed server side. 
			picking elevated terrain
				- i think we simply left mouse click build up, right mouse click delete/dig. We'll try that for now.  We just need a box to show
				where we're picking with left mouse click... that is to say, to show where the sculpt will go (though we cant show dig, since one or other)
				- so our marker needs to know when it's over a terrain mesh and then return upper layer index
					AND if no current meshes on that layer, we need to create the layer
					- if all we do for starters is add tool marker (maybe it shows us an auto-tiled preview) starting with just a box outline
					and pick the right model and elevate the tool marker accordingly, then we're good....
			DIGGING - the lower layer if it does not exist has to be created and become all raised connected hills?  
						and then the layer above it now has to be re-autotiled to adjust that it's "floor" is now represented
						by raised hills on the lower floor?  OR OF COURSE WE CAN START WITH RAISED LOWER FLOORS AS OUR DEFAULT FOR ANY LaYER
						sothat digging is now inherently always supported.

		
Adjacents that are not paged in... more concerned about paying in first before auto-tiling?
- for non paged in, remember that first we have a buffer of paged-in but just not visible... 
- need to UNPAGE maplayers that get paged out in ClientPager
- need to verify PageIn/Page out continuously in very large world
- need to verify even numbered Zone sided worlds work... seems when the center offset is not 0,0,0 that we have problems.
- expand rules to clear/remove tiles that are covered
- digging out unsupported terrain should delete that unsupported terrain above?  or not allow the digging that would result in unsupported terrain above it.
- footprint data
- add "layername" to the script so that the Tool knows which layer this type of paint segment is being applied to.
- walls can come in two varieties... full tile size or edge sizes....  which means two different layer types.

- bugs
	- still bounding box issues with Structure / minimesh visibility
	- fix issues with paging in/out on larger than 3x3 zones
	- fix skysphere, should be bigger and lower 
	- fix clouds, have them fade out in distance?
	
- GUI - Right Mouse Click Menu in game
	- when we LEFT click an entity, i'd like for that to result in highlight (outline and/or terrain marker) and then be able to RIGHT click to tell it where to go.  
	- so how is that action/functionality binded?
		-		well, right mouse click on the entity 

- FX
// - billboard clouds for far horizon 
// - fix sun and moon
// - lens flare
// - fog shader
//		http://ploobs.com.br/?p=1868
		can FOG VOLUMES / RAY MARCHING IN A VOXEL / 3D TILE GRID EASIER/FASTER than other 3d implementations?
		http://advances.realtimerendering.com/s2014/wronski/bwronski_volumetric_fog_siggraph2014.pdf
			- consider a single billboard for each tile that we can then move, and then for lighting, consider how it gets added to shadow mapping depth and then resulting lighting equation
		https://www.youtube.com/watch?v=xubLTC7meJU#t=170 
			- notice use of modulation texture which is just like typical cloud noise 
			
- initialize mTilemask on creation
- find out why the tilemask seems to stop working after a while
- enable showing of footprint of component and valid/invalid placement 
	
	- resolve how we show footprint / tilemaskgrid and regular textures
		- do we render footprint as overlay quad?  
		- what about as "grid" section added to shader of terrain/structure meshes? our UV coords would all need to match.  in fact
                  every vertices UV should simply be 0-1 as ratio of it's position between the dimensions of a tile size.
		- or since full tilemask grid rendering is debug aid, can we simply switch from normal rendering of textures, to the tile grid view where we don't use UV, but pixel position instead.
			- does this explain why our gridlines also dont all align properly since they're using UV's?
				- and can't we simple render grid by ratio of pixel location and ignore UVs for that?
				
				
- http://dice.se/wp-content/uploads/Chapter5-Andersson-Terrain_Rendering_in_Frostbite.pdf
- procedural height based texturing
	- i think mostly for our terrain, we simply create good texturing ourselves offline.  if we then want to add snow, foilage based on altitude, fine. but the basic texturing for steep faces should be done ahead of time.
- detail texturing
	http://forum.thegamecreators.com/?m=forum_view&t=207224&b=1
 float4 baseColour = tex2D(baseSample, In.UV);
  baseColour *= 2.684 * tex2D(baseSample, In.UV*4);
  baseColour *= 2.684 * tex2D(baseSample, In.UV*16);
  baseColour *= 2.684 * tex2D(baseSample, In.UV*64);
  baseColour *= 2.684 * tex2D(baseSample, In.UV*256);
What's happening is that the texture (one of The Slayer's wonderful free concrete textures in this case - Free Textures) is being sampled at several different LODs and the results are then simply multiplied together. The factor 2.684 is an arbitrary factor to prevent the final result becoming too dark - it needs to be calculated separately for each texture (and, ideally, separately for each colour component although I haven't done that here). The average colour of the source image is approximately RGB = (96,95,95) so I've brightened each multiplication by the factor 2.684 = 255/95.


- pathing across zones?	
BUG: attempting to mouse pick a new nav destination that is in an area in an adjacent zone that is 
not directly adjacent to the source zone, then the BroadphasePathing will fail.  For some reason it's not able to find
that "inland" area in the adjacent zone.  It can only find those AReas that are immediatley adjacent.
BUG: i dont see portals generated in empty adjacent zones
BUG: not converting NAV waypoint coords to Region coordinates of the new zone NPC has crossed into
BUG: sometimes when pathing if the start.y is -0.00000002  it will result in Floor() function making it -1 and then 
     that will screw up pathfind when we try to find an Area that contains that start tile.
BUG: why on earth is the fine grained pathing so... strange?  i suppose part of the problem is, when it's steering
     it gradually turns and so it ends up oscillating a bit as it over steers.  Of course this is seperate from the problem where it overshoots sometimes and where it does not use a large enough epsilon, or where it will go back to a waypoint 1/2 meter a way just so that it can turn around and then go to the next waypoints that are in opposite direction.  that first waypoint should be essentially ignored if it's that close and going overall wrong way.  It's not baseball where it has to touch every base.
	 
//       TODO: how do we deal with connectivity where we want it to only
//             use ground tiles and ignore fly-able areas?
//             Do we keep different types of connectivity maps for different unit types that have different movement capabilities?
//             - probably yes since connectivity is contextually about unit types and thier capacity to traverse a map which 
//               naturally means it must take into account that units capabilities.  It makes no sense to confine a bird to same connectivity
//               map as an elephant.
		
	http://aigamedev.com/open/tutorials/theta-star-any-angle-paths/
	http://www.gamasutra.com/blogs/SvenBergstrom/20140109/208374/Pathing_Excursions__more_natural_paths.php?print=1		
	- ai "wander" must take into account obstacles
		- ai "wander" ALSO must not navigate out of bounds!
	- AI pathing keeps overshootings
	- broad phase using connectivity graph
		- broadphase should use Connectivity.IMapLayerObserver for updating Areas and Portals
		
		- broad phase is "global" pathing and "local" is per Zone
			- our tile approach gives us some natural tiles to build connectivity with
			- we can update connectivity in real time when zones structure/terrain changes
			- First we must generate connectivity that broadphases uses
			- second we perform broad phase path
				- Broadphase involves A* from start area in start zone to end area in end zone.
					- so how is that algorithm built specifically regarding relative coords from start to end
					when traversing the different graph of each zone and computing traversal weight?
					- how do we traverse through portals?
						- well portals is how we find "adjacents"
							- and we must be able to cache previousStartArea and previousDestArea so that if multiple portals from start to dest exist, we dont run the traversal cost each time.  However we do always allow for multiple areas to be traversed and evaluated from DIFFERENT areas to see if one route is better than another.
							
				- on successful broad phases, for each zone as npc traverses each node in broadphase, we do normal pathing
				- we still keep all zone edge tiles though as seperate areas so we always have proper tile x,z at each boundary
				- we also keep edge tiles around things like ladders, 
	

					
					// - fixing pathing to not overshoot.. seems to do that sometimes
					//		
					// - entity will walk off world bounds if game is minimized.  should not be able to do that
					//   "Wander" does not look at tilemap at all.
					//
					// - incorporating mouse click of one zone into creation of a path series
					//	 that allows us to path across zones
					//
					// - HUD graphic for showing sectors and zones
					//
					// - stitching Portals across zones
					// 		- we aren't going to have all Areas[] loaded for entire world right?
					//		  - how do we differentiate Areas then?  Dictionary seems better than array or list
					//							
					// - file i/o of our areas and portals
					

	- alternatively to broadphase, we don't allow cross zone pathing and instead make zones bigger to negate the need for this functionality?
	- final alternative, limit pathing to just between adjacents and then 
		a) perform algorithm on a combined map data array 
			- should attempt this first and test performance
		b) perform algorithm seperately for each zone and stich path together?
				- this is surely too problematic

		
// TODO: FLOW FIELD PATH FINDING
//		- https://www.youtube.com/watch?v=smmQ0ONzs50
//      - http://youtu.be/arx064_I9ck
//      - http://gamedevelopment.tutsplus.com/tutorials/understanding-goal-based-vector-field-pathfinding--gamedev-9007
//      - http://leifnode.com/2013/12/flow-field-pathfinding/
//      - http://coldconstructs.com/2013/10/flow-field-pathfinding-with-flocking/ 
//                      For the update function, you need to break it up like this:
						//foreach (agent) {
						//	calculate steering
						//	update _accel
						//}
						//
						//foreach (agent) {
						//	update velocity
						//	update position
						//}
						//
						//Otherwise some of your steering behaviours will be seeing their neighbours velocity/position from after they moved, rather than before they moved.
						//With Cohesion and Separation is is really important that all entities see the system in the same state to get correct behaviour.
						//	
//        - the field that is generated gets to be used by all the agents that are grouped and going to same destination
//			- seems to combine some concepts from Collaborative Diffusion 

	Tile Based Games FAQ 
		http://archive.gamedev.net/archive/reference/articles/article728.html
	- traversal cost is a combination of
		- support type
		- obstacle weight if applicable
			- when adding a terrain or structural tile, we must increment++ traversal weight of tile above as well
			- when removing a terrain or structural tile, we must decrement-- traveral weight of tile above
				- this might lead to other sort of physical casading effects such as cave in
				
(todo: mouse picking being off on terrain due to not picking the layer above the terrain we are trying to place mouse over visually)
	- requires ensuring there is always one empty "blanket layer" above the highest layer that has structure/terrain on it.
(todo:  actual obstacle layer used for pathing)
(todo:  obstacle layer dynamicaly written to when placing terrain, structures and obstacles)
	- as style is placed, obstacle footprint must be written.
		- different styles have different footprints
			- in the past, 1 Entity -> 1 footprint
				- but now we want Entity -> ModelSelector ->Models[]
				  where each Model can have it's own footprint.  So where then do we supply a Footprint and
				  what process do we use to create it/modify it/assign it and to write/erase those footprints to the specified data layer?
				  - our footprint editor should be able to allow us to navigate the model's visual tree
					and assign a default footprint as well as a footprint override per model
					- how does scaling of the entity affect the footprint of a model?
					- with footprints attached directly to models, there's no need to manage association
					between footprint and a potentially complex sub-model tree with nested selector nodes
						- however, having footprints attached directly to models means scaling of the entity should not occur
						- what if there was some other way to associate footprints with submodels?  
						
		- slopes are accounted for by weight
(todo:  added mouse pick location markers)
(todo:  added a mouse pick command to direct an NPC to move "succeeded" animation marker)
(todo:  mouse pick off map to direct an NPC to move will be ignored)
(todo:  npc's can path find across zones)
(todo: npc's that can jet pack can cross chasms of size 1 - how do we implement these sorts of rules with pathing & weights?)
(todo:  even numbered zone sided game worlds (eg. 2x2))

- water
- weather fx (rain , lightening) - this game symbolizes hell so the environmental atmosphere fx are important.
- terrain generation
	- A Method For 'Growing' Rivers In A Randomly Generated World 
		- http://www.pixelenvy.ca/wa/river.html


[02:04.00] <Hypnotron> imagine a box that is 3 x 3 x 3 
[02:04.34] <Hypnotron> the directional light imagine isshining high overhead but not straight down.  but theshadow cast on the ground is still pretty short
[02:04.53] <Hypnotron> the side of the box where theshadow is cast on the ground, is itself shadowed
[02:04.57] <Hypnotron> is this correct?
[02:05.26] <Hypnotron> i mean... how can it be in shadowon itself on it's back side?
[02:05.32] <SylvainTV> depends
[02:05.37] <Hypnotron> it might be shaded, but notshadowed
[02:05.41] <SylvainTV> usually the "back shadow" is shaded
[02:06.13] <SylvainTV> i mean the face away of the light
[02:06.13] <Hypnotron> how do i disable back shadow?
[02:06.16] <Hypnotron> right
[02:06.20] <SylvainTV> good question!
[02:06.24] <Hypnotron> :)
[02:06.33] <SylvainTV> what type of shadows?
[02:06.39] <Hypnotron> pssm
[02:06.50] <Hypnotron> cascades
[02:08.34] <Hypnotron> maybe pcf when i add it will makeit look better...
[02:08.43] <SylvainTV> yea hm
[02:08.48] <SylvainTV> you gotta do something like that
[02:09.26] <SylvainTV> color = ambient&emissive + max(ndot l, 0) * shadowfactor;  
[02:09.57] <SylvainTV> you're doing lighting by yourselftoo right,
[02:09.58] <SylvainTV> ?
[02:10.08] <Hypnotron> yes
[02:10.47] <SylvainTV> so you can do that i guess
[02:10.55] <SylvainTV> this way you won't see the shadowhappening there
[02:11.06] <Hypnotron> any downsides to doing that?
[02:11.18] <SylvainTV> hm
[02:11.21] <SylvainTV> no 
[02:11.32] <SylvainTV> depend what you want to do though
[02:11.48] <SylvainTV> sometimes you just want cheapshadow and multpily everything by shadow factor at the end
[02:11.52] <SylvainTV> but it's less flexible of couse
[02:12.13] <SylvainTV> not sure how you're doing now?
[02:12.20] <Hypnotron> http://makosoft.com/stuff/shading2.png
[02:12.50] <Hypnotron> you can see the back faces aresplotchy...  i am ok (for now) with the front since ithink i can fix that with depth bias changes
[02:12.58] <SylvainTV> yes
[02:12.59] <Hypnotron> for strange wall faces that arerocky geometry
[02:13.13] <SylvainTV> no shading there though
[02:13.14] <SylvainTV> it seems
[02:13.25] <Hypnotron> yeah... i fixed it a bit sincethat screenshot
[02:13.46] <Hypnotron> ill post another one
[02:13.48] <Hypnotron> recent
[02:26.14] <Hypnotron>  http://makosoft.com/stuff/shading3.png
[02:26.33] <Hypnotron> actually that doesnt look muchbetter 
[02:26.34] <Hypnotron> shading wise
[02:27.14] <Hypnotron> only thing thats better is i gotrid of some of the projective aliasing by making sure the light box was bound properly
[02:27.37] <Hypnotron> *bound tightly... or at least more so than it was
[02:28.23] <Waterman> Hypnotron, either there is diffuseor not   (?)
[02:28.50] <Waterman> dot(normal, sundir) smaller than 0= no diffuse 
[02:28.56] <Waterman> in shadow = no diffuse
[02:29.24] <SylvainTV> yea waterman that was what I wassaying earlier
[02:29.32] <SylvainTV> i think it's the best way to avoid most of this
[02:29.40] <Waterman> so it's ambient + diffuse * smaller of those limiting factors
[02:29.53] <SylvainTV> this way you can have your bias as you want
[02:30.13] <Waterman> well ya..
[02:31.29] <Waterman> and remember the diffuse is adot(), which u don't seem to have there? When goingtowards shadow, it's already almost 0 on those self-shadowing walls
[02:32.08] <Waterman> diffuse = saturate(dot())
[02:32.17] <Waterman> to not go negative
[02:36.53] <Hypnotron> thanks!  the problem was using"WrapLambert" that adds +0.5 and not really understanding what it did.  i guess its for lazy ambient lighting?
[02:37.33] <Hypnotron> wraplambert -> return  NdotL *0.5f + 0.5f;
[02:38.04] <Hypnotron> but i just used regular ndotl andthat stopped adding so much diffuse to polys facing awayfrom light
[02:38.15] <Hypnotron> i still have to now get the shadow to be based on ndotl
[02:38.16] <Hypnotron> too
[02:38.23] <Waterman> U must see that the dot does not go negative !!!!
[02:39.33] <Waterman> / Diffuse
[02:39.34] <Waterman>     float angle = saturate(dot(normal, light));
[02:39.34] <Waterman>     float3 diffuse = angle *materialDiffuse.rgb * SunDiffuse;
[02:42.27] <Waterman> return  NdotL * 0.5f + 0.5f;     <- 0 ... 1 but erratic, uses negative light or sumthing
[02:42.45] <Waterman> imho
[02:45.25] <Hypnotron> ok.  you 2 have been great help. i will fix this when i come home from zug
[02:46.29] <Waterman> Make independent, self-containedand proud burgers!



- EDITOR (icons, plugin panel design)
	- WarThunder uses the Dagor Engine - http://www.youtube.com/watch?v=Xd-dFUF3r2s
	- http://wiki.warthunder.com/index.php?title=Instructions_for_Using_the_Missions_Editor
	- http://wiki.warthunder.com/index.php?title=Location_editor
	- DETAIL TEXUTRES & DECALS - interesting warthunder location editor wiki page is how they can specify decal textures to TILES which is an interesting way since we dont have to tie them to any object at all.
		- instead we can render them after we've rendered terrain and/or structure and layer the decal on top.
		- note: detail textures can these be rendered in screenspace in a post shader?
- AI
	- npc.css script added to our robot MK1
	- OnUpdate() will manage an "AI State" blackboard object.  Look at our ViewController blackboard and do same thing.
	- we may wind up having to build a behavior tree from script during initialization
		- our NPC will simply move to a waypoint, wander, chase, etc... 
		- pathing status tracked in blackboard along with all ai state
		- AI vs AI - red vs blue testing 
		- integrate simple pathing initially that ignores obstacles and simply moves in 2D space
- Databases
	- i think at some point we will have to just create a test bed application using various databases to gauge performance
		- Volant - https://github.com/kjk/volante
		- https://dbreeze.codeplex.com/
		- RaptorDB - http://www.codeproject.com/Articles/316816/RaptorDB-The-Key-Value-Store-V     <-- this seems fast, but it has no in place memory store.  It is append only so the size of the db grows every change you make.  Maybe not so bad for certain uses... but for dynamic data of a real time app, seems bad... although you can compact the db.
		- BinaryRage - https://github.com/mchidk/BinaryRage  <-- this is really just a glorified file system.  each object is serialized to a unique file under specified path.  _IF_ KGB USED ONE FILE PER XML OBJECT and only put prefabs in zips and left the rest of the scene in files, we'd get probably solve performance issues related to writing our scenes too.  TODO: I should add flag to my saved scenes to compress or not which can only be set on creation.  This way our prefabs can use it but our full scenes do not.  Also flag for table per entity instead of the shared by entity types.  Moreover, an option to specify a subpath such as a Zone/Region...  erm that wont work i dont think?   how could we do that?  we could probably set an I/O flag on entities to create a subfolder but then we'd need to know how to traverse that during deserialization.  Otherwise the "shards" we could simply specify ourselves.  Our Pager would know the breakdown.
		

	
- God Rays
		// this site makes me understand godrays and why it's a 2d problem
		// http://xnauk-randomchaosblogarchive.blogspot.com/search?updated-max=2012-10-04T07:27:00-07:00&max-results=7&start=4&by-date=false
				
			// TODO: so these ModelLookup segments are currently specified by mModelLookupPaths 
			//       and perhaps those when loaded get added to a parent ModelSelector we add here so that
			//       Terrains, Structures (Walls, ceilings, floors) etc can all exist under same branch
			//       and perhaps their corresponding minimeshes are stored in a dictionary with a key so that
			//       they are easier to find during restore of layout and painting during runtime.
			//       But this is what we must do next... allow for runtime painting of a segment
			//       - in the short term, we dont care about logic for auto-tiling
			//		- we want brush
			//		- writing to correct layer/style.bmp (how do we know what type of segment we have?)
			//		- adding of the model lookup in the brush to the "modellookuppaths" custom property
			//		- how do we raise/lower terrain in a way that matches with our tile based design?
			//        - in FPSCreator, you have to raise/lower the frame of reference to build on adjacent layer (up or bottom)
			//			- but terrain should behave somewhat differently in that unless there is an interior system within it's bounds
			//            building up or down should act like adding more dirt or exscavating respectively.
			// TODO: We can automatically build up levels by simply "painting" terrain on top of other terrain
			//       and logically we know that we are sculpting upwards... but it might involve a keyboard command to raise lower
			//       the focus of the painting tool...  and to make it obvious what level the tool is on
			//       if our tool simply has a visual "Tile" box then we can see exactly where it is
			//      - instantiation of the DefaultAppearance object will assign the default shaderpath for loadtvresource.
			//			- this appearance should be able to load the proper type based on the Geometry...
			//          - and ideally, if geometry changes, to switch techniques
			//				- or if one shader instance could compile each type of shader for all DEFINE variants
			//              and assign the correct TVShader based on geometry and settings.
			// http://www.shawnhargreaves.com/hlsl_fragments/hlsl_fragments.html 	
			// http://msdn.microsoft.com/en-us/library/windows/desktop/bb509610%28v=vs.85%29.aspx	
			
precompiling shaders to asm and then adding those to our zip and loading them so our shader text is not available to users
"c:\e-tv.net\fxc\fxc.exe" /Tfx_2_0 /O1 /Vd/LD /nologo c:\e-tv.net\fxc\shader.fx /Fo c:\e-tv.net\fxc\shader.obj /Fec:\e-tv.net\fxc\error.txt
then load via TV.Glob.GetDataSourceFromMemory (p,data);
				
MUSC: http://luckylionstudios.com/royalty-free-video-game-music-library/

BUG: after adding items to Structure I think is not recursing them during picking... so we cant select them
BUG: Zones beyond shadow range should not be included in shadowmapping
BUG: i think there's issues inserting our zones into octree 
	- this seems to be why our zone's dont seem to render at all and why the frustum culling is borked initially to.
	and then once i move the camera forward/backward it seems to cause the udpate to finally propogate?
	- i think this is fixed now by forcing an initial minimesh.Render() call at end of MinimeshGeometry's LoadTVResource() UPDATE: well maybe kinda.  it seems to leave no more completely blank spots
	as long as camera is moving, but still on initial, there can be no updates to octree placement which must mean
	the boundingboxes are not right
	
BUG: issue with child array collection being modified at runtime when adding/remove children to scene
BUG: how can we page various layers of a zone and/or should we just make some layers invisible?
	- so we can see far away mountain but not trees and buildings on it
TODO: i'm thinnking i should totally get rid of flattened tileIDs and edgeIDs and strictly use
TODO: am not saving changes to the bitmap
TODO: - domainscript / auto-tiling script can disable shadow cast for interior tiles?
	- well those minimeshes wouldnt even have shadows enabled for them!  floor minimesh for instance woul RCV but not CAST shadow
TODO: - trying to place regular assets (not structures) into other zones seems to not work
			


- fix shadows 
	- flag objects as static or dynamic and get shadow buffers for them seperately
	http://udn.epicgames.com/Three/ShadowingReference.html#Per-object%20dynamic%20shadows
	- optimize shadows
		http://john-chapman-graphics.blogspot.com/2013/01/shadow-map-allocation.html
		- multiple lights
		- distance field shadows 
		https://docs.unrealengine.com/latest/INT/Engine/Rendering/LightingAndShadows/Shadows/index.html
		- static objects render to a shadow map 
		- dynamic objects that are .Moveable render to a seperate shadow map and then we 
		sample from both depth textures and use additive blending.
		- ambient occlusion can be done this way too for our landscapes and other static objects.
Lights
	- test multiple point light "torches"
	- adding multiple point lights to shader
	
	
Shaders
	- fog
	- zak's anistropic lighting models
	- terrain height based coloring DEFINE to shader
	- bloom
	- water
	- deferred
				// techniques - describe which vs and ps functions to call
			//		- they are usually used when you have to render objects multiple times but can't do it within multiple passes within the same shader
			//        because first you have to render other scene elements.   So in this way, techniques keep the code together
			//      - techniques are great when you don't want to have to track which shader is currently set on a mesh.  You know the one shader supports
			//        every technique it will need.
			//		- switching techniques is as expensive as switching shaders on gpu
			//		- using a ton of techniques is like using ubar shaders when instead it's better to
			//        use fragments
			//			- using techniques isn't too different than using DEFINES
			//		
			
			// use of Passes in shaders - planet shader with clouds and atmosphere added in as seperate passes
			//	- USE PASSES FOR HIGHLIGHT/OUTLINE effect as pass2
			// http://xnauk-randomchaosblogarchive.blogspot.com/2012/07/basic-hlsl-lighting-techniques-episode_3120.html
			// i wonder if there's any problem with using those passes when you might have entities flying inside the atmosphere
			// and now you can't control the order of the atmosphere transparcy to come after drawing the ship inside the atmosphere
			// still though, this example really defines for me what it means to use passes 
Paging
	pager LoadedStandby  enum option for areas we've paged in but dont wish to render til we are closer
	- superior to trying to override entity.Visible since that we want available for game specific scripting and not to be used by general engine entity management
	- i need to better make it so zones paging in and paging out are fully in/out before they can be reversed
	- minimeshes and all geometry must not be Render(), Update(), AdvanceCollide() while paging in/paging out.  
	- must not being to page out while we're rendering.  i dont know if there's any other way than to sychronize that

NPCs
	- NPCs can have spawn points in a zone, but the NPCs themselves are not to be saved with the Zone.  They must be manageable whilst their zones are paged out.  Thus NPCs are managed seperately and not even as full loaded entity's but as "digest" of NPCs.	
	-https://www.youtube.com/watch?v=yZ5wo-xmAyY
		- when you look at FPSCreator original version vs the new version they are making, they are sacrificing a simplicity of design that would allow them to do novel things in terms of NPC AI and NPC quantities and creating living worlds... in order to be a third rate generic FPS game maker.
		
BUILDINGS / FOOTPRINTS
	- building wall placements on a new data layer
	- we will stick with our row/column scheme and see how diagonals might fit in as a "half" row or "half column"
	for 32bit values (which we can do if we store our integers as floats and dont exceed 16777215 indices
	// http://cottonvibes.blogspot.com/2010/08/32bit-floats-integer-accuracy-and.html
	alternatively, we could store the "half rows and half colums" as starting at rowcount * columncount and then
	treating them as starting at index 0 from there once we subtract rowcount * columncount 
	this would still allow us to trivially know if the index was a diagonal and to trivially know which cell it was in.

	
BUG - make a test scenario where i can test the theory that TV3D is not updating shader semantics inbetween mesh renders when enabling/disabling lights such as we do when rendering different zones where we need to enable/disable
the different star point lights.	
	- is it only true if all lights are NOT managed.
	- we need a really small test scene where we can control the light radius
	- todo: this may also be a multithreading issue associated with LightEngine.SetLightPosition because .SetLight (data) works as an alt method of changing light translation.

FIXED. Entity translations that are SET by simulation update do not set change flags if the translation delta = Vector3d.Zero(). 	This eliminates unnnecessary bounding volume updates.
FIXED -  Shaders modification from plugin is something we've been lacking for some time.
BUG: - world shaders dont accept multiple stars pointlights

 BUG - when generating galaxy, stars, textures and other heavily recycled resources are created and then destroyed and are thus removed from repository but end up being re-created again.
 now for things like procedural textures this is fine, but not fine for things like domain object scripts.
	- timing out resources during generation could help, that is rather than auto removing on removeal of last reference, just wait til both last ref and x interval has passed.
		
IF we have these spatial "rooms" that help with spatial culling of visible cells
i think it should be something the CelledRegionNode does internally by itself and is independant of the actual CelledRegion entity.  However, perhaps there is then a way to cells[] results = CelledRegion.QueryVisibleCells or CelledRegion.DrawOverlay();

In the case of an Overlay HUD graphic for a tile, what i could do is on the render of the celled tile...
But, then that doesn't help with the overall bounds rendering snce if no tile is added then no overlay can be rendered.
 -mShowEditLayout vs mShowCellOverlay 
	- the one shows the entire available editable space (Edit Mode)
	      - can use just one mesh for each floor and tiled texture
	            - our shaders have to use tiled texturing?
	      - the other shows just an overlay over cells that are placed (Arcade Mode)
	      - what about the one that shows the various connnectivity too?
	          - like sim city electrical grid overlay?
	  
		 
 - we still need our overall sphere cull though to find nearby entities or lights.
 but once the item has started to use one of the fx, those temporary fx things can be
 monitored by the fx class instance and not then be added to the scene as entities?

rules validation
Entity.SetCustomPropertyValues ()  needs to return broken rules
        - the worker for setting the properties needs to send commandsuccess or commandfail.
			- if commandfail it needs to include the fail codes and return those.
	

=============================BEGIN
DEALING WITH TILE SEAMS
-----------------------------
CTF-Magma does have both visible lighting-difference and texture-coordinate seams between the mesh pieces.
Look real close at the areas where the paths meet the mountains, the mountains meet the base, etc.

You have a few options you can use to minimize the seams.

- Make sure that the area that you are splitting the meshes at has faces that are as close to identical 3d orientation. That way the lighting across the faces will be reasonably close. In other words, don't break the mesh where faces fall at sharp angles.

- Use complex textures. If you try using textures such as flat concretes, metals, or mech/tech style, the lighting differences on the seams will be more noticeable. Especially if you are using textures such as those found on Phobos or ShipTech etc. Earth style textures will hide the lighting differences between the meshes better.

- Keep your lighting quite bright and even across the map. You'll notice that Magma is not strong on shadows. Keep the ZoneInfo ZoneLight.AmbientBrightness quite high (15 to 20), which reduces shadows and dark spots. Note that AmbientBrightness pushes up the lighting (ie: reduces shadows) on SMeshes and Terrain faster than it does CSG.

- If you find that you have edge areas where the lighting differs a lot, you can sometimes place a Light actor right next to a SMesh vertex that is too dark, and set it to a very small light radius, just enough to force-light the vertex.

- If all else fails, you can reduce the brightness of Light/Sunlight actors, and use the SMesh's Display.AmbientGlow to push up the brightness of SMesh pieces. Because AmbientGlow is constant and not related to scene lighting, it always lights smesh pieces the same.

- If you are using Vertex-Blending on your SMeshes, also don't forget to set the Display.bUseDynamicLights to False.

TilePaint - Dig/Fill/Raise/Lower tool seemless functionality
---------------------------------------
- 

Hope some of this helps...
============================= END DEALING WITH TILE SEAMS
	
BUG - VERIFY MESH IMPORT (.X, .TVA, and .OBJ loader)  AFTER REFACTOR VIEWPOINTCONTROLLERS 
BuG - VERIFY PREVIEW WINDOW AFTER REFACTOR VIEWPOINTCONTROLLERS 
BUG - VERIFY COMPONENT HUD
BUG - Ability to switch from exterior free to exterior chase, to exterior fly 2 seemlessly.
	- switch viewpoints to that of a vehicle
		- this means vehicle should have it's ChaseViewpoint attached to it?
			- a viewpoint attached to as child to a Vehicle, but with inability for cloned to be serialized
			now should allow us to switch to various viewpoints of vehicles and worlds even?
			- or do we generate viewpoints on the fly rather than clone their existing copies?
			
FIXED - Fly2 animation should now cause Behavior Tree updates to viewpoint to suspend and then unsuspend when completed playing.
	- fly2 animation creation and control is now handled by behavior tree.
	- a EntityInput of "play" "flyto" input is created in order to start the behavior tree on creating the animation frames and initializing play as well as responding to finished event?
BUG - fly-to towards a fast moving object will not update target position in real-time so the fast mover won't be where we flew to.
BUG - cant go back to freelook after using "fly to"
BUG - add a velocity and acceleration indicators to our shipexterior
BUG - add velocity changer as +/- somewhere to speed things up (throttle notch bar)
	- http://www.sssim.com/en/product/studio/manual/basic_6.html
	http://www.youtube.com/watch?v=7THAkFD8o6E
	http://www.youtube.com/watch?v=zqaMlKf9lDA&list=PLD7ED780492E5486A <-Geocentric model of the solar system, demonstrating the celestial sphere and epicycles.
	- MLP3D is nice!
	- kerbal too http://www.youtube.com/watch?v=x_9KWsgdafI&list=PLINugROHWPal0SMS85Y4wRwdObcI2GtPM
		- kerbal uses a menu that even allows you to select engines from exterior and shows menu of options as well as list some data
		- so lets go the menu route
BUG - Digest / Starfield
	- our procedurla helper temp starfield, we should generate names for each as we do our 
	procedural systems, and then allow click to show that in the html side for the star we've picked to
	verify our picking actually works.
	- also shoudl render labels for each at correct spot		
BUG - move motion field adding to the scene to our exterior HUD and make sure it gets unloaded during 
      workspace switching
	  - motion field position updates can/should be done in a shader.  Seems too expensive to be moving tv vertices around.  That said, it also means that we can't use pointsprite mesh because i dont think shader works with those under tv.
BUG - our overlay tile placement grids are always drawn at origin and if the users ship is not there it's off?
      no that cant be true because ship is not placed at origin.... im not sure why its off since the Viewpoint refactor.
BUG - we are not responding to all cases for mScene.NodeResized()
	- proxy nodes are being added to mChangedNodes and it should be pointing to the referenced entities instead.
	- need to verify that child and parent nodes in entity hierarchy gets treated independantly as far as their octree position is concerned. Indeed spatial graph should not care at all about entity hierarchies.
	FIXED - need to stop using flags like .Scaled and .Rotated and such in multiple spots.  ChangeState.EntityMoved, 
	ChangeState.EntityResized should be used instead if that is what im really interested in notifying the scene of


BUG	- navigation circular halo graphic/hud control for choosing heading?
BUG	- yaw/pitch/roll indicators for manual docking
		- this way we choose the angles we want and allow ship AI to compute how long to fire to get us to that orientation
BUG - we need to profile cpu use from octree octants being created/destroyed and entitynodes moved as for example, worlds orbit. also even just the EntityNode moved and octree bounds test even if within same octant we need profile info

	

NOTE: in the below, as an item is finally added to a particular linkd list, there the instancing is checked
and determinination is made which mesh, and such.  We also solve the issue of single minimesh hosting items from different zones!  Within each "Mesh" we can now AddInstance and supply a special bucket code to use.

		
Entity - Mount Child Entity <-- allows you to then mount and place a child entity
- do we use Update() in script to update switch flags?  For example in Update() { if (damage <= .1) SetSwitchParam (none) elseif damage <= .4 SetSwitchCustomParam(lightDamage) else if ... >= 1.00 SetSwitchParam(destroyed)}
	- fxproviders have to be per view too 

			"A single shot"
	http://board.dailyflix.net/index.php?/topic/81709-a-single-shot-2013/
	
	"Save Haven"
	http://board.dailyflix.net/index.php?/topic/63541-safe-haven-2013/
	

	
PICKER
-------
- bug: Our reactor prefab has a 90 degree z rotation assigned to the Model.  This rotation is not being included in the mouse picking calculation.  If we remove that rotation we then get perfect picking.
	-otherwise the picking seems to work perfectly.  
	- perhaps the following bug listed below of setting mesh to identiy is part of the problem?  It's not just loss of scale its loss of rotation.
- BUG: I set meshes to identity and then i do model space picking on them, however what i should be doing is setting them to 0,0,0 origin not identity because that changes the scale right?  or are we properly transforming the ray too first?
- BUG: I dont think scaling of models is taken into affect on Picker.cs	
- in floorplan view, the pickparameters should be set so as to only allow picking of interior items?  (although what about exterior hardpoint placement?)
- picking is off in some of the exterior isometric views (not sure if it's light entity interfering, lack of pick sorting, sort order)


HARDPOINTS - WEAPONS, ENGINES, THRUSTERS, and then 
=========================================================================================
- for each Weapon, Engine, Thruster, etc, those have their own mount points for FX such as engine glows
	muzzle flashes, emitter locations, etc.
- hardpoint concept from M.A.V
	- http://www.youtube.com/watch?v=1hX8aK7YhxE
	- http://www.bombdogstudios.com/
	- this M.A.V concept is great really.  Hardpoints will get exposed from interior to exterior
	and user can then snap items that can be attached to hardpoints to them and the alignment is done for the user.
	     - only the modder must care to make sure that items attached to hardpoints align properly to that hardpoint.
		 
- hardpoint concept from Kinetic Void
	- http://www.youtube.com/watch?v=bBN5OPJw6T4&context=C4045425ADvjVQa1PpcFN6LEqOKGauu9xI_hxaymOxY30EPhfONg4=
	- what i could do is define the hardpoints from the interior of the ship as helper cubes that dont render during game only ship design.  These are placed on the interior and will then be visible on the exterior to where you can place things.  This ensures that the engines and guns and such are properly placed on the outside.
	And they can also be exported as .obj scene so that you can build your exterior model around it properly.
	The hardpoints will be flexible enough in that they can be lengthened but not shortened so that they can protrude outward enough depending on the exterior hull shape you model.
	
Engines/Thrusters/Hardpoints
http://www.web3d.org/wiki/index.php/About_the_X3D/VRML_ROUTE_statement
----------------------------
Interior
	-> has a custom property category "link" or why not make it a 
	real property?  Animations already have it..  
	
Somewhere, our game must enforce that either a Vehicle has hardpoints which an interior can assign to
or the interior creates hardpoint registering associations which then exterior entities can be bound to.
I like the later more because it doesnt pressupose any specific quantities that will be made available for interior. Instead, it allows arbitrary interior components which then when in exterior view, are visible through the Vehicle.Hardpoints[] list.
	- so what is a hardpoint?  Is it an entity?  Is it some composite member of a Vehicle?
      is it just some custom property value that references an interior item "owner/source/provider" and an exterior item "target/attached"?
	  - when an interior item has a hardpoint, perhaps it just specifies it in it's own custom property
	  then the vehicle can handle the registeration.  Likewise, when the child is removed, the vehicle
	  can handle removal as well as removal of any linked exterior items... in fact, it can even
	  cause exterior items to "fall off" at runtime and become debris.
	  - the hardpoint itself can be considered a ROUTE/ROUTER/ROUTING/BRIDGE/LINK object.  Its similar
		to a portal only it has no space, it's purely a logical association and in our case its managed
		entirely by a Vehicle as the only things that need to know how hardpoints work are 
		1) the interior component that has a hardpoint
		2) the vehicle
		3) the exterior editor - must be able to show hardpoints.  How does that happen if hardpoints are purely virtual and dont have an exterior representation?
			- it might require that "links" between entities where an entity can be attached to either end are known KGB node types.  Neverdaunt8bit calls them tronics or something.
			They aren't perhaps too disimilar from a physics "joint" except here the linkage has a different meaning.
		how would we restore links from saved data?
			- answering this can help us design them.
			all links are non shareable and have a source and a target entity or entityID.
			if link naming scheme is done properly, we might be able to restore a link by just having Link Source" and "Link Target" properties where target entity refers to the source id.
			- the thinking is if a link is a logical component of entities tronics in neverdaunt are interesting.  they various entities are like flow chart nodes taht declare various inputs and outputs and which can be linked together.
			- one cool aspect is, if we had "exterior output" vs "interior output" and such
			and making this aspect of entities inherit to KGB and not app specific, then our editor
			could deal with them.
			custom properties vs "input" and "outputs" can just be a type of CATEGORY (x3d refers to them as "AccessTypes" custom property that KGB can look for when entities are inserted into the scene.
				- routes in x3d specify event->target->target property 
			- how are links restored is key.  In our animation manager, we use friendly names within
			the entity, here we would need to use entity IDs so dragging drop style connections is best
			but, 


	
16) Pods can be added as exterior assemblies to the main Vehicle and a special "bridge" cell(s) must
exist to connect the two.  In other words, a pod connects not fully like a superstructure but instead by a pod hardpoint.  Once connected, they can be seen in the interior.
3) 	- a "skirt" that connects the 2 dimensions celled grid meshes at holes between the two and along the edges.
			- skirt can be a single generated mesh for each continguous hole
			- skirt can be one seperate minimesh quad for every one cell length edge of the skirt
			- skirt is purely cosmetic and is not an entity, but does need to be "managed" at design time especially as hole configurations are modified.
				- if skirts are stored as models under modelsequence as "skirts" or some such, the question is 	how do we associate each skirt model index with it's corresponding "hole"

Thruster				
Hardpoint -> vehicle queries added component for hardpoint property

	 http://www.newerth.com/wiki/index.php/XR_Map_Triggers
     http://game-engine.visual3d.net/wiki/entity-creation-models-prefabs-avatars-and-entity-types
     - in the visual3d implementation, a trigger is added as a child to an entity
    in order to associate it (just drag and drop the trigger onto it)
    http://unity3d.com/support/documentation/Components/class-CapsuleCollider.html
     - i like how in unity3d, their colliders can be flagged as triggers which
     tells the physics engine to ignroe them as collision objects that need physics reaction calcs
    but to still notify the app that something has entered the trigger volume of that collider
    Contrast to Unreal where triggers are seperate Entities.  Hrm...
	
Exhaust plumes - i noticed in oolite that rather than jedi sword vibrate the plumes, you can also flicker/module their transparency and brightness of the inner and outer plumes as another form of animation to make them look alive


=======================================================================================================
Tactical / Nav map and waypoint plotting! (SOLVES MY 3D NAV/TACTICAL/HELM DESIGN ISSUES!!!) http://www.freeworlds-tow.net/dev/
=======================================================================================================
http://www.youtube.com/watch?v=_QfsYIvJ8pY  <-- watch this from the freeworlds 2.0 vid 
http://www.freeworlds-tow.net/dev/


Animation Controller
----------------------------------------------------------
we have keyframe animations sure
we have interpolation animations that are assigned to Transforms\Transforable dervived classes.
	
IMPORTANT: Since ultimatley our physics and animations that modify our Entities, maybe 
we dont want them to direclty edit Entity properties and even they must go through SetProperties(Spec[] specs)

If this is the case, we do not want our Animations to directly modify Entities potentially either?
They too much be a changeProperty request perhaps?

Track
	Animation {name = "run", sequenceStyle = AnimSequence_Sequential; } 
		KeyFrameSequences[] // a collection of 
			// only one sequence for "diffuse" or "translation" or "rotation" allowed.
			KeyFrameSequence { T[] mKeyFrames; }
		
	AnimationSequence {name = "climb ladder", sequenceStyle = AnimSequence_Sequential;}
		KeyFrameAnimation[] Animations; {0 = BonedAnimation_Climb, 1 = Y Axis Translation Up}
			KeyFrameAnimation {T[] mKeyFrames; }
				// BonedAnimation <-- derived from KeyFrameAnimation
				// InterpolatedAnimation <-- derived from KeyFrameAnimation
Track	<-- this is now problematic because
			the purpose of a track is to track every animation clip's progress
			and this cannot be done if a track hosts an animation that in turn hosts
			a collection of clips.
				- I suppose all clips in a single animation cannot loop until all are finished.
				- in this way, one track could work, however it still needs the ability
				to control every clip that is ultimately hosted by the track.
Entity 	
	AnimationController
		Track <-- used by AnimationController
	Animation[] <-- i should then combine Track and Animation
		AnimationClip[]
		BonedAnimationClip
		InterpolatedAnimationClip

	how do you create an Animation for a sub-model?
	Well model animations can be referenced in the overall Entity.AnimationController via the model's friendly name such as "Left blast Door" with the animation name followed by @Close 
	
	So this way we always have unique animation naming in the AnimationController... and also an easy way for scripts to call animations
	So our Plugin for animations needs to assign Animations to the Model, not the Entity directly UNLESS it's an animation that is a sequence of animations made up from it's child models.
	we can easily animate a door closing initially using a rotation interpolator using an offset
	and coordinating that with any other related models having their animation played at the same time...
	Unless we can find a way to group those in the AnimationController to get them playing at same time...
	
-----------------------------------------------------------------------------------------
Model Hierarchy Notes (<-- don't edit this header. search string specified in Model.cs
-----------------------------------------------------------------------------------------
    // todo: we really should enforce that underlying Mesh3d (TVMesh) and Actor3d (TVActor) have to have an identy matrix.
    //       This translates into ModelBase not being allowed to have a local Matrix either.  The entity is always the top level
    //       WorldMatrix to use and thus never any issue of having to do any matrix multiply. This is really the sane way to go.
    //       Entities are really our model (model as in Model View Controller) and the model is just for grouping LOD and such
    // 
	            // like Entities, Model's cannot be shared.  This is because different appearances
            // on one mesh off the Model's hierarchy will result in all Model's that share the
            // Model instance to have that change regardless if it's what we intend.  
            // This makes it too unweidly to use.  Instead we will endeavor to make Model
            // lightweight.
			
			// only Entities have option of not inheriting scale.
            // Models and ModelSwitches MUST inherit because whenever
            // user scales Entity, they mean to scale the models it contains
            // otherwise there is nothing to scale!
            // If they wish for per-model-level scaling, then they can
            // still scale those additionally independantly at their local
            // matrices, but otherwise Models and ModelSelectors always inherit
			
    //     1) Models are NOT SHAREABLE and thus CAN contain instance data. This makes sense because
    //     it is unreasonable to change one appearance under one model instance because it woudl require
    //     the entire Model be cloned.  
    //     2) Models can NOT contain child Models of their own  (only switches lods sequences can)
    //          - this is great because we know once we've reached a Model node, there is no further to recurse.
    //     3) Models can NOT contain child LOD or Switches / Sequences  (only switches lods sequences can)
    //          - this is great because now we know that only Entities can contain a single lod/switch/sequence node
    //            and only those lod/switch/sequences can contain other lod/switch/sequences.
    //            Model's themselves can only ever hold geometry and appearance.
    //
    //     Model (tank body)
    //          Mesh3d
    //          Appearance
    //	          Material
    //  		  Shader
	//			  Layers[n]
    //                  Texture
    //     ModelLOD
    //         Model  TankBodyHighResolution
    //          Mesh3d
    //          Appearance
    //               Shader
    //               Material
    //               Layers[n]
	//                     Texture
    //         Model  TankBodyLowestResolution
    //          Billboard
    //          Appearance
    //               Shader
    //               Material
    //               Layers[0]
	//                     Texture
    // 
    //    ModelSelector // selects child based on damage level
    //              ModelLOD  - Undamaged Model
    //                  Model - HighRes Undamaged
    //                  Model - LowRes Undamaged
    //              ModelLOD - Heavy Damage Model
    //                  Model - HighRes Damaged
    //                       Appearance
    //                  Model - HighRes Undamaged
    //                       Appearance
    //

    // They always "select" a current child at runtime, they never retain that info.
    //   So in this sense Appearance and TextureSet's work fine although i think for LOD geometry, when we add the Appearance
    //  and Apply it to a Model, all children should have their geometries updated to use that mesh because otherwise
    //  you can switch lod's at runtime and end up with no texture or materials set on it.
    //
    //   So in this sense, this is our hybrid SceneGraph / Resource sharing scheme that is better than TV3D in the sense that
    //   its easier to setup complicated LOD and appearance child hierarchies.  

    // todo: DamageLODSwitch - in addition to hosting LODswitch, it should be able to host a DamagedSwitch 
    // It's trivial to implement because all we do is pass the entity to  Model.Render (entityInstance)  and then
    // internally in Model.Render () we already start with any LOD selection and thus LOD's should select
    // themselves based on the Entity as well and if a particular LOD is a DamageLOD, it will lookup the 
    // Entity.Damage  value first!  Damange percentage can be 0-1.0f and be like KEYFRAMES (potentially even tweening between)
    //       and have it return the proper geometry to render based on that.  DamageSwitch can also contain a LODSwitch for LOD versions of damage.
    //       Model shoudl also be able to generate LOD's for us.  They will be retained here though since they are not seperate "resources" 
    //       and cannot be directly got from the repository

    //
    // WHY COMPOSITE MODELS SUCH AS MODELS DIRECLTY UNDERNEATH MODELS ARE PROBLEMATIC AND WHY
    // INSTEAD I THINK COMPOSITE ENTITIES ARE BETTER...
    // - The primary concept is that only Entities need "instance" data that is unique for each occurrence.  If a model can be shared
    //    then it can never hold any instance data.  So if you had hierarchical models under models directly, then the entity ultimately
    //    has to have seperate instance data for each model that it ultimately is responsible for.  So then the question becomes
    //    Why not just have composite entities to retain the data for 1:1 entity:model and then parent entities only need know how
    //    to control child entities and can lookup the values of any retained values from it rather than do it, itself.  

    // NOTE: MOdels do have position, rotation and scale which allow you to alter the modelspace position of the underlying mesh
    //           For instance, let's say the center of the mesh is 0,0,0 and you want it to be at 0,-10,0 to put the bottom of the mesh
    //           on the floor.  Or maybe the model faces the wrong direction by default, you can apply a rotation to get it facing
    //           The right way.  Naturally all instances of the model are affected which is usually desireable.

    // Perhaps in addition to Appearance, models will handle some audio as it relates to what should be played
    // when the entity is hit and queries the model for Model.Hit (this, intensity, location)
    // or even Model.Destroy (this, weapontype, intensity, location).

    // Perhaps now even physics material properties and collision skin (model space) goes onto the Model whereas the physics instanced data is still in
    // The entity.  Then we have Entity.Model.Physics.PhysicsMaterial , Entity.Model.Physics.CollisionSkin
    // and the entity can easily query those details.  The Entity.PhysicsBody node is initialized with the model's physics data.
    // The only complication is in joints for complex entities.  If there's a joint connecting say the Turret Model with the Tank Body Model
    // in our treeview, perhaps the joint is shown with body Models underneat it?  Entity.Joint.TurretModel + Entity.Joint.TurretBody?
    // Hrm.. 
    // ToDO: Maybe DynamicModel : ModelBase  is one that can be influenced by physics contrary to StaticModel : ModelBase
    //           Actually no, all we'd neeed is a Physics property that contains the physical statistics that an Entity can use for
    //           simulating the physics, but otherwise the ModelBase either may or may not have a Physics data associated with it.

    // The way we handle Appearance is at runtime, we check the "Appearance" first
    // and puth that onto the traversal's Appearnce stack.  Then as we encounter Models that dont have one, those are
    // the appearances we use.  Then when we render, we only update the teture/materials on the Geometry
    // if the appearance values set on it are not the same as the existing.
    // NOTE: we have to use this runtime traversal method of checking because we cannot rely on IsDirty because the underlying
    // Geometry can still have been changed by some other Appearance.  When this happens the Geometry gets changed
    // but any other Appearance doesnt and the only way it can know to change the value is if it checks the values
    // prior to rendering.  

    //bool IsPickable { get;set;} // with respect to picking, if this is set, then contained Model or Geometry's
    //                            // can be picked.
    //bool PickPreview { get; set;}  // when true, when a child is picked the overall entity is returned as the result
    //                               // and not the individual child.  In this way you can pick a tank's turret yet
    //                               // still return the overall Tank Model.
    //                                // If pickPreview = false then we return just the exact mesh that was picked.
    //                                // NOTE: If you have just the end mesh, then its easy to recurse up to find the parent
    //                                // IModel object since an IModel can only ever have one non shared IModel 
    //                                // parent unlike Mesh3d which is a resource and can have multiple parents.
    //                                // NOTE:  This does in fact mean you arent going to ever return just the simple Mesh
    //                                // because that isnt an entity per se, its just a resource like a texture.  Only the
    //                                // IModel is pickable.
    //                                // The real question is maybe the Pick object should deal with these sorts of thing?
    //                                // I mean not the IsPickable, i think thats valid... but in terms of what to return.
    //                                // There's which Model, then there's whether its simple hit/miss or also return the triangle

Voxel Brush for Reactors, Engines, Marching Cubes
=========================================================================================
We would still be able to enforce footprints, and the reactor entity would still be a single entity and the brush
is for shaping it's visual and it's volume/surface area which we can use to recompute other stats.  
	- requires a library of lego pieces with which to build up the mesh
		- can have rounded pieces, bevels, etc
	- Marching cubes implementation to turn scalar/voxel data sets into 3D meshes, complete with tangents, ambient occlusion, and colliders.
		- implement this in TV mesh
		- maybe we can have multiple temp meshes that have various number of verts and use those to
		make realtime editing really fast.  Then when not in edit mode, convert those meshes to real ones.
		- E:\dev\c#\Transvoxel-XNA-master    <--  ooooh! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!<------
			- cant compile and run because it uses 4.0 and task parallel extension
			- http://www.synapsegaming.com/cfs-filesystemfile.ashx/__key/CommunityServer.Discussions.Components.Files/29/3036.voxnorm.png
		- http://www.youtube.com/watch?v=Eh_6WlEtgyI
			- E:\dev\c#\Voxel Model Editor 0.3b
	- Texturing can be very similar to what we do now with texture atlases where each face of each
	cube is given a texture in an atlas to use and since the faces are so small, we can have many tiles on each texture.
		- and we can generate the texture by allowing user to paint the faces manually... initially with just per face resolution but eventually
		with 16x16 up to 64x64 per face.  
			- these must create a pallette of up to say 256 sub-textures.
			- actually with a 256x256 pallette, we can have 1024 colors and use those
			http://www.youtube.com/watch?v=pTWenv6JrZY
	
	
CRYSIS FOAMY WAVES
============================================================================
The easiest way to make beach foam without any additional modeling and/or complex vertex manipulation is to do it the way Crysis does it...all it really needs is a full-scene depth map.. which most modern renderers already do anyway.

I do it this way in my own renderer:

I calculate an absolute depth for the ocean floor...I do it reconstructing the pixel position in world space from a previously rendered depth map (methods of reconstructing depth have been discussed at length in the graphics forum). Then, once you have world position, you simply find the length from the y postion to the water height.

Ince you know the depth, its easy to create value between 0-1 form the shallowest area to a given depth. Then you use that value to lerp in some foam texture.

For my foam i use an animated noise texture with an alpha mask, but you could use anything..i just lerp it like this:

watersurface.rgb=(watersurface.rgb,foam.rgb,shorevalue*foam.a); (this assumes that the shallowest area is 1.0f).

This doesnt look perfect in all cases..sometimes in cases of depth discontinuity you get a sharp cutoff from an area of foam to an area of no foam.
I think that's acceptable given the ease of implementation. 

============================================================================
BEGIN INTERIOR
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
BEGIN INTERIOR
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
BEGIN INTERIOR
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
BEGIN INTERIOR
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
BEGIN INTERIOR
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
BEGIN INTERIOR
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
============================================================================
BEGIN INTERIOR
============================================================================
=================================================
BEGIN INTERIOR
	
Rodina - interior deckplan builder
http://www.youtube.com/watch?feature=player_detailpage&v=f4aeVMaUWng#t=20s

Deck Plan Edit NOTE
----------------------
The Sims and First Person Shooter Creator simplicity is key.
(Marketing ad slogan - "Lovingly craft capitol ships"
http://msmvps.com/cfs-filesystemfile.ashx/__key/CommunityServer.Blogs.Components.WeblogFiles/valentin.Arcane.Esquisse/6886.test.png
i also saved above image in KeystoneGameBlocks  root path.
Notice the floating tool windows along the left?   The top brush one kinda looks like a nice way to implement a deck selection panel, both for editing decks and switching between them during arcade runtime

- in startrek tng, they have different lighting on the bridge to correlate with daytime and nighttime.  i like it.

DECKPLAN BUILDING  --  AMAZING GUI DESIGN!!!!
----------------------
E:\creative\Specs_All\3d - Deck Builder\computer_schematic_linernet.gif  
i found the above EXCELLENT graphic at 
http://www.geocities.com/starfrontiers/starships/linernet.gif
http://www.geocities.com/starfrontiers/starships/sfships.html

This of course can be replicated for all schematics for control including power and weapon controls/links!!!

Hell, it might even help for crew schedules.

I'm so glad i found this.  

I'd also like to be able to print out generated cross sections of computers such as
file:///E:/creative/Specs_All/3d%20-%20Deck%20Builder/agshipinfo.gif
file:///E:/creative/Specs_All/3d%20-%20Deck%20Builder/glennainfo.gif
VEHICLE EXTERIOR EDITOR
	- this should use same orbit / arcball camera used by nav view!
		- now with the user's exterior ship fixed, we can put up a 4 view potentially and allow
		player to select a prefab asset browser item
			- hardpoint
			- thrust plume
			- turret
			

=======================================================================================================
SEGMENTS
=======================================================================================================
\pool\FPSCreator_Data\meshbank\scifi\moonbase\corridors\service_corridor\wall_a.x
texture = column_d.tga
	
segment designer panel   
http://openpipeline.cc/tutorials/assets-master-files-and-master-scripts/

	- ModelSelector - so now that we have a ModelSelector with child flags and we have the ability to dynamically have the Wall script set the enabled children flags for it's ModelSelector, all we need is to send an event to any wall entity when it is placed, or when it's adjacent wall has changed (added/removed or different segment enabled) and this will trigger a fairly tidy automatic update. 
		- this can be disabled when not in edit mode.
		- if ModelSelector flags are set, we should gray out changing of those flags in child Model in the plugin, and disallow command to change it as well if ModelSelector's flags are set.  In other words, parent flags trump child flags? 
	- ModelSegementSelector
		- here the idea is that based on which floor models neighbor each other within a given "room", the correct neighboring wall or tile is automatically selected.
		- thus designing walls and floors means designing the segment selection logic.
	- semgent_ALL.x - selected when there is no wall above or below 
	- segment_UP.x - selected when this wall is stacked on one below when 
	                 there is no floor seperation between the upper and lower decks
	- segment_DOWN.x - selected when this wall is stacked beneath one above when there is no floor seperation between the upper and lower decks.
	- segment_MID.x - selected as middle wall when there is no seperation between 2 decks.
	- segment_CORNER.x - allows us to fill in the gaps where walls meet at the corner
	- segment_CURVED.x - this covers two adjacent wall edges in a single cell.
	
	- segment_EXT.x - this is custom for our purposes where no double wall models are used but rather a single model for exterior walls.
	- diagonal walls
- curved walls
- a way to edit ceilings
	- i think ceilings should be automatically placed when placing a tile.  A ceiling is only to be removed when the user moves up a floor and explicitly deletes the floor.
		- ceiling is just a double sided to a floor.  Entity wise, ceiling and floor is the same entity with two models. One floor and one ceiling.
		- ceilings can be edited when designing a "segment"
- segments
	- a way to edit all partitions appearance without modifying their domain object
	- a quick way to view the armor strength of any partition.
		- perhaps some type of view when a cell is selected all of it's partitions are shown with their main armor data
		- maybe having a hud text number appear to show the hitpoints/pass defense of every partition
		when that toggle is enabled.
segment / wall / floor creation
	- our policy is that all walls are ALWAYS created automatically for the user... adjoining of walls is done automatically.
	- but also consider that portals dont apply until you're in first person... from top down deckplan view they just dont apply and the idea is that when top down the LOD drops significantly.
		- thus quadtree is necessary and limits perhaps on camera angle (limit to iso perspective and limit height above a floor but don't limit rotation angle)

		- cannot move components after being placed
		- architectural rules testing
			- height clearance
		- need hud alignment indicators to make it easier to align components to others
		- what happens when a wall is deleted where there's already a door?
			- how do you prevent halfheight walls from being deleted before the door is deleted?
		- rotated component on subsequent placement should retain rotation instantly
		- copy of an existing component should load it with that copied rotation so placing components is easier
		- FIXEd. exterior ship rotation "front" needs to face +Z
		FIXED - delete of walls not working
		FIXED - component placement not invalidating from walls
		FIXED - component placement not invalidating from no floor to sit on
		FIXED - we collapse boundaries but can we collapse floors?
		- how do we deal with full height/half height floors?
			- walls should be auto selecting just based on whether the floor itself is designated half / full
				- but how does that impact floor level selection and rendering?
					- we should still render current floor and floors that are visible beneath it
		- hack menu item in footprint editor to replace all flagged tiles with a differnet flag value
	
Ship Interior (postponed feature - focus on First In aspects instead)
	- diagonal walls this time from the start
	- build upon our new map grid tile system

Animations:
        // how might i store the data for animating a turret on a space ship?
        // Let's say that we have an EntityShip and an EntityTurret
        // and Turret has two Animations "rotate" and "elevate"
        // with min/max horizontal angles and min/max verticle elevation angle.
        // And a max speed which can be modified by damage percentage or even increased by
        // bonus mods (all computed in script)
        // Now since our targetting is technically computed by the server
        // client side our scripts may be more geared towards just visual approximation
        // but server side we can still be much more accurate on computing hits... that is
        // we can simulate at least in part by first making sure the target is in an approximate
        // cone based on direction of turret.
        // and then apply mods (operator bonus, software bonus, distance, etc) to compute success.
        // Still, how do we tie the turret's animations to the Entity's behavior tree?
        // In a sense, we should think of the turret as being operated and running it's own tree
        // essentially independant from the Vehicle.  It's not the Vehicle that runs the turrets
        // it's the Turret's own behavior tree who's scripts accept as input various variables
        // relating to the ship it's on, it's damage, whether it has power, it's operator (ccrew member
        // software or both) and such.

        // So to any extent the ShipEntity contorls the turret, it's only in the form of the shipEntity
        // maybe iterating thru it's children and calling childEntity[i].Perform(context, elapsed);
        // 
        // The state of an animation should be independant of the animation data.  Unfortunatley tv
        // doesn't do this for it's actors really.  But it doesn't amtter cuz our Animation.cs nodes
        // only contain data about the animation itself.
Planet Rendering	
		- TODO: BUG: I need an if/else to use large frustum vs small frustum.  Currently ive disabled large frustum and left no way to dynamically select which way of culling to use.
		
Enemy Bases \ Exterior Structures
	- tile construction set
	- saveable and restorable upon load
	
BUG: why is shader being created for each zone paged in?  
	- this should be shared use of the InstancedGeometry PSSM.fx file
	- THIS COULD EFFECT SELF SHADOWING OF TERRAIN IF PSSM DOES NOT CONTAIN THE SAME ONE, however it's using GEOMETRY #define and not INSTANCEDGEOMETRY #define so not sure what's going on really.
	
Particle Systems
	- PLAN - just as with TV3D, we will make each particle system seperate.  They can share IndexedGeometry because
	the AddInstance() method will update the positions each frame?
	
	- increasingly the answer seems to be PER ZONE particle systems.  It assists in threading as well.
		- #1 so how do we instantiate a HeavyParticleEmitter (or HeavyParticleEffect) from script and to all relevant zones.
		- #2 how do we handle boundary crossing
			- does the emitter cross or does the entire HeavyParticleEffect get cloned and crosses?
			- treating the effect like a full entity perhaps, normal boundary crossing checks and then
			we need to share the rendering of the instancedGeometry somehow... or else there's little point in
			using instancedGeometry.  We could just use seperate geometry elements.
		- #3 some particles we want as hierarchical and not direct child of Zone... 
			- and these we still potentially want them emitting (production) such as heat damage and such
		
		// indeed, what if a the particle system is a child entity that is spawned
		// when our entity script initializes(), and is owned by that entity
		// who can command to emit more particles as it "fires" weapons and such
		// or as it receives damage.  The particles are always rendered relative
		// to it's owner.
		// i dunno...  having them all as a single laser system makes it faster to 
		// update their positions and do collisions all at once...  can even do
		// laser 2 laser collisions to cancel out "bullets"...  the main problem 
		// is the zones and tracking a particles position as it crosses boundaries
		
		// what is the simplest solution?  The simplest I think is to make each particle system (effect)
		// instance seperate and allow them to be parented to other entities and to traverse across zones.
		// And the emitters and particles are inherent to the System. Emitters and particles are not
		// derived from entity.  Effects can cross zone boundaries, emitters and particles do not.
		// These entities are a type of pooled resource... so they can be instantiated quickly.
		//	- they are shared by name used in script?
		
		// TODO: does the IEntitySystem get added to Root?  perhaps for now yes...
		// TODO: ideally we want it added to camera's region, but this makes the system dependant
		// on each viewport that is open doesn't it?   The only truly indepednant way is for per region particle systems and where the underlying renderer is shared?  
		// TODO: what if the effect is per region?  we would for instance find the region of the entity that is emitting the particle and use that... ok two issues there
		//       for each zone it's too many? and then if just for some eg 3x3 zone bubble around camera, then
		//       we have problem of lasers crossing into areas where they shouldhit something but cant because that zone is beyond our 3x3 bubble.
		//       What we are doing with InstancedGeometry now is treating that instanced Geometry as a full fledged Geometry of a Model that is child of our Structure entity.
		//       With one entity as an entire particle system manager, we have issues of precision away from origin...
		//       but not if rendering in camera space... right? but rendering in camera space is not same as tracking actual laser positions in region space
		//       Can we have one effect for lasers, using different textures and different dimensions of lasers (using lookup texture for instance) 
		//       but then again, tracking their world positions is problematic... with Structure's and tiles, it's 1:1 and i suspect if we don't worry about (for now 1.0)
		//       having simulation of entities that are in zones that are not loaded, then this way can work.  So perhaps for short term
		//       we simply replace the laser effect as is, with the InstancedGeometry and don't worry about anything else... just get it working.
		
		    
    // I think i prefer minimeshes
	// TODO: HOWEVER - what if we want to use Receptrons and Emitters and for lasers
	//       when colliding with target, are responded to by the Receptrons on the Entity.
	//       TODO: consider how gravity is produced by a celestial body and consumed by a Vehicle.
	//       KeyCommon\Simulation\EnergySim.cs
	//       KeyEdit\Simulation\Simulation.cs <-- note how entities register an emitter and receiver?
	//                                            So for lasers, an entity should register a new emission
	//                                            and then allow the game simulation to handle collision
	//                                            tests and consumption by receptrons on receiving entities.
	

	// TODO: to be able to handle region boundaries, what if each particle system
	//       was specific to a given region the same way vegetation and structures are?
	//       then, we can do simple bounds tests of lasers position (with a laser's position always
	//       being it's leading edge like the tip of the sword)
	// TODO: kind of makes us think, for physical based particles that have collisions, we should
	//       just use entities and a single billboard mesh since all boundary crossing gets handled for us
	//       but if we want to have many and that is overkill...
	//       - but the old way of dealing with particles is the way we describe... the "new" way of
	//       batching, deals with movement, collisions, rendering as batches.  
	//       Our star digest when dealing with positions uses global positions, but the problem there of course is
	//       the precision but stars for stardigest do not need high precision.  Lasers/particles do.
	
	
		
	- zone boundaries - this must be considered from start
		- simulation of zones' particles versus rendering of those particle systems
			- in Runescape you can see that zones are being simulated even before rendering
				so particles should be seperated from their rendering as well.
	- particles spawned via Script is good because it allows us to put gameplay 
		per NPC type into compartmentalized scripts.
	
	- are all particles treated equally?  "heavy" particles vs "light" particles
	- i need to come up with a decision here and implement this...
		- what is a particle, particle emitter, particle system and how do they relate to zones
		and how do they relate to fast moving objects they should be hierarchically associated with
		- normally a particle system is fire & forget and each set of emitters can be part of a seperate EFFECT
		system and then attached TV3D style hierarchically. 
			- but we additionally want a particle to be able to influence the simulation such as with heat, explosive damage/shockwave, etc and to do so crossing zones AND to be able to simulate in zones without necessarily rendering.  In other words, it's more than a particle... it's a lightweight entity
			- simulation zone crossing is very important.
		- the way TV3D handles this is to have seperate systems for every use case.  The graphics are tied to each instance.  You can update() the system, but there's no point if you can't see it because there's nothing physical about TV3D particle systems.  
		- if Zone crossing is a priority for simulation, then how does this impact our implementation?  
			- remember that the entire simulation should be run-able from digest version too.  This tells us that
			a single ModeledEntity derived "emitter" should exist for ALL zones with each particle then having the info it needs included for region and owner.
			- remember that each PARTICLE emitted from a single emitter can potentially cross different zone boundaries
			so in other words, the particle's need to be "migrate-able", not just the emitter.
				- perhaps then what we're talking about is a POOL of particles that are actually entities... hrm.. but isnt this slow?  
			- TODO: do we already allow for a Zone's entities to be loaded but not drawn client side?
				- the server can have all active zone's loaded and not render them, but what does client do? It should at least be able to load entitities and skip rendering of them until X concentric distance is reached.
			- currently, we have an Emitter as derived ModeledEntity which hosts particles.  If each Zone had the same Emitter, then we could pass particles between them perhaps.  
				- or if there was only one Emitter per Zone and different simulation modifiers per particle. Bah
				that's just not the way emitter's work. Emitter modifiers are for all particles created by that emitter.
			
			THis is fubar.  Why can't I make any progress on particle systems?
			- i need to just focus on the laser and remove references to the explosion effect first of all.
			then I need to keep existing code and try to handle region boundary crossing with it that way.
			- AI must also find other NPC targets across zones.

			

		
		Manager 
			ParticleEffect[] [server created guid]
				Emitters[] : ModeledEntity;
					Dictionary<Region>
						Particles[]
						
					Model
				
				
				
Camera - isometric angle
		- game style camera and not free form anymore
		
Simulation Timing
- speed up factor
	- Add drop down menu item for simulation multiple x1, x2, x4, x8, x16, x32, x64, x128
	- speeds up ship travel times without huge performance hit by running physics simulation more (but maybe we try that first)
	- missiles speed up
	- pathing - walking speed of npc onboard ship and planet side
	- animations - speeds up animation of eliptical orbits
	- animations - speeds up rotation of planets
	- animations - clouds, day & night cycles
	- animations - actors, idle, walk, etc
	- gameTime where x elapsed seconds in simulation == x elapsed time in "game" time
		- game logic such as fuel consumption must be based on the gameTime not normal elapsedSeconds
	- look at how Celestia and Orbiter simulations handles this
	- look at how submarine simulations handle this
		- sims3 also
		- the main issue i think is that animations, game logic (eg NPC actions and decisions) which update based on "gameTime"
		but physics updates on a seperate hertz.  
	
Celestial Bugs	
- BUG: #define NORMALMAP not set on WorldShader.fx so we currently just hardcode this define within WorldShader.fx or else we get no proper normal mapping.
- BUG: BoundingBox rendering is fubar
- BUG: star rendering not using alpha testing
- BUG: star lens flare not using alpha testing?
- BUG: sun billboards no longer rotate.. script loading / executing error?
- BUG: billboards no longer render properly
- BUG: vehicles need custom shader to handle point light star light

- disable motion field for Component Footprint editor and Interior Floorplan editor workspaces.  It's resulting in a very strange lookiing mass of billboards
  that grind the frames per second to a halt if you try to move close to it.
    
 - camera collision - http://www.gamasutra.com/blogs/EricUndersander/20131001/201382/Accurate_Collision_Zoom_for_Cameras.php
 
- floorplan is not being rendered at origin and jitter results if ship is far from origin and also the rotation is visible if the ship is rotated (eg move it towards a waypoint first then goto floorplan)

- what if i draw ceiling/floor "beams" as i do other lines like powerlines?
	- beams add weight, increase strength
	- the particular type of beam can be selected
	- we might as well just assumes that beams exist automatically and so the only real 
	design limitation is that htere are no floating floors.
	
- define in-bounds for entire Morena Smuggler again.

- place exterior edge floors and ceiling tiles
	- add flag to make these exterior floor and ceiling tiles non deletable, only appearance can be changed
  - do we auto generate sidewalls between bottom floor eges and top floor edges if no vertical wall is placed?
		- we would have to autogenerate because the differences in distance between top and bottom could be substantial
		- or we could enforce (since we are designing the boundaries ourselves) that max of one tile difference between external walls connecting tops and bottom floors.
			- in fact we could designate these tiles as exterior hull tiles 
		- the other problem is that there isn't necessarily 1:1 line up between the top and bottom floors if their outlines are not the same especially considering one floor may have more tiles than the other so they simply cannot line up 1:1
			- i think we should enforce how the exterior walls connect during boundaries painting since end user can then only modify interior walls and floors

	
  0) by default since we no longer have in bound painted cells as having a tile segment, and tiles must be explicitly painted by user
     FIXED. - when generating our interior visual meshes, we should default all cells as collapsed.  
	 - the visual of our in-bounds grid will show as collapsed all cells to initially until their bounds are painted "in-bounds"
   0) the floor paint/unpaint should use similar grid as in-bound grid only out of bounds cells should all be collapsed and only inbounds
      where the floor is NOT painted should be rendered as transparent tiles with a grid border.	
		- this floored area grid should be able to be enabled/disabled
			- we should perhaps smartly determine which grid to use depending on which mode we are in and always show that one or none if "ShowGrid" == false


	
// 1) wall auto-tiling
// 2) wall half height / full height issues
// 3) ramps, ladders, stairs, 
//      - placement restrictions
//          - ramps can't go through walls
//          - ramps can't go through components
//          - ramps must be placed on a floor (and in bounds)
//          - obstacle placmeent test 
//          - surface placement test (eg walls must be placed ontop of floors or other walls)

// 4) doors, hatches, ladders, ramps
//        - csg stencil reworking 
// 4.5)reactor, stations, cargo, catwalks, railings, transparent catwalk textures, visual representations for power,fuel,plumbing,life support, network links.
// 5) FIXED. show red footprint when illegal placement
// 6) pathing (threaded)
// 7) chairs and bed does not cause illegal placement when going thru walls

// 9) should in bounds using tilemasks?
				
Segment Damage
		- floors must track damage per tile, hitpoints, armor DR/PD
		- we really must spec all this out.
5) - With fixed ship hulls (eg Morena Smuggler), we can manually just place our exterior thrusters as well as pre-wire them up to interior thrusters.  
?) - option to fog of war not render interior parts that are too far?
	- camera height above floor should have bounds as should the up down angle of rotation
	
	
0) - painting bounds cells 
	a) this should set a "MODE" to the HUD that will cause this HUD graphic to be rendered
	b)  should collapse and uncollapse cells yes but... should not be using our actual
	    floor models.  should use HUD graphic
		We need to stop rendering of the actual floor meshes when boundary painting mode is active
		we should only be rendering the hud mesh
		i) but interior region (celledregion) must still be pickable
		ii) FIXED. if grid lines for each is too difficult to do without lots of overdraw at cell borders, then 
		can we use a transparent HUD graphic instead?
		 - FIXED. i think we should start with the tranparency
		        - FIXED. need transparent material
				- FIXED. need alpha_blend mode set on appearance 
				- FIXED. need i believe alpha test set...
		iii) FIXED. Hud graphic version of our inbound/out of bounds grid will use an atlas
		iv) FloorplanViewportControl "show grid" is not required for inbound/outof bounds really.  
			- the grid is required to see what constitutes in bounds or out of bounds.  Empty grids are out of bounds.
			- FIXED. we do also need to prevent rendering of the interior when in "boundary definitions" mode

		v) we may want to show multiple floor bounds meshes at a time!

- half shell exterior view of our mesh that we can choose to render during interior floorplan view
	- one that is designed to fit around our floors
- ability to disable via toolbar the grid of inbound cells in floor paint mode
	- it's just really annoying to look at
- ability to select between individual floor render mode or all or all at or below the current
	- then i can add ladders and ramps and post new screens

- changing between bounds and floors MODE must modify visibility of Interior CelledRegion in 
	FloorPlanControl
		- add a TOGGLE to switch modes and thereby hide/show proper toolbar icons
			- prevent this toggle from switching when not authorized (eg not a modder, just an end user)
		- changing to floor should remove bounds painting from toolbar
		- bounds painting should require access and not be allowed for anyone
		
Walls - Our interior walls we can render as a single mesh potentially also, by manually moving a wall "segment" within the mesh just as we collapse and uncollapse tiles.  We can do this easily for walls.  It will allow for super fast wall rendering, but still allow us to have individual segments.  I think it will also let us have all these different wall types 
	- FIXED. Double side our walls next
	- FIXED. fix the scaling and alignment of our test wall
	- since now our walls dont have their own script, it's up to the celledregion to have script for wall placement/alignment?

	- Add code to select a half height wall as well which is for crawl spaces, storage, and vents
		- I think all walls should be "half height" internally and when drawing them as a user, a full wall simply adds two double sided
		  half wall stacks.
		- can you have a half height walled area INSIDE of a full height space?
		- smart logic for determining whether something can be placed somewhere based on what exists in neighboring cells
		- connectivity MUST be updated as we place structures as well.
		- smart logic for determining which walls get placed based on neighboring walls.
	- Collection of minimesh & management of collection for all the different wall styles we'll use
		Tool Options (segment draw settings)
			- left wall texture
			- right wall texture
			- left wall style
			- right wall style 
				- these should point to some kind of a segment definition?
					- but if we change the texture and keep a style, how do we know to leave the previous texture?  
		10) Brush painting/erasing mechanic can be used to set our hitpoints, armor DR/PD and armor layers
	and to which stats for weight will be computed.	
	
	- HOW DOES SINGLE HUGE WALL MESHES IMPACT STENCIL HOLES
	- FIXED - walls on each deck are distinct segments but no longer Entities.  
	- interior walls get managed by single entities that internally track arrays of
	damage and connectivity and armor/hitpoints/strength, etc. This way interior "structure" is vastly reducedand instead our interior components are mainly the individual entities.
		- the biggest advantage is memory savings and caching and performance in general.  The expense is perhaps less OO and less extensibility in the future.. potentially.
		- but for our fixed ships, larger ships require faster rendering of walls.
			- size of interiors trumps the fact they are dull walls.
				- we make up for dull by the layout of the floorplans themselves and the illusion of really being on massive ships with your band of rebels trying to escape.

13) I have floors i want to view... raising/lower floors but also option to view all and 
	- we visually represent the interior celledregion floors with a ModelSequence
	that contains 7 models one for each floor.  
		- if we later have a different ship, how does the GUI know which models will be the floors?
		will it always be assumed that there's just one ModelSequence that contains N floors and so 0 - N-1 are our model indices?
		- Or perhaps there is a way to have the gui query for models using a floor naming convention?
		this way we could find and enable.
		Query is our friend! And it doesnt matter where in the subtree our floors are!
		- Query is also perhaps how we get the number of floors
			- remember, layers are not floors exactly.  

?) Brush designer (floor/ceiling/wall)
	- can select from prefab which will fill all brush style elements 
		- can also independantly change a style and save as new style
		- what do these two gui's look like?
	- Right\Left style
		- Visual Style
			- mesh (floor/ceiling/wall)
			- light material
			- texture atlas & atlas index
		- Physical Style (is this per side or per segment?)
			- armor dr/pd
			- hitpoints
			- composition - statistical but maybe these along with armor/dr/hitpoints is automatically set based on mesh selection and material
			                so that visually, user can become aware of what walls do what based just on looking at them
			- thickness - but because of how we join walls, these in 1.0 at least will only be statistical thickness and not visually thicker
		- Transport Style <-- is this a different type of "paint" able option for floor masks? how does this vary from the brushes we are designing now?
		                      - one is a placement tool still i think, the other is more the painting of data layer
			- electricity/water/fuel/ventilation are styles of "transport"
			
1) - painting floor/ceiling cells
	a) sets a "MODE" to the HUD so that the boundary HUD grid is not rendered.
	b) top most floor has ceiling by default and cannot be modified
	c) bottom most floor has floor by default and cannot be modified except to add hatches and such for existing vehicle
	d) Floor/Ceiling meshes should both be added to our ModelSequence generated in CelledRegion.CreateVisuals
		- ceilings ? constructed exactly the same but with normals manually reversed for all vertices?  that would allow us to keep them matched indentically "id" wise 
			- right now do we reserve a seperate TVMesh for every floor?  Since it's impossible to see a ceiling and a floor at the same time
			  could we "reverse" the ceiling and update the UV and Atlas?
		- thicknesses of our floor/ceiling - what does this look like?  how do we configure?
			- or KISS and just have different wall prefabs have different strengths and so visually walls relay their strenght.
			- thicknesses differences VISUALLY is _OUT_.
				- causes too many problems trying to standardize stairs and ladders and even components that are sitting between them if we now have to worry about total headroom clearance because we might have high floor and low ceiling combined plus any other combinations.
			- thickness at best visually we may allow some modest visual differences that are like thin/normal/thick/heavy, but mostly it'll jsut be data driven differences.
				- GUI - I think we can make data driven done through textures perhaps.  This way visually a player can look at a wall and know it's composition in a way that makes the texture of the wall part of the GUI so at a glance when designing the ship, the player knows the composition.
					- this is VERY MUCH LIKE MINECRAFT.
					- maybe material color can provide increased degrees of material strength for a given texture representation.
			- there should be ceilings too.  so our "floor" meshes need another one sided mesh to represent ceilings and which
		is automatically collapsed or expanded based for those situations where there cannot be a ceiling such as the lowest
		expanded floor "y" axis tile at that particular x,z axis coordinate
	e) Hatch entity  - we can experiment with hatches and ladders and stairs and ramps before we go on to walls
	f) ladder - we can experiment with hatches and ladders and stairs and ramps before we go on to walls
	
2) How do we assign the texture atlas for each floor (each floor we can allow to have a different texture atlas)
	- when restoring saved vehicle, are the atlas index values for each floor painted cell restored?
	- atlas should allow independant atlases for ceilings and floor grid meshes
	- atlas is in the interior's "appearance" texture, verify it's visible
				
BUG - the corner bits of wall footprint overlap with the adjacent walls making it impossible to drop adjacent perpendicular walls
	- temp fix was to remove those bits from the footprint in the floorplan viewport control's config of the painter, however, the proper fix is when a wall is placed to ignore those end bits or something else... because ultimately those bits for pathing need to be set.
	

- painting over walls and floors with different type should replace them
	- this applies for different wall meshes
	- But for just changing the texture
		- i think an "appearance" prefab where it changes the pointer to a paintbrush or something and that will replace the Appearance 
		under the entity.
		
BUG - placing an interior item like wall or door onto the floor must involve more than simply moving the y position half the distance down of the cellsize.  If the door for instance is not the fullheight of the cell, then it wont be enough and it will be floating above the floor.  Instead we must move the item such that it's Y position is floor.Y + object.Height / 2  where floor.Y = cellCenter.Y - cellSize.Y / 2

BUG - EdgeID for double walls/doors should always return same EdgeID when computing from cellID and orientation, but this is not the case... although it winds up in correct position when rendered.  i dont understand this! <-- think this is fixed.  I forget what the issue whas

StarMade - minecraft style space sim is interesting
http://www.youtube.com/watch?v=qOAJLNmzXm4
http://www.youtube.com/watch?v=XqGL5TdDdZU <-- power distribution
The Known Universe
http://www.youtube.com/watch?v=17jymDn0W6U

FIXED: Door placement can positively benefit from an alpha HUD reference marker that shows where the door will be placed upon clicking.
BUG - Door is not snapping properly and also not only placing on valid wall segmented edges

NEEDED: When moving the mouse in 3d exterior placementtoool, the target future drop location is always centered on screen and not influenced by mouse movement at all.  looks / feels strange.

- fix the rotation of the doors so that same side is always on interior of an outside wall
	- actually this is problematic... whether a door is on left or right is relative... somewhat... assuming doors are symmetrical.
	If doors are not symetrical (eg outside has different appearance, then as user, we should be able to manually rotate the door about Y axis by 180)
- real time visual feedback for walls and floors
	- real time add/remove/invalid location marker as mouse moves
NEEDED: Ability to rotate items being placed by holding down control or alt... see Sims3 controls
NEEDED: ability to place actors onto floorplan with feet on the current deck level and footprint created?
         
- exterior mesh pointlight shader fubar
- vehicle "goto" menu is not responding to ESC key.  Input controller should pass that to any active input aware buttons or menus                
	- should be similar to how the placement tool works
	
		
- Advanced Floor Tiling
	- eventually when the floorplan is limited to the exterior siloghette, some nooks and crannies may need to be filtered
	as "outside the siloughette" when dragging and dropping tiles to paint big areas.  Cuz right now its just a rectangular fill
	and doesnt check if some of those tiles are outside the silogette.
		- a mask of the un-useable tiles could easily cull those tiles from the returned list.

- find a hatch mesh - rectangular
- find stairs mesh (2x by 2y slope)
- find ladder
	- ladder prefab should contain both the ladder bottom, ladder top and hole frame + punch as a single prefab.
		- the query script should make sure both the floor and ceiling and floor of 2nd deck are clear and can accept.  So all of thse checks by the different subentities must return true to create the final result check bool value.
	 for some components like ladders,
	 it is comprised of 3 sub entities
	 - ladder
	      - requires no obstruction from floor to ceiling
	 - hole in wall
	      - requires clear floor/ceiling above
	 - railing on top
	      - requires no obstruction from floor to mid cell height
	 Here the overall script for the "Ladder" entity should handle the queryplacementvalidation

- place an interior turret and allow that turret to target and fire at npc

- FIXED - hud should show footprint on deck floor as we are positioning in real time
		- maybe this uses a marker over the top or maybe it just temporary alters the atlas index but then i have to track these changes as the marker moves and undo them when leaving
		FIXED - maybe we change the preview material from green to red in case of invalid location
- BUG - footprints should rendering using different atlas index

- BUG - UN-APPLY footprints when removing walls, floors or components
- BUG - wall corners both meshes and structure and the footprint issue
		- we cannot have overlapping footprints or else we cannot unapply them properly.
			a) we either allow an exception when removing edge structures that will leave corner
			when there is any other edge structure sharing that corner
			b) or we have width-wise walls use a different footprint than length wise walls



- tile mask/flags
	how does one do a "duct" without 3d?  Well im thinking by simply linking ducts as sub-graphs
	it certainly would be most elegant to have a 3d grid of cells like voxels but the memory use would suck.
	With 10 centimeter division, there could be quite good detail  but in 100meter x 100 meter x 100 meter Borg cube ship
	it would consume 1,000,000,000 cells each taking up probably minimum of 
	- how do we handle clearance of items that are too tall for where user is attempting to place?
	
	//  In a sense now already by 'SceneNodes" 
	
	- every item still has a SceneNode... a tile though has to be some underlying datastructure
	- adjacent tiles define a room unless they are partitioned
	  - i think some earlier logic has each title having 4 full quad portals and then expanding that "room" and pushing the portal
	  to the outermost adjacents... ugh this is so annoying.

	  - when you create a new "deck/sector" you will be asked to set the height of the sector (default is 2.5 meters = ~8 feet.  minimum is 1 meter such as for a crawlspace) and the cubic x,y shape.  minumum is 1 meter x 1 meter, default is 4x4

-the first thing you do is plot out the shape of the region's internals.  I mean it's _always_ rectangular, but you can define the various rooms and such that are contained within it.  The key thing to know aobut a region is that it's page-able so region's should be designed in a way that helps with performance when running a particular ship.

- if you have any wall pre-fabs of the proper size, those can be selected, however they must have proper dimensions.
however, if you want to be able to use the default 

=======================================================================================================
END SEGMENTS
=======================================================================================================


=======================================================================================================
LINKS - power, network, ventilation & life support, fuel, water & sewage
=======================================================================================================
http://www.antlr.org/wiki/display/ST/StringTemplate+cheat+sheet
http://www.sharpgis.net/post/2006/07/14/Using-XAML-for-rendering-maps.aspx
http://www.codeproject.com/Articles/288193/HTML5-vs-FLASH-vs-SILVERLIGHT
https://sharpmap.codeplex.com/
http://diveintohtml5.info/
http://dev.w3.org/html5/markup/button.html#button
http://dev.w3.org/html5/markup/input.html#input
http://www.99lime.com/elements/#btn-example
https://htmlrenderer.codeplex.com/documentation
http://htmlrenderer.codeplex.com/
	- but i dont know if it supports native HTML form widgets 
		- uses HTML 4.01
http://code.google.com/p/html-engine-mini/
		
- should always show the footprint overlays of devices that can make use of that link 
	- this has the benefit of alerting us when we have not created a footprint for an entity and thus are unable to connect a link to it!
- create a GUI panel that perhaps shows in plugins that shows our links and power generating devices and power using devices
	- do we just show the devices or do we name and list these "links?"   I think we should show just the devices and the links are
	strictly a graphical overlay because they are networks and 
	- maybe we can allow temperary bridges between networks using loose cables, but these have short life and might restrict closing of doors
- we need to solve how the height of an object is calculated.  is the mesh centered such that at y =0 the item's lowest vertex exists or 
  y =0 is middle point of mesh vertices?
  
 - interfaces for links -> common interface system
	- the interface for links IS the visual painting of the floorplan
		- clicking on various devices will now show us a custom menu that is defined by that entity's script.
		currently out "quicklook" means to do that but it is really bad design.  I like the idea of use HTML that each
		script can define for it's respective component.
	- interfaces for inventory (any item that contains other items has an inventory)
	- interfaces for functions (any device that can perform tasks/jobs has such an interface
		- eg. chemical analyzer
		-	  manufacturing workshop station
	- interface for information (any device that stores data or can be used to retreive data, has such an interface)
	- 	manifests
	-	schedules
		duty rosters
		employee records
		passenger records
		store items for purchase
		inventory items for sale
// http://www.digitalrune.com/Support/Blog/tabid/719/EntryId/144/Creating-an-XNA-Tree-View-Control.aspx

FIXED - power link painting
	- FIXED. prevent power link command from being sent until the operation is completed however
	  we should allow for the HUD to update until/if it needs to be corrected if the operation is invalid.
	  - FIXED. we must avoid "Save" of the entire tree during an operation that is save of database
	 

Interior Portals and Interior -> Exterior Connectivity 
================================================
Lasers or projectiles that hit the exterior of the ship are transformed by an inverse matrix to put them into interior space coordinates Culling always has the RegionOffset stack starting from root region and so should interior portals connect to the root
- the difference is when camera traverses through a portal, we first need to push the camera's region/position, then compute the region/position that the camera would be in for traversing objects on the other side of the portal so that's simply 

Portals in the Interior to Exterior connect to the root region and during rendering from interior through an exterior portal, we render in the local space of the Interior region.

Portals from the Exterior to the Interior are attached as children ofthe Vehicle\Container and point to a destination that is an Interior region within that Vehicle.  At this point during culling or drawing from exterior to interior we do have to transform the interior entities by the RegionMatrix of the Vehicle
 SceneNode node = Core._CoreClient.SceneManager.SpatialGraph.CreateSceneNode(entity);
 todo: in the initial case of creating a universe with tons of regions, we dont add the regions to the spatial graph hus there is no _sceneNode to add Star Systems too either so we have to check for null

if (_sceneNode != null) _sceneNode.AddChild(node);

what to do about multiple sceneNode parents as you recurse?  which parent does the child scenenode get added too?
well i guess there's two types of sceneNodes, there's the basic kind that just encapsulate a bounding volume.. those are usually for non region entities and they always have just one scenenode but it can have multiple parents.  the multiple parents then must be a kind of RegionNode or SectorNode.  
I had how i was going to handle entities in sectors but im forgetting...
i do recall one basic prinicple which is that sectors do NOT have their own coordinate system.  In this respect a Sector is really like a type of spatial node that we DO save to file unlike other types.  Thus, entities in a sector are basically placed under these sector"nodes" without a need for any other type so you have Portals too then can be (maybe?) purely spatial constructs that connect SceneNode's to SceneNodes.  All entity traversal pathfinding, culling, etc is done through the spatial constructs, connectivity graph, etc.

So when an entity wants to path find, it must be connected to the Scene (thus have it's own scenenodes) and it must traverse through the spatial graph. Thus lots of things can be relegated to the scenenode's for AI such as paths perhaps and connectivity graph?

Consider that with a CG structure contained with a RegionNode, and with RegionNode's being connected to other RegionNodes, then having CG sectors point to CG sectors in other RegionNode's is a simple matter of ensuring that all edge faces of CG cells that border the RegionNode's bounds, that they result in a traversal to their RegionNode's neigobr and then dynamic pathing can be used to find the right cell within that RegionNode to continue at.  Thus the main difference between CG sectors/portals is that they arent used for culling because they are too course.  So, they'd need to be sub-graph within a RegionNode seperate from the other Sectors/Portals which in effect are a higher level connectivity.

Seems to me then with connectivity of scenenodes (portals would be a scenenode type too) then the whole "connect interior portals with exterior views to the root of the scene is no longer necessary at all because now instead we just traverse via connectivity from inside out.
Traversal isnt done through a portal frustum but directly via a list of neighbors.

so a question is, isnt easier to just have connectivity done via non SceneNodes as directly Region to Region? Why use SceneNodes for that at all?  Well for one thing, connectivity is a spatial issue not a hierarchical one so aesthetically it belongs in SceneNodes.  But why else?

NOTE: Another key difference between connectivity and portal frustum is that connectivity doesnt care about path to a neighboring region it only tells you who the immediate neighbors are.  Thus, a portal that generally says "to exterior" can then create the portal frustum and then start recursing through all exterior neighbors rather than going to the root.  This also means we dont even need a root anymore AND it might simplify camera tracking since a translated camera must traverse through a connected neighbor.  We can use raytest to find the path, and provid collision response for attempts for paths that dont lead to a neighbor (e.g. edge of world)

ModeledRegion  <-- shares aspects with ModeledEntity and is treated as NOT having it's own coordinate system because it's position and such that it just gets rendered exteriorly like any other entity, however it can conton another region that does have it's own coordinate system
//      Model   
//      Region Interior;  
//            SceneNode[] Sectors;  <-- these do get saved to xml.  Portals from here go where?  Recall that portals are in region coords but interior/exterior boundary ones can find themselves needing multiple destinations that are dynamically updated But with sectors inside here like this, doesnt that break our seperation of entity graph and scenenodes?  A better way perhaps would be to have Region.Entities[]  and then for each individual entity to have it connected to can't recall also how this fits/doesnt fit with our armor and vehicle frame modeling...  actually it seems to work ok.  Frame are the wall and floor segments we lay down and Armor can be layerered onto the exterior of a frame to provide defense.  So if you have an adjoining room, does that mean the shared wall cant be armored since their is an interior side?  not exactly.  a bulkhead is basically an armored interior wall right?  or is it just a heavyier frame wall?
Or, if a frame is just the skeleton and armor must be layed as paneling, then that's different.  Frame relates to structural strength.

A room with a weak frame might have limits to how many decks can be above it for instance... and armor weight likewise is limited by the strength of the frame as well.
	
Interior - CSG Stencils
---------------------------------------------------
Entity (Door)
	- ModelSequence
		- Left FrameModel (flag MODELFLAG.GEOMETRY)
			- Mesh3d
		- Right Frame Model (flag MODELFLAG.GEOMETRY)
			- Mesh3d
		- PunchModel (flag MODELFLAG.CSGStencil)  <-- note: only individual model is defined as CSGSTENCIL not entire entity.
			Mesh3d
	- DomainObject  <-- so the question is, can this single DomainObject tie these two frame halves models together?
				    <-- so in our script do we first grab each frame model child and then 
				    <-- do we also then disable picking of the individual children during runtime?  We want all damage to be as one entity?
		- Script
			- BUG - The targets of CSGStencil sources needs to be recursive.  Or do they? is there a scenario where a wall for example wich a child entity would need csgstencils on the models of that child entity?
			
DoorEntity  <-- before this entity can be active, child entities must be loaded so a flag (Ready==false) to wait before any scripts can run? 
            // but how on earth do we know if the DoorEntity has a child animated door at all?          
	(flags - CSGStencil, CSGTarget, DrawCSGStencil, 
	Geometry Mesh;
	ICollider Collider;  // could be a BoundingBox too contained in a BoxCollider
	                     // is collider scaled with entity along like mesh?
	Geometry CSGStencil; // is stencil scaled with entity like mesh? 
	AnimatedDoorEntity child; // obviously has to be seperate entity since it can be translated & rotated differently during animation
	
- how do either WallEntity or DoorEntity with SwitchGeometry look with damage LODs and/or regular LODs?
	
	- FIXED. when the Door entity is added to a wall, the Door will set the flag onto the 
	- todo: when the wall is deleted, how do we also delete the door?  
		- perhaps it's easier if the wall has as a child, the door
			- door as decorator entity
			- makes it easier to pair up STENCIL with TARGET
				- ok, how exactly would this work?
				
			- if this is the case, how do we flag in the celledRegion footprint that this wall
			has a door and thus update the gridtile mask?
				- perhaps the wall itself can include script info for tagging celledregion
				tilemasks with doors/windows/etc location info
				- 
		- perhaps a wall cannot be deleted before it's door is deleted.  upon picking, the door is always
		selected first.
	 
 
		http://xboxforums.create.msdn.com/forums/p/97636/582459.aspx#582459
http://www.gamedev.net/topic/448921-stencils-as-screen-door-transparency/
http://stackoverflow.com/questions/5781345/trying-to-understand-stencils-xna-4-0-windows-phone-7
http://www.crappycoding.com/tag/xna-4-0/     <--- drawing craters in textures using stencil buffer
http://iloveshaders.blogspot.com/2011/05/using-stencil-buffer-rendering-stencil.html		
http://evanw.github.com/csg.js/

- if a model is a CSGStencil, when it's placed onto a celledregion, the celledregion queries for this case
	- it recurses all models to find csgstencils and if it finds one, then it flags the other segment (wall/floor/ceiling) that has a CSGAccept flag set, as a CSGTarget.
		- todo: what if we change the csgstencil status?  must notify the celledregion so it can make necessary changes


FIXED:  currently CelledRegion.Collide does not allow us to pick other entities within the CelledRegion.
FIXED: improve cell picking acuracy... especially when close to the cell being picked it gets worse
-verify that now interior picking still works when Vehicle is moved
- Maksing out Mouse Picks through CSG of doors/windows
	- build list of picked entities sorted by closeness
	- if the closest thing is a CSG Punch mesh (invisible but pickable = true) then select the next closest thing besides the CSGTarget of the punch
	(aka it's parent)

FIXED - footprint editor, need way to paint to different bits in the footprint data
		- footprint
		- access space

NEW. FOotprint scaling if Entity.Flag & AutogenerateFootprint is enabled
FIXED. Placement Tools, Move/Scale/Rotate tools did not propertly utilize network commands.  Now preview of commands never results in a network command.  Only final mouse up does.  This was crucial to modify before moving on to the previewing of interior component re-scaling, re-positioning and re-rotating.

POSTPONED: - Floorplan generation from exterior mesh
	- we need some rules on the interior space as to how it must be designed.
	you CAN have seperate "groups" to the exterior ship mesh, but perhaps we enforce certain group names 
	then only those groups with the proper naming convention will be parsed for specific reqts such as
	- they must be completely closed volumes (no doors, hatches, etc... those are added by the user)
	- minimum volume for 1 tile for each of these closed volumes.
	- anyway above is just preliminary thoughts for how to make computing the floorplans simpler.
	
http://www.opengl.org/resources/code/samples/advanced/advanced97/notes/node11.html
http://www.opengl.org/resources/code/samples/advanced/advanced96/node33.html  	

			
F:\stuff\_KGB_PICS\Killing_Horizon_ShadowMap_Atlas_System_Overview.jpg
	- BlindSIded's interior shadow mapping used a 6 sided cube map for pointlights and would use that single cubemap to apply to the entire scene
	- dgreen's version seems to create 10 shadowmaps in a texture atlas per object per light.  This seems just very expensive, even though the resolution seems pretty low.  But each of these shadowmaps needs to be applied to the scene.
	- http://www.youtube.com/watch?v=_grmwtnYI-U
	- http://www.pjblewis.com/articles/tile-based-forward-rendering/    <-- i think this is it
	- http://developer.amd.com/resources/documentation-articles/samples-demos/gpu-demos/amd-radeon-hd-7900-series-graphics-real-time-demos/
	- http://aras-p.info/blog/2012/03/02/2012-theory-for-forward-rendering/
	- "In my demo implementation I don't make use of any compute shaders or fancy GPU-built linked lists. It's implemented using OpenGL 3.3, but there are no reasons it couldn't be done using 2.0. Assuredly, it can be faster to do the tiling on the GPU, and, if using the depth buffer, it can avoid stalls, but it is still very quick to bin several hundred lights into a low-res grid using the CPU."
		- so indeed, 
	- http://www.gamedev.net/topic/639491-convert-multiple-lighting-shader-to-per-vertex-lighting/
	http://www2.ati.com/misc/samples/dx9/FixedFuncShader.pdf
	http://www.gamedev.net/topic/588764-solved-dx9---normal-mapping-with-multiple-lights/
	articles\dev\3d\clustered_shading_preprint.pdf

=================================================================================================
INTERIOR - FOOTPRINT	
NEEDED: Footprint work on interior

sims3 footprint info
http://www.thesimsresource.com/tutorials/view-post/post/2719/Adding%20tiles%20and%20fixing%20the%20footprint
NOTE: I can build in a tool into my cell component editor to turn on the high res footprint and allow users
to select the appropriate boxes to be saved out as a data file.

<Hypnotron> Mith
<Hypnotron> http://www.thesimsresource.com/tutorials/view-post/post/2719/Adding%20tiles%20and%20fixing%20the%20footprint
<Hypnotron> scroll down to the picture where there's a grid full of green checkboxes
<Hypnotron> it's the last image on the page
<Hypnotron> what i want to know is... if you rotate the "footprint" (defined by the green checkboxes) by 45 degrees
<Mith> hi
<Hypnotron> will those checkboxes still map 1:1 with another
<Mith> i don't understand
<Hypnotron> cuz in sims3 for instance, you dont have to have a sofa, chair, whatever.. be aligned perfectly square to an axis
<Hypnotron> it can be at 45 degree angle
<Mith> ok
<Hypnotron> and the corresponding footprint of that item then has to set flags in the underlying map
<Hypnotron> im trying to figure out how to compute those when its rotated
<Hypnotron> easy to do when it's not rotated
<Hypnotron> or when it's squared along an axis its easy
<Hypnotron> so figuring out the 45degree case
<Mith> you would end up with partial squares being occupied
<Hypnotron> yeah, thats what it looks like in the game when u turn the grid on and see hwo something aligns when rotated
<Hypnotron> maybe it sets a special flag that indicates it's half occupied.. and maybe even indicates which diagonal half
<Mith> is that necessary?
<Mith> the squares look pretty small
<Mith> i doubt it makes a significant difference
<Hypnotron> yeah, i was wondering about that myself
<Hypnotron> because in game the squares are much bigger... 
<Mith> i would just consider a square occupied or not occupied. If a translated square ends up on four other squares, then all four are taken
<Hypnotron> more like the footprint you see at the top only each of those big tiles is divided into quarters
<Hypnotron> forplacing things, only walls have the minimum limit of a full big tile
<Hypnotron> hrm... that would in fact mean the game has a finer grid that it uses for pathing 
<Mith> yes
<Mith> only for close grids
<Mith> so you after some maths for repositioning the cells?
<Hypnotron> well... i can do the transform of the centers of each and then find where they intersect with a 2d grid.. and maybe the centers is good enuf and dont worry about whether a corner overlaps
<Mith> ok
<Hypnotron> that part is not hard... i was originally worried about dealing with the half squares.. and i didnt realizee they use a finer grid underneath
<Hypnotron> but i do have to re-think some things in light of this
<Hypnotron> i dont think this breaks anything though.. it just means my pathing layer maps are different resolution
<Hypnotron> i hope there's not some weird cases where i rotate and some weird hairline fractures are created
<Hypnotron> because of just rounding to nearest center
* Hypnotron likes to worry
<Hypnotron> probably not possible

http://www.cpp-home.com/forum/viewtopic.php?f=4&t=10614


	
=================================================================================================
INTERIOR - Engine and Power Plant construction Kit - using Bricks
=================================================================================================
http://www.entoforms.com/2011/06/29/ship-ahoy-man-if-only-that-sounded-cool/
http://code.google.com/p/entoforms/
\keystonegameblocks\design\schematics.pdf  <-- note the warp drive!  it can be built up of parts. 
	- batteries too!
	- storage tanks too.  Sphere cylinder meshes can be stacked vertically or horizontally.  

It just occurred to me that with some basic texture lego like primitives... users can build an engine manually that looks the way they want.  With scripting they can also add some lights and such.  We can also compute which meshes of the engine are completely occluded by virtue of being inside the plant and thus dont need to be rendered.

In effect, it's a minecraft esque way of designing engines.  The good news here is, there's no longer any need to SCALE the underlying meshes for engines or plants or whatever.  Instead we simply brick them up to size and we can apply different corner bricks, cap bricks, etc to complete the look.  For purposes of mass and output, the only thing will consider is the overall volume (this way users dont have to actually add meshes to the inner non visible part).   So, to get this to work, I think 

EngineEntity
	GeometrySequenceNode
		- brick0
		- brick1
		- etc

###And what if we actually then allowed for the exterior of the ship to be built that way as well?  Where the user can place their turrets and snap in parts and what not.
Provide a huge list of barrels, engine nozels.  Allow users to make their own.  But the key is, there's no modeling, just snapping of parts together.
- a tank can be built into the armored areas and be inaccessible.  User then drags on the connctivity piping layer, the connections from the water tank to various relays.
	- the tank parts can be like cut into wedges first, then you can construct a tank and add the end pieces and corner pieces.
###For armoring, they can simply add entire cubes of armor to exterior cells and then finally have a wall.  seperating the exterior.  This way even double hulls can be constructed.
		
###For engines that directly use nuclear reactions for thrust, the same applies.  Connect the nozel to stacked cylinder slices and cap both ends and connect with nozel throat
http://www.projectrho.com/rocket/enginelist.php
And wouldnt it be awesome to have various particle fx for the various types of exhaust.


FIXED - Sol System BUG: Some gas giants may not be rendering because of the Query we do in iconizenorecurse() to determine if we will render their HUD icon representations instead.  
FIXED -  Unfortunately, ive got some bug now with loading multi-region zones.  Array index out of range exceptions it seems... seems to involve iterating through arrays that have changed size perhaps?  This seems repository.get() race condition with locking the .Get() call.  We cannot lock that because we get scripts trying to call .Get() while the entity is locked.
FIXED - forgot to update the UseGlobalCoordinates for "flyto" animatin changes to the keyframes.
FIXED- Fixed so long as i go through DecrementRef() -> just as i sychronized IPageable loading through Factory.Create() i should be sychronizing their Dispose() because i run into scenarios where im trying to unload, then load again and then borrowing from factory and then trying to render while its being disposed because that started when the refcount reached 0.
FIXED - tool placement preview is showing items wrong location after viewpoint refactor
FIXED - interior wall placement exception after viewpoint refactor
FIXED - interior floor grid is visually hosed after viewpoint refactor
FIXED - Zone.cs ChildEntityBoundsFail() - THere's a bug with trying to assign translation of an entity that is not direct child of Zone (eg a moon is parented to world then star then system THEN region and it would fail there easily)  So far it works because we're just moving either ships or viewpoints.	
FIXED - is there a case where when stellar systems or stars are paged out and then paged back in when nearing those zones again, that they're not properly removing their parent references AND are not being removed from repository and so are being cached and then having their children re-added?
	FIXED - this seems last paging bug besides some apparently mesh loading issue where in some zones, the planets have atmospheres but no land sphere... and possibly no cloud sphere either
	FIXED - octree culling iussue? EntityMovement now handled properly.
FIXED - implement "fly-to" camera animation rather than the abrupt jump
FIXED - could help to have the rotation occur faster than the fly-to.
FIXED - fix "fly-to" across zones
FIXED - autoplay animation for worlds and star coronas? why do they orbit coronas dont rotate after deserialization?
FIXED - why can't i click on iconproxy's?  ScaleFactor and Billboard matrix used during rendering but not culling was preventing easy functionality.  Switched to using 2D screenspace icons and picking in 2d space.  
FIXED - EditorViewController to be depricated in favor of scriptable Viewpoints	
FIXED - I think this was caused by our Zone boundary enforcement being broken for a bit but now fixed -> in multi-region galaxies, I think the locations of systems (stars, worlds) as seen across a zone border is fine, but I think the screenspace position calc for label and proxy icon is off.  I should be able to test this with small zones and with small components in this and forcing draw of icon.
FIXED - Repository.Get() dictionary thread locks  prevent race conditions on sharing objects.  
FIXED: star quaternion animation rotation is obviously hosed.
FIXED: minimesh.cs.AddInstanceData should resemble Model.Render() and handle scaling, billboarding, etc
- FIXED - walls and floors are still using cell x,y,z coordinates and not tile coordinates and so the footprints are being drawn in the wrong location for walls and floors.
- FIXED - rotating our bunk bed test component results in an array out of bounds exception
- FIXED - footprints > 16x16
	- VERIFIED - use one of our bunk models for testing this
- FIXED - positioning of components should use footprint tile snapping and not cell snapping
- FIXED. fix rendering and culling and picking across interior and exterior and multiple regions
- FIXED. add option to make exterior only alpha transparent not entirely invisible	so we can see sims walking around 

FIXED: Preview generation thumbnail only works once.
	FIXED: - unloadng the preview generation should remove it fully so that it can be recreated next time.
	FIXED: - preview generation window when active should be sole mouse capture and modal dialog.  We should not have to move the window to avoid moving the main 3d viewport or floorplan.

FIXED: Saving an entity as a new entity somewhere else does not allow for creation of new preview generation.
FIXED (Can't reproduce): Seems material change settings aren't saved in the prefab?
FIXED - asset browser needs a combo drop down for switching to categories.
FIXED - AssetBrowser window should start under COmponents folder when in Floorplan Edit.  The filter should be set appropriately as well.
FIXED. Instanced meshes when mini.AddInstance() now use the model's RegionMatrix not the entity's. 
FIXED: floorplan floor dropdown should work
FIXED: Quadtree for celledregions added. 
	- there are errors when placing floors in the celledRegion quadtree.  unsure what they are.
FIXED - KeyPlugins.BaseEntityPlugin.buttonSavePrefab_Click()
		this method results in an AssetBrowserDialog that displays wrong tree nodes!
FIXED -- assetbrowser needs way to hide the filetree
FIXED - re-saving an Entity is not using the correct zipentry.filename which must be full entry path including dir and filename.
FIXED - actually i  think above is correct, it's the new folder that is not!
FIXED - solution explorer resets bug
FIXED - filter to asset browser so we can create seperate ones for different views
	 and only show relevant things to that view	
FIXED - interior floors, walls, doors currently dont render because trying to add to minimesh which is not refactored yet to work with csg stencils, and various lighting & appearance hashcodes
FIXED: When unloading placementtool, the preview source entity is not removed from the scene.
FIXED - Model.GetScalingFactor unnnecessarily computing a scaling factor for entities that are not using far frustum and which are inside the close frustum.
		
FIXED - Wall Placement - placing double sided wall on exterior edge results in an error

FIXED: Replace Model with ModelSelector does not work in plugin.	
FIXED: Fix Model scale changing via plugin.  
FIXED: Punches added to our doors, prefabs saved afterwards, stencil rendering csg working
FIXED. (moved to Model) Mesh3d is no place for the SwitchMode.CSGStencil flag because a simple sphere or cube might be reused as non CSGStencil also. Clearly the place is in the Switch node and in the Entity.

FIXED. Floor tiling
		- still havent implemented proper drag and drop painting of floors.
		- fix bug with cellindex error on ReadXML for Floor tile prefab.

FIXED. boundary cases for placing walls end up appearing on opposite side
FIXED. seemless switching between wall and floor placement
				
FIXED.  fix wall height (art dimensions)	
FIXED - doors/windows (proof of concept stencil buffer based fake csg implemented as hard coded test. works great!)
	- is it possible during our traversal to first find all segments that have a CSG mesh attached where the CSG mesh is active and needs to be applied.
	And then to render those FIRST?  How on earth do i blend this with the far rendering stuff...  maybe can work since the idea is to not draw anything where the stencil is
	so it wouldnt even overwrite what was drawn first.  Then, once all of these are drawn first, we can render the rest of the scene normally and make sure to skip the CSG ones.
	WOuld this work?  If so, we could do it all in our normal ScaleDrawer.cs and not as an FX
		- Add Flag  CSG <-- that flag can be set by the script controlling the entire "Door" entity which perhaps consists of
		the frame, the door, the punch (the punch is mesh but either through script or a special type of switch node, is used to alter rendering... hrm...
		cuz the key is the wall needs to be rendered with and 
		http://wiki.truevision3d.com/tutorialsarticlesandexamples/programming_hlsl_shaders5
		
FIXED. minimesh floors seem to draw without proper zbuffer and far away meshes render right throw them when they shouldnt.
FIXED. still not drawing debug lines in correct place for interiors 
	- note; i believe this is fixed as we now render lines using proper regionPVS which maintains proper view matrix

FIXED. if exterior mesh of proper size we have to make it invisible and have no pick response of it's own yet
still allow for interior to be visible and picked.
	- FIXED. this could be a matter of the Picker.
	- FIXED. Interior should be visible too if exterior is invisible
	
FIXED (Added check to skip Interior if Entity is Container) EntityNode box of Vehicle uses generic Entity bounding box which takes the interior region's box and of course interiors' coordiante systems are always fixed location.
	
FIXED. if container has an "interior" you can switch from interior to exterior (region centric) and perhaps as well everything else stops getting rendered and it's more of a Sims (or first person shooter creator) open view of your interior.  

FIXED. multifloor editing verification
		
FIXED.   Walls if you look at the models used by FPSCreator, are built as halves, but with (i think) the frame as a single? Is there any good point to this?  On the one hand it would put each half wall entity into it's own cell, but this needlessly doubles our culling and rendering.  Forget it. Logically walls are shared and thats how ive implemented them.
	- FIXED.  No longer do i implement double walls as 2 entities. They are now 1 entity with 2 models.  Thus, i could potentially still allow as a high end system option, the ability to have doors with seperate models for each side to allow for increased variety.
  		
FIXED. Place Door On Wall
	- is the door AddChild() to wall or to CelledRegion?
		- map layer modification is easier if it's placed to the CelledRegion...
		This is also consistant with the notion of STACKS in a cell rather than other parented children.
		I think the other parented child should be reserved for things that are IN the interior but
		NOT affecting cell layer... that is.. they are weapons being carried, things like that.
		
	- FIXED. first save the door as a prefab
	- FIXED. door domain script must be added
	- FIXED. door script must denote via it's query that it's a type of segment (like wall edge)

	FIXED - verify & debug wall footprints are being applied in correct spots when dropping a wall
when dropping walls, 

	FIXED - placing walls along exterior edge of floorplan fixed
			
	FIXED. make interior camera no longer inside of interior but instead inside of the exterior's region
  but add a smaller bounds and this way now we can overlay the exterior and switch between views
  - need to enable picking and culling variability depending on mode interior or exterior edit
  - as well as allow overlay transparency, transparency of exterior walls

	FIXED - change floor tiles to render from a texture lookup table so that we can still utilize one draw call for the floor as a single grid mesh.
	
	FIXED - save load of interior's wall segments
	
	- FIXED - FPS creator uses 100x100 unit walls.  In game i think that represents 2.5 x 2.5 meters.  In our project i'm debating whether we go to 1.25x1.25 meter tiles as our half size walls, and then allow for two stacked to be a full height wall and for doors, those segments are 1.25x 2.5 or potentially double doors 2.5x2.5.  I don't know yet.  
			// http://www.modthesims.info/showthread.php?t=322241
			//https://developer.valvesoftware.com/wiki/Half-life_2_Dimensions
			// http://forum.thegamecreators.com/?m=forum_view&t=114444&b=24
			// 		Segment Size = 100 FPSCreator Units = 8' 4" = 254cm
		- FIXED. switched to 1.25 meter tiles square
			
FIXED - ceilings added to our layers and grid when floor layer > 0.
FIXED - saving interiors! 
	
FIXED - Exterior transparency slider.  How can we make transparency in one view and not have it modify
the model's material permanently
FIXED - HUD picking not re-wired after seperating HUD from scene.


	FIXED - nested "ref" nodes to seperate xml tables may not be working
	FIXED - get exterior to stop rendering interior deckplan grid
		FIXED - why is that on the same hud branch as our 3d editor hud?
		FIXED - i think if we disable all HUD rendering it wont render since the interior deckplan
		is added to HUD branch.  So that is an issue of adding that hud element and removing it.
		I think our floorplan view needs to do this and then our normal editor needs to be using a seperate hud

	- FIXED. interior grid coordinates must now take into account hierarchy of interior region
	
	- FIXED. (For Enable) - "Model" page in plugin needs checkboxes for "Enable" flag and maybe "Visible" flag,  right now we're attempting to treat Enable as meaning Visible
	
	- FIXED. when browsing ATLAS texture, trying to switch back to placing a component fails.
		- FIXED. we need to properly re-initialize the browser for picking components from our mod
	- FIXED. toolbar option to toggle rendering of exterior and interior
	- FIXED. option to render exterior with transparency but in a way that doesnt require us to modify the actual alpha of the material of our ship
		- FIXED. we just want it as a rendering option we can override the normal exterior rendering.
		- FIXED. transparency slider for exterior render in floorplan viewport
	- with exterior rendering off, interior placement picking should work
	- with exterior rendering ON, exterior placement to hardpoints should work
	- FIXED.  (was failing to recursively load children when cloning = true) re-saving a prefab doesnt render the image for some reason
	- add slider to change camera speed in, interior view from 0.1m , 1, 2, 5, 10, 50, 100m, 500m (perhaps with 10 increments)
		-FIXED. camera speed needs to be a RenderingContext property
	
	- FIXED. - ("shareable" flag was not set in older prefabs.) re-saving a prefab and then selecting it in placement tool and trying to place it will turn previously placed instance (used for resave) to have the "preview" material saved on it.
		- FIXED. - verify that this does or does not also happen when first importing a new geometry as entity and then trying to place it into the scene.

	- FIXED. initial floors meshes are not initialized to 0 tile index texture
		- FIXED. our inbounds but painted "hole" meshes do NOT show in floor meshes but in HUD overlay that will show our "grid" hud mesh that has no collapseable cell options when in floor painting mode.
			- FIXED. remember, this is because when in floor painting mode (as opposed to bounds painting) we must use mesh grid to show the outlines of available inbound cells and when this grid is shown
			it must show the outlines of the holes too or else we dont know what the bounds are.
			- so this grid must be toggle-able
	- FIXED. must supply tile count to the procedurla helper cell setuv call or it wont work for both 
	bounds and floor painting which uses different size atlases
		- FIXED. so we need to decide whether we pass dimensions or pass an atlas and then what if there is no atlas?
		  
	FIXED - are NodeState being instance and read and then applied to prefab instances? i dont think they are
	FIXED - converted Light creation to use Node_Create_Request
	FIXED - prefabs now can be reference in xml via "src" attribute.
	FIXED - I/O of walls
	FIXED - Footprint editor implemented
		    - shared HUD between all 3 viewports in Footprint edit workspace
			- picking of HUD elements
			- PaintTool for drawing to the component's footprint.
			
	FIXED - Only one footprint of our double sided walls is being applied.
	FIXED - Array.Remove extension methods needed to return a new array.  Could not modify calling array.
	FIXED - Merged Procedural Shader with GroupAttribute
	FIXED - Footprint editor that is miniature tilemaskgrid painter.
	FIXED - verify walls update footprints properly by looking if a wall placed on horizontal or vertical edge has proper footprint on tilemaskgrid.
	FIXED - picking of the HUD footprint quad should work for component editor since we don't have celledregion to use instead.
	FIXED - add axis indicator to view... it's too confusing knowing which direction to expect default
	FIXED - i think currently our models for each axis are not all pointing in positive directions 
	FIXED - axis indicator position should be fixed from bottom left corner of window, currently it moves based on viewport dimensions
	FIXED - ability to delete walls
- FIXED. culling of solar systems is still problematic.  
- FIXED. universe gen results in light.translate "attempting to read or write to protected memory" exception
	- seems for some reason the light is being constantly added and removed from multizone scenes...
	- as i recall, this had something to do with the call for setting the light's position.  One way works and another didnt?
- FIXED. (modified lock(obj) closing brace to include the call to .LoadTVResource()) universe gen results in a domainobject rule (eg. mRules.AddRule() sychronization issue it seems)

- FIXED. star labels of our nav digest mesh 
- FIXED. star picking takes you to zone view

	
================================================
================================================
================================================
END INTERIOR
================================================
================================================
================================================
================================================

=================================================================================================		
On Using Portals vs Hardware Occlusion
=================================================================================================
<Hypnotron> hey steve, you there?
<Hypnotron> not sure how busy you are, but take for instance the ship in this pic
<Hypnotron> http://www.makosoft.com/stuff/kgb_b53.PNG
<Hypnotron> what id like to do is to get a cross section of a specific part of that ship as a 2d image so taht the parts inside the ship are say black and the parts outside are white
<Hypnotron> but actually
<Hypnotron> i want to take several cross sections and get over a nearby range and use the minimum for the final
<Hypnotron> so like imagine a 10 foot tall deck from floor to ceiling
<Hypnotron> so my cross section would encompass samples of the cross section from floor to ceiling
<Hypnotron> and the final cross section should contain all of the others
<Hypnotron> so i guess a Max not minimum
<Hypnotron> a superset of all the otehrs i guess
<Hypnotron> im trying to figure out how to do that easily... considering you'd have to clip triangles
<Hypnotron> or something
<Hypnotron> or i dunno how to do it best
<Hypnotron> anyway
<Hypnotron> once i have the 2d image
<Hypnotron> the siloquette style cross section that represents a "deck"
<Hypnotron> i want to be able to then allow users to draw ontop of it and to be able to do bounds checking to make sure when they draw something they are staying within the black part of the siloquette
<Hypnotron> i would know how to do that using just planes
<Hypnotron> just like a frustum only more planes, that'd be easy
<Hypnotron> but from a 2d image maybe there's another way
<Hypnotron> not really sure how to construct 2d planes from the siloquette so im thinking maybe there's some other way that is similar to an occlusion query against the  silouqette
<steve|work> hrrm
<steve|work> an interesting idea
<Hypnotron> the first part is how to construct the siloquette 
<Hypnotron> wondering if the only way is to iterate thru all the triangles in the model and find the ones that intersect the plane and to build a new polygon connecting all the intersection points
<Hypnotron> ugh, but then i would need to know how to connect them in the right order
<Hypnotron> that's why the idea of being able to somehow rendering a siloquette without even worrying about recreating new polygons from the plane intersections
<Hypnotron> seems better if that's even possible
<steve|work> no
<steve|work> hrm
<steve|work> you can use custom clip planes
<steve|work> which clip in addition to the view frustum
<Hypnotron> that sounds like it would result in fence, although i guess an algo could be used to then fill in the middle
<Hypnotron> floodfill of sorts
-
<Hypnotron> hey steve, no sure if you're afk or not but last week or so we were talking about hardware occlusion as opposed to portals/sectors and then i remembered something that portals/sectors offered that im not sure how you deal with otherwise... since you're traversing from the camera's current spot through portals to other sectors
<Hypnotron> you can pick up the lights as you go and dump them when their range runs out and so you easily know what lights affect what objects
<Hypnotron> and it makes it so easy to have a light not enabled if its on the other side of a wall
<Hypnotron> it also can make it easier to setup pathfinding
<Hypnotron> the pathfinding is no problem since you can just create a navmesh that will store all the connectivity 
<Hypnotron> but what about the lighting, how would you deal with that?
<steve|work> interesting..
<steve|work> well, ideally you'd alerady have a quadtree structure or something similar
<steve|work> and using the hardware occlusion system you'd be able to detect which regions in the quadtree/octree are visible
<steve|work> you would then use the data in the octree to check for lights affecting objects
<HypoAFK> ok. thanks. ill have to research that a bit
<HypoAFK> im almost definetly not using portals/sectors for my ship internals... just on the ship intneral / outside boundary for windows and cargo/landing bays
	


=================================================================================================
=================================================================================================
c# PHYSICS
=================================================================================================
=================================================================================================

Helm - Orbital Maneuvers and Orbital Mechanics
----------------------------------------------
	// - step thru physics
	// - nav view
	// - 2d draw textured quad for hud for ships and planets
	// - alligned quad trail
	// - projected orbit elipse (- presumeably this must use  
	
	
helm control - how does it look?
	- list of engines
	- list of bodies
	- list of maneuvers & ETAs
	- current maneuver and standing orders (eg maintain orbit)
	- current orbit data
		- apeopsis / periopsis
		- altitudes, plane
	- current state

http://graphics.stanford.edu/papers/rigid_bodies-sig03/
http://www.cs.cmu.edu/afs/cs/user/baraff/www/pbm/pbm.html
http://www.continuousphysics.com/ftp/pub/test/physics/papers/IterativeDynamics.pdf
http://www.braeunig.us/space/orbmech.htm
http://www.youtube.com/watch?v=BCZRF9o8ytc  <-- nice tutorial! wow so helpful!
	- orbit BODY @ DISTANCE  <-- this is a standing order that constantly updates?
	                             <-- or does "maintain"/"maintenance orbit" have to be enabled?
		- orbit BODY @ MAX
		- orbit BODY @ GEO_X <-- this is alias for some distances that must be computed and then the normal BODY @ DISTANCE is used
	- transfer to BODY @ DISTANCE
		- will wait for a desireable orbital position before leaving orbit towards the new BODY
		
	- match velocity & altitude (for following vessels)
	
	
	
Physics - orbits, n-body  especially the last post in that thread
===========================================
http://www.physicsforums.com/showthread.php?t=262733
http://www.gamedev.net/topic/481263-c-particle-to-particle-gravity/  <-- same guy also posted to gamedev.net and posted his code

// the following i believe uses HNBody Symplectic Integration  --> http://janus.astro.umd.edu/HNBody/
http://shootout.alioth.debian.org/u64q/program.php?test=nbody&lang=csharp&id=2  <
http://shootout.alioth.debian.org/u64q/program.php?test=nbody&lang=csharp&id=3 <--fastest


http://www.codeproject.com/KB/directx/BelievablePhysics.aspx

matrix.cpp Invert()
http://nccastaff.bournemouth.ac.uk/jmacey/GraphicsLib/html/_matrix_8cpp-source.html

http://www.nigels.com/glt/doc/matrix4_8cpp-source.html
http://www.truevision3d.com/forums/showcase/earth_moon_65_downloadable_src_media_bin-t11713.0.html


Now that i think about it, our IPhysicsEntity is fine and should contain properties for enablePhysics, affectedByGravity, etc
and really our actual physicsBody should be a PhysicsController?  to be consistant with how we want to have our control logic seperate from our entities just like buttons and such.  Well there is such a thing as a "PhysicsControllre" and I think what we need to do is move some more functionality (like the apply() series of functions) into PhysicsController and have PhysicsBody be much more like an implementation of IPhysicsEntity.  Hrm, controllers are a bit different in bepu's physics.  In his they are created to control collisions and after an object becomes stable they are removed... So controllers are basically offer coherency for collisions objects between frames.  One difference is we could rename Controller to CollisionController and PhysicsBody to PhysicsController

- finish the bepu demos
  - will require a basic IPhysicsEntity so we can verify translation and such work back and forth
  	- need to be able to suspend physics on an object that is being dragged or grabbed by a grabber
          ideally this should be done via the IPhysicsEntity interface to set the IsPhysicallySimulated = false and true afterwards.

- add the Kapow as a type of entity that can be controlled via EditController

- see if we get same good results, if they all work then i think we can say we have fixed all bugs introduced during the integration
	- part of this will entail shooting out an object so we need hardcode probably for that
- would be nice to be able to click on an entity in the editor and change it's physics attributes at runtime


velocity = momentum / mass
linearMomentum = velocity * mass

apply linear impulse simply += to momentum so if momentum = 0 and you applyImpulse of 100, then for a 100kg object, velocity = 1


consider the order of operations 
 - main loop update
     - based on input, udate direction and velocity and such
     - run physics
     	- physics resolves collisions and advances objects
        - physics notifies when an entity has been updated



Entity--------------->SceneNode <-- merge with CollisionPrimitive?  i dont think thats wise...
 \__PhysicsBody
        \__ PhysicsController
        

Entity--------------->SceneNode
\---CollisionPrimitive -->  with references to both Entity and PhysicsBody 
 \__PhysicsBody
        \__ PhysicsController

What is the difference between a CollisionPrimitive and a SceneNode?  
	- Both we'd like to have hierarchical representation in WorldSpace. Right?
        - CollisionPrimitives tend to have specific derivied based on the type of the entity... 
		-so spherePrimitive.  How does this fit 
		- convex hull
		- triangle mesh
		- cylindar
		- capsule

clearly cylinder and capsule and triangle mesh wouldnt be used for culling so a collision primitive is different than a spatial graph node...


Now what TV3D does, and BEPU and I think most games really, is they have the collision and physics data structures as seperate but with an object reference form the PhysicsBody to the Entity, and from the Entity to the PHysicsBody.


There are two downsides there, one of which at least I think i can avoid.  I _can_ share boundingbox data but I don't think hierarchical bounding / spatial structures I can... i'm not 100% sure yet but it seems like it would be difficult...

  hrm... spatially i have sceneNode's which are fundamentally hierarchical bounding volumes.  In many respects, they are like a collisionprimitive except structure...  but then things like RegionNode's and Octree's dont make as much sense...  hrm...



http://cdn1.ustream.tv/swf/4/viewer.110.swf?cid=1/581508&varnish=true

http://www.euclideanspace.com/threed/games/options/timestep/index.htm

=================================================================================================
=================================================================================================
RESOURCES / PACKAGES
=================================================================================================
=================================================================================================
Project Explorer - just the loaded stuff (a scene graph but of entities and spatial/pathing info only)
Resources - this is just either viewed from Import open dialog or a dir tree tab
Library - these are available "nodes" - we'll have the ability when wanting to set appearances or entity scripts, etc to always use the current ones that are in the "quick assign" slots... similar to MSPaint's fore/back color slots.  when selecting a resource there is a preview window and its the same preview used for material preview, texture preview, etc?


RESOURCES
-raw resource files like .obj, .tvm, tva, bmp, dds, .terrain, 
DATABASE
but then we also have our saved appearance nodes, material nodes, texture nodes, models w/lods, bonedmodels... basically every IResource type that is NOT an entity.  
-MODELS
-APPEARANCE     <-- should appearance just be apart of the model? We certainly dont want a bunch of GroupAttributes and crap.  Then again, if you have an "appearance" selected already, and you can give it a name like "asphalt" and it's already got the texture and material set to it... then that can simplify things.  hrm.  similarly with walls... being able to treat "appearance" like a complex "brush"
   -MATERIALS
   -TEXTURES
   -SHADERS
LIGHTS
 - http://www.youtube.com/watch?v=p_6eoGIigI4  <-- good light editing ideas
-ENTITIES
Entity Browser is trickier... a ship is basically a hierarchy of entities...


so yeah i think i do need to go back to my original idea where "import" will create the xml-ized versions of things and add them to our 'data' library.  I could keep the xml, and any related texture in the same directory to make it easier to replace them... but thats no good really because when you "delete" an entity from the library you wouldnt want to delete the underlying resource since you might not have copies anywhere else on disk... so you _would_ want to keep the raw files together too... hrm...  But also recall that before i had "Appearance" above a Model because Model's had instance data and then i changed this when i introduced the Entity object which would instead hold isntance data and allow Model's to be.  ANSWER? ->  Material, Shaders, Textures can be saved seperately, but NOT Appearance or GroupAttributes.  Instead, a user can go into an "Appearance Editor" for a Model and choose textures and materials and shaders from the library and import new ones if needed.

So our simplified method of setting "appearance" to a node is all done behind the scenes.  There's no need to list "children" instead we can directly just edit LOD, Appearance, Behavior, etc.  The fact we have a hybrid scene graph underneath is irrelevant.  

data\assets  ?
data\resources
    \resources\textures
    \resources\meshes
data\library\
    \library\vehicles
    \library\buildings
    \library\models
    \library\bonedModels
    \library\appearances
    \library\vegetation


Animation GUI Editor
MindFusion makes the diagram/flowchart component blind used in his fx editor
http://www.mindfusion.eu/


UPDATE: I like the way neoaxis screens has a "resource editor" which i think is basically really a "node" editor for being able to edit "loaded" nodes or library nodes.  I like how it "smartly" decides what set of modifying pages to show based on the type of resource


When editing a boned entity for instance, our property editing is abstracted so we have  
BoneEntity
    - general tab
    - model tab  (can set LOD's and ranges, and appearance (texture, materials, shaders)
    - physics tab
    - behavior / AI tab
=================================================================================================
==============================================================================
Networking Notes 
==============================================================================

EVE Online player social interaction empowerment is the key to many years of playability for the player
	- the social constructs built into the game that encourage interactions (and long term interactions) and which even emphasize a meta game over the traditional game, are keys.
	- the meta game is much closer to real life role playing and participating in a fantasy realm.
- good AI is important and player driven (at least in part) world building is important, but those are still secondary to things like players being able to form contracts with one another.  PLayers driving missions.  Players being able to forge alliances, sign treaties, plege allegiances, and to have these diplomatic interactions enforced and be binding to the player.  Costs for breaking deals (assuming this is allowed) should be comensurate with the deal itself.  
	- so if you want to remove "grind" the _only_ solution is to allow inter-relationships mimic real life.  The interactions are complex, but the world can remain relatively simple.  
	- guilds, alliances, cease fires, 
	- for wars, allow players at high levels to have X amount of clansmen that basically allow that player to respawn and join the war instance X amount of times.  Then once they are all dead, they are out of the war and the remaining clansmen are allowed to continue.
		- when the player respawns after their final death, they cannot join the war, but the story goes that they were wounded and recovering and unable to join the war.  
		- this mechanic is a good way i think to make combat within "wars" feel a lot more weighty.
			- unlimited respawns detract from the gamey-ness of war
	- i think focus on economics is generally a bad idea in MMOs.  This is because economics are unfair and the game gets unbalanced.  A game built around material things like items, weapons and gold is not a long term game.  In most games at high levels money becomes worthless anyway and all it does is unlock the ability to get items.  So why money?  An unlock provision alone should be good enough.  The real economy of the game is in playing the game.
	- bounties, player created missions for others to take on, 
	- player controlled NPCs
		- this is an extension of world building.  The NPC's arent manually controlled instead these are NPCs who are members of your fellowship and who you lead (like Mount & Blade) and who you can assign duties to such as protect your village).  
		- this provides a completely different element to the game.

	- i think Everquest Next is focussing too much on the procedural world and player driven world building.
		- player driven world building is great but it often feels way too tokenish.
			- if a player can build a world, id say, give them a swath of land and do not let them modify the terrain. 
				- but allow them to cycle through sections of real estate they can choose from.
			  - only allow them to build structures on it. 
			  - 
	- social constructs should not be limited to the types of "contracts" that appeal to men. (eg. bounties, trade, etc)
		- what about marriage constructs?  and grounds for divorces?
		- what if there was a meta system where a player could manage and grow their estate?
			- female players might enjoy "playing house" by managing servants on their fief and acting like Scarlett O'Hara?
			- they might also enjoy dealing with the social issues of their employees (maids included) and helping them resolve them.
			this is all just food for thought, no idea yet.
			- managing farming, crop cycling, what gets planted in what field
			- animal / heard maintenance
				- roles for maids, who is milking, who is cleaning, etc
			- throwing balls?
			- attending festivals
			
	- i sort of prefer the idea of a very massive world that is fully constructed of user "kingdoms" and where a big bulk of the play is not warring, it's in role playing and playing games within the game and thus using the game as a chat/social interface primarily.  Their avatars are then agents for use in changing the game, shaping the world, exherting the players will when diplomacy doesnt work.
		- a full blown first person realm is counter conduscive to all that.  
		- a more traditional isometric MUD can allow for much deeper and broader gameplay.
		in fact if youlook at screenshots like http://forums.tigsource.com/index.php?topic=34168.0
		you see how problematic it is to make giant worlds with realistic terrain using a first person or 3rd person perspective with a realistic world.  You can actually get a much more believable world by using the abstract isometric view and making it extremely vast and using a world map to travel long distances.
	- Political System
		- im not talking about governments and elections and campaigns per se, i'm talking more about the systems that a game would need to have as native constructs to support such things.
			- voting?
				- how do you make it binding? (Func<issue, min term, max term, can be appealed, voting period>)
				- well maybe this is a bad idea.  A game like EVE, these sorts of user interactions are done outside the game.  The game does support memberships into various guilds though, but i dont think they themselves support management functions of the guilds themselves.
			  
Progression towards networked gameplay
-----------------------------------------
- lobby does not track all users does it?
	- it certainly does not inform all users of all other users logged in
	- it does not inform user of all games, only filtered games based on some settings.
	- for a specific table the user wants info on or wishes to join, the players at that table are reported.
		- for persistent dog fighting games, the user can go to the "table" view page but from there can only join... 
		- persistant game types as opposed to non persistant do not get removed from list of games in the lobby.
	
- get authentication and lobby bullet proof and 24/7 on their own.
- get gameserver bulletproof and working with a persistent single solar system universe, and basic newtonian movement sans gravity
	- spawn one enemy for every user in a region.
		- that enemy targets the one user only
		- when that enemy dies, spawn a new one.
					- no orbit mechanics, just simple direct thrust movement.
- client lobby and ability to join/quit/anytime
	- server browsing  (useful for editing and gameplay.. hrm..)
	- disconnect resume

- players must be able to host games
	- to host a game, player logs in and selects "Create Game"
		- but these are for specific types of matches... what they can't host are the 24/7 servers.  Why not?
		- they wait for players to join the table and then they start
		- once the game starts the table is removed from list of visible games
		
- we'll run our own as well for the 24/7 furball servers and for some persistent campaigns
	- persistent campaigns require a cheap subscription (something like $25.00 a year)
	- the 24/7 style servers authenticate with authentication server, starts it's games, then logs into the lobby to describe the types of games it is running so they can be broadcast to users of the lobby.
- perhaps some match style games can be hosted via a "Create Game" command to a game server via an admin tab in our client
  #ifdef ADMIN_CLIENT
  so that all commands from all clients are validated and authorized by our own server to prevent cheating for important games. 
  Heck, it's also a good option for people running their own servers and to be able to remotely have it create games of it's own so  to do that the gameserver when connected to lobby must be able to host table matches as well as persistent.
  
  HOW DOES THIS AFFECT DATABASE FOR GAMESERVER?  <-- well for alpha we'll just ignore and only worry about reaching alpha for a single furball persistant server   - also mainly our games database is for statistics tracking.  Part of the fun of playing a properly registered client that must authenticate is that stats get updated to the server.
  So that's our basic reqts.
	- users must be able to create tables and register persistant games
	- gameservers must be able to create tables and register persistant games
	- an admin client should be able to have the lobby tell a game server to create some type of table games or  persistant games.
		- we're going to try to use TCP/IP and keep our bandwidth way down like a poker game

	- only one game can be hosted per authenticated connection.
	- only one instance of an authenticated connection allowed connected to the lobby
		
	- tournaments list (just like in Ultimate Bet or something)
	- a list of custom created user games (traditional master server browsing)
	- a list of custom persistent furball (deathmatch or CTF style) servers
	- an automatic ladder system using predefined game rules and maps 
		-  co-op ladders for 2- 16 player per side teams
 	- DONT - send entire user lists
		- only users added to buddy lists (sortable by clan mates, friends, relatives)
			- perhaps an ability to have your friends list "public" and "personal" sections and users can then spider your lists to see the social network between them.
	- DONT - send entire games lists
		- it's always a filtered list of some kind kgbgame_persistent001


Network server browsers
-----------------------------------------
http://www.qtracker.com/
   http://www.serverbrowser.net/
   
 DC Universe trailer
 http://www.youtube.com/watch?v=H7Nf-m6WGl4
 
IP to country flag
-----------------------------------------   
   downloading the IP CSV (lat long) there seems to maybe be a way to even do a bit of friendly nation versus matches where we track on our stats the wins and victories by country and by city and such
http://www.ensode.net/postgresql_csv_import.html   <-- import csv into postgres

- x,y,z - w coordinate is for instance id and entities can only see each otehr that are on the same w coordinate.

- get within a meter of hidden objects (things that can be scanned) before the server will send you entity over the wire so you can't hack it.

Stand Alone Server Modifications
- what to load, what not to laod
- Zire uses procedural so he can just load on demand
	- we can use procedural in terms of the client knowing how to generate textures and planets, and we effectively use procedural to generate star systems, and can then compute an orbital position based on the current time.  But I think initially in terms of the server or loopback holding the entire universe.. that is at least in terms of holding region arrays, that is something we'd have loaded and to what degree things would be loaded, is more loosely handled (empty region with seed, sphere bounding volumes, ship hulls, and then actual geometry and textures for client...


http://www.gamedev.net/community/forums/mod/journal/journal.asp?jn=345337&reply_id=3661606



http://my.bzflag.org/w/Network_Protocol#Message_types
from BZFlag
A player normally only sends an update when its position or orientation as could be predicted by other players differs from its true position or orientation by a certain tolerance. Other players are expected to use the last known player data to extrapolate the current position and orientation. This technique is known as dead reckoning and has two primary benefits: network traffic is decreased since updates needn't be sent continuously and players on systems with slower frame rates appear to move smoothly to players on systems with faster frame rates. 

Rather than spam position and such, in my game i really should be able to get away with only sending a server update once per second unless my velocity or angular velocity has changed.

Lidgren notes
------------------------------------------------

*** I get how acks are generated.  It'd be nice if stored messages and resends could be made a little more generic so that even if automatic reliability is turned off in the library, the user can externally do their own resends by calling those methods directly.

This way we can also directly alter the buffer if need be, if for instance we want to use delta packets where some new packets will replace previous packets.  However, maybe that is best done outside of the app entirely...  but there's the rub, we would still need to be able to associate those acks, with a buffer that is changing to include more and more accumulated deltas.

**** So how would delta packets be retrofitted?  You have a message that is of a commandID.  If you get a new command that has updated info, you could search the outgoing buffer, update the relevant bytes, and not quite sure about how to adjust the acks because if these are being sent UNRELIABLE, then we need ACKS to be sent anyway... unless for NetChannel.DeltaPackets.  However the CreateAcks() shows us that if we create the Acks on the fly, we can pack them better.  Similarly it seems, if we created the delta packet buffer on thefly using just the commands (outside of the library then) then this could be good.

      *** So again, how would we deal with acks here?  Acks tell us which commands in our history can be removed in the creation of our "delta packet."  So part of what we'd need then perhaps is an option to get an event for when an ack for a deltaChannel ACK packet is received, and to be able to know that an ack with a certain id automatically removes the need for all commands less than a certain timestamp.  So the critical aspect is that we are able to identify the ack.  This is elegant because this way we're still just looking for a specific ack and the trick wrt to the delta packet is to not "store" the message in m_messageSTore because it wont use Reliable.  It'll just be a special UnreliableDelta that will generate an ACK.



- the main server code is single threaded.  
- it uses i think queues only because while that thread is read/sending messages, the calling application of the library can be reading/writing to those queues from any of its threads and so it needs to use locks so that the calling app can be multithreaded.

- so this doesnt change the fact that we will want to use IOCP, but it does reinforce the idea of maintaining a common queue at least until down the line when we might use an external queue such as MSMQ

Authentication
------------------------------------------------

1\ to host a server, you need to authenticate and then you'll get added as a service that other users can log into that of course could easily be hacked on the client side with an exception that you can still run server initiated re-checks to authentication at anytime to ensure that the client is legit... this means they would have to decrypt and sign with a key they were given proving that were able to receive it


LOBBY vs MASTER vs STEAM 
------------------------------------------------

authentication v lobby v master server v steam
- in evo's lobby, when a game is ready to start, the player is automatically sent the info to connect to that game.
- in a dedicated authentication, the only games a user could join would be the 24/7 looping servers that didnt care what users were in the game.  


- master <-- used when no matchmaking is required and anyone not banned can play. (perhaps with some ping restrictions, regional restrictions)
- lobby <-- required for when the particular players allowed are determined through lobby matchmaking
	- buddies

Unlike Lenn's game, i will be able to have a server just "start" a game after waiting for a period for users to transition from the lobby... and when the game starts, i can have the servers notify a tracker that updates the kgbtracker database.  Then if a user wants to join another game, after failing the first, they lobby is quickly able to verify with a tracker that the player never started in that game afterall.  In fact similar to Lenns,  players registered to a game will be added to the in progress games tracker but when the game starts and they're not in it, the tracker will be responsible for removing them.  Likewise, the tracker can completely shut down and free all players from a registered game that failed to start at all for any reason for x interval.
--

What if the master server was also an authenticating server?  I guess the first thing i need to remember is that i can quickly ramp up the otehr server types if i just build a lobby that properly supports the different types of server monitoring
	- no global lobby chat, just private chat and table chat.

--
	- as far as users wanting to host their own non 24/7 servers, well we probably have to allow that if we get anything close to the number of users we would ultimately like. (plus we could never offer a good experience to foreign users with just one US server) a user that has  acdkey, starts his server, that server registers with master or lobby, and gets a tracker to upload results and such to.  The one rule we could enforce is that the owner of a dedicated server cant play on his own server from the LAN or directly at keyboard.  He must do so over the internet.


Instant Action Servers
---------------------
for the 24/7 servers, it's just like Counterstrike
	- the games are basically infinetly looping in "levels" or "maps" and either free for all, x versus x, just keep going.  Maps are different for the different game modes.  That is to say, some maps are only compatible with certain game modes.
	- the server browser for these types of games are justlike counterstrike.


Match Servers
----------------------
for the sit-n-go games, it's a lobby

for the long duration persistent campaign games, these are coordinated like sit-n-go games only after they start, instead of being short term scenarios, they use large campaign maps and can potentially last days or weeks or months.


Ladder & Tourney Servers
-------------------------
for the ladder games, the matchups are chosen for you but you can play anytime you like and the ladder play keeps going forever with no utlimate champion like in a tournament.  However, there can be ladders where every player is only allowed to play say 12 matches or 100 matches, etc.  So they can end.

for tournaments, the matchups are chosen as well but there's a limited number of games and the brackets narrow until there is a champion.


any server can then use attributes
	- tracked
	- official
	- private password
	- 

About Starcraft networking model
--------------------------------------------------------------
 http://aff2aw.com/blog/starcaft-networking.html
Starcaft is the most popular RTS of all time. It might not be the best but it is the most popular. Just recently I got into an discussion on how StarCraft implements networking. We where talking about two types of networking which are lock step networking model and server correcting model.
 
In lock step model every thing happens on all the clients at once and only the client commands player commands are exchanged between the players. This requires 100% deterministic simulation so that each client simulates the game exactly the same.
 
In the server correcting model the clients also try to simulate the game world. But they don't have to be exact. Some clients can use GPU for physics while other use CPU. Some clients might not even have access to the whole game state just what server gives them. Server periodically corrects the clients.
 
Starcarft definitely uses lock step model of networking.
 
Starcarft packets are divided into 2 main groups. The Command1 group and the Command2 group. Command1 groups packets handles with joining or leaving the game while Command2 group handles what happens during the game.
 

Command Group 1
 
Each command one packets stars with a Command1 packet header. This includes check-sum to verify the packet is correct. Thats odd considering the network software/hardware already should do that for you even when you are using UDP. Then it also contains flags to verify and resend lost packets. Does not appears that there is a notion of unimportant packets - probably no need to since this is using lock step model. Then it has sent and receive counters - so that packets stay in order. The flags and ordering combined nicely make the packet loss-less TCP type connection work over UDP.
 
The commands in this group includes Join Requests, Ping, Pick Player position, team, and race, Get Game state, Get Map and Map options, and some Leave Messages.
 
The random seed is also generate at game start. Even though random numbers are random they sequence they come in is not. And this sequence is picket at game start and is used for the duration of the game.
 

Command Group 2
 
This command group is more interesting because its where the real time messages happen. They are very similar to the command 1 group. The messages are sent about 4 a second. Avg time between messages is not quite 250ms but is 219ms probably because the speed constant is easy to tweak. The interesting thing is that every time step a command group 2 packet is sent. Each command group 2 packet contains N sub packets or a special NULL packet if there isn't any. This is how starcaft knows when to start a new simulation turn I guess when it has gotten all packets for that time step from all connected clients.
 
The type sub packets are a lot like what 2aw has. There is player selected units packet and a player selected units to add. Kind of odd considering you can select up to 12 units any ways.
 
The is order packet which is used for all the orders. There is lots of different orders in starcaft even if you don't realize it.
 
Then there is a lot of packets which just active deactivate abilities. I find this odd because there is ton of abilities in starcaft and i would have though that having just use ability and stop ability with and ability ID inside the order would have been enough. If they wanted to optimize and move the ability ID into the space of packets why didn't they do that for orders too?
 
There is no order queues in starcaft. Some thing that was one of the 1st features to make it in 2aw because i love it so much.
 
There is also some messages commands - interesting to note that both command1 and command2 has sending message packet, one in the game lobby and one in game. Its interesting that game lobby is handled by the local game server rather then the battle net lobby - which I would have though be more logical.
 
Note there is no unit positions, health, or stats updates ever. Even when they get build or die. Only what player clicks and orders - that is because using lock step networking model all of that can be derived.
 

RTS Networking
 
Talking about RTS networking always deserves a metnio of the "1,500 Archers" paper about networking in Age of Empires. It looks like starcaft does it nearly the same. I wonder what the modern RTS like SupCom, WC3, Wic, and SoSE doe for networking. Do they jump on flexibility of server correcting model or do they still stick with tried and true lock stepping model.
 
See more info here: http://forum.valhallalegends.com/index.php?topic=17702.0

			
Second Life Networking details
--------------------
http://wiki.secondlife.com/wiki/Avatar_Appearance#Level_Of_Detail_.28LOD.29_mesh

Permissions block 
First line: The token permissions followed by the permission block version 0 
Second line: open brace { 
A sequence of permission name/value pairs, each on its own line 
Final line: close brace } 

The permission name/value pairs are: 
base_mask, with 8-digit hexadecimal value 
owner_mask, with 8-digit hexadecimal value 
group_mask, with 8-digit hexadecimal value 
everyone_mask, with 8-digit hexadecimal value 
next_owner_mask, with 8-digit hexadecimal value 
creator_id, with agent UUID in hexadecimal 8-4-4-4-12 format 
owner_id, with agent UUID in hexadecimal 8-4-4-4-12 format 
last_owner_id, with agent UUID in hexadecimal 8-4-4-4-12 format 
group_id, with group UUID in hexadecimal 8-4-4-4-12 format 
group_owned, with 0 (false) or 1 (true) flag 

If a name/value is missing, a default value is assumed. For maximum compatibility, everything should be explicitly specified except group_owned when false.
 
Flags are defined in llinventory/llpermissionsflags.h: 
PERM_TRANSFER = 0x00002000 
PERM_MODIFY = 0x00004000 
PERM_COPY = 0x00008000 
PERM_MOVE = 0x00080000 

Common masks are: 
PERM_NONE 0x00000000 
PERM_ALL 0x7FFFFFFF 

And common values are: 
no modify: PERM_ALL & ~PERM_MODIFY = 0x7fffbfff 
no copy: PERM_ALL & ~PERM_COPY = 0x7fff7fff 
no modify or copy: = 0x7fff3fff 
no transfer: PERM_ALL & ~PERM_TRANSFER = 0x7fffdfff 
no modify, no transfer = 0x7fff9fff 

		
	NetConnection sender = message.Sender;
	int id = message.Buffer.ReadInt32()
	switch (id)
	{
		case Enumerations.JoinGame:
			CommandBase cmd = Create(id, buffer);
			cmd.Execute (lobby.JoinGame, 
			LobbyAPI.JoinGame (cmd, sender); // no need for a cmd.Execute because the api function handles it using supplied args.
			                                 // and this API can be overridden in derived types so client and servers can handle differently
											// or entirely different api's can be called if client receives vs server
			break;
		case Enumerations.PerformBehavior:
			PerformBehavior behavior = Create (id, buffer);
			// don't queue this behavior/command, execute immediately...  but we could easily switch later on
			// when received here we could do behavior.Sender =sender;
			// or we can wrap the command/behavior in an object that will include the Sender
			// note here there is no behavior.Execute ();  but maybe there could be... hrm.. but then
			
			// perhaps below could be sent to BehaviorAPI.PerformBehavior (behavior, sender);
			EntityBase entity = GetEntity(behavior.SourceID);
			entity.PerformBehavior (behavior.Name, behavior.Args);
			// how do we know whether we need a Vehicle reference in the Args?
			// there might be a function in the entity in question to get whatever references to a vehicle parent it needs.
			// otherwise like in lua, the args just need to be specified in an agreed upon order
			// so if say a target ID to fire a laser at is one of the args, we can call a function to get the entity represented by it
		default:
			break;
	}

		// actually from reading this codeproject article 
		// http://www.codeproject.com/KB/cs/DelegateBusinessObjects.aspx
		// he has each class implementing a CreateRules() method and thus
		// all we really have to do to avoid some of these rules (e.g. build rules, game rules, etc) from being available
		// for inspection by the client is to use a Delegate for that CreateRules() method as well and don't allow
		// those same delegates to exist on the Client. 
		
		Validation... I can see one advantage to the above which explicitly is mentioned in the articles which is
		here validation occurs prior to being able to persist this object and that otherwise, it's ok to have
		invalid properties on an object.  
		
		But now I'm realizing a few things.  1) This type of validation doesnt really fit with my ICommand model
		where i need to be able to undo/redo explicit commands (editor or build).  Further, issuing orders to crew
		ICommand.Sender <-- add a Sender object property that can be used to identify issuer of the command.
		
		IResponse <-- results of commands including any details about why the request was denied.
		
		 //mHost.ChangeMaterial(AmbientR.Value, AmbientG.Value, AmbientB.Value);
           // mHost.ChangeNodeState();
            System.Data.DataSet ds = new System.Data.DataSet("Material");
          //  mHost.ChangeNodeState (id , ds);  // dataset effectively contains the member name (eg. "ambient" and the value) so we
            // dont need a "message" param
            // DataSet solves the immediate issue related to my plugins... 

            // in Evo we had these rather complex field type structures so that Lenn wouldn't have to write any SQL
            // but now... im thinking maybe we can \ should for 1.0 just hardcode our SQL queries for our various object types
            // We can still abstract that away, but we wont need these gangly switch statements to convert the fields to from
            // those structs just so we can avoid hand writing all the sql queries.  I think we can still use
            // StorageContext 
            System.Data.DbType fieldType;
            System.Data.DataColumn column;

            //column.DataType = 
            //column.Caption = 

            // note: if i stored the childID as binary and the typename ID as an int that i lookup for string table name
            // then parsing that field could be done extremely quickly so the subsequent call to grab the child ent could be pretty fast
            // could stored procs be written to do that to avoid sending multiple calls across the dbconnection?


            // IStorageContext
            //      SQLStorageContext
            //      BinaryStorageContext  <-- creates an IRemotable byte array
            //          - but does this send just the top + children types/ids or does it have to send the entire hiearchy?
            //            if you send the entire hierarchy you wind up duplicating a lot i think...unless you wind up having to make a seperate
            //            request for the id's of all children that you dont already have cached\stored in the db
            //

            // maybe i can store the mappings for each type in a file.. xml or just CSV


=================================================================================================
SCRIPTING
=================================================================================================

TRIGGERS and SCRIPTED SWITCHES - LOD, RollOver, Damage, etc
---------------------------------------------------
such as the Control entity having specifically a means of following any specific path down a switch.  But again, im not sure how this is done without code... 

well a simple index value is fine for determining which child item in a switch BUT, what if there's multiple switches, then what do we do?

Typically during traversal, when reaching a switch, the switch should then query the Entity and determine which path... ok... for an LOD switch i can see, for Damage switch i can see... for RollOver switch... hrm... does it just check RollOver?  Is it possible to have a more generic implementation that doesnt depend on the type of switch that exists?

YOU COULD HAVE A SCRIPT ==> that the user sets/types for that entity that when the traverser reaches a switch, the switch then says "Hey Entity, this is my "name", which path do i take?"  and then the Entity responds with the index of the child switch (and if that index doesnt exist the switch goes with default)


NOTE: In gamebryo, they read arguments from a byte array just like i did with my plugins!  And just like with plugins, i can still force the scripts to communicate in a way that goes through our network layer... rihgt?   
Well the only way to really know is to start a test ship that has an engine and an on/off switch. 

Rather than using these ROUTEs, lets just script these node types....  and just like with my plugins, users will actually go through a specific ScriptingInterface and will not direclty modify types.  This way we can handle any ICommand / IRemotable we need.
http://www.youtube.com/watch?v=PoV8sOyXZS8  <-- in fact restricting them to an interface for scripting is exactly what Gamebryo does!
http://www.youtube.com/watch?v=z-EuS1EYk8o  <-- lua in leadwerks
http://www.gamedev.net/community/forums/topic.asp?topic_id=457999  <-- using lua scripts many times... as in on server
http://gamedev.stackexchange.com/questions/3453/would-using-lua-scripts-to-define-game-logic-for-an-mmo-server-be-a-lot-slower-th 
where he says 				
		
		
///////////////////////////////////////////////////////////////
////    On Sun, 22 Sep 2002 22:55:30 -0500
////Steve Baker <sjbaker1@airmail.net> wrote:

////<snip>

////I'm in work so I don't have a lot of time to type: I'll try to give more
////answers later.

////> * How should the game handle collision detection for scripted objects?
////>   Does
////>    the script make collision detection queries and do the business of
////>    stopping the motion when it hits something - or should the game
////>    engine deal with the consequences of a collision and just inform
////>    the script what hapened?

////Event queries are possibly a bad idea - you could end up with all
////manner of odd timing behaviours. One method you may want to try is to
////let scripted objects register handlers that are called by the engine
////when specific events are detected. So say that when a scripted object
////hits a wall, its "on_scene_collision()" function is called. When it is
////hit by a projectile its "on_projectile_hit()" is called... 

////A possible plus to the event method is that you could have "default"
////events, so that the engine can provide a bunch of default behaviours,
////but the script writer can override the defaults if necessary.

////> * How does the scripting interface deal with telling the script the
////> position
////>    of the player and other creatures?

////One method you could use is to have a set of query functions 

////get_named_object()
////get_enemy_list()

////or the like and give each object in the game a unique name. you could
////use this to at least partially prevent rogue scripts mucking up your
////enemy data. Or maybe just expose the object list and let the script deal
////with looking at it - that's a grubbier option though.
 
////> * Should scripts be able to communicate with each other?

////If you have named objects, you could have a

////send_message(object_name, message)

////function. Give each object a queue of messages and send_message() adds
////messages to the end of that queue. You could then use
////a get_next_message() function to pull messages off the queue, or if
////you're implementing engine-triggered events for collisions you could
////even allow objects to register an "on_new_message()" event handler.
////Or provide a get_next_message() function that is called from within an
////on_new_message() handler to go through all the new messages in the
////queue...


////> How do existing games deal with this stuff?   Is there a 'classic'
////> game somewhere with a scripting interface that's known for having "Got
////> It Right" ? If so, where do I go to find out how it works?

////One place to look would be the Quake and Quake2 source code, they'll
////probably give you some good ideas to start with. I'd also really
////recommend that you have a look at the sources and receptrons system in
////the dark engine (Thief, Thief2, System Shock 2) which is an immensely
////flexible system. Unfortunately the source isn't available - you'll need
////to work out how they work by using them. There is some extensive
////documentation on S&Rs on Dromed Central at

////http://www.thief-thecircle.com/dromed/navsubject.asp?subVar=STIMU1

////S&Rs combine event handling, messaging and a load of other tricks. If
////you don't have Thief or Thief2 this probably won't be much use to you
////though - you really need to play around with S&Rs to see what they can
////do. There is also some stuff in both Game Programming Gems 1 and 2 (not
////got my copy of 3 yet...) 

////Chris


////    I have a bit of experience here, so I'll take a crack at it...


////> * I could provide (for example) a function to position an object that 
////> 'belongs'
////>   to the script at a specified X,Y,Z,Heading,Pitch,Roll - but should I 
////> instead
////>   make the interface be Velocity+Direction and let the game do the 
////> integration
////>   down to positions - or perhaps the interface should just be a place to 
////> head
////>   towards and a choice of several 'modes' of getting there?

////You'll probably all three approaches. A script might want to add a
////new static object to the world (1), or maybe apply forces to all
////dynamic objects to push them away from an explosion (2) or run a
////pathfinding algo to get from a to b (3). Pathfinding is generally
////too cpu-intensive to be coded in a script.


////> * How should the game handle collision detection for scripted objects?   

////Collision detection should happen in your C code (too slow for
////scripts, and script writers don't want to be bothered). When a
////collision is detected call a hit() function or similar on the
////scripted object and pass it the object that it hit. The script
////can then determine what to do about the contact.


////> * How does the scripting interface deal with telling the script the 
////> position
////>   of the player and other creatures?

////I have a FindEntity() that can locate another object by name.
////The script can store a reference to the entity in a variable, and
////then call GetPosition() etc. as needed. That is, the scripted
////object should ask for what it needs.


////> * Should scripts be able to communicate with each other?

////If you allow this, it should definitely be through some sort of
////indirection like messaging or an event system. That way a script
////can safely ignore events that it doesn't recognize. For game objects
////it's not too bad, because you can standardize the interface to
////a "thing", but for the AI logic it does get kind of fuzzy. The
////best bet is to keep object boundaries clear.


////> How do existing games deal with this stuff?   Is there a 'classic' game
////> somewhere with a scripting interface that's known for having "Got It 
////> Right" ?

////It has been my experience that the *best* way to this stuff is via
////a plugin/component system. No matter how much stuff you give the
////scripters, there will always be something you didn't think of.
////Create a simple base of functionality, a standard object system
////for your scripts, and a standard way to add to it.

////A good place for info on these kind of things is the unrealtech page
////at http://unreal.epicgames.com.

////Jason
////379

Components scripting
-========================
in this document, search for without quotes "There are a variety of benefits over the previous implementation"   and there is a paste of a cocnept by someone who was thinking in anti-objects terms.  Put more responsibility on the components for handling various integration with parent entities... and do NOT have the parent entity responsbile for everything.  Consider how adding any new thing forces aall parents to be modified in that case.  that is lame so the antiobjects thinking is good here?  maybe,... im just typing this to remember but i havent thought it thru properly yet.
core engine scripting demo
http://www.youtube.com/watch?v=_nNBwUUUx2w&feature=related


I see a lot of game scripting examples where all they are doing is scripting "content."
And it's a lousy way to teach scripting I think because there's no sense in scripting
availability of things or the attributes of things or data driven behavior.  
We want to script entirely new behavior that goes beyond simple data driven behavior.

so lets start by making our female character an NPC and scripting her behavior.
 - get a gun in her hand
 - have the gun have it's event types.
 - maybe have two of them, and have them fight
   using different behavior each

-------------------------------------------------------------------------
SCRIPTING - THIEF - RECEPTRONS, STIMULUS
-------------------------------------------------------------------------
Important note about Sensor Detection (actually maybe rethink with the thief style receptron/stimulus method that is easy to script and elegant code wise too)

- the server should create a sensor profile for the various types of detection for each craft and then use that profile to 
broadcast explicitly a value to other units.  Why?  So we can create decoy profiles.  A player can construct a decoy emitter and attach it to 
something or a countermeasure and since it's a real entity, it will be received by remote players just as if it were any other type.  In other words
rather than tell the user they've contacted something, we send them sensor return data and then it's up to the player/npc sensor operators to determine
whether the signal is real or not.  Part of that could be comparing the return data's signature or something.  This is something we can
implement sooner rather than later as part of how our sighting/detection works
reactor.OnTick()
{
	// this onTick for component specific simulation shoudl run at just 1hertz.  We could alternate
	// every .5 hertz where power gens create power and dispatch, then in the second .5 hertz the 
	// power is consumed and those devices perform if active.
	if (this.PoweredOn)
	{
		output = this.PowerOutPutPercentage * MaxPower * this.Efficiency 
		
		// deliever units of power to all devices 
		remainingPower = output;
		while (remainingPower > 0)
			foreach (PowerConsumer device in mDevices)
				if (remainingPower >= device.PowerReqt)
					// emit power to this consumer
					// todo: i recall wanting to use the theif darkengines concept of stimulus & receptrons and such... but now the details of how
					// i was going to implement that are more sketchy.
					
					// a Star should produce a unit of heat and send that to every vehicle or craft in range... those vehicles
					// can then propogate that heat and it may not penetrate the armor and do no damage except maybe raise the hull temperature.
					// But this sort of stimulus object sending to receptors offers a generic way to deal with transmissions of energy (kinetic energy too) and programming the responses based on the type of energy as well as the type of receiver that's processing it.
	}		
}

to me the concept behind Thief's sources and receptrons is that a source is a type of stimulus object
and the receptron is an object that holds various properties for responding to a received stimulus.  
The receptron is thus a definition for the resulting behavior that should occur when a stimulus is recepted.
Thus receptron is synonymous with "response" where all these various responses are specifc.
The key to understanding receptrons though is to understand the benefits of being able to communicate
in terms of Stimulus and Receptrons via scripts because it simplifies the interfaces needed and 
yet it provides a large enough vocabulary to be very expressive and flexible.

However, the above description of how its used and why its used isnt very concrete.  First of all
this language provides specific actions and events and so is completely un-nebulous.

For instance, an arrow that hits a guard in the chest... that arrow is a stimulus and is handled by a receptron on the guard that is scripted to handle the specific stimulus class that is being applied.  

Thus, a quick dictionary lookup of  receptron[stim.GetType().Name)].Apply (stim) can be done.  or perhaps first a TryGetValue(stim.GetType().Name) so that it can be ignored.
a Key thng about these scripts is that really they're not performed that often..  So a question might be
all of these perhaps little scriptable objects, are better than scripting all the individual entities?  

I think the obvious answer is found in looking at the nature of receptrons and stimuli.  The stimuli is emitted and the receptron absorbs and so the source and target entities are different and yet all the information on how a stimulus should affect a target is embedded solely in the stimuli object and the receptron.  So you can fire a blue green laser with 1000 watts of output, and that stimulus contains all the info for the damage that can be done against various materials.

It then applies to a receptron that is charged with handling that particular class of stimulus and combined, damage results, and sounds, and fx are all contained with no need whatsoever for that info to be contained in either the gun or the hull entities themselves.  They instead exist solely in the output and the input entities themslves which we call stimulus and receptron.
 Entity.Receptors[]   
     Entity.ReceiveStimulus (stimulus)
      {
how do we implement fall through?  Where say some stimulus is reduced by contact, but not entirely and so falls through to other parts?  I think from the server side, that must be computed ahead of times so only specific final affects apply... however, they use the receptor pattern so those client side scripts can run and produce proper sound and visuals and animations and particles such.
          foreach (Receptor receptor in mReceptors)        // the potentially cool thing here is that these stimuli can be sent over the wire
//              bool result = receptor.TryApply(stimulus);    // and much more easily occluded, or otherwise not sent to users who cant/shouldnt see them
                
      }
A laser "OnFire" script might emit a Stimulus every 30 ms while it's firing. (or some configurable hertz)  But by objectifying emissions (including radio emissions and such) our receptrons act like geiger counters and our interactions become much more easy to govern.

And so your actual entities can be rather simple, but combined with a bunch of receptrons can end up being able to respond in complex ways.

Receptors absorb stimulus.  In effect, Receptors are both sensor objects and physical response objects since Receptrons can be used to detect signals and such as well as deliver damage to the host of that Receptron.

I think the key thing about so called stimuli and receptrons is that they are more akin to "material" properites of something in the world.  So they can help dictate in a generic way, what sound should occur when a certain stimuli hits a certain receptron.  In this way, you're scripting those specific interactions and NOT having to script how a bullet interacts with every specific NPC out there.  Instead if that NPC has a specific receptron to handle a specific stimulus that receptron can be shared across many NPC's or even non NPCs.
      // waterEmitter <-- type of stimulus
      // fire_receiveWater <-- type of receptron

a radio transmitter can emit a single Stimulus to every enemy in range (via server side tests) modified by the enemies instruments sensing capabilities (eg they have a Receptron that can detect the Stimulus) think....  What I do know is that we want/must start narrow focus and _only_ expose what we need when we need and to consider anything we add and whether it would represent a way for players to cheat in multiplayer.

http://thief.wikia.com/wiki/DromEd/Properties/Act_React/Receptrons
http://thief.wikia.com/wiki/DromEd/Properties
 
So in turns of scripting the above, obviously Stimuli and Receptors are individual scripted objects that are easily shared.
However, we ended up potentially needing lots of them.  Object explosion...
And they don't entirely replace in fact the scripting of behaviors like OnHit (where a receptron doesnt know how to specifically tell a ship what type of lod damage model to switch to or something) or OnDie, or OnSpawn etc.  Those we still need.
All this specifically does is objectify the interactions between emitters and receptors.  
In this sense, our game interactions are much more object oriented.  Perhaps this is ok so long as we can share lots of Receptors and not have a ton of unique implementations.

So how does this impact our actual implementation decision where im still trying to resolve how to tie
entity scripted behaviors to entities, and then later entity's receptrons's responding to stimli.
Well in terms of our Receptrons, i think one very useful feature is that types of receptron can only be added (hosted by) entities which have specific interfaces.  e.g.   within the handling of 

     receptor.TryApply(stimulus)  // where say stimulus is laser beam and receptor is just weaponHit
     {
         // we know that the mHost of this receptor has been cast as a IDestructable
         // 

TODO: I think best if a receptor flag is tested to determine if this Entity should respond to the emitted stimulus.  Then we use a flyweight to apply the stimulus based on properties of that Entity and properties of the Stimulus.
  IColdReceptor
  IHeatReceptor
  IConcussionReceptor
  IParticleEnergyReceptor   (perhaps same as IRadiationReceptor)
  IKineticEnergyReceptor
  IRadiationReceptor    ( but wouldnt we want different receptors for weapon energy vs communications energy like LADAR vs Beam?)
 IAlive -> ISentient


public class EconomicCycle
{
	mConsumers;
	mProducers; // do we need seperate mConsumers or should each consumer subscribe to a producer
		        // furthermore, they should be able to subscribe with a priority
	mProductionStore;
	
	public void Production()
	{
		for (int i = 0; i < mProducers.Length; i++)
		{
	
		    IProduct[] products = mProducers[i].Get();
			for (int j = 0; j < products.Length; j++)
				mProductionStore.Add(products[j]);
		}	
	}
	
	// seperate thread will now consume produced products
	// based on their access to the various production stores
	public void Consumption()
	{
	}
}

Star
	Transmitter[] Transmitters;   // gravity, heat, electronmagnetic interference, 
	
class Receiver
{
	string name;
	int type;
	
}

class Graviton : Emission
{
	
}

class Emission // aka Energy
{
	Transmitter Source;
	
}

// InitializationScript can add transmitters
target.AddTransmitter (gravitonTransmitter);
target.AddTransmitter (heatRadiationTransmitter);

// then inside of the Entity upon the adding of a transmitter, it registers
// Scene.Simulation.Register (Transmission, entity);
// 	{
		mTransmitters.Add (entity.ID, Transmission);
//	}

//  Simulation.UpdateTransmitters()
//  {
//		foreach (Transmitter in mTransmitters.Values)
//		{
//			
//		}
//  }

interface IShape
{
	
}

class ShereEmitter : IShape
{
	
}

class Transmitter
{
	int flags; // enabled, reqs line of sight to receiver, transmitOneTimeOnly, 
	string name;
	int type;
	int frequencySeconds;
	int lastTransmit;
	int lifeTime;
	int range; 
	IShape shape;     <-- perhaps shape is the defining aspect of a Transmitter
	               especially the GUI interface
				   <-- next is the 
					- fallOff
				   <-- what about when we want to emit a damage emission for instance only
				   when direct contact or very close proximity is reached... such as
				   a proximity mine or fuse?  This is a Trigger of course and not a Transmitter
				   but Triggers can emit too.
				   
	Receivers[] mLastReceivers;
		
}

// IScriptable
//      Scripts[] GetScriptableEvents()  // all - read only
//      Scripts[] GetScriptableEvents (InterfaceID) // only those scripts specific to a particular interface - read only
//      AssignScript ()
//      RemoveScript()
//      IEntity -> most all entities are scriptable 

//  Entity.GetEvents()
//  Entity.AssignScript(eventID, script)

// NOTE: THe primary purpose of these interfaces is just to describe those unique methods and properties that those types need
//           such as for PoweredMachine (TurnOn, TurnOff)
//           This will be important when we want to be able to do queries on our Vehicle to find objects of a particular interface
//          Then we can also sort those based on location (container\subassembly) on the ship

// IDestructable (Implements ICollidable)
    // note: regualar (non IPhysicalEntity) IEntity does not inherit IDestructable because some entities like lights or wayponts or portals are not physical entities
        // IPhysicalEntity - IReceptor[] mReceptors, void ReceiveStimulus(),  Tick() --> OnTick script
        // IArmor  -> armor is not a component as it does not have volume or count towards surface area (only assemblies count toward surface area)
        // IContainer 
        //     ISubAssembly (note landing gear will not be an assembly, we will handle that differently than GURPS)
        // IComponent -has weight, cost, volume, surface area, hitpoints, 
            // IWeapon  - consumes ammo and/or power, Fire - OnFire event script, Tick - OnTick handles recharges and reloads, Reload - OnReload, 
                                // - Fire OnFire - produces Stimulus (sound, muzzle blast/smoke, and a damage projectile stimulus  
            // IPoweredWeapon
            // IPoweredMachine  - TurnOn, TurnOff, 
                // IPowerSuppy
                // IFuelConsumer
                // IPowerConsumer
                // IPropulsion --> produces a unit of thrust each cycle.  Consumes a unit of power and/or fuel each cycle (also implements IDestructable)

Hrm...
   public class Control : StaticEntity, IEventHandler, IInputCapture  <-- Keystone\\Controls\\

I like perhaps that our scriptable events are in the form of  EventType.XXXX
so our dictionary of events uses EventType.XXX for key.
and some of these events can be null.  
So let's start simply by using our Control as our template since that will make it easy to just start coding...
Our various base classes can initiate the events in that dictionary, where some are null and some are not... we cant externally add new events, only replace existing ones in the dictionary.  So the question seems to be just how do we serialize?

each needs to be a key value pair of eventType, scriptPath  (if not null) So we can assign null, a default delegate or a script

But maybe better to just have the ScriptNodes to simplify how these are saved/read in our XML.  We still have restrictions on how these scripts can be assigned to the dictionary of scripts, (cant load a script that's not relevant and have it apply)
So what does this mean for our entity browser?   Do we see the script nodes and can click on them and pop up a plugin that is the script editor?
 
- EntityEditCtrl has to list the allowed events, then we need to allow drag and drop of scripts with option to createNew, and then name it and drag and drop and code it and save changes.


-------------------------------------------------------------------------

=================================================================================================
LOCALIZATION  (Resource files)
=================================================================================================
http://msdn.microsoft.com/en-us/magazine/cc163609.aspx

=================================================================================================
CONFIGURATION FILES
=================================================================================================
Normally when you launch any app, the config is read in at start and those settings are applied.
The Quake model was cool in how cvars were sent to the engine... so in effect, config was read in and the values sent in the form of cvar commands to the command processor.

Now when the editor is launched, we're not just dealing with graphics/networking/game settings, we're dealing with windows application environment settings persistance so this is a bit of a different deal.  Those settings can be saved in the same config, but they're not sent as cvars to the game engine.  

I think we would be taking a loaded property bag and doing
window.DisplayMode = bags.Properties["displaymode"].ToString();

So we're trying to acknowledge that yes there is a difference between windows application settings vs game engine settings.
Well that's somewhat shadey if you consider things like "showboundingbox" "showgrid" which are per viewport

However a clear distinction is the control panel startup whcih allows users to modify the config file
and then the actual launch, and then also runtime editing of settings via cvar commands...

Now whether we re-load the ini from within formMain or pass in initialized ini is a smaller question compared to the more fundamental questoin of how do we deal with xml config data and cvars and menuitems.

// the answer could be to do like Quake does and add a prefix to the cvar so that
                    // "showgrid" becomes  "vp_0_showgrid" and "vp_1_showgrid"
                    // and other commands like "dbg_enableprofiler" has the "dbg" prefix

How do we reconcile our Interpreter (which currently handles keybinds well and invokes
binded functions when a key mapped to an action is pressed) with our CommandProcessor.

Well, for starters our CommandProcessor has each command having the cability within itself to perform a specific task
aschronously potentially with ability to invoke a callback on completion and manage undo/redo stack.  The CommandProcessor
class itself is mostly just a manager for the running of these commands.

This makes the CommandProcessor much better for being extended to work in a network environment.  Yes there are tons of commands but they are simple and each is seperate.  This is perhaps better than having some huge switch statement somewhere

The interpreter on the other hand is a very simple immediate run keybind script that runs a (in the future) potentially scripted handler or a hardcoded one.  It's designed for key/mouse input interpretation and then execution of handlers and is not designed to be used over a network... for that, say a "Fire" input command that needs to be replicated over the network, we could modify our Interpreter's handlers to create Command objects that can be serialized across the network.

Indeed, in my editcontroller, i do use Command inside of MoveTool and LineTOol and such so that
these commands do go through the CommandProcessor, do get Undo/Redo stack management, and can be serialized across the network transparently by the CommandProcessor.  One of the clear beauties of having a CommandProcessor is that these commands are funneled thru a single point and can be serialized to network at one point as well as perhaps serialized to a "vcr" playback file.

Now some commands that dont need to be pushed onto the stack like a simple npc entity movement... only "Edit" commands need to have "redo" right?  In any case, how do i differentiate those?  And how do i make it so that these simple commands get executed very quickly... without lots of class creation/destruction?  Well recycling commands in a cache would help... what else?
 
Or if there were some kind of CVAR\INI Interface and each class that needed to handle gui, could directly output\input cvars that were under it's "section" name(s).  So it goes   forms\controls (menus\buttons\textboxes) --> cvarReader\Writer <--> Ini

Consider that eventually a lot of gui intitiated commands for actual gameplay type events should go through as a cvar that can be sent to the server and replicated.  So this really is necessary.  There difference is that those commands wont (typically) need an INI, but i think it's a good working example to use when designing this code.  cvars\commands arriving externally are reformed and added to a queue.  During the gameloop they are processed and handled.  How would a cvar in that case arrive and then get "read" by the IConfigurable so it can be saved to the INI?  I mean imagine a version of our editor that did not have a GUI at all and relied on command line to modify things like showgrid?  Clearly that goes to a command processor first, then somehow gets converted to a command that calls Viewport.Context.ShowFPS = bleh; and likewise calls IConfigurable.ReadConfiguration (string cvar); 

One theory is that if the cvar is created into a full blown command class, then it would have the code to do everything directly... knowing implicitly what it needs to do.   

Consider how a Fire weapon command + script works?  
Keep in mind how +fire and such works with interpreter to invoke handlers
  - this represents some differentiation of commands...?  
What about the difference between a "cvar" setting and a "command" ?

forcing all gui commands and controls in general through the loopback server would force me to write proper client / server code.


assuming each configurable class handles it's own ini read/write the nice thing about below is that each IConfigurable can write to the ini anything it wants and no other classes needs to know what any other class is writing.
IConfigurable
{
	string ConfigurationName; // e.g. "viewport0"
	bool ReadConfiguration (string cvar); // reads a single cvar that could have come externally from console
	bool ReadConfiguration (Settings.Initialization ini);
	bool WriteConfiguration (Settings.Initialization ini);
	Event ConfigurationChanged;  // as the user makes a menuItem change for instance, this can raise an event
}

in some ways a configuration can be thought of as cached commands, so reading them could in turn send across the network _if_ they are not just local commands.  I guess most configuration commands are local though.  I think the way to proceed is to implement IConfigurable and use those to restore saved settings.

assuming we use cvars generated by the say menuItemShowFPS_Click(object sender EventArgs args) instead we could do

Core.CommandProcessor.Process (string cvar)
{
	// determine the type of the cvar based on it's prefix
  
	// should this cvar be written to the ini

	// should this cvar be sent to the server?

	// 
}

=================================================================================================
DATABASE
=================================================================================================
As my project progresses and as I perhaps start to run into performance problems with my save/load scheme
maybe something like db4o  or this dbfdotnet BTree dBase style project used on codeproject/codeplex  would be good?
http://dbfdotnet.codeplex.com/
hrm, or this
http://www.codeplex.com/fastdbf/

OR NOW there is apparently a .net interface/librarires for MS VFS (virtual file system).  Must test to see if it's faster.

http://www.codeproject.com/KB/directx/BelievablePhysics.aspx

matrix.cpp Invert()
http://nccastaff.bournemouth.ac.uk/jmacey/GraphicsLib/html/_matrix_8cpp-source.html

http://www.nigels.com/glt/doc/matrix4_8cpp-source.html

customers 
     contactinfo (primary mailing info)
     billinginfo
     profiles
     licensed\purchased products 

purchases (contains keys to orders in the orders table)
   customerID orderID

products and skus(bundles of individual products)

orders


----------------------------------------
KERBEROS FORMAT
----------------------------------------
http://tools.ietf.org/html/rfc4120
http://en.wikipedia.org/wiki/Kerberos_(protocol)
http://www.freesoft.org/CIE/RFC/1510/53.htm
http://social.technet.microsoft.com/Forums/en-US/winserversecurity/thread/04ab94c4-f1d0-4176-beba-ef2355fb1cbf/
http://www.example-code.com/csharp/http_kerberos.asp

Ideally id like to make my tickets and authenticators match the layout of kerberos.  This really should be a simple task taking no more than a day.

Indeed, http can use kerberos and smtp and more.



========================================
 Who does what?
 ===================================
One of the first implementation questions that comes up with this project is deciding where which methods should be stored. There are players who interact with items, areas interacting with players, players interacting with classes, items interacting with items, skills interacting with items... its a mess.My initial thought was to organize the methods as belonging to players (this is, as far as I can tell, the standard approach taken by mud implementations thus far). Following in that fine tradition, players would contain all functionality, and items would contain only data about themselves. The implementation would look something like this:

class Player
  attr :name, :objects
  def initialize(name)
    @name = name
    @objects = []
    @body = {"wielded" =&gt; nil, "torso" =&gt; nil}
  end
  def get(item)
    @objects << item
  end
  def wield(item)
    if @objects.index(item) and item.can?("wield")
      @body["wielded"] = item
    else      raise "Cannot wield #item}"
    end
  end
  def wear(item)
    if @objects.index(item) and item.can?("wear")
      wear_location = item.attributes["wear location"]
      @body[wear_location] = item
    else
      raise "Cannot wear #{item}"
    end
  end
end

class Item
  attr_reader :name, :attributes
  def initialize(name)
    @name = name
    @attributes = {"wear" =&gt; true}
  end
  def can?(action)
    @attributes[action]
  end
end

class Weapon < Item
  def initialize(name)
    super(name)
    @attributes["wield"] = true
  end
end

class Armor < Item
  def initialize(name)
    super(name)
    @attributes["wear"] = true
  end
end

class ChestArmor < Armor
  def initialize(name)
    super(name)
    @attributes["wear location"] = "chest"
  end
end

class LegArmor < Armor
  def initialize(name)
    super(name)
    @attributes["wear location"] = "leg"
  end
end

However, as I sat and considered implementing hundreds more methods in that manner, I realized that this was an awfully complex approach. Sure, it was completely intuitive, but it was going to be about as entertaining as rereading Prelude the Foundation a fifth time. As a bonus, it was going to be a real pain to make changes in, because the behaviors and the data the behaviors acted upon were being stored separately.At about this time the anti-object article drifted up into my conscious mind, and I decided that I would consider a different implementation. I decided that the methods that acted upon items ought to be contained by the items themselves: I would see how well things might work out if I moved all the complexity into the items. Here is my implementation using this approach:

class Player
  attr :name, :inventory, :body
  def initialize(name)
    @name = name
    @inventory = []
    @body = {
      "wielded" => nil, 
      "torso" => nil,
      "legs" =>; nil
     }
  end
end

class Item
  attr_reader :name
  def initialize(name)
    @name = name
  end
  def get(actor)
    actor.inventory < self
  end
end

class Weapon < Item
  def wield(actor)
    actor.body["wielded"] = self
  end
end

class ChestArmor < Item
  def wear(actor)
    actor.body["torso"] = self
  end
end

class LegArmor < Item
  def wear(actor)
    actor.body["legs"] = self
  end
end

There are a variety of benefits over the previous implementation: we are now keeping track of whether or not something can be worn/wielded/got and how to wear/wield/get it in the same spot. This means changes only require looking at one section of code, instead of two are required by the earlier implementation. It also allows us to take advantage of polymorphism (ChestArmor and LegArmor respond differently to the method of the same name).In addition, the default item initialization is sufficient for all the subclasses, because all other data about the object will be stored within its methods (nice and Lispy). Not having to chain together a handful of super calls strikes me as a pleasant improvement (Random Question: do you think if you had a sufficiently deep class hierarchy, you could overflow the Ruby stack? I am thinking yes.).I have some concerns about how the second design appears to depend too much upon the implementation of the Player class; the Java programmer in me wants to build a copious API that completely encapsulates the implementation details. My slightly saner half thinks it is cleaner to leave it as it is. If necessary I can alter the implementation by creating a hashmap-like API over whatever datastructure I would replace the @body hashmap with.Although Im not one to consider lines of code as a metric for quality, the second version is 41 lines to the first versions 68 (I am, however, apparently one to have their cake and eat it too). In addition to being shorter, it also strikes me as being simpler and more understandable (no flow control, and no need to explicitly raise any exceptions, well simply use Rubys reflection capabilities to ask item.respond_to?(wield) and have a simple error message we return to the player if the item has no method corresponding to their command).

=================================================================================================
CSG routine
http://builders.reprap.org/2006/08/polygons-and-csg.html
http://reactos.freedoors.org/Reactos%200.3.8/ReactOS-0.3.8-REL-src/dll/win32/glu32/libtess/README


quad edge
http://www.cs.cmu.edu/afs/andrew/scs/cs/15-463/2001/pub/src/a2/quadedge.html

half-edge
http://www.flipcode.com/archives/The_Half-Edge_Data_Structure.shtml

winged edge
http://www.cs.mtu.edu/~shene/COURSES/cs3621/NOTES/model/winged-e.html

need to create an intermediary structure to render the vertices

- the normals are all f'd up when drawing the decohedron

rules:
  - i maintain a list of free edges. 
 - ugh.  check out this maybe for some help. its delauny stuff tho but it's got some added functions i dont have 
http://tog.acm.org/resources/GraphicsGems/gemsiv/delaunay/quadedge.C
http://en.wikipedia.org/wiki/Polygon_mesh
http://www.openmesh.org/index.php?id=214
http://wscg.zcu.cz/wscg2006/Papers_2006/Short/E17-full.pdf
http://tog.acm.org/resources/GraphicsGems/
  - when plotting points, if no edge is formed (you plot 1 vert and then change out the linetool before a second segment is made) then nothing occurs.  I could enforce a rule where I can't add "vertices" but only edges where one or more points of the edge can be existing coords.
  - everytime an edge is added to an unclosed face, an itteration is performed to see if that newest edge closes the current face at which point any remaining "free" edges are 

   	- in fact, i think one vertex is effectively a closed edge with origin and dest the same vert.
		- the only real necessity here is that we need to tie these to our "IndexedFace" and these have to be tracked
                if they are closed or not yes?  I mean for rendering with any real speed, we need to have these IndexedFaces precomputed and not have to itterate through all our quadedge faces which dont maintain a list of verts but instead uses the quadedge info to find them on the fly.  The thing is, the quad edge structure is meant to be used on the fly for drawing... 
Now since we arent using DrawINdexedPrimitive and just DrawPrimitive, that simplifies drawing a lot, however still, we want to be able to properly track GROUPS and FACES.  Potentially we could expand QuadEdge face to include it's list of Verts but seems if our QuadEdge FAce is 1:1 with our list of IndexedFaces, then that's not necessary.  So in fact, the key is to simply make sure that our QuadEdge faces and IndexedFaces remain 1:1 and that we're tracking in our INdexedFace after each edit operation, whether any faces have been closed.  Part of that does\will require that we do intersection tests to determine if a new line segment is bisecting any existing faces so taht they can be split.

- if new stand alone vertex (no origin precedes it, no existing vertex picked) then we must create a new closed vertex edge


http://www.softsurfer.com/Archive/algorithm_0111/algorithm_0111.htm#intersect2D_SegPoly()\
http://tog.acm.org/resources/GraphicsGems/gems/RayPolygon.c


- in sketchup, it seems that they do in fact send a notification to the EditableMesh itself on which vertex, face, edge is to be rendered a certain way such as "selected" and such.  In fact, if i ever plan to render with textures, im going to have to have more flexibility in this regard anyway.

- on the one hand this does simplify some of the post DebugDraw stuff i currently do.  Still not 100% on how it handles the selected face bit.  Seems they apply a transparent texture to that face that has the hashed sort of lines.

- this is gonna require that the current way i handle my vertices with the seperate face breakdowns differently... i should add a rendering path that just uses the quadedge structure alone and to see if it's going to be feasible... unless i can find a proper way to integrate it.  I mean right now i am doing draw primitives using a single call against a linelist i've built up.

Or i should just skip that part and get the manipulation working.  Just put in something temp for vertex selection so i can verify i've got one, then add the code to move the edge/vertex/face with the unprojected mouse position

- yeah, skip that part and lets just get face and edge moving.. then ill do vertex with vertex highlighting drawing three 3 pixel lines colored green

- IMPOSTER SYSTEM BUG - Ah, one other thing about that article...he doesn't seem to take into account screen space vertices that are off the screen in his algorithms, this causes some imposters to blow up and cover the screen.  <-- This quote is from dgreen02 the author of Warbots Online and Urban Empires on gamedev.net.  I have in the past had some issues and maybe that's what it was however I assume now that culling should handle that?  But maybe not if the computed screenspace verts if they are outside of view then somehow that screws up the unproject when creating the 3d coords later in the algo.

- debug to highlight nearest vert
  - debug to highlight adjacent edges

// todo: i think i do need to use ID's otherwise there's just no proper way to communicate
// back to EditableMesh which face or vertex or edge or whatever i need to move.  So
// go back in and make sure IDs work _and_ from now on i wont even worry about id matching index
// there's no point.  I only need to rebase things when i export.  
// HOWEVER, the main problem with ID's is that you have to itterate through the entire list and check id's to find
// the right index.  Maybe this is not such a big deal if itterations can be fast...
// NOTE: Actually if i use Edge, Vertex, Face from the QuadEdge, those are actually classes and could be directly edited...
// without ever having to screw with IDs...
// ARGH: Althought for network editing, ID's would be superior...?  

- load a 2d square .obj
- pick an edge and move it
- pick a vert and move it
- delete an edge - verify in sketchup that this collapses the face and keeps it closed
- delete a vert - verify in sketchup that it collapses the face and keeps it closed and doesnt just leave it open

- plotting verts and creating a new qe structure
- creating new faces
- deleting faces
- bisecting faces
- deleting eddges and merging faces


- plot vertex
- delete vertex

- make edge (no faces yet)
- delete edge (no faces yet)

- make face
- delete face

- bisect face thus making two
- delete shared edge thus merging into one face
    - verify that the two faces are planar

	


todo: when picking, i need to continue and then pick the closest face (potentially) if "CLOSESET" flag is set

todo: when a totally invalid .obj file is loaded, it should fail gracefully and not result in having to restart the app

- normal problem
 - the reason our shading isnt working is because normals arent included in our vertices

we do have a triangle list, but the problem is i think that some triangles have normals that are different for vertices they share this means we need an intermediary vertex list based on unique triangles... this sux but there is no way around it so we need to comute our unique triangles based on vertices that are unique when considering triangles and vertices combined its just intermediary for rendering only... and then for tvm saving too

the answer is our triangle array which already uses indices for both coords and normals and uvs


todo: - add the following note to deckplan spec notes
   - the sketchup file "TDF Ship ARES.skp" is great for showing sort of an overview of the hull generation as well as the entire ship in a exterior mode with translucent skin and all decks visible.  

todo: add the following note about why we need a legit ship builder...
      - looking at the user starships in google sketchup one thing becomes clear, most arent designed to actually "work" using engines, fuel tanks, minimum armor, and certainly not in accordance to any performance statistics.  They just say they work and this is how fast or whatever and that's that.  Our ship builder must be made so that the ships "work" 

todo:
- was pondering how to deal with ConvexHull and whether it should be saved as reference object in the Mesh3d and Actor3d and such. I remembered that PhysicsBody from JigLibX is and must be in EntityBase.  So server side, the physicsBody must have in its save/load in the xml references to what tyep  of collisionskins it needs.  So clearly when creating a physicsBody and attaching it to the EntityBase, it must grab the localcoord version of the ConvexHull. 
  - convexHull must be the one used from JigLibX
  - i must implement the xml save/load in the relevant JigLibX classes
  - 


-1) when paging in a scene initially, there's so much that needs to be paged in, the rendering should be suspended until everything is paged in because otherwise it takes way too long.
0) in universe generation, get the meshes to save/recycle properly using unit sphere mesh or whatever is required.
1) InitScene() in FormMain for when needing to re-create cameras for the primary scene and then assign them to the viewports and assign the controllers


3) we also need to then have Geometry.HullType enums used.  HullType i think is for physics, and perhaps for culling we absolutely need boundingsphere data in our xml and potentially also boundingBox.
4) then we can get our GameServer to run loading just the hull\sphere\box for server side collisions.
5)need to get the pager to create the list of IPageableTVNode resources to be paged in.  We need to sort them and have a way to abort ones for regions that are no longer needed, as well as way to re-sort them on changes in proximity.

- technically there should be no reason why on the server i couldnt technically load the classes for textures and such so long as i never actually try to load the underlying resources.
- Pager - need an alternate Pager for server mode that will load primitives for things but no geometry.
- SceneReader.ReadEntity() - when in server mode, needs to not add underlying TVResources and such...
  needs to skip branches (perhaps with a filter setting) that arent needed since we are using the same .XML level files.  
  - this needs to be considered in the context of how geometry creation on the client is done (ship building\designing)
    as well as how Editor works in localloop.
  
- there's a bug in connectionMaintenance loop in NetServer where CreateBuffer runs out of memory... leak somewhere?
- proper handling of timeouts particulary in gameserver for failed authentication or registration.
- authentication session tracking 
  - could this be useful to maintain a cache?
- dead connections in authentication server seem so fast
- loading of the variables for server startup from xml files
  - these files on the client should be updateable 
  - half life servers i think use a simple xml file that only contains authentication and master server addresses (primary and secondaries)
- logging (security) 
- thread pool for the database connections
- 

Case NetMessageType.Data
	' read first byte and determine the command and have the command deserialize itself
	while (message.Buffer.LengthUnread > 0)
		Dim command As Integer = message.Buffer.ReadInt32()
		CommandProc(command, message)
	end while
	
=================================================				
SMOKE TRAILS
http://www.youtube.com/watch?v=ZXD4N_Mi1iE
Looks badass in this mod

http://www.youtube.com/watch?v=H6gk8GViu4Q

Notice how in the above vids the tactic is always the same... fly up super close and then fire?  WHy?

Because weapon fall off for lasers and particle weapons is too high or too easily intercepted.  If we really want to have long range combat, then weapons need to function much more differently. The big ships must remain stealthy, hidden, the scouts and patrols need to be able to decoy, jam, and provide all the support roles, but they should have very long range intercepting abilities and also rely on stealth and counter measures... but weapon falloff should not be as dramatic as in most games.

Missile Trails
--------------
Periodically record the position of the exhaust in a circular queue. Draw a quad strip from the key frames, but rotate at each pair of verts so it faces the camera. Fade out 

=================================================================================================
SDL, SDL2-CS, SDL2.NET, SDL2#, MonoGame, Mono, MonoDevelop, SharpGL, OpenTK, Tao, TaoClassic 
=================================================================================================
http://stackoverflow.com/questions/15183275/how-to-add-sdl-net-window-to-a-c-sharp-windows-form-application
http://monogame.codeplex.com/discussions/406312
http://stackoverflow.com/questions/6443976/monodevelop-components-docking-tabbed-dockgrouptype-issue
http://mono.1490590.n4.nabble.com/Looking-for-examples-for-MonoDevelop-Components-Docking-td4659349.html
https://github.com/PintaProject/Pinta/tree/master/Pinta/DockLibrary
SDL2#, OpenTK, Tao, TaoClassic, and SharpGL

=================================================================================================
Custom Animation:  Bye bye TV Actor?  We'll see...
=================================================================================================
Havok 6.5 behavior editor has some great ideas  ->  http://www.youtube.com/watch?v=sclYyTiqRrw

(also check out that open source Mount & Blade model & actor viewer i saved somehwere... i forget where offhand but i have it)
http://www.truevision3d.com/forums/printpage.html;topic=18579.0   <- CAL3D + TV3D
Actually after reviewing   E:\dev\c#\XNACal3d
i think its entirely possible to handle this using just TVMesh.
We would handle the skeleton updates for each mesh ourselves and skeleton can be shared with just the matrix states maintained inbetween.

Mesh and Model Format

I decided to go with my own formats because I want to have firm control of what goes into a mesh and a model. Many formats are just too limited and I have no control over them, but with my own I can add or remove things at will. Since I also wrote the export script, anything I can do in Blender I can easily make part of my format and use in the game.

I used Cal3D format for Flora and Fauna, but there were several things I didnt like about it. One, I couldnt easily add to the format. Two, the animation seemed very CPU and memory intensive. I dont think it was implemented efficiently, but also probably because I had to bake the animations, since the per-keyframe animator didnt work. Three, the animation was per-vertex, whereas my animation is per-mesh.

Format structure:

Model is a skeleton and a set of actions.

-Skeleton is a collection of bones and their relative locations. Each bone has a mesh associated with it.

Mesh is a collection of vertices and vertex information (UV coordinates, normals, etc.), faces, and materials. (A material may include texture.)

-Action is a collection of bone keyframes.

Keyframe defines the position of a bone during a certain frame.

Mesh format is very similar to OBJ. I just made some cosmetic changes and added more information (vertex count, etc.) to make it easier to parse.

Model format is standard skeleton animation, except I am not using skinning or anything like that. The reason is: I want to be able to substitute a different mesh in for any other mesh used by a bone. I know this will make the game look less realistic, but that is something I truly dont care about it. Making the game realistic falls pretty low in my list of priorities. Its a lot more important to make the game immersive. I dont believe you need realistic graphics for that.

Mesh Renderer and Animator

I wrote my own mesh renderer. (Woo-hoo, who hasnt?) It could not have been more straightforward. The animator on the other hand took me a day to work out. I had to understand how Blender stores bone parameters, how I can store those into a file, then load them and animate them with minimum effort. I decided to go with simple quaternion animation. Right now the rendering process looks something like this for every bone:

Set the default quaternion rotation. This corresponds to the bone being at rest. It also has a neat effect of changing bones coordinate system, which is necessary for the next step.

Then, for each animation, see if it applies to this bone. If it does, apply the quaternion rotation. The way its stored in the file is in bones local coordinate system. Thats why I had to do the first transformation.

After all is done, translate the bone D units in Y direction, where D is the length of the bone and Y always points along the bone, away from the parent bone. (This means the center of the object always has to coincide with the end of the bone.)

Edit: (The transformations are listed in order they are called in OpenGL. Their application is actually done backwards, so translation is applied first, etc.)

Now, all of this isnt set in stone. I am most likely going to shift a few things here and there, but I think the core structure is laid down pretty well. There was a lot of trial and error setting it up. Quaternion interpolation was especially painful, but I am pretty happy with the result. Now I will have to figure out how I want to handle the animation blending, since several animations can affect the same bone. That shouldnt be too hard







http://www.google.com/imgres?imgurl=http://foodiedani.files.wordpress.com/2006/12/arroz-con-pollo-closeup.jpg&imgrefurl=http://foodiedani.wordpress.com/2006/12/29/arroz-con-pollo/&h=300&w=448&sz=35&tbnid=cHUpxT6XEVJ3dM::&tbnh=85&tbnw=127&prev=/images%3Fq%3Darroz%2Bcon%2Bpollo&usg=__Vh0sMNQf7nqyghtjwuKxDE8T3V0=&ei=tdm6Sa3QJ5LQsAPpjtAw&sa=X&oi=image_result&resnum=6&ct=image&cd=1

paint.net - How to make a nebula star field space background
=========================
menu\effects\noise\add noise

menu\adjustments\invert colors

menu\layers\add new layer

menu\effects\distort\pixelate


=================================================================================================
Blind User support
=================================================================================================
=================================================================================================

http://forum.unity3d.com/threads/32765-Smooth-transition-between-perspective-and-orthographic-modes
using UnityEngine; 
using System.Collections; 

[RequireComponent (typeof(Camera))] 
public class MatrixBlender : MonoBehaviour 
{ 
    public static Matrix4x4 MatrixLerp(Matrix4x4 from, Matrix4x4 to, float time) 
    { 
        Matrix4x4 ret = new Matrix4x4(); 
        for (int i = 0; i < 16; i++) 
            ret[i] = Mathf.Lerp(from[i], to[i], time); 
        return ret; 
    } 

    private IEnumerator LerpFromTo(Matrix4x4 src, Matrix4x4 dest, float duration) 
    { 
        float startTime = Time.time; 
        while (Time.time - startTime < duration) 
        { 
            camera.projectionMatrix = MatrixLerp(src, dest, (Time.time - startTime) / duration); 
            yield return 1; 
        } 
        camera.projectionMatrix = dest; 
    } 

    public Coroutine BlendToMatrix(Matrix4x4 targetMatrix, float duration) 
    { 
        StopAllCoroutines(); 
        return StartCoroutine(LerpFromTo(camera.projectionMatrix, targetMatrix, duration)); 
    } 
}
=================================================================================================

// Infinity Quest for Earth -  Monday, August 30, 2004 journal entry   
----------------------------------
// http://www.gamedev.net/community/forums/mod/journal/journal.asp?jn=263350&cmonth=8&cyear=2004
I finally fixed the impostor bug. The formula i used was wrong, i was not calculating the frustum field of view angle correctly. It was a bit tricky to understand why, but revising my trigonometry helped a bit. For those interesting, the code looks like this: for a viewer position located at ViewPos, the impostored object being represented as its bounding sphere Center, Radius,

float d = distance(ViewPos, Center)
float fov = asin(Radius / d)
float l = d * tan(fov)
matrix4x4 viewMatrix = buildLookAtMatrix(ViewPos, Center)
viewMatrix = buildTranslateMatrix(-ViewPos) * viewMatrix.transpose()
matrix4x4 projMatrix = buildProjectionMatrix(fov, 1, znear, zfar)
matrix4x4 worldMatrix = buildIdentityMatrix()



To render the impostor, set your camera properties to projMatrix (the argument 1.0 is the aspect ratio, it's 1.0 since the impostor texture is square), viewMatrix and worldMatrix and render your object in a texture.

To display the object as a textured quad, use this:

matrix4x4 rotMatrix = buildLookAtMatrix(ViewPos, Center)
vector3d xAxis = vector3d(l, 0, 0) * rotMatrix
vector3d yAxis = vector3d(0, l, 0) * rotMatrix
vector3d vertex0 = -xAxis - yAxis + Center;
vector3d vertex1 = xAxis - yAxis + Center;
vector3d vertex2 = xAxis + yAxis + Center;
vector3d vertex3 = -xAxis + yAxis + Center;


 Welcome to the unofficial channel for the Truevision3d graphics engine!
The quad being defined by (vertex0, vertex1, vertex2, vertex3) with tex coords (0, 0), (1, 0), (1, 1) and (0, 1) respectively.



from InfinteUniverseEngine
----------------------------------
E:\dev\cpp\Samples\InfinteUniverseEngine\iue
JWObject.cpp GetScaledModelMatrix
CDoubleMatrix C3DBase::GetScaledModelMatrix(C3DBase *pCamera)
{
	// This code scales the planet's size and distance to the camera down when it's too far away.
	
	// This solves a problem with many video card drivers where objects too far away aren't rendering properly
	// It also alleviates the Z-buffer precision problem caused by having your near and far clipping planes too far apart.
	static double MAX_DISTANCE=(double)16000000.0;		// Distance to desired far clipping plane
	double MAX_DISCERNABLE;
	static double HALF_MAX=(double)(MAX_DISTANCE*0.5);	// Everything between HALF_MAX and MAX_DISCERNABLE is scaled exponentially between HALF_MAX and MAX_DISTANCE
	CDoubleMatrix m = GetModelMatrix(pCamera);
	CDoubleVector v;
	C3DBase *commonParent = C3DBase::GetCommonParent(this, pCamera);
	v = (GetFullPosition(commonParent) - pCamera->GetFullPosition(commonParent));
	
	double dDistance = v.Magnitude();
	if(dDistance > HALF_MAX)
	{
		// Beyond this distance, everything is rendered at MAX_DISTANCE
		MAX_DISCERNABLE = Max((double)MAX_DISTANCE, (double)(1000*boundingRadius));
		v /= dDistance;
		double dFactor = MAX_DISTANCE;
		if(dDistance < MAX_DISCERNABLE)
			dFactor = (double)(HALF_MAX + HALF_MAX * (1.0 - exp((HALF_MAX - dDistance) / MAX_DISCERNABLE)));
		else
			dDistance = MAX_DISCERNABLE;
		
		v *= dFactor;
		m.f2[3][0] = v.x;
		m.f2[3][1] = v.y;
		m.f2[3][2] = v.z;
		dFactor /= dDistance;
		m.Scale(dFactor, dFactor, dFactor);
	}
	return m;
}

=================================================================================================
=================================================================================================

some pseudo preliminary entity group selection box code by me.  need to work on more
------------------------------------------------------
// entity box selection
const float fardistance = 1000000;
TV_3DVECTOR resultMinNear= new TV_3DVECTOR();
TVMaths.Project2DPointTo3D(mouse2dStartX, mouses2dStartY, 0, ref resultMinNear);
TV_3DVECTOR resultMaxNear= new TV_3DVECTOR();
TVMaths.Project2DPointTo3D(mouse2dEndX, mouse2DEndY, 0, ref resultMaxNear);

// to avoid perspective being applied to our pick ray for the far points, we'll just extend these points straight out
// in the camera direction
TV_3DVECTOR dir = Normalize(camera.Pos - Camera.Look);
TV_3DVECTOR resultMaxFar = resultMaxNear + (farDistance * dir);

TV_3DVECTOR box.Min = resultMinNear;
TV_3DVECTOR box.Max = resultMaxFar;

// if either the min max bounds of your entities are in the selection box, the entity is visible
foreach entity in myentities
    if ((entity.minx > box.MinX) and (entity.minx < box.MaxX) and (entity.miny > box.MinY) and (entity.miny < box.MaxY) and (entity.minz > box.MinZ) and (entity.minz < box.MaxZ)) ||
	((entity.maxx > box.MinX) and (entity.maxx < box.MaxX) and (entity.maxy > box.MinY) and (entity.maxy < box.MaxY) and (entity.maxz > box.MinZ) and (entity.maxz < box.MaxZ))
       return true;
     else
        return false;


--------------------------------------------
// unit rectangle RTS selection box test
If Inp.IsMouseButtonPressed(0) = False Then
                If MouseB1 = True Then
                    Mouse2Coor.x = MouseX
                    Mouse2Coor.y = MouseY

                    Mouse3Coor.x = Mouse1Coor.x
                    Mouse3Coor.y = Mouse2Coor.y
                    Mouse4Coor.x = Mouse2Coor.x
                    Mouse4Coor.y = Mouse1Coor.y
                    MouseB1 = False

                    'select units
                    CollResult = Scene.MousePick(Mouse1Coor.x, Mouse1Coor.y, MTV3D65.CONST_TV_OBJECT_TYPE.TV_OBJECT_LANDSCAPE, CONST_TV_TESTTYPE.TV_TESTTYPE_ACCURATETESTING)
                    Mouse1Coor.x = CollResult.GetCollisionImpact.x
                    Mouse1Coor.y = CollResult.GetCollisionImpact.z
                    CollResult = Scene.MousePick(Mouse2Coor.x, Mouse2Coor.y, MTV3D65.CONST_TV_OBJECT_TYPE.TV_OBJECT_LANDSCAPE, CONST_TV_TESTTYPE.TV_TESTTYPE_ACCURATETESTING)
                    Mouse2Coor.x = CollResult.GetCollisionImpact.x
                    Mouse2Coor.y = CollResult.GetCollisionImpact.z

                    tMouse1Coor = Mouse1Coor
                    tMouse2Coor = Mouse2Coor
                    For u = 0 To MaxUnits
                        'Unit(u).IsSelected = False

                        If Mouse1Coor.x < Mouse2Coor.x And Mouse1Coor.y < Mouse2Coor.y Then
                            tMouse1Coor.y = Mouse2Coor.y
                            tMouse2Coor.y = Mouse1Coor.y
                        ElseIf Mouse1Coor.x < Mouse2Coor.x And Mouse1Coor.y > Mouse2Coor.y Then
                            tMouse1Coor = Mouse1Coor
                            tMouse2Coor = Mouse2Coor
                        ElseIf Mouse1Coor.x > Mouse2Coor.x And Mouse1Coor.y > Mouse2Coor.y Then
                            tMouse1Coor.x = Mouse2Coor.x
                            tMouse2Coor.x = Mouse1Coor.x
                        ElseIf Mouse1Coor.x > Mouse2Coor.x And Mouse1Coor.y < Mouse2Coor.y Then
                            tMouse1Coor = Mouse2Coor
                            tMouse2Coor = Mouse1Coor
                        End If

			// itterate through all items nad perform unit in box test
                        If Unit(u).IsUsed = True And Unit(u).Team = 1 Then
                            If Unit(u).GetPosition.x > tMouse1Coor.x And Unit(u).GetPosition.x < tMouse2Coor.x Then
                                If Unit(u).GetPosition.z < tMouse1Coor.y And Unit(u).GetPosition.z > tMouse2Coor.y Then
                                    Unit(u).IsSelected = True
                                End If
                            End If
                        End If

                    Next
                End If
            End If



JVIPER'S CODE FOR DRAWPRIMITIVES WITH A TVSHADER  from this thread http://www.truevision3d.com/forums/tv3d_sdk_65/tv3d_and_cal3d-t18579.0.html
=============================================
Dim D3DDev as Device      'DirectX Device
Dim D3DVrtBuff As VertexBuffer   'DirectX Vertex Buffer
Dim D3DIndBuff As IndexBuffer    'DirectX Index Buffer
D3DDev = New Device(TVInternalObjects.GetDevice3D)  'Pass DirectX Device Pointer to DirectX Device contructor to retrieve the DirectX Device TV3D is currently using.
                
On Error GoTo NoRender  
D3DDev.TestCooperativeLevel()  'Check whether the DirectX Device has not been lost. Usually if a DirectX Device is lost because the window has bee re-sized. If this is the case, we skip the rendering 
On Error GoTo 0

'Now  we create our DirectX instances of our Vertex and Index buffers
D3DVrtBuff = New VertexBuffer(GetType(Typ), VertexArray.Length, D3DDev, Usage.Dynamic, Vertex.D3DFormat, Pool.Default)
D3DIndBuff = New IndexBuffer(GetType(Integer), IndexArray.Length, D3DDev, Usage.Dynamic, Pool.Default)
D3DVrtBuff.SetData(VertexArray, 0, LockFlags.Discard)
D3DIndBuff.SetData(IndexArray, 0, LockFlags.Discard)

If (Not (D3DIndBuff Is Nothing)) And (Not (D3DVrtBuff Is Nothing)) Then
    D3DDev.Indices = D3DIndBuff
    D3DDev.VertexFormat = VrtFormats 
    D3DDev.SetStreamSource(0, D3DVrtBuff, 0, SizeOf(GetType(Vrt)))
    'Here we passed the size of your Vertex Type in bytes
    'The SizeOf function comes from the System.Runtime.InteropServices.Marshal namespace.

    'Now we are ready to render 
    'Here we can render with DirectX fixed pipeline, or with a shader
    'If you pass a valid shader to this function, it will render with the shader
    If Not (refShader Is Nothing) Then
        '!!!!!!IMPORTANT!!!!!!
        'MAKE SURE YOU UPDATE THE SEMANTICS FOR YOUR SHADER!
        'You'll be using alot of TVShader.SetEffectParam..... functions.
        For pn As Integer = 0 To refShader.GetPassCount - 1
            TVInternalObjects.Shader_Begin(refShader, pn)
            D3DDev.DrawIndexedPrimitives(PrimitiveType.TriangleList, 0, 0, VertexArray.Length, 0, CInt(IndexArray.Length / 3))
            TVInternalObjects.Shader_End(refShader)
        Next pn
    Else
        'Otherwise we'll just render using fixed pipeline
        D3DDev.RenderState.Lighting = True
        D3DDev.RenderState.SpecularEnable = True
        D3DDev.DrawIndexedPrimitives(PrimitiveType.TriangleList, 0, 0, VertexArray.Length, 0, CInt(IndexArray.Length / 3))
    End If
    D3DDev.Indices = Nothing
    D3DDev.SetStreamSource(0, Nothing, 0)
End If

NoRender:
    If Not (D3DVrtBuff Is Nothing) Then D3DVrtBuff.Dispose() : D3DVrtBuff = Nothing
    If Not (D3DIndBuff Is Nothing) Then D3DIndBuff.Dispose() : D3DIndBuff = Nothing
    If Not (D3DDev Is Nothing) Then D3DDev = Nothing


XENOCODE POSTBUILD NATIVE EXE - VIRTUALIZED  March.9.2010  build I GOT THIS WORKING!  --> bin\Obfuscation\xenocodeconfig2.postbuild
-------------------------------------------
Add _ALL_OF_THE_ dlls  from  E:\dev\c#\KeystoneGameBlocks\Editor\bin\Debug  or Release
	- MTV3D65.dll 
	- d3dx9_36.dll
	- ZipForge.dll
	- DevComponents.DotNetBar2.dll
	VorbisDotNet.dll
	- Settings.dll <-- this one im not sure about.  I copied and pasted a non xenocoded one after the fact because i thought maybe it was bitching about 
	- JibLibX.dll
	- Lidgren.Network.dll
	- MHull.dll  (no StanHull.lib since that is compiled in MHull.dll i think - althoug i havent run any code that tests MHull in this native exe)
		
the following if not added to the virtual file system, must be included in the install directory (thats why they should be added to the virtual file system)
C:\Program Files\Microsoft XNA\XNA Game Studio\v3.0\References\Windows\x86\Microsoft.Xna.Framework.dll
C:\WINDOWS\Microsoft.NET\DirectX for Managed Code\1.0.2911.0\Microsoft.DirectX.Direct3DX.dll
C:\WINDOWS\Microsoft.NET\DirectX for Managed Code\1.0.2902.0\Microsoft.DirectX.Direct3D.dll
C:\WINDOWS\Microsoft.NET\DirectX for Managed Code\1.0.2902.0\Microsoft.DirectX.DirectInput.dll
C:\WINDOWS\Microsoft.NET\DirectX for Managed Code\1.0.2902.0\Microsoft.DirectX.DirectSound.dll
C:\WINDOWS\Microsoft.NET\DirectX for Managed Code\1.0.2902.0\Microsoft.DirectX.dll



EXCEPT you do not need the KeyEdit.vhost.exe  obviously.


------------------------------------

Cal3d loader used by jmonkeyengine.com is 

<model>
  <skeleton>data/cal3d/cally/cally.csf</skeleton>
  <mesh>data/cal3d/cally/cally_chest.cmf</mesh>
  <skin></skin>
  <material>data/cal3d/cally/cally_chest.crf</material>
  <meshes>
      <submesh>
          <mesh>data/cal3d/cally/cally_calf_left.cmf</mesh>
          <skin></skin>
          <material>data/cal3d/cally/cally_skin.crf</material>
          <visible>true</visible>
      </submesh>
      <submesh>
          <mesh>data/cal3d/cally/cally_calf_right.cmf</mesh>
          <skin></skin>
          <material>data/cal3d/cally/cally_skin.crf</material>
          <visible>true</visible>
      </submesh>
      <submesh>
          <mesh>data/cal3d/cally/cally_foot_left.cmf</mesh>
          <material>data/cal3d/cally/cally_skin.crf</material>
          <skin></skin>
          <visible>true</visible>
      </submesh>
      <submesh>
          <mesh>data/cal3d/cally/cally_foot_right.cmf</mesh>
          <material>data/cal3d/cally/cally_skin.crf</material>
          <skin></skin>
          <visible>true</visible>
      </submesh>
      <submesh>
          <mesh>data/cal3d/cally/cally_hand_left.cmf</mesh>
          <material>data/cal3d/cally/cally_skin.crf</material>
          <skin></skin>
          <visible>true</visible>
      </submesh>
      <submesh>
          <mesh>data/cal3d/cally/cally_hand_right.cmf</mesh>
          <material>data/cal3d/cally/cally_skin.crf</material>
          <skin></skin>
          <visible>true</visible>
      </submesh>
      <submesh>
          <mesh>data/cal3d/cally/cally_head.cmf</mesh>
          <material>data/cal3d/cally/cally_skin.crf</material>
          <skin></skin>
          <visible>true</visible>
      </submesh>
      <submesh>
          <mesh>data/cal3d/cally/cally_lowerarm_left.cmf</mesh>
          <material>data/cal3d/cally/cally_skin.crf</material>
          <skin></skin>
          <visible>true</visible>
      </submesh>
      <submesh>
          <mesh>data/cal3d/cally/cally_lowerarm_right.cmf</mesh>
          <material>data/cal3d/cally/cally_skin.crf</material>
          <skin></skin>
          <visible>true</visible>
      </submesh>
      <submesh>
          <mesh>data/cal3d/cally/cally_neck.cmf</mesh>
          <material>data/cal3d/cally/cally_skin.crf</material>
          <skin></skin>
          <visible>true</visible>
      </submesh>
      <submesh>
          <mesh>data/cal3d/cally/cally_pelvis.cmf</mesh>
          <material>data/cal3d/cally/cally_pelvis.crf</material>
          <skin></skin>
          <visible>true</visible>
      </submesh>
      <submesh>
          <mesh>data/cal3d/cally/cally_ponytail.cmf</mesh>
          <material>data/cal3d/cally/cally_ponytail.crf</material>
          <skin></skin>
          <visible>true</visible>
      </submesh>
      <submesh>
          <mesh>data/cal3d/cally/cally_thigh_left.cmf</mesh>
          <material>data/cal3d/cally/cally_skin.crf</material>
          <skin></skin>
          <visible>true</visible>
      </submesh>
      <submesh>
          <mesh>data/cal3d/cally/cally_thigh_right.cmf</mesh>
          <material>data/cal3d/cally/cally_skin.crf</material>
          <skin></skin>
          <visible>true</visible>
      </submesh>
      <submesh>
          <mesh>data/cal3d/cally/cally_upperarm_left.cmf</mesh>
          <material>data/cal3d/cally/cally_skin.crf</material>
          <skin></skin>
          <visible>true</visible>
      </submesh>
      <submesh>
          <mesh>data/cal3d/cally/cally_upperarm_right.cmf</mesh>
          <material>data/cal3d/cally/cally_skin.crf</material>
          <skin></skin>
          <visible>true</visible>
      </submesh>
  </meshes>
  <animations>
    <anim>
      <name>walk</name>
      <anim>data/cal3d/cally/cally_walk.caf</anim>
    </anim>
    <anim>
      <name>strut</name>
      <anim>data/cal3d/cally/cally_strut.caf</anim>
    </anim>
    <anim>
      <name>kick</name>
      <anim>data/cal3d/cally/cally_tornado_kick.caf</anim>
    </anim>
    <anim>
      <name>jog</name>
      <anim>data/cal3d/cally/cally_jog.caf</anim>
    </anim>
    <anim>
      <name>idle</name>
      <anim>data/cal3d/cally/cally_idle.caf</anim>
    </anim>
  </animations>
</model>


=================================================================================================
reality engine features (bought by Epic for Unreal 3)
Author  	Artificial Studios  	 	
Graphics API 	DirectX 	Operating Systems 	Windows, Xbox
Programming Language 	C/C++ 	Status 	Inactive
Documentation 	Yes 		
Features 	
	General Features 	Object-Oriented Design, Plug-in Architecture, Save/Load System, Other:
 	Standardized high-quality OO C++ with heavy inline documentation. Full Game Implementation source included.
	Scripting 	
 	Full integration with .NET scripting languages, allowing programmers and artists to write fully debuggable, IDE-integrated code in your favourite language, from C#, C++/CLI, to VB.NET without the need for a compiler
 	Cross-platform support through Mono Compiler
 	Python support, as an alternative or addition to .NET support, ensuring maximum choice and compatibility
 	Core engine is fully standardized object-oriented C++ with an extremely high level of inline documentation
 	Full compatibility with Xbox, Xbox2, and modular rendering and OS components allow for support of other consoles such as PS3
	Built-in Editors 	
 	No compile times. Click "Play" to instantly switch between edit mode and in-game action!
 	Visual placement and editing of gameplay objects such as players, NPC's, inventory items, AI path nodes, and light sources -- with a full realtime view of their appearance, including 100% dynamic shadowing. Includes a data-driven property editing framework, allowing level designers to easily customize any game object, and programmers to expose new customizable properties to designers via script.
 	Fully-featured GUI Designer that allows you to assemble menus visually (including Tab-pages) exactly as they appear in-game.
	Physics 	Basic Physics, Collision Detection, Rigid Body, Vehicle Physics:
 	Use of NovodeX FX multi-scene management to take advantage of the upcoming Ageia PPU (Physics Processing Unit).
 	Ragdoll character animation, allowing you to mix physics with animations for dynamic effects such as character damage.
 	Integrated physics editing inside of Reality Builder, supporting creation of optimized collision primitives for models and skeletal animated meshes; constraint editing; and interactive physics simulation and tweaking in-editor.
 	Fully integrated support for physics-based vehicles, including player control, AI, and networking.
 	Volumetric "physics zones" allow differentiation of constants like inertial damping, for instance objects accelerate slower in water
	Lighting 	Per-vertex, Per-pixel, Volumetric, Lightmapping, Radiosity, Gloss maps, Anisotropic:
 	Per-Pixel Lighting and shading with support for PS3.0, PS2.X, PS2.0 and PS1.1.
 	Precomputed Radiance Transfer (aka "Realtime Radiosity") support, allowing for Real-Time Subsurface Scattering and Soft Shadowing.
 	Unified dynamic world lighting and shadowing, including day/night cycles. Heavily optimized for maximum performance in huge, complex scenes.
	Shadows 	Shadow Mapping, Shadow Volume:
 	Real-Time Subsurface Scattering and Soft Shadowing and using Spherical Harmonics and Precomputed Radiance Transfer
 	Shadow & masked-light map projectors, and soft drop-shadows
	Texturing 	Basic, Multi-texturing, Bumpmapping, Mipmapping, Projected:
 	Total integration with popular commercial editors allows artists to create environments, view & configure shaders and lighting, and implement powerful Python-driven scripts directly from their native environment.
	Shaders 	Vertex, Pixel, High Level:
 	Support for PS3.0, PS2.X, PS2.0 and PS1.1. Shading includes dynamic projection mapping, normal mapping, Phong specularity, per-pixel reflection mapping, refractions, virtual displacement (parallax) mapping, animated textures, mix/detail shaders, fabric, anisotropic scattering, water, and other configurable pixel & vertex shaders.
	Scene Management 	General, Occlusion Culling, LOD:
 	Open-ended world structure places no limits on environmental design, with full artist-driven and procedural Level-Of-Detail support.
 	Per-pixel Occlusion Culling. Occlusion is automatic, fast, and accurate to the pixel.
 	Integration with popular 3D editors (Max, Maya) allows artists to create environments, view & configure shaders and lighting with realtime viewport feedback, and implement powerful Python-driven or C#-driven scripts.
 	Reload Scripts on the fly to see your changes without having to restart the application
	Animation 	Keyframe Animation, Skeletal Animation, Animation Blending:
 	Character Normal Mapping, Spherical Harmonics, Rag Doll Physics, skeleton-based multi-weighted.
 	Seamless transitioning between physics & keyframe animation. Physics-based character bone influences also allow for procedural animation
	Meshes 	Mesh Loading, Skinning, Progressive:
 	Character Normal Mapping & Spherical Harmonics, with skeleton-based, multi-weighted-bone vertex shader animation.
 	Characters can contain any number of arbritrary pixel & vertex shaders on multiple materials
 	Export tools for 3D Studio Max, Maya for bringing weighted meshes, skeletons, and animation sequences into the engine.
 	Precomputed Radiance Transfer data & lightmaps automatically mapped to Level-Of-Detail meshes.
 	Instance any mesh for efficient batch-rendering.
 	Optionally Bake or Instance PRT to save memory.
	Special Effects 	Environment Mapping, Lens Flares, Billboarding, Particle System, Depth of Field, Motion Blur, Sky, Water, Fire, Fog, Weather, Mirror:
 	Image Post-Processing (stackable) including Depth of Field, Night Vision, Motion Blur, Light Blooms, Volumetric Lighting, and non-photorealistic rendering.
 	Water system with procedural waves, per-vertex and per-pixel refraction and reflection of the surrounding World
 	Arbritrary Render Target on-demand usage
 	FX-system manager with automatic render-batching, optional z-sorting, & vertex & pixel shader-driven systems
	Networking System 	Client-Server:
 	Optimized Client/Server-Authoritative networking incorporating latency prediction & adaptive data degradation
 	Includes Voice Communication.
 	Platform-independent networking component to power Linux or MacOS dedicated servers.
 	Networked game state allows multiple users to connect to a design server and make changes to the game world using the full power of Reality Builder.
 	Allows truly simultaneous workflow - anyone can log in and spectate, design or play.
 	Server doubles as a CVS - synchronizes all prefabs and game assets contained in the level upon connection.
 	Replaces need for CMS tools such as AlienBrain
 	Integrated voice chat
 	Distributed lighting calculations - users can calculate PRT data on their own machines and update the server upon completion.
	Sound & Video 	2D Sound, 3D Sound, Streaming Sound:
 	Environmental Audio with EAX and 5.1 Surround.
 	Ogg Vorbis sound streams
 	Videos can be used as any texture, in any shader
	Artificial Intelligence 	Pathfinding, Decision Making, Scripted:
 	Intelligent pathfinding, both predetermined and dynamic with obstacle avoidance
 	Decision-making based on adaptive state machines.
 	Reactions to stimuli such as sight and sound
 	Completely written in Reality Script, easy to extend to any custom behaviors
 	AI can be run on the Server, with the Events replicated to Clients
	Rendering 	Fixed-function, Render-to-Texture, Fonts, GUI:
 	Built with DirectX 9.0 from ground-up to take full advantage of cutting edge technology developments, while fully scalable to DirectX7/8 generation hardware.
 	High-Dynamic Range Rendering Using Floating-Point buffers, allowing for Tone Mapping, Exposure Adaption, and Blue Shift, for camera/eye perceptual rendering.
 	Powerful fully "What You See Is What You Get" Scene Editor running on Reality.
 	Includes material library, entity library, shader configuration, physics setup, entity setup, rendering setup, sky configuration, redundancy-filtered PRT lighting compiler, all with realtime visualization as lights and meshes are moved around the scene.
 	Advanced mesh-instancing capability to cut down on scene memory and rendering overhead
